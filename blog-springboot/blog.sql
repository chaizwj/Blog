/*
 Navicat Premium Data Transfer

 Source Server         : mysql
 Source Server Type    : MySQL
 Source Server Version : 80022
 Source Host           : localhost:3306
 Source Schema         : blog

 Target Server Type    : MySQL
 Target Server Version : 80022
 File Encoding         : 65001

 Date: 10/02/2023 13:32:30
*/

SET NAMES utf8mb4;
SET FOREIGN_KEY_CHECKS = 0;

-- ----------------------------
-- Table structure for blog
-- ----------------------------
DROP TABLE IF EXISTS `blog`;
CREATE TABLE `blog`  (
  `blogid` bigint(0) NOT NULL AUTO_INCREMENT COMMENT '博客id',
  `title` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '标题',
  `uid` bigint(0) NULL DEFAULT 1,
  `content` longtext CHARACTER SET utf8 COLLATE utf8_general_ci NULL COMMENT '内容',
  `createTime` timestamp(0) NULL DEFAULT CURRENT_TIMESTAMP(0) COMMENT '创建时间',
  `firstpicture` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT '' COMMENT '首图',
  `thumbs` int(0) NULL DEFAULT 0 COMMENT '点赞数',
  `published` tinyint(1) NULL DEFAULT 0 COMMENT '发布状态',
  `recommend` tinyint(1) NULL DEFAULT 1 COMMENT '推荐状态 ，默认是1  直接被推荐到首页',
  `shareStatement` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '版权状态',
  `views` int(0) NULL DEFAULT 0 COMMENT '浏览次数',
  `typeid` bigint(0) NULL DEFAULT NULL,
  `description` longtext CHARACTER SET utf8 COLLATE utf8_general_ci NULL,
  `commentabled` tinyint(1) NULL DEFAULT 1 COMMENT '评论状态.默认是1 可以评论',
  PRIMARY KEY (`blogid`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of blog
-- ----------------------------
INSERT INTO `blog` VALUES (4, '单链表逆序方法', 1, '<p> 最近做了几道leetcode，发现自己还是没有形成知识体系，因此决定把所学的做个积累。这篇文章主要讲的是<strong>单链表逆序的两种方法</strong>：<strong>头插法与递归</strong>。（目前只想到两种，持续更新）</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200821184809352.png#pic_center\" alt=\"在这里插入图片描述\" /><strong>带头结点的单链表</strong></p>\n<h3 id=\"一头插法\">一、头插法</h3>\n<p> 头插法，顾名思义就是从链表的头部插入。当我们要把该链表顺序逆序成head-&gt;4-&gt;3-&gt;2-&gt;1时（头结点不用），显然我们需要两个指针cur（指向要插入的结点），next（指向cur的下一个结点）。</p>\n<p> 在此，我用了一个辅助的头结点reverseHead便于操作，cur首先指向的是值为1的结点，next指向的是2。这时，把cur指向的结点放在reversehead后，再让cur=next，继续放下一个结点...以此类推，<strong>后面的结点都放在了reverseHead的最前面</strong>，即实现了逆序。</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200821191759293.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0RsaWhjdGNlZnJlcA==,size_16,color_FFFFFF,t_70#pic_center\" alt=\"在这里插入图片描述\" />\n<strong>上面展示的是第一个结点的情况，画的有点丑，不过应该能看懂。。</strong></p>\n<pre><code class=\"language-java\">public static void reverseList(Node head) {\n        //如果当前链表为空，或者只有一个节点，无需反转，直接返回\n        if(head.next == null || head.next.next == null) {\n            return ;\n        }\n<pre><code>    //定义一个辅助的指针(变量)，帮助我们遍历原来的链表\n    Node cur = head.next;\n    Node next = null;// 指向当前节点[cur]的下一个节点\n    Node reverseHead = new Node(0);\n    //遍历原来的链表，每遍历一个节点，就将其取出，并放在新的链表reverseHead 的最前端\n<pre><code>while(cur != null) {\n    next = cur.next;//先暂时保存当前节点的下一个节点，因为后面需要使用\n    cur.next = reverseHead.next;//将cur的下一个节点指向新的链表的最前端\n    reverseHead.next = cur; //将cur 连接到新的链表上\n    cur = next;//让cur后移\n}\n//将head.next 指向 reverseHead.next , 实现单链表的反转\nhead.next = reverseHead.next;\n</code></pre>\n<p>}\n</code></pre></p>\n<p></code></pre></p>\n<h3 id=\"二递归法\">二、递归法</h3>\n<p> </p>\n<p><img src=\"https://img-blog.csdnimg.cn/202008211939004.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0RsaWhjdGNlZnJlcA==,size_16,color_FFFFFF,t_70#pic_center\" alt=\"在这里插入图片描述\" />\n接着，又回溯到上一个递归中去，即head指向的值为2，以此类推。</p>\n<pre><code class=\"language-java\">    public HeroNode reverseList(Node head){\n        if (head == null || head.next == null) {\n            return head;\n        }\n        // 找到原来链表的最后一个结点，即为逆序后链表的第一个结点\n        Node reverseHead = reverseList(head.next);       \n<pre><code>    Node temp  = head.next;\n    // 实现一个结点的逆序\n    temp.next = head;\n    head.next = null;\n    // 返回逆袭后链表的头结点\n    return reverseHead;\n}\n</code></pre>\n<p></code></pre></p>\n', '2020-03-01 14:08:00', 'https://unsplash.it/800/450?image=106', 126, 0, 1, '原创', 137, 2, '大家一起来看看吧！123123213123', 1);
INSERT INTO `blog` VALUES (5, 'elasticSearch安装', 16, '<p><img src=\"https://img-blog.csdnimg.cn/20210118213724387.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0RsaWhjdGNlZnJlcA==,size_16,color_FFFFFF,t_70\" alt=\"异常信息\" />\n  elasticSearch在安装完ik分词器插件启动后的报错异常信息如上↑，根据命令行信息可知，应该是es的权限不足，因此配置一下即可。\n  找到jdk安装位置，<img src=\"https://img-blog.csdnimg.cn/20210118214043428.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0RsaWhjdGNlZnJlcA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\" />\n  E:\\study file\\jdk1.8.0_221\\jre\\lib\\security（本机目录，自行替换即可），打开jre目录下的java.policy文件，在grant{ };中加入一行即可，permission java.security.AllPermission;\n  此外，要记得es存放位置的文件夹名不能有空格，否则也会被报io异常\n<img src=\"https://img-blog.csdnimg.cn/20210118214242845.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0RsaWhjdGNlZnJlcA==,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\" /></p>\n', '2020-11-28 11:12:00', 'https://unsplash.it/800/450?image=353', 76, 0, 0, '原创', 46, 2, '大家不会的话可以来参考这个', 1);
INSERT INTO `blog` VALUES (123, 'sql注入如何解决', 1, '<p>123123123</p>\n', '2021-12-23 18:13:00', 'https://unsplash.it/800/450?image=1000', 53, 0, 1, '原创', 78, 2, '123123123213', 1);
INSERT INTO `blog` VALUES (123123124, '梅西为什么是球王', 16, '<h4 id=\"使用-markdown-编辑器来开始书写你的博客吧已经支持markdown编辑器上传图片的功能123123132\">使用 markdown 编辑器来开始书写你的博客吧! 已经支持markdown编辑器上传图片的功能123123132</h4>\n', '2021-12-23 18:18:00', 'https://unsplash.it/800/450?image=1005', 35, 0, 0, '转载', 90, 22, '123123123123123123', 1);
INSERT INTO `blog` VALUES (123123135, '运动的好处', 1, '#### 使用 markdown 编辑器来开始书写你的博客吧!&emsp;已经支持markdown编辑器上传图片的功能', '2023-01-14 20:26:00', 'https://unsplash.it/800/450?image=1005', 10, 0, 1, '原创', 12, 22, '23213123123123123123', 1);
INSERT INTO `blog` VALUES (123123136, '上海美食', 17, '<h4 id=\"使用-markdown-编辑器来开始书写你的博客吧已经支持markdown编辑器上传图片的功能\">使用 markdown 编辑器来开始书写你的博客吧! 已经支持markdown编辑器上传图片的功能</h4>\n', '2023-01-22 23:32:00', 'https://unsplash.it/800/450?image=1010', 15, 0, 1, '原创', 134, 23, '111116666666', 1);
INSERT INTO `blog` VALUES (123123153, '121111111', 1, '<p>666688888888</p>\n', '2023-01-26 22:57:00', 'https://unsplash.it/800/450?image=1009', 0, 0, 1, '转载', 1, 2, '679iu个国家和个股机会给', 1);

-- ----------------------------
-- Table structure for comment
-- ----------------------------
DROP TABLE IF EXISTS `comment`;
CREATE TABLE `comment`  (
  `commentid` bigint(0) NOT NULL AUTO_INCREMENT,
  `uid` bigint(0) NULL DEFAULT NULL,
  `content` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '评论内容',
  `create_time` timestamp(0) NOT NULL DEFAULT CURRENT_TIMESTAMP(0) ON UPDATE CURRENT_TIMESTAMP(0) COMMENT '创建时间',
  `blogid` bigint(0) NULL DEFAULT NULL,
  `reply_commentid` int(0) NULL DEFAULT NULL,
  `reply_uid` int(0) NULL DEFAULT NULL,
  `root` bigint(0) NULL DEFAULT NULL,
  `reply_username` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  PRIMARY KEY (`commentid`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 191 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of comment
-- ----------------------------
INSERT INTO `comment` VALUES (38, 16, '嘿嘿', '2023-01-12 09:39:12', 4, NULL, NULL, 1, NULL);
INSERT INTO `comment` VALUES (39, 1, '哈哈啊哈哈啊哈', '2023-01-11 22:19:07', 4, NULL, NULL, 1, NULL);
INSERT INTO `comment` VALUES (119, 16, '12321', '2023-01-12 10:22:13', 4, 0, 0, 1, NULL);
INSERT INTO `comment` VALUES (162, 16, '6666', '2023-01-12 11:13:10', 4, 38, 16, 0, NULL);
INSERT INTO `comment` VALUES (163, 16, '6666', '2023-01-12 11:14:57', 4, 38, 16, 0, 'bbb');
INSERT INTO `comment` VALUES (164, 16, '7777', '2023-01-12 11:15:12', 4, 39, 1, 0, 'aaa');
INSERT INTO `comment` VALUES (165, 16, '888', '2023-01-12 11:15:22', 4, 39, 16, 0, 'bbb');
INSERT INTO `comment` VALUES (166, 16, '999', '2023-01-12 11:23:58', 4, 39, 16, 0, 'bbb');
INSERT INTO `comment` VALUES (167, 16, '1000000', '2023-01-12 11:24:55', 4, 39, 16, 0, 'bbb');
INSERT INTO `comment` VALUES (168, 16, '111', '2023-01-12 11:31:52', 4, 39, 16, 0, 'bbb');
INSERT INTO `comment` VALUES (169, 1, '123？', '2023-01-12 11:32:17', 4, 119, 16, 0, 'bbb');
INSERT INTO `comment` VALUES (170, 1, '123？', '2023-01-12 11:32:22', 4, 39, 1, 0, 'aaa');
INSERT INTO `comment` VALUES (171, 1, '111', '2023-01-12 11:32:27', 4, 39, 16, 0, 'bbb');
INSERT INTO `comment` VALUES (172, 1, '对213213', '2023-01-12 15:47:14', 4, 119, 1, 0, 'aaa');
INSERT INTO `comment` VALUES (175, 1, '666', '2023-01-12 21:40:27', 4, 38, 16, 0, 'bbb');
INSERT INTO `comment` VALUES (176, 1, '000', '2023-01-12 21:40:36', 4, 38, 1, 0, 'aaa');
INSERT INTO `comment` VALUES (177, 1, '21312321', '2023-01-14 20:27:47', 123, 0, 0, 1, '');
INSERT INTO `comment` VALUES (178, 1, '6666', '2023-01-14 20:27:52', 123, 177, 1, 0, 'aaa');
INSERT INTO `comment` VALUES (179, 16, '牛的', '2023-01-14 20:28:26', 123, 177, 1, 0, 'aaa');
INSERT INTO `comment` VALUES (180, 1, '666的啊', '2023-01-25 20:54:36', 4, 119, 16, 0, 'bbb');
INSERT INTO `comment` VALUES (181, 1, '哈哈', '2023-01-25 20:54:41', 4, 119, 1, 0, 'aaa');
INSERT INTO `comment` VALUES (182, 18, '123123', '2023-01-25 20:58:53', 123123124, 0, 0, 1, '');
INSERT INTO `comment` VALUES (183, 1, '*', '2023-01-25 22:02:29', 4, 0, 0, 1, '');
INSERT INTO `comment` VALUES (184, 1, '****', '2023-01-25 22:02:41', 4, 0, 0, 1, '');
INSERT INTO `comment` VALUES (185, 1, '我真的是*了啊', '2023-01-25 22:03:01', 4, 0, 0, 1, '');
INSERT INTO `comment` VALUES (186, 1, '6', '2023-01-30 20:36:35', 4, 185, 1, 0, 'aaa');
INSERT INTO `comment` VALUES (187, 1, '好的呢', '2023-01-30 20:36:58', 4, 119, 16, 0, 'bbb');
INSERT INTO `comment` VALUES (188, 1, '。', '2023-01-30 20:37:09', 4, 185, 1, 0, 'aaa');
INSERT INTO `comment` VALUES (189, 1, '1111', '2023-01-30 20:37:14', 4, 119, 1, 0, 'aaa');
INSERT INTO `comment` VALUES (190, 1, '6', '2023-01-30 21:10:24', 4, 185, 1, 0, 'aaa');
INSERT INTO `comment` VALUES (191, 1, '7', '2023-01-30 21:10:31', 4, 119, 1, 0, 'aaa');

-- ----------------------------
-- Table structure for crawlerblog
-- ----------------------------
DROP TABLE IF EXISTS `crawlerblog`;
CREATE TABLE `crawlerblog`  (
  `blogid` bigint(0) NOT NULL AUTO_INCREMENT COMMENT '博客id',
  `title` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '标题',
  `username` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `content` longtext CHARACTER SET utf8 COLLATE utf8_general_ci NULL COMMENT '内容',
  `avatar` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT '0' COMMENT '发布状态',
  `views` int(0) NULL DEFAULT 0 COMMENT '浏览次数',
  PRIMARY KEY (`blogid`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 123124036 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of crawlerblog
-- ----------------------------
INSERT INTO `crawlerblog` VALUES (123124003, '网易二面：CPU狂飙900%，该怎么处理？', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <h2><a id=\"_2\"></a>说在前面</h2> \n <p>社群一位小伙伴面试了 网易，遇到了一个 性能类的面试题：</p> \n <h2><a id=\"CPU900_7\"></a>CPU飙升900%，该怎么处理？</h2> \n <p>可惜的是，以上的问题，这个小伙没有回答理想。</p> \n <p><strong>最终，导致他网易之路，终止在二面，非常可惜</strong></p> \n <p>现在把这个 题目，以及参考答案，收入咱们的</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124790425\">尼恩Java面试宝典 PDF</a>》<br> ，供后面的小伙伴参考，前车之鉴啊</p> \n <h3><a id=\"CPU200__18\"></a>首先，说明一下问题：CPU飙升200% 以上是生产容易发生的场景</h3> \n <blockquote> \n  <p>注：本文以 PDF 持续更新，最新尼恩 架构笔记、面试题 的PDF文件，请从这里获取：<a href=\"https://gitee.com/crazymaker/SimpleCrayIM/blob/master/%E7%96%AF%E7%8B%82%E5%88%9B%E5%AE%A2%E5%9C%88%E6%80%BB%E7%9B%AE%E5%BD%95.md\">码云</a></p> \n </blockquote> \n <hr> \n <h4><a id=\"1MySQL900_25\"></a>场景:1：MySQL进程飙升900%</h4> \n <p>大家在使用MySQL过程，想必都有遇到过CPU突然过高，或者达到200%以上的情况。</p> \n <p>数据库执行查询或数据修改操作时，系统需要消耗大量的CPU资源维护从存储系统、内存数据中的一致性。</p> \n <p>并发量大并且大量SQL性能低的情况下，比如字段是没有建立索引，则会导致快速CPU飙升，如果还开启了慢日志记录，会导致性能更加恶化。生产上有MYSQL 飙升900% 的恶劣情况。</p> \n <h4><a id=\"2Java900_33\"></a>场景2：Java进程飙升900%</h4> \n <p>一般来说Java 进程不做大量 CPU 运算，正常情况下，CPU 应该在 100~200% 之间，</p> \n <p>但是，一旦高并发场景，要么走到了死循环，要么就是在做大量的 GC, 容易出现这种 CPU 飙升的情况，CPU飙升900%，是完全有可能的。</p> \n <h4><a id=\"900_39\"></a>其他场景：其他的类似进程飙升900%的场景</h4> \n <p>比如Redis、Nginx等等。</p> \n <p><em>尼恩提示：大家介绍场景的时候，就说自己主要涉及了两个场景， Java进程飙升900%、MySQL进程飙升900%两种场景，其实，这两个场景就足够讲半天了， 其他的，使用规避技巧规避一下就行。</em></p> \n <h3><a id=\"MySQLCPU900_45\"></a>场景一：MySQL进程CPU飙升到900%，怎么处理？</h3> \n <hr> \n <p><strong>定位过程：</strong></p> \n <ul>\n  <li>使用top 命令观察，确定是mysqld导致还是其他原因。</li>\n  <li>如果是mysqld导致的，show processlist，查看session情况，确定是不是有消耗资源的sql在运行。</li>\n  <li>找出消耗高的 sql，看看执行计划是否准确， index 是否缺失，或者实在是数据量太大造成。</li>\n </ul> \n <p><strong>处理过程：</strong></p> \n <ul>\n  <li>kill 掉这些线程(同时观察 cpu 使用率是否下降)， 一般来说，肯定要 kill 掉这些线程(同时观察 cpu 使用率是否下降)，等进行相应的调整(比如说加索引、改 sql、改内存参数)之后，再重新跑这些 SQL。</li>\n  <li>进行相应的调整(比如说加索引、改 sql、改内存参数)<br> index 是否缺失，如果是，则 建立索引。也有可能是每个 sql 消耗资源并不多，但是突然之间，有大量的 session 连进来导致 cpu 飙升，这种情况就需要跟应用一起来分析为何连接数会激增，再做出相应的调整，比如说限制连接数等</li>\n  <li>优化的过程，往往不是一步完成的，而是一步一步，执行一项优化措辞，再观察，再优化。</li>\n </ul> \n <h2><a id=\"1MySQL_62\"></a>场景1的真实案例：MySQL数据库优化的真实案例</h2> \n <p><em>尼恩提示：以下案例，来自互联网。大家参考一下，准备一个自己的案例。</em></p> \n <p>本问题亲身经历过。</p> \n <p>之前开发同事编写的SQL语句，就导致过线上CPU过高，MySQL的CPU使用率达到900%+，通过优化最后降低到70%~80%。下面说说个人在这个过程中的排查思路。</p> \n <p>首先，我们要对问题定位而不是盲目的开启什么 慢日志，在并发量大并且大量SQL性能低的情况下，开启慢日志无意是将MySQL推向崩溃的边缘。</p> \n <p>当时遇到这个情况，分析了当前的数据量、索引情况、缓存使用情况。目测数据量不大，也就几百万条而已。接下来就去定位索引、缓存问题。</p> \n <ol>\n  <li>经过询问，发现很多查询都是走MySQL，没有用到缓存。</li>\n  <li>既然没有用到缓存，则是大量请求全部查询MySQL导致。通过下面的命令查看:</li>\n </ol> \n <pre><code class=\"prism language-sql\"><span class=\"token keyword\">show</span> processlist<span class=\"token punctuation\">;</span>\n</code></pre> \n <p>发现类似很多相同的SQL语句，一直处于query状态中。</p> \n <pre><code class=\"prism language-sql\"><span class=\"token keyword\">select</span> id form <span class=\"token keyword\">user</span> <span class=\"token keyword\">where</span> user_code <span class=\"token operator\">=</span> <span class=\"token string\">\'xxxxx\'</span><span class=\"token punctuation\">;</span>\n</code></pre> \n <p>初步分析可能是 user_code 字段没有索引导致。接着查询user表的索引情况：</p> \n <pre><code class=\"prism language-sql\"><span class=\"token keyword\">show</span> <span class=\"token keyword\">index</span> form <span class=\"token keyword\">user</span><span class=\"token punctuation\">;</span>\n</code></pre> \n <p>发现这个字段是没有建立索引。增加索引之后，该条SQL查询能够正常执行。</p> \n <p>3、没隔一会，又发生大量的请求超时问题。接着进行分析，发现是开启了 慢日志查询。大量的SQL查询语句超过慢日志设置的阀值，于是将慢日志关闭之后，速度瞬间提升。CPU的使用率基本保持在300%左右。但还不是理想状态。</p> \n <p>4、紧接着将部分实时查询数据的SQL语句，都通过缓存(redis)读写实现。观察一段时间后，基本维持在了70%~80%。</p> \n <p>总结：其实本次事故的解决很简单，就是添加索引与缓存结合使用。</p> \n <ol>\n  <li>不推荐在这种CPU使用过高的情况下进行慢日志的开启。因为大量的请求，如果真是慢日志问题会发生日志磁盘写入，性能贼低。</li>\n  <li>直接通过MySQL show processlist命令查看，基本能清晰的定位出部分查询问题严重的SQL语句，在针对该SQL语句进行分析。一般可能就是索引、锁、查询大量字段、大表等问题导致。</li>\n  <li>再则一定要使用缓存系统，降低对MySQL的查询频次。</li>\n  <li>对于内存调优，也是一种解决方案。</li>\n </ol> \n <h4><a id=\"2JavaCPU900_108\"></a>场景2展开：Java进程CPU飙升到900%，怎么处理？</h4> \n <hr> \n <p><strong>定位过程：</strong></p> \n <p>CPU飙升问题定位的一般步骤是：</p> \n <ol>\n  <li>首先通过top指令查看当前占用CPU较高的进程PID；</li>\n  <li>查看当前进程消耗资源的线程PID：top -Hp PID</li>\n  <li>通过print命令将线程PID转为16进制，根据该16进制值去打印的堆栈日志内查询，查看该线程所驻留的方法位置。</li>\n  <li>通过jstack命令，查看栈信息，定位到线程对应的具体代码。</li>\n  <li>分析代码解决问题。</li>\n </ol> \n <p><strong>处理过程：</strong></p> \n <ol>\n  <li> <p>如果是空循环，或者空自旋。</p> <p>处理方式：可以使用Thread.sleep或者加锁，让线程适当的阻塞。</p> </li>\n  <li> <p>在循环的代码逻辑中，创建大量的新对象导致频繁GC。比如，从mysql查出了大量的数据，比如100W以上等等。</p> <p>处理方式：可以减少对象的创建数量，或者，可以考虑使用 对象池。</p> </li>\n  <li> <p>其他的一些造成CPU飙升的场景，比如 selector空轮训导致CPU飙升 。</p> <p>处理方式：参考Netty源码，无效的事件查询到了一定的次数，进行 selector 重建。</p> </li>\n </ol> \n <h3><a id=\"JavaCPU_700_138\"></a>Java的CPU 飙升700%优化的真实案例</h3> \n <hr> \n <p><em>尼恩提示：以下案例，来自互联网。大家参考一下，准备一个自己的案例。</em></p> \n <p>最近负责的一个项目上线，运行一段时间后发现对应的进程竟然占用了700%的CPU，导致公司的物理服务器都不堪重负，频繁宕机。</p> \n <p>那么,针对这类java进程CPU飙升的问题，我们一般要怎么去定位解决呢？、</p> \n <h4><a id=\"top_152\"></a>采用top命令定位进程</h4> \n <p>登录服务器，执行top命令，查看CPU占用情况，找到进程的pid</p> \n <pre><code>top\n</code></pre> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/c80a75bbcea98fbdbcfaca66beb6932f.png\" alt=\"\"></p> \n <p>很容易发现，PID为29706的java进程的CPU飙升到700%多，且一直降不下来，很显然出现了问题。</p> \n <h4><a id=\"top_Hp_168\"></a>使用top -Hp命令定位线程</h4> \n <p>使用 <code>top -Hp &lt;pid&gt;</code> 命令（为Java进程的id号）查看该Java进程内所有线程的资源占用情况（按shft+p按照cpu占用进行排序，按shift+m按照内存占用进行排序）</p> \n <p>此处按照cpu排序：</p> \n <pre><code>top -Hp 23602\n</code></pre> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/b000eaa5cd16429d8a1e38e231c33d85.png\" alt=\"\"></p> \n <p>很容易发现，多个线程的CPU占用达到了90%多。我们挑选线程号为30309的线程继续分析。</p> \n <h4><a id=\"jstack_189\"></a>使用jstack命令定位代码</h4> \n <p><strong>1.线程号转换5为16进制</strong></p> \n <p><code>printf “%x\\n”</code> 命令（tid指线程的id号）将以上10进制的线程号转换为16进制：</p> \n <pre><code>printf \"%x\\n\"  30309\n</code></pre> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/7d59f31286eaaba43200b5ddd5dd3d0a.png\" alt=\"\"></p> \n <p>转换后的结果分别为7665，由于导出的线程快照中线程的nid是16进制的，而16进制以0x开头，所以对应的16进制的线程号nid为0x7665</p> \n <p><strong>2.采用jstack命令导出线程快照</strong></p> \n <p>通过使用dk自带命令jstack获取该java进程的线程快照并输入到文件中：</p> \n <pre><code class=\"prism language-bash\"> jstack <span class=\"token parameter variable\">-l</span> 进程ID <span class=\"token operator\">&gt;</span> ./jstack_result.txt \n</code></pre> \n <p>命令（为Java进程的id号）来获取线程快照结果并输入到指定文件。</p> \n <pre><code class=\"prism language-bash\">jstack <span class=\"token parameter variable\">-l</span> <span class=\"token number\">29706</span> <span class=\"token operator\">&gt;</span> ./jstack_result.txt\n</code></pre> \n <p><strong>3.根据线程号定位具体代码</strong></p> \n <p>在jstack_result.txt 文件中根据线程好nid搜索对应的线程描述</p> \n <pre><code class=\"prism language-bash\"><span class=\"token function\">cat</span> jstack_result.txt <span class=\"token operator\">|</span><span class=\"token function\">grep</span> <span class=\"token parameter variable\">-A</span> <span class=\"token number\">100</span>  <span class=\"token number\">7665</span>\n</code></pre> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/25d3958861221b0ed64a13f4091f6809.png\" alt=\"\"></p> \n <p>根据搜索结果，判断应该是ImageConverter.run()方法中的代码出现问题</p> \n <p>当然，这里也可以直接采用</p> \n <pre><code class=\"prism language-bash\">jstack <span class=\"token operator\">&lt;</span>pid<span class=\"token operator\">&gt;</span> <span class=\"token operator\">|</span><span class=\"token function\">grep</span> <span class=\"token parameter variable\">-A</span> <span class=\"token number\">200</span> <span class=\"token operator\">&lt;</span>nid<span class=\"token operator\">&gt;</span>\n</code></pre> \n <p>来定位具体代码</p> \n <pre><code class=\"prism language-bash\"><span class=\"token variable\">$jstack</span> <span class=\"token number\">44529</span> <span class=\"token operator\">|</span><span class=\"token function\">grep</span> <span class=\"token parameter variable\">-A</span> <span class=\"token number\">200</span> ae24\n<span class=\"token string\">\"System Clock\"</span> <span class=\"token comment\">#28 daemon prio=5 os_prio=0 tid=0x00007efc19e8e800 nid=0xae24 waiting on condition [0x00007efbe0d91000]</span>\n   java.lang.Thread.State: TIMED_WAITING <span class=\"token punctuation\">(</span>sleeping<span class=\"token punctuation\">)</span>\n    at java.lang.Thread.sleep<span class=\"token punctuation\">(</span>Native Method<span class=\"token punctuation\">)</span>\n    at java.lang.Thread.sleep<span class=\"token punctuation\">(</span>Thread.java:340<span class=\"token punctuation\">)</span>\n    at java.util.concurrentC.TimeUnit.sleep<span class=\"token punctuation\">(</span>TimeUnit.java:386<span class=\"token punctuation\">)</span>\n    at com.*.order.Controller.OrderController.detail<span class=\"token punctuation\">(</span>OrderController.java:37<span class=\"token punctuation\">)</span>  //业务代码阻塞点\n</code></pre> \n <h4><a id=\"_258\"></a>分析代码解决问题</h4> \n <p>下面是ImageConverter.run()方法中的部分核心代码。</p> \n <p>逻辑说明：</p> \n <pre><code class=\"prism language-java\"><span class=\"token operator\">/</span>存储minicap的socket连接返回的数据   <span class=\"token punctuation\">(</span>改用消息队列存储读到的流数据<span class=\"token punctuation\">)</span> ，设置阻塞队列长度，防止出现内存溢出\n<span class=\"token comment\">//全局变量</span>\n<span class=\"token keyword\">private</span> <span class=\"token class-name\">BlockingQueue</span><span class=\"token operator\">&lt;</span><span class=\"token keyword\">byte</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token operator\">&gt;</span> dataQueue <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">LinkedBlockingQueue</span><span class=\"token operator\">&lt;</span><span class=\"token keyword\">byte</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token operator\">&gt;</span><span class=\"token punctuation\">(</span><span class=\"token number\">100000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">//消费线程</span>\n<span class=\"token annotation punctuation\">@Override</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">run</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token comment\">//long start = System.currentTimeMillis();</span>\n    <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>isRunning<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token comment\">//分析这里从LinkedBlockingQueue</span>\n        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>dataQueue<span class=\"token punctuation\">.</span><span class=\"token function\">isEmpty</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n            <span class=\"token keyword\">continue</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">byte</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> buffer <span class=\"token operator\">=</span> device<span class=\"token punctuation\">.</span><span class=\"token function\">getMinicap</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>dataQueue<span class=\"token punctuation\">.</span><span class=\"token function\">poll</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n       <span class=\"token keyword\">int</span> len <span class=\"token operator\">=</span> buffer<span class=\"token punctuation\">.</span>length<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>在while循环中，不断读取堵塞队列dataQueue中的数据，如果数据为空，则执行continue进行下一次循环。</p> \n <p>如果不为空，则通过poll()方法读取数据，做相关逻辑处理。</p> \n <p>初看这段代码好像每什么问题，但是如果dataQueue对象长期为空的话，这里就会一直空循环，导致CPU飙升。</p> \n <p>那么如果解决呢？</p> \n <p>分析LinkedBlockingQueue阻塞队列的API发现：</p> \n <pre><code class=\"prism language-java\"><span class=\"token comment\">//取出队列中的头部元素，如果队列为空则调用此方法的线程被阻塞等待，直到有元素能被取出，如果等待过程被中断则抛出InterruptedException</span>\n<span class=\"token class-name\">E</span> <span class=\"token function\">take</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> <span class=\"token class-name\">InterruptedException</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">//取出队列中的头部元素，如果队列为空返回null</span>\n<span class=\"token class-name\">E</span> <span class=\"token function\">poll</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre> \n <p>这两种取值的API，显然take方法更时候这里的场景。</p> \n <p>代码修改为：</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>isRunning<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n   <span class=\"token comment\">/* if (device.getMinicap().dataQueue.isEmpty()) { continue; }*/</span>\n    <span class=\"token keyword\">byte</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> buffer <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token keyword\">byte</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">try</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        buffer <span class=\"token operator\">=</span> device<span class=\"token punctuation\">.</span><span class=\"token function\">getMinicap</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>dataQueue<span class=\"token punctuation\">.</span><span class=\"token function\">take</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">InterruptedException</span> e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        e<span class=\"token punctuation\">.</span><span class=\"token function\">printStackTrace</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n……\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>重启项目后，测试发现项目运行稳定，对应项目进程的CPU消耗占比不到10%。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/d1cccf29d4c87d03b09c8d3face46c78.png\" alt=\"75.png\"></p> \n <blockquote> \n  <p>注：本文以 PDF 持续更新，最新尼恩 架构笔记、面试题 的PDF文件，请从这里获取：<a href=\"https://gitee.com/crazymaker/SimpleCrayIM/blob/master/%E7%96%AF%E7%8B%82%E5%88%9B%E5%AE%A2%E5%9C%88%E6%80%BB%E7%9B%AE%E5%BD%95.md\">码云</a></p> \n </blockquote> \n <h3><a id=\"_325\"></a>参考文献：</h3> \n <p>https://developer.aliyun.com/article/1053255</p> \n <p>https://www.zhihu.com/question/22002813/answer/2662962349</p> \n <h2><a id=\"_335\"></a>推荐阅读：</h2> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128725701\">峰值21WQps、亿级DAU，小游戏《羊了个羊》是怎么架构的？</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128533821\">场景题：假设10W人突访，你的系统如何做到不 雪崩？</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128697096\">2个大厂 100亿级 超大流量 红包 架构方案</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128684641\">Nginx面试题（史上最全 + 持续更新）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128671196\">K8S面试题（史上最全 + 持续更新）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128708648\">操作系统面试题（史上最全、持续更新）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128670335\">Docker面试题（史上最全 + 持续更新）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057567\">Springcloud gateway 底层原理、核心实战 (史上最全)</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124120506\">Flux、Mono、Reactor 实战（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125059491\">sentinel （史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057545\">Nacos (史上最全)</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/114527369\">TCP协议详解 (史上最全)</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/123420859\">分库分表 Sharding-JDBC 底层原理、核心实战（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126992542\">clickhouse 超底层原理 + 高可用实操 （史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120702536\">nacos高可用（图解+秒懂+史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264803\">队列之王： Disruptor 原理、架构、源码 一文穿透</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264508\">环形队列、 条带环形队列 Striped-RingBuffer （史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125135726\">一文搞定：SpringBoot、SLF4j、Log4j、Logback、Netty之间混乱关系（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128265067\">单例模式（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125017316\">红黑树（ 图解 + 秒懂 + 史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/109459593\">分布式事务 （秒懂）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128123114\">缓存之王：Caffeine 源码、架构、原理（史上最全，10W字 超级长文）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/113751575\">缓存之王：Caffeine 的使用（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126579528\">Java Agent 探针、字节码增强 ByteBuddy（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120747767\">Docker原理（图解+秒懂+史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/116425814\">Redis分布式锁（图解 - 秒懂 - 史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85956246\">Zookeeper 分布式锁 - 图解 - 秒懂</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85922561\">Zookeeper Curator 事件监听 - 10分钟看懂</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83957259\">Netty 粘包 拆包 | 史上最全解读</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83758107\">Netty 100万级高并发服务器配置</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/102557988\">Springcloud 高并发 配置 （一文全懂）</a>》</p> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 3352);
INSERT INTO `crawlerblog` VALUES (123124004, '一文说清楚http、tcp、socket、websocket区别', '诺浅', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <h1><a id=\"_0\"></a>写在开头</h1> \n <p>阅读本文，需要您对<code>tcp/ip协议簇</code>协议有一定的了解，本文旨在带你了解Socket到底是啥，他与<code>tcp/ip协议簇</code>、<code>WebSocket</code>、<code>Http</code>等协议之间的关系</p> \n <h1><a id=\"OSI__2\"></a>OSI 网络七层模型</h1> \n <ol>\n  <li>第一层：应用层，定义了用于在网络中进行通信和传输数据的接口；（Http协议位于该层）</li>\n  <li>第二层：表示层，定义不同系统中数据的传输格式，编码和解码规范等；</li>\n  <li>第三层：会话层，管理用户的会话，控制用户间逻辑连接的建立和中断；</li>\n  <li>第四层：传输层，管理着网络中端到端的数据传输；（Tcp协议位于该层）</li>\n  <li>第五层：网络层，定义网络设备间如何传输数据；（IP位于该层）</li>\n  <li>链路层，将上面的网络层的数据包封装成数据帧，便于物理层传输；</li>\n  <li>物理层，这一层主要就是传输这些二进制数据。</li>\n </ol> \n <h1><a id=\"TCPUDP_11\"></a>TCP/UDP</h1> \n <p>网上有大量关于TCP协议的讲解，我这里只说一句，TCP协议已经是比较底层的协议，后面要讲的HTTP、WebSocket等基本都是基于这个协议的上层协议。在TCP协议中规定了连接之前需要三次握手等约定。</p> \n <h1><a id=\"HTTP_13\"></a>HTTP</h1> \n <p>HTTP协议即超文本传送协议(Hypertext Transfer Protocol )，是Web联网的基础，也是手机联网常用的协议之一，HTTP协议是建立在TCP协议之上的一种应用层协议。</p> \n <p>HTTP连接最显著的特点是客户端发送的每次请求都需要服务器回送响应，在请求结束后，会主动释放连接。从建立连接到关闭连接的过程称为“一次连接”。</p> \n <p>在HTTP 1.0中，客户端的每次请求都要求建立一次单独的连接，在处理完本次请求后，就自动释放连接。<br> 在HTTP 1.1中，则可以在一次连接中处理多个请求，并且多个请求可以重叠进行，不需要等待一个请求结束后再发送下一个请求。</p> \n <p>由于HTTP在每次请求结束后都会主动释放连接，因此HTTP连接是一种“短连接”。</p> \n <p>要保持客户端程序的在线状态，需要不断地向服务器发起连接请求，通常情况下即使不需要获得任何数据，客户端也保持每隔一段固定的时间向服务器发送一次“保持连接”的请求，服务器在收到该请求后对客户端进行回复，表明知道客户端“在线”。若服务器长时间无法收到客户端的请求，则认为客户端“下线”，若客户端长时间无法收到服务器的回复，则认为网络已经断开。</p> \n <p><strong>为什么要有http，不能直接用TCP通信吗？</strong><br> TPC/IP协议是传输层协议，主要解决数据如何在网络中传输，而HTTP是应用层协议，主要解决如何包装数据。</p> \n <blockquote> \n  <p>在传输数据时，可以只使用（传输层）TCP/IP协议，但是那样的话，如果没有应用层，便无法识别数据内容，如果想要使传输的数据有意义，则必须使用到应用层协议</p> \n </blockquote> \n <p>应用层协议有很多，比如HTTP、FTP、TELNET等，也可以自己定义应用层协议。WEB使用HTTP协议作应用层协议，以封装HTTP文本信息，然后使用TCP/IP做传输层协议将它发到网络上。</p> \n <h1><a id=\"WebSocket_32\"></a>WebSocket</h1> \n <p>WebSocket也是基于TCP协议之上的应用层协议，他的出现解决了HTTP协议无法服务器主动推送的问题。<a href=\"https://blog.csdn.net/qq32933432/article/details/97943282?csdn_share_tail=%7B%22type%22:%22blog%22,%22rType%22:%22article%22,%22rId%22:%2297943282%22,%22source%22:%22qq32933432%22%7D\">http协议和Websocket协议的区别</a></p> \n <h1><a id=\"Socket_34\"></a>Socket</h1> \n <p>长久以来，我绝对技术猿们搞不清楚Socket是有原因的，网上很多文章会把Socket叫做Socket协议或socket连接，这其实是不对的，很容易让人误解Socket也是一个协议。但其实</p> \n <blockquote> \n  <p>Socket本身并不是协议，而是一个调用接口（API），通过Socket，才能使用TCP/IP协议。</p> \n </blockquote> \n <p>什么意思呢？比如你要喝水，你是不是要吸管？吸管就可以理解为Socket，而水就是TCP协议。</p> \n <p>你不给我吸管我怎么喝豆浆？你不给我筷子我怎么吃饭？你不给我方向盘我怎么开车？我感觉我的话已经触及到你们的灵魂。</p> \n <p>也就是说，可以把Socket理解为一个工具，可以用这个工具来使用TCP协议。</p> \n <blockquote> \n  <p>TCP/IP只是一个协议栈，就像操作系统的运行机制一样，必须要具体实现，同时还要提供对外的操作接口。这个就像操作系统会提供标准的编程接口，比如win32编程接口一样，TCP/IP也要提供可供程序员做网络开发所用的接口，这就是Socket编程接口。</p> \n </blockquote> \n <p>实际上，Socket跟TCP/IP协议没有必然的联系。Socket编程接口在设计的时候，就希望也能适应其他的网络协议。所以说，Socket的出现只是使得程序员更方便地使用TCP/IP协议栈而已，是对TCP/IP协议的抽象，从而形成了一些最基本的函数接口，比如create、 listen、connect、accept、send、read和write等等。</p> \n <h1><a id=\"_48\"></a>总结</h1> \n <ul>\n  <li><code>TCP</code>是底层通讯协议，定义的是数据传输和连接方式的规范。他的连接是<code>tcp://ip:port</code>的形式，比如<code>tcp://127.0.0.1:8888</code></li>\n  <li><code>HTTP</code>是应用层协议，定义的是传输数据的内容以及格式的规范。是对TCP的封装。他的连接是<code>http://ip:port/path</code>的形式，比如<code>http://127.0.0.1:8888/getUser</code></li>\n  <li><code>WebSocket</code>也是应用层协议，其出现解决了HTTP只能单向传输的问题。他的连接是<code>ws://ip:port/path</code>的形式，比如<code>ws://127.0.0.1:8888/getUser</code></li>\n  <li><code>Socket</code>本身不是协议，是一组接口，他可以支持不同的传输层协议（TCP/UDP），当使用TCP协议进行连接时，该Socket连接就是一个TCP连接。他的连接也是<code>ip:port</code>的形式，比如<code>127.0.0.1:8888</code>，你无法跟HTTP或WebSocket一样给他指定路径，如果要实现路径路由，只能是在传输的报文中加入路径参数，然后应用层进行路由，但这种做的本质，其实相当于你自己的应用实现了路由的功能，所以通过这里，你可能更能理解上面说的：<strong>在传输数据时，可以只使用（传输层）TCP/IP协议，但是那样的话，如果没有应用层，便无法识别数据内容，如果想要使传输的数据有意义，则必须使用到应用层协议。</strong></li>\n </ul> \n <p>参考：<br> https://zhuanlan.zhihu.com/p/542458842</p> \n</div>', 'https://profile.csdnimg.cn/E/B/A/3_qq32933432', 5323);
INSERT INTO `crawlerblog` VALUES (123124005, 'python小游戏——像素鸟代码开源', '小刘在C站', '<div id=\"content_views\" class=\"htmledit_views\"> \n <blockquote> \n  <p>♥️<strong>作者：<a href=\"https://blog.csdn.net/lzl10211345?type=blog\" title=\"小刘在这里\">小刘在这里</a></strong></p> \n  <p>♥️<strong>每天分享云计算网络运维课堂笔记，努力不一定有收获，但一定会有收获加油！一起努力，共赴美好人生！</strong></p> \n  <p>♥️<strong>夕阳下，是最美的，绽放，愿所有的美好，再疫情结束后如约而至。</strong></p> \n </blockquote> \n <p id=\"main-toc\"><strong>目录</strong></p> \n <p id=\"%E4%B8%80.%E5%91%88%E7%8E%B0%E6%95%88%E6%9E%9C-toc\" style=\"margin-left:0px;\"><a href=\"#%E4%B8%80.%E5%91%88%E7%8E%B0%E6%95%88%E6%9E%9C\">一.呈现效果</a></p> \n <p id=\"%C2%A0%E4%BA%8C.%E4%B8%BB%E4%BB%A3%E7%A0%81-toc\" style=\"margin-left:40px;\"><a href=\"#%C2%A0%E4%BA%8C.%E4%B8%BB%E4%BB%A3%E7%A0%81\">&nbsp;二.主代码</a></p> \n <p id=\"%E4%B8%89.cfg-toc\" style=\"margin-left:40px;\"><a href=\"#%E4%B8%89.cfg\">三.cfg</a></p> \n <p id=\"3.README-toc\" style=\"margin-left:0px;\"><a href=\"#3.README\">四.README</a></p> \n <hr id=\"hr-toc\"> \n <p></p> \n <h1 id=\"%E4%B8%80.%E5%91%88%E7%8E%B0%E6%95%88%E6%9E%9C\"><strong>一.呈现效果</strong></h1> \n <p class=\"img-center\"><img alt=\"\" height=\"748\" src=\"https://img-blog.csdnimg.cn/4fa7b4a6c03d4757adf6e8e830bf850e.png\" width=\"400\"></p> \n <h2 id=\"%C2%A0%E4%BA%8C.%E4%B8%BB%E4%BB%A3%E7%A0%81\">&nbsp;二.主代码</h2> \n <pre><code class=\"language-python\">\'\'\'\nFunction:\n    坠落的小鸟小游戏\ncsdn账号：顾木子吖\n\'\'\'\nimport cfg\nimport sys\nimport random\nimport pygame\nfrom modules import *\n\n\n\'\'\'游戏初始化\'\'\'\ndef initGame():\n    pygame.init()\n    pygame.mixer.init()\n    screen = pygame.display.set_mode((cfg.SCREENWIDTH, cfg.SCREENHEIGHT))\n    pygame.display.set_caption(\'坠落的小鸟 ——源码基地：959755565 \')\n    return screen\n\n\n\'\'\'显示当前分数\'\'\'\ndef showScore(screen, score, number_images):\n    digits = list(str(int(score)))\n    width = 0\n    for d in digits:\n        width += number_images.get(d).get_width()\n    offset = (cfg.SCREENWIDTH - width) / 2\n    for d in digits:\n        screen.blit(number_images.get(d), (offset, cfg.SCREENHEIGHT*0.1))\n        offset += number_images.get(d).get_width()\n\n\n\'\'\'主函数\'\'\'\ndef main():\n    screen = initGame()\n    # 加载必要的游戏资源\n    # --导入音频\n    sounds = dict()\n    for key, value in cfg.AUDIO_PATHS.items():\n        sounds[key] = pygame.mixer.Sound(value)\n    # --导入数字图片\n    number_images = dict()\n    for key, value in cfg.NUMBER_IMAGE_PATHS.items():\n        number_images[key] = pygame.image.load(value).convert_alpha()\n    # --管道\n    pipe_images = dict()\n    pipe_images[\'bottom\'] = pygame.image.load(random.choice(list(cfg.PIPE_IMAGE_PATHS.values()))).convert_alpha()\n    pipe_images[\'top\'] = pygame.transform.rotate(pipe_images[\'bottom\'], 180)\n    # --小鸟图片\n    bird_images = dict()\n    for key, value in cfg.BIRD_IMAGE_PATHS[random.choice(list(cfg.BIRD_IMAGE_PATHS.keys()))].items():\n        bird_images[key] = pygame.image.load(value).convert_alpha()\n    # --背景图片\n    backgroud_image = pygame.image.load(random.choice(list(cfg.BACKGROUND_IMAGE_PATHS.values()))).convert_alpha()\n    # --其他图片\n    other_images = dict()\n    for key, value in cfg.OTHER_IMAGE_PATHS.items():\n        other_images[key] = pygame.image.load(value).convert_alpha()\n    # 游戏开始界面\n    game_start_info = startGame(screen, sounds, bird_images, other_images, backgroud_image, cfg)\n    # 进入主游戏\n    score = 0\n    bird_pos, base_pos, bird_idx = list(game_start_info.values())\n    base_diff_bg = other_images[\'base\'].get_width() - backgroud_image.get_width()\n    clock = pygame.time.Clock()\n    # --管道类\n    pipe_sprites = pygame.sprite.Group()\n    for i in range(2):\n        pipe_pos = Pipe.randomPipe(cfg, pipe_images.get(\'top\'))\n        pipe_sprites.add(Pipe(image=pipe_images.get(\'top\'), position=(cfg.SCREENWIDTH+200+i*cfg.SCREENWIDTH/2, pipe_pos.get(\'top\')[-1])))\n        pipe_sprites.add(Pipe(image=pipe_images.get(\'bottom\'), position=(cfg.SCREENWIDTH+200+i*cfg.SCREENWIDTH/2, pipe_pos.get(\'bottom\')[-1])))\n    # --bird类\n    bird = Bird(images=bird_images, idx=bird_idx, position=bird_pos)\n    # --是否增加pipe\n    is_add_pipe = True\n    # --游戏是否进行中\n    is_game_running = True\n    while is_game_running:\n        for event in pygame.event.get():\n            if event.type == pygame.QUIT or (event.type == pygame.KEYDOWN and event.key == pygame.K_ESCAPE):\n                pygame.quit()\n                sys.exit()\n            elif event.type == pygame.KEYDOWN:\n                if event.key == pygame.K_SPACE or event.key == pygame.K_UP:\n                    bird.setFlapped()\n                    sounds[\'wing\'].play()\n        # --碰撞检测\n        for pipe in pipe_sprites:\n            if pygame.sprite.collide_mask(bird, pipe):\n                sounds[\'hit\'].play()\n                is_game_running = False\n        # --更新小鸟\n        boundary_values = [0, base_pos[-1]]\n        is_dead = bird.update(boundary_values, float(clock.tick(cfg.FPS))/1000.)\n        if is_dead:\n            sounds[\'hit\'].play()\n            is_game_running = False\n        # --移动base实现小鸟往前飞的效果\n        base_pos[0] = -((-base_pos[0] + 4) % base_diff_bg)\n        # --移动pipe实现小鸟往前飞的效果\n        flag = False\n        for pipe in pipe_sprites:\n            pipe.rect.left -= 4\n            if pipe.rect.centerx &lt; bird.rect.centerx and not pipe.used_for_score:\n                pipe.used_for_score = True\n                score += 0.5\n                if \'.5\' in str(score):\n                    sounds[\'point\'].play()\n            if pipe.rect.left &lt; 5 and pipe.rect.left &gt; 0 and is_add_pipe:\n                pipe_pos = Pipe.randomPipe(cfg, pipe_images.get(\'top\'))\n                pipe_sprites.add(Pipe(image=pipe_images.get(\'top\'), position=pipe_pos.get(\'top\')))\n                pipe_sprites.add(Pipe(image=pipe_images.get(\'bottom\'), position=pipe_pos.get(\'bottom\')))\n                is_add_pipe = False\n            elif pipe.rect.right &lt; 0:\n                pipe_sprites.remove(pipe)\n                flag = True\n        if flag: is_add_pipe = True\n        # --绑定必要的元素在屏幕上\n        screen.blit(backgroud_image, (0, 0))\n        pipe_sprites.draw(screen)\n        screen.blit(other_images[\'base\'], base_pos)\n        showScore(screen, score, number_images)\n        bird.draw(screen)\n        pygame.display.update()\n        clock.tick(cfg.FPS)\n    endGame(screen, sounds, showScore, score, number_images, bird, pipe_sprites, backgroud_image, other_images, base_pos, cfg)\n\n\n\'\'\'run\'\'\'\nif __name__ == \'__main__\':\n    while True:\n        main()</code></pre> \n <h2 id=\"%E4%B8%89.cfg\">三.cfg</h2> \n <p>\'\'\'配置文件\'\'\'<br> import os</p> \n <p><br> # FPS<br> FPS = 60<br> # 屏幕<br> SCREENWIDTH = 288<br> SCREENHEIGHT = 512<br> # 管道之间的空隙<br> PIPE_GAP_SIZE = 100<br> # 图片<br> NUMBER_IMAGE_PATHS = {\n  <!-- --><br> &nbsp;&nbsp;&nbsp; \'0\': os.path.join(os.getcwd(), \'resources/images/0.png\'),<br> &nbsp;&nbsp;&nbsp; \'1\': os.path.join(os.getcwd(), \'resources/images/1.png\'),<br> &nbsp;&nbsp;&nbsp; \'2\': os.path.join(os.getcwd(), \'resources/images/2.png\'),<br> &nbsp;&nbsp;&nbsp; \'3\': os.path.join(os.getcwd(), \'resources/images/3.png\'),<br> &nbsp;&nbsp;&nbsp; \'4\': os.path.join(os.getcwd(), \'resources/images/4.png\'),<br> &nbsp;&nbsp;&nbsp; \'5\': os.path.join(os.getcwd(), \'resources/images/5.png\'),<br> &nbsp;&nbsp;&nbsp; \'6\': os.path.join(os.getcwd(), \'resources/images/6.png\'),<br> &nbsp;&nbsp;&nbsp; \'7\': os.path.join(os.getcwd(), \'resources/images/7.png\'),<br> &nbsp;&nbsp;&nbsp; \'8\': os.path.join(os.getcwd(), \'resources/images/8.png\'),<br> &nbsp;&nbsp;&nbsp; \'9\': os.path.join(os.getcwd(), \'resources/images/9.png\')<br> }<br> BIRD_IMAGE_PATHS = {\n  <!-- --><br> &nbsp;&nbsp;&nbsp; \'red\': {\n  <!-- --><br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \'up\': os.path.join(os.getcwd(), \'resources/images/redbird-upflap.png\'),<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \'mid\': os.path.join(os.getcwd(), \'resources/images/redbird-midflap.png\'),<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \'down\': os.path.join(os.getcwd(), \'resources/images/redbird-downflap.png\')<br> &nbsp;&nbsp;&nbsp; },<br> &nbsp;&nbsp;&nbsp; \'blue\': {\n  <!-- --><br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \'up\': os.path.join(os.getcwd(), \'resources/images/bluebird-upflap.png\'),<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \'mid\': os.path.join(os.getcwd(), \'resources/images/bluebird-midflap.png\'),<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \'down\': os.path.join(os.getcwd(), \'resources/images/bluebird-downflap.png\')<br> &nbsp;&nbsp;&nbsp; },<br> &nbsp;&nbsp;&nbsp; \'yellow\': {\n  <!-- --><br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \'up\': os.path.join(os.getcwd(), \'resources/images/yellowbird-upflap.png\'),<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \'mid\': os.path.join(os.getcwd(), \'resources/images/yellowbird-midflap.png\'),<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \'down\': os.path.join(os.getcwd(), \'resources/images/yellowbird-downflap.png\')<br> &nbsp;&nbsp;&nbsp; }<br> }<br> BACKGROUND_IMAGE_PATHS = {\n  <!-- --><br> &nbsp;&nbsp;&nbsp; \'day\': os.path.join(os.getcwd(), \'resources/images/background-day.png\'),<br> &nbsp;&nbsp;&nbsp; \'night\': os.path.join(os.getcwd(), \'resources/images/background-night.png\')<br> }<br> PIPE_IMAGE_PATHS = {\n  <!-- --><br> &nbsp;&nbsp;&nbsp; \'green\': os.path.join(os.getcwd(), \'resources/images/pipe-green.png\'),<br> &nbsp;&nbsp;&nbsp; \'red\': os.path.join(os.getcwd(), \'resources/images/pipe-red.png\')<br> }<br> OTHER_IMAGE_PATHS = {\n  <!-- --><br> &nbsp;&nbsp;&nbsp; \'gameover\': os.path.join(os.getcwd(), \'resources/images/gameover.png\'),<br> &nbsp;&nbsp;&nbsp; \'message\': os.path.join(os.getcwd(), \'resources/images/message.png\'),<br> &nbsp;&nbsp;&nbsp; \'base\': os.path.join(os.getcwd(), \'resources/images/base.png\')<br> }<br> # 音频路径<br> AUDIO_PATHS = {\n  <!-- --><br> &nbsp;&nbsp;&nbsp; \'die\': os.path.join(os.getcwd(), \'resources/audios/die.wav\'),<br> &nbsp;&nbsp;&nbsp; \'hit\': os.path.join(os.getcwd(), \'resources/audios/hit.wav\'),<br> &nbsp;&nbsp;&nbsp; \'point\': os.path.join(os.getcwd(), \'resources/audios/point.wav\'),<br> &nbsp;&nbsp;&nbsp; \'swoosh\': os.path.join(os.getcwd(), \'resources/audios/swoosh.wav\'),<br> &nbsp;&nbsp;&nbsp; \'wing\': os.path.join(os.getcwd(), \'resources/audios/wing.wav\')<br> }</p> \n <h1 id=\"3.README\">四.README</h1> \n <p># Introduction<br> https://mp.weixin.qq.com/s/44CZjwvjnH0kkkKIn5U9Uw</p> \n <p># Environment<br> ```<br> OS: Windows10<br> Python: Python3.5+(have installed necessary dependencies)<br> ```</p> \n <p># Usage<br> ```<br> Step1:<br> pip install -r requirements.txt<br> Step2:<br> run \"python Game6.py\"<br> ```</p> \n <p># Game Display<br> ![giphy](demonstration/running.gif)</p> \n <blockquote> \n  <p>♥️关注，就是我创作的动力</p> \n  <p>♥️点赞，就是对我最大的认可</p> \n  <p>♥️这里是小刘，励志用心做好每一篇文章，谢谢大家</p> \n </blockquote> \n</div>', 'https://profile.csdnimg.cn/A/1/9/3_lzl10211345', 1483);
INSERT INTO `crawlerblog` VALUES (123124006, '这些低代码平台，你是否知悉？', '神州永泰', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <p>低代码low-code，无代码no-code，合称LCNC，近年来获得较快发展。低代码和无代码(LCNC)软件应用是当今商业领域最大的技术创新之一。顾名思义，低代码和无代码开发有助于简化开发流程，而不需要复杂的编程工具或专业知识。LCNC对用户的技术知识要求很低，是易于实施的开发解决方案。本文将集中介绍12种低代码平台。</p> \n <p>一 JeeSite</p> \n <p>1 简介<br> JeeSite 快速开发平台，不仅仅是一个后台开发框架，它是一个企业级快速开发解决方案，后端基于经典组合 Spring Boot、Shiro、MyBatis，前端采用 Beetl、Bootstrap、AdminLTE 经典开发模式，或者分离版 Vue3、Vite、Ant Design Vue、TypeScript、Vben Admin 最先进技术栈。提供在线代码生成功能，可自动创建业务模块工程和微服务模块工程，自动生成前端代码和后端代码；包括功能模块如：组织机构、角色用户、菜单及按钮授权、数据权限、系统参数、内容管理、工作流等。采用松耦合设计，微内核和插件架构，模块增减便捷；界面无刷新，一键换肤；众多账号安全设置，密码策略；文件在线预览；消息推送；多元化第三方登录；在线定时任务配置；支持集群，支持SAAS；支持多数据源；支持读写分离、分库分表；支持微服务应用。</p> \n <p>JeeSite快速开发平台的主要目的是能够让研发人员快速的开发出复杂的业务功能。让开发者注重专注业务，降低技术难度，从而节省人力成本，缩短项目周期，提高软件安全质量。</p> \n <p>JeeSite 自 2013 年发布以来已被广大爱好者用到了企业、政府、医疗、金融、互联网等各个领域中，JeeSite 架构精良、易于扩展、大众思维的设计模式、工匠精神打磨每一个细节，深入开发者的内心，并荣获开源中国《最受欢迎中国开源软件》奖杯，期间也帮助了不少刚毕业的大学生，教师作为入门教材，快速的去实践。</p> \n <p>JeeSite4的升级，作者结合了多年总结和经验，以及各方面的应用案例，对架构完成了一次全部重构，也纳入很多新的思想。不管是从开发者模式、底层架构、逻辑处理还是到用户界面，用户交互体验上都有很大的进步，在不忘学习成本、提高开发效率的情况下，安全方面也做和很多工作，包括：身份认证、密码策略、安全审计、日志收集等众多安全选项供你选择。努力为大中小微企业打造全方位企业级快速开发解决方案。</p> \n <p>2 官网地址<br> JeeSite 官网地址：<a href=\"http://jeesite.com\">http://jeesite.com</a><br> JeeSite 在线文档：<a href=\"http://docs.jeesite.com\">http://docs.jeesite.com</a><br> JeeSite 演示地址：<a href=\"http://demo.jeesite.com\">http://demo.jeesite.com</a><br> JeeSite 演示地址（Vue）：<a href=\"http://vue.jeesite.com\">http://vue.jeesite.com</a><br> JeeSite 源码下载：<a href=\"https://gitee.com/thinkgem\">https://gitee.com/thinkgem</a><br> JeeSite 在线提问：<a href=\"https://gitee.com/thinkgem/jeesite4/issues\">https://gitee.com/thinkgem/jeesite4/issues</a><br> ThinkGem 博客：<a href=\"http://my.oschina.net/thinkgem\">http://my.oschina.net/thinkgem</a></p> \n <p>二 JeecgBoot</p> \n <p>1 简介<br> JeecgBoot是一款基于BPM的低代码平台！前后端分离架构 SpringBoot 2.x，SpringCloud，Ant Design&amp;Vue，Mybatis-plus，Shiro，JWT，支持微服务。Jeecg不仅提高了UI能力，还降低了前后端分离的开发成本，具有一系列低代码能力：Online表单、Online报表、Online图表、表单设计、流程设计、报表设计、大屏设计等等。</p> \n <p>JeecgBoot基于代码生成器，支持无代码配置化快速开发，适用于常见的企业信息管理系统开发，比如OA办公、ERP系统、客户关系管理系统等，显著提高开发效率，降低开发成本。</p> \n <p>代码托管在Github和Gitee，star数量超14.7K，fork数量超5.7K，获得多个奖项，连续五年中国最火TOP5、十大优秀开源项目、2014年微信开发商大会第一名。</p> \n <p>JeecgBoot和多个项目一起，形成了完善的解决方案。</p> \n <p>(1) JeecgBoot</p> \n <p>基于代码生成器的低代码开发平台，无代码配置化，前后端分离架构，技术栈使用主流的Java + Spring Boot + MyBatis，前端使用node + Ant Design。</p> \n <p>最新版本JeecgBoot2.2.1，发布于2020年7月13日，包括多项功能优化，支持Docker一键部署。</p> \n <p>(2) JeecgCloud</p> \n <p>Jeecg Boot的微服务版本，基于Nacos服务注册和发现框架。</p> \n <p>最新版本1.0.0 Beta，发布于2020年5月21日。</p> \n <p>(3) JeecgUniApp</p> \n <p>一站式跨平台，完整的移动解决方案，采用Uniapp+ColorUI 框架，APP、小程序、H5多终端适配。</p> \n <p>版本1.0.0 Beta，发布于2020年6月8日，最新改版上线于8月17日。</p> \n <p>(4)JeewxBoot</p> \n <p>基于Java + Spring Boot开发的微信管理平台，采用插件机制，支持公众号、小程序、第三方平台，包括公众号基础管理、群发、系统权限、抽奖活动、小程序官网等功能。</p> \n <p>最新版本1.1.0，发布于2019年12月5日。</p> \n <p>(5) JeewxAppCMS</p> \n <p>基于wepy语言开发小程序，包含CMS网站基本功能，快速开发应用。</p> \n <p>最新版本1.1.0，发布于2020年5月30日。</p> \n <p>2 官网地址<br> Jeecg-boot 官网、Github 及详细测评<br> Jeecg-boot 官网：<a href=\"http://www.jeecg.com/\">http://www.jeecg.com/</a><br> Github：<a href=\"https://github.com/jeecgboot/jeecg-boot\">https://github.com/jeecgboot/jeecg-boot</a><br> JeecgBoot测评：《JeecgBoot 后台管理框架怎么样评价如何？》</p> \n <p>三 Pig - PigX 快速开发平台的开源版</p> \n <p>1 简介<br> Pig 基于 Spring Cloud、OAuth2.0、Vue的前后端分离的快速开发平台，PigX 是它的商业版本。Pig面向企业开发场景，封装了大量技术开发包、组件并支持 SaaS 多租户，为企业提供了一个可支持各类业务系统或产品快速开发实现的微服务应用数字化融合平台。</p> \n <p>Pig 基于 Spring Cloud 微服务框架进行封装，平台设计灵活可扩展、可移植、可应对高并发需求。同时兼顾本地化、私有云、公有云部署，支持SaaS模式应用。企业级应用系统所包含的常用开箱即用的模块，并支持灵活的可配置性和拓展性。一套基于 Spring Cloud 的微服务应用程序框架，可帮助公司更快，更高效地进行微服务开发。相较于业界使用广泛的开源版本平台，提供更强大的功能和更全面的服务支持。</p> \n <p>基于 Spring Cloud Hoxton 、Spring Boot 2.2、 OAuth2.0 的 RBAC 权限管理系统，基于数据驱动视图的理念封装 Element-ui，即使没有 Vue的使用经验也能快速上手。提供对常见容器化支持 Docker、Kubernetes、Rancher2 支持，内置低代码生成模块，可以适用于不同开发领域。</p> \n <p>2 Pig 官网、Github 及详细测评<br> Pig 官网：<a href=\"https://pig4cloud.com\">https://pig4cloud.com</a><br> Github：<a href=\"https://github.com/pig-mesh/pig\">https://github.com/pig-mesh/pig</a></p> \n <p>四 若依（RuoYi）</p> \n <p>1 简介<br> 若依 RuoYi 是一套完全开源，基础功能完备的 admin 后台管理框架系统。它基于经典技术组合 Spring Boot、SpringCloud、Apache Shiro、MyBatis、Thymeleaf ，若依前端有 BootsTrap 和 Vue + Element两个版本。若依是快速开发框架的佼佼者，内置了常见的后台管理系统模块，以及后端代码生成器，可一键生成后端代码，让开发者更好的专注在自己公司业务逻辑的开发上。基于SpringBoot、Spring Security、Jwt、Vue的前后端分离的后台管理系统<br> RuoYi-Vue 是一个 Java EE 企业级快速开发平台，基于经典技术组合（Spring Boot、Spring Security、MyBatis、Jwt、Vue），内置模块如：部门管理、角色用户、菜单及按钮授权、数据权限、系统参数、日志管理、代码生成等。在线定时任务配置；支持集群，支持多数据源，支持分布式事务。</p> \n <p>2 官网地址</p> \n <p>若依官网：<a href=\"http://ruoyi.vip\">http://ruoyi.vip</a></p> \n <p>3 主要特性</p> \n <p>完全响应式布局（支持电脑、平板、手机等所有主流设备）<br> 强大的一键生成功能（包括控制器、模型、视图、菜单等）<br> 支持多数据源，简单配置即可实现切换。<br> 支持按钮及数据权限，可自定义部门数据权限。<br> 对常用js插件进行二次封装，使js代码变得简洁，更加易维护<br> 完善的XSS防范及脚本过滤，彻底杜绝XSS攻击<br> Maven多项目依赖，模块及插件分项目，尽量松耦合，方便模块升级、增减模块。<br> 国际化支持，服务端及客户端支持<br> 完善的日志记录体系简单注解即可实现<br> 支持服务监控，数据监控，缓存监控功能。</p> \n <p>演示地址：<a href=\"http://vue.ruoyi.vip\">http://vue.ruoyi.vip</a><br> 代码下载：<a href=\"https://gitee.com/y_project/RuoYi-Vue\">https://gitee.com/y_project/RuoYi-Vue</a></p> \n <p>*技术选型<br> (1）系统环境</p> \n <p>Java EE 8<br> Servlet 3.0<br> Apache Maven 3<br> (2）主框架</p> \n <p>Spring Boot 2.2.x<br> Spring Framework 5.2.x<br> Spring Security 5.2.x<br> (3）持久层</p> \n <p>Apache MyBatis 3.5.x<br> Hibernate Validation 6.0.x<br> Alibaba Druid 1.2.x<br> (4）视图层</p> \n <p>Vue 2.6.x<br> Axios 0.21.x<br> Element 2.15.x</p> \n <p>*内置功能<br> 用户管理：用户是系统操作者，该功能主要完成系统用户配置。<br> 部门管理：配置系统组织机构（公司、部门、小组），树结构展现支持数据权限。<br> 岗位管理：配置系统用户所属担任职务。<br> 菜单管理：配置系统菜单，操作权限，按钮权限标识等。<br> 角色管理：角色菜单权限分配、设置角色按机构进行数据范围权限划分。<br> 字典管理：对系统中经常使用的一些较为固定的数据进行维护。<br> 参数管理：对系统动态配置常用参数。<br> 通知公告：系统通知公告信息发布维护。<br> 操作日志：系统正常操作日志记录和查询；系统异常信息日志记录和查询。<br> 登录日志：系统登录日志记录查询包含登录异常。<br> 在线用户：当前系统中活跃用户状态监控。<br> 定时任务：在线（添加、修改、删除)任务调度包含执行结果日志。<br> 代码生成：前后端代码的生成（java、html、xml、sql)支持CRUD下载 。<br> 系统接口：根据业务代码自动生成相关的api接口文档。<br> 服务监控：监视当前系统CPU、内存、磁盘、堆栈等相关信息。<br> 缓存监控：对系统的缓存信息查询，命令统计等。</p> \n <p>五 BladeX<br> 1 简介<br> BladeX 是一个基于 Spring Boot 2.7 &amp; Spring Cloud 2021 &amp; Mybatis 等核心技术，用于快速构建中大型系统的基础框架。<br> 已稳定生产近一年，经历了从Camden-&gt;2021的技术架构，也经历了从FatJar-&gt;Docker-&gt;K8S+Jenkins的部署架构。<br> 采用前后端分离的模式，前端开发两个框架：Sword(基于React、Ant Design)、Saber(基于Vue、ElementUI)。后端采用SpringCloud系列，对其基础组件做了高度的封装，单独出一个后端核心框架：BladeX-Tool。<br> BladeX-Tool已推送至Maven私有库，直接引入减少工程的模块与依赖，可更注重于业务开发。集成Sentinel从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。注册中心、配置中心选型Nacos，为工程瘦身的同时加强了各模块之间的联动。封装集成了基于注解+Web可视化的数据权限，灵活配置，无需重启直接生效。定制了基于Nacos的轻量级、高拓展性的动态网关，完美支持多团队开发。精心设计集成了minio，完美支持多租户模式下的oss对象存储需求。</p> \n <p>2 BladeX 官网、Github 及详细测评<br> BladeX 官网：<a href=\"https://bladex.vip/\">https://bladex.vip/</a><br> BladeX Github：<a href=\"https://github.com/chillzhuang/SpringBlade\">https://github.com/chillzhuang/SpringBlade</a></p> \n <p>3 架构简介<br> 基于SpringBoot2、SpringCloud Hoxton、Mybatis构建核心架构<br> 采用Oauth2协议进行统一的Token下发与鉴权，保证系统安全性<br> 使用Gateway进行网关的统一转发，生产环境采用Traefik代理<br> 微服务统一注册至Nacos，Nacos担任注册中心与配置中心的角色<br> 采用Feign进行远程调用，Ribbon进行负载，Hystrix进行熔断<br> 采用Sentinel进行限流，保障系统整体的性能<br> 集成Seata，为分布式事务保驾护航<br> 具有日志收集与监控服务为一体的能力<br> 支持FatJar、Docker、K8s、阿里云等多种部署方式</p> \n <p>六 卡拉云<br> 1 简介<br> 卡拉云是新一代企业级低代码开发平台，可帮助开发者快速搭建后台管理系统。卡拉云从 2020 年第一个公测版开始，已经迭代升级了多个大版本，特别针对国内企业级大型后台管理系统搭建场景优化。</p> \n <p>卡拉云可快速搭建企业级后台管理系统（ERP、CMS、CRM、OA、MES、订单管理、客户管理、物流管理、财务管理等复杂系统），它内置常用的前端组件，简单鼠标拖拽即可快速生成。可一键接入数据库和 RESTful API、企业微信、钉钉、飞书等常见的数据源，可在前端直接写 SQL &amp; js ，实现复杂的代码逻辑。</p> \n <p>卡拉云之所以能快速搭建后台管理系统，是因为它把后台管理系统抽象成三个部分，「前端组件」、「数据源」、「连接前端组件和数据源的简单 JS 代码」，每个部分卡拉云都帮开发者写好，不用再重复造轮子，开发者只需调用即可。</p> \n <p>卡拉云帮助开发者把所有前端组件写扎实，开发者只需要拖拽即可一键生成所需组件，无需操心任何前端问题。也无需自己搭建后端，只需要简单填写配置表即可接入数据库、API 等常见数据源。前后端卡拉云都帮助开发者写好，开发者只需要写简单的 JS &amp; SQL 代码连接前后端即可实现后台管理系统快速搭建。接下来，我来详细测评卡拉云的技术细节。</p> \n <p>卡拉云由三个部分组成，前端组件+后端数据源+连接组件与数据源的简单代码。</p> \n <p>卡拉云针对国内互联网应用场景进行了许多优化，不论是使用习惯上，还是应用场景上都更贴近国内用户。如集成了阿里、腾讯、华为等多家云存储、可轻松调用七牛云 API、Leancloud API、金数据、又拍云、企业微信、钉钉等常见的第三方应用接口，方便开发者直接使用。</p> \n <p>2 官网地址<br> 卡拉云官网：<a href=\"https://kalacloud.com/\">https://kalacloud.com/</a></p> \n <p>七 Retool</p> \n <p>Retool 是面向企业的低代码开发平台。使用 Retool 可快速搭建后台管理工具，比如快速构建 admin 后台管理、销售 ERP、客户 CRM、数据分析看板、amazon 云端文件上传管理等基于数据库或 API 的企业工具。</p> \n <p>新事物刚出现，没亲身体验前，总是很难理解。我们总会把新事物与我们已认知的东西来做对比，有人说 Retool 是帮你配置好的 Vue &amp; React 、是可视化拖拽编程平台、是在线前端生成器（并不是）。这些说法都只描述了 Retool 很小的一个点，Retool 是新一代低代码开发平台，是程序员的新效率工具，是历史上不曾有的新工具，拿旧地图看新世界总会有很大偏差，建议你亲自试试看。如果你访问 Retool 比较慢，或想用中文界面，国内也有类似概念的低代码平台，比如卡拉云，后文我们也会对比这两个平台的优缺点和差异。</p> \n <p>Retool 有三大特点，无需任何前端编程基础的拖拽组件生成、可连接一切数据库及API，前后端无缝衔接、高度灵活性，高度可定制，为开发者而生。、、</p> \n <p>八 AppSmith<br> 1 简介<br> AppSmith 是印度一家创业公司开发的低代码开发工具，它的原型是另一家名叫 Retool 的美国的创业公司。AppSmith 从 2019 年开始开发，到现在已经发行了 1.x 版本。用户可使用 AppSmith 开发自己的企业内部管理工具，一键接入数据库及 API（支持 RESTful API、PostgreSQL、DynamoDB、MongoDB、Firebase 等），仅需拖拽即可生成的前端 UI 组件。有清晰的权限系统，企业团队在 AppSmith 上开发的 app ，可根据使用者的身份划分权限。<br> AppSmith有以下特性：<br> （1）简单拖拽即可创建前端组件；<br> （2）可一键接入多种数据库及 API；<br> （3）无需处理前后端问题，会简单 JS 即可；<br> （4）权限清晰，一键邀请同事加入开发或使用；</p> \n <p>2 官网地址<br> AppSmith官网：<a href=\"https://www.appsmith.com/\">https://www.appsmith.com/</a></p> \n <p>九 Budibase</p> \n <p>1 简介<br> Budibase是一个开源的低代码平台，可以帮助在很短的时间内创建一个满足业务应用的web程序。Budibase是包括构建，设计以及自动化业务应用（比如，管理面板，表单，内部工具，客户入口等等），这些都集成在Budibase的低代码平台中。兼容多种数据源，包括MongoDB和PostgreSQL等流行数据库以及Google Sheets等电子表格程序，允许用户快速构建客户端门户和管理面板等应用程序。</p> \n <p>Budibase的特点：<br> 支持外部数据源，包括 MongoDB、MySQL 等；<br> 支持 Rest API 拉取数据；<br> 能够使用应用的内置数据库或上传 CSV 来导入数据；<br> 各种数据类型和功能，包括附件、关系、公式等；<br> API 整合平台，整合不同的 API，帮助你轻松建立内部应用、表单等；<br> 能够使用内部表格生成自动页面；<br> 构建单页应用；<br> 自动生成的 CRUD（创建、读取、更新和删除）页面；<br> 私人和公共应用；<br> 只需点击几下就可以定制你的应用的主题；<br> 容易为你的应用实现深色模式主题；<br> 一个功能丰富的表单生成器，满足广泛的要求；<br> 支持 Webhook；<br> 与诸如 Zapier 等的第三方集成；<br> 基于特定触发器的灵活自动化选项；<br> 能够将 JavaScript 添加到你的自动程序中；<br> 为拥有自己基础设施的用户提供自我托管选项；<br> 免费的单点登录认证/管理；<br> 用户管理选项，将团队分配到不同的应用；<br> 支持 SMTP 电子邮件；<br> 电子邮件模板，以配合你的品牌和风格；<br> 支持 OAuth 登录。目前仅限于谷歌；<br> 图表、表格和卡片来优雅地展示数据。</p> \n <p>2 官网地址<br> Budibase官网：<a href=\"https://budibase.com/\">https://budibase.com/</a></p> \n <p>十 ToolJet<br> 1 简介<br> ToolJet 是一套开源的低代码开发平台框架，可快速构建和部署企业内部工具，帮助开发团队节省大量开发时间。开发者可使用 ToolJet 连接多种常见的数据库（如 PostgreSQL、MongoDB、Elasticsearch 等）也可以直接接入 RESTful API，甚至可以直接调第三方工具（比如 Stripe、Slack、Google Sheets、Airtable 等），灵活的前端组件拖拽生成，无需懂任何前端技术。</p> \n <p>ToolJet的特点：</p> \n <p>（1）ToolJet 可接入多种数据源、API及第三方工具；<br> （2）ToolJet 拖拽生成前端组件；<br> （3）可参与共享开发。</p> \n <p>2 官网地址<br> ToolJet官网：<a href=\"https://www.tooljet.com/\">https://www.tooljet.com/</a></p> \n <p>十一 DronaHQ<br> 1 简介<br> DronaHQ 作为一个低代码工具，其最大突出优势便是能够在已有应用程序上，创建出美观且响应灵敏的内部系统。DronaHQ 提供了丰富的功能组件（多达 50+ 数据源连接、90+ UI 组件），并提供了教程一步步指导创建、设计、部署和托管自己的应用程序。</p> \n <p>DronaHQ特点：</p> \n <p>（1）丰富的数据源、UI 组件支持<br> （2）界面 UI 美观（有的人可能会觉得有点卡通）<br> （3）响应式 UI，支持在「桌面」「移动端」模式间切换<br> （4）丰富的文档支持</p> \n <p>2 官网地址<br> DronaHQ官网：<a href=\"https://www.dronahq.com/\">https://www.dronahq.com/</a></p> \n <p>十二 码匠<br> 1 简介<br> 码匠是一款对开发者友好的低代码平台，在支持多种数据源的同时提供了一套开箱即用的组件，帮助您快速构建功能完善的内部应用，让您专注于业务发展。码匠针对国内用户使用习惯做了大量优化，UI 界面设计更加适合国内场景，并整合了多款国内数据源，包括 飞书、企业微信、钉钉、阿里云 OSS，等等。不仅如此，码匠还提供了国内业务场景下常见的租户管理、更加细粒度的权限控制、审计日志等功能，为您的企业信息安全保驾护航。</p> \n <p>码匠特点：<br> （1）写SQL、配置组件，即可获得功能完善的内部应用，让您可以专注于业务发展。<br> （2）码匠提供了表格、按钮、输入框、选择器等一套功能强大、开箱即用的UI组件。您可以在5分钟内组装完成您的应用程序。<br> （3）可以轻松的连接到MySQL、MongoDB、Redis、Clickhouse等数据源。码匠会加密存储认证信息，此外不会存储客户任何数据。<br> 还提供了一个私有化部署版本，可以自行部署以便完全控制码匠实例和所有数据。</p> \n <p>2 官网地址<br> 码匠官网：<a href=\"https://majiang.co/\">https://majiang.co/</a></p> \n</div>', 'https://profile.csdnimg.cn/1/A/D/3_helloworldchina', 8676);
INSERT INTO `crawlerblog` VALUES (123124007, '《流浪地球 2》 Deepfake 小试牛刀，45+ 吴京「被」年轻，变身 21 岁小鲜肉', 'HyperAI超神经', '<div id=\"content_views\" class=\"htmledit_views\"> \n <p><strong>内容一览：</strong>在春节档科幻电影「流浪地球 2」中，主演吴京、刘德华、沙溢等人饰演的角色，跨越 14 年之久，视效团队正是借助 Deepfake de-aging 技术，呈现出了演员不同年龄段的容貌。</p> \n <p><strong>关键词：</strong>De-aging&nbsp; &nbsp;Deepfake&nbsp; &nbsp;流浪地球&nbsp; &nbsp;</p> \n <p></p> \n <p>「流浪地球 2」上映 8 天，总票房就已经突破了 24 亿，打破 36 项纪录，获得 91 项里程碑成就。其中，<strong>21 岁小鲜肉刘培强（吴京饰），以及年轻帅气图恒宇（刘德华饰），给观众留下了深刻的印象。</strong></p> \n <p></p> \n <p>流浪地球官方微博发布的一段视频中，讲述了换脸特效背后繁复的工程难度。</p> \n <div class=\"csdn-video-box\"> \n  <iframe id=\"rzrDThIG-1674970999301\" src=\"https://live.csdn.net/v/embed/271893\" allowfullscreen=\"true\" data-mediaembed=\"csdn\"></iframe> \n  <p>变！变！变！20 岁吴京变身小鲜肉</p> \n </div> \n <p>在知乎提问「《流浪地球 2》幕后有哪些不为人知的制作难题」中，《流浪地球 2》视效总监、MOREVFX 创始人徐建，<strong>坦言技术上第一难点就是「De-aging」数字换龄。</strong></p> \n <p></p> \n <p>查看徐建完整回答，请访问：</p> \n <p><em><strong><a class=\"link-info\" href=\"https://www.zhihu.com/question/579613527\" title=\"https://www.zhihu.com/question/579613527\">https://www.zhihu.com/question/579613527</a></strong></em></p> \n <p></p> \n <h1><strong>&nbsp;数字换龄，45+ 吴京变身 21 岁小鲜肉</strong></h1> \n <p></p> \n <p>de-aging 是一种应用于影视作品的视觉特效技术，<strong>是指利用数字编辑 (digitally editing)&nbsp;或计算机绘图 (computer graphics，简称 CG) 技术，</strong>实现演员在特定场景下的年轻化。</p> \n <p></p> \n <p>在电影「流浪地球 2」中，演员吴京、刘德华、王智等多人饰演的角色，<strong>都涉及到了角色年轻化，即 de-aging。</strong></p> \n <p></p> \n <p class=\"img-center\"><img alt=\"\" src=\"https://img-blog.csdnimg.cn/img_convert/2e168e1e3e18ca0909c10908010e23f2.png\"></p> \n <p style=\"text-align:center;\"><strong>用吴京年轻时的 2D 素材训练 AI 模型进行 de-aging</strong></p> \n <p style=\"text-align:center;\"><strong>为实拍素材完成换脸</strong></p> \n <p></p> \n <p><em><strong>一个小番外：</strong>根据电影剧情推算，刘培强出生年份正是 2023 年。</em></p> \n <p></p> \n <p>以吴京为例，现实中吴京在拍摄这部电影时，年龄 45+（根据百度百科资料推算），但是电影中 2044 年时的刘培强只有 21 岁，<strong>45+ 的演员挑战饰演 21 岁的「小鲜肉」，着实需要点技术加持。</strong></p> \n <p></p> \n <h1><strong>&nbsp;3 大主流 de-aging 方法梳理</strong></h1> \n <p></p> \n <p>实际上，当时全世界主流的 de-aging 方法共分为 3 类。</p> \n <p></p> \n <p class=\"img-center\"><img alt=\"\" src=\"https://img-blog.csdnimg.cn/img_convert/3525c8558a038c403817f1a79a81cd95.png\"></p> \n <p><strong>该方法分为两个主要步骤：</strong></p> \n <p></p> \n <p>* 制作数字人并进行 de-aging</p> \n <p>通过演员佩戴的表情捕捉设备，扫描演员并生成数据库，制作目标演员的数字人，然后根据演员早期职业生涯剧照及视频素材，对数字人进行 de-aging。</p> \n <p></p> \n <p>* 基于演员佩戴的动作捕捉设备，对数字人进行动画制作</p> \n <p>根据「流浪地球 2」视效总监徐建在知乎的分享，<strong>此方法预算高、国内相关人才不足，且身上的设备可能会影响打斗场景拍摄及演员表演情绪的传达。</strong></p> \n <p class=\"img-center\"><img alt=\"\" src=\"https://img-blog.csdnimg.cn/img_convert/9bd68c2482ba92304cd9204f625816a0.gif\"></p> \n <p></p> \n <p style=\"text-align:center;\"><strong>威尔史密斯佩戴设备进行动作及表情捕捉</strong></p> \n <p></p> \n <p class=\"img-center\"><img alt=\"\" src=\"https://img-blog.csdnimg.cn/img_convert/af6b88dbceccda3f0185a5526e2287fd.png\"></p> \n <p>在电影「爱尔兰人」中，工业光魔开发了一种无需佩戴物理设备或在面部做标记的 de-aging 技术，演员被三台摄像机设备环绕拍摄，一台为正常拍摄机位，另外两台负责记录 de-aging 需要的数据，<strong>通过拍摄红外镜头收集必要数据，以数字方式再现表演。</strong></p> \n <p></p> \n <p class=\"img-center\"><img alt=\"\" src=\"https://img-blog.csdnimg.cn/img_convert/3c2b3bbd6cf9818407bf136307010879.gif\"></p> \n <p style=\"text-align:center;\"><strong>摄像机记录的数据结合光线影响&nbsp; 对角色进行 de-aging</strong></p> \n <p></p> \n <p></p> \n <p class=\"img-center\"><img alt=\"\" src=\"https://img-blog.csdnimg.cn/img_convert/0758c42a169bcf04d729cb625bd3468b.png\"></p> \n <p>&nbsp;在电影「美国队长 3：内战」中，视效团队利用小罗伯特唐尼早期的影视作品、视觉素材，训练基于 Deepfake 算法的 AI 模型并完成换脸。</p> \n <p></p> \n <p class=\"img-center\"><img alt=\"\" src=\"https://img-blog.csdnimg.cn/img_convert/1117840154c0c95d8b17ca73895bd5a5.jpeg\"></p> \n <p style=\"text-align:center;\"><strong>Deepfake 年轻版钢铁侠 Tony Stark&nbsp;</strong></p> \n <p></p> \n <p>据「流浪地球 2」视效总监徐建介绍，早在电影开拍一年半之前，视效团队就开始了技术实验，测试了 5、6 种换脸方法后，视效团队最终决定采用 de-aging 方法三，<strong>基于 Deepfake 算法用演员年轻时的 2D 素材训练 AI 模型，最终迭代 500 多万次后，替换实拍素材。</strong></p> \n <p></p> \n <h1><strong>&nbsp;人脸年轻化及增龄的论文梳理</strong></h1> \n <h2></h2> \n <h2><strong><a class=\"link-info\" href=\"https://studios.disneyresearch.com/app/uploads/2022/10/Production-Ready-Face-Re-Aging-for-Visual-Effects.pdf\" title=\"《Production-Ready Face Re-Aging for Visual Effects》\">《Production-Ready Face Re-Aging for Visual Effects》</a></strong></h2> \n <p>DisneyResearch 团队提出了一个 Face Re-Aging Network，简称 FRAN，可以在不丢失身份的前提下，自动重塑视频中的人脸图像，实现目标人脸年轻化或增龄效果。</p> \n <p></p> \n <p class=\"img-center\"><img alt=\"\" src=\"https://img-blog.csdnimg.cn/img_convert/52a35eecf669633c9e7501ff70e56191.png\"></p> \n <p style=\"text-align:center;\"><strong>输入人像年龄 35 岁</strong></p> \n <p style=\"text-align:center;\"><strong>上下排分别为 re-aging 为 65 岁和 18 岁</strong></p> \n <p></p> \n <h2><strong><a class=\"link-info\" href=\"https://arxiv.org/pdf/2005.04410.pdf\" title=\"《High Resolution Face Age Editing》\">《High Resolution Face Age Editing》</a></strong></h2> \n <p>本篇论文提出了一个用于面部年龄编辑的 encoder-decoder 架构，<strong>使用一种简单的方法实现了高分辨率人脸年龄编辑，</strong>可以输出 1024*1024 分辨率的图像。</p> \n <p></p> \n <p class=\"img-center\"><img alt=\"\" src=\"https://img-blog.csdnimg.cn/img_convert/5264b10acdfd14b53c2ea48a916e9d6f.png\"></p> \n <p style=\"text-align:center;\"><strong>依据输入人脸（黄色框）</strong></p> \n <p style=\"text-align:center;\"><strong>输出不同年龄段的高质量人脸图像</strong></p> \n <p></p> \n <h2><strong><a class=\"link-info\" href=\"https://arxiv.org/pdf/2005.04410.pdf\" title=\"《Only a Matter of Style: Age Transformation Using a Style-Based Regression Model》\">《Only a Matter of Style: Age Transformation Using a Style-Based Regression Model》</a></strong></h2> \n <p>本篇论文提出了一种图像到图像的转换方法，直接将真实的面部图像编码到预先训练好的无条件 GAN 的 latent space 中，进行老化转变。<strong>可以仅凭试验者的一张照片就生成全年龄阶段的容貌，精确到每一条皱纹。</strong></p> \n <p></p> \n <p class=\"img-center\"><img alt=\"\" src=\"https://img-blog.csdnimg.cn/img_convert/9f0d16d4a6ce8c0f6e87ce37f550aaaa.png\"></p> \n <p style=\"text-align:center;\"><strong>使用论文提出的 SAM 架构生成的老化结果</strong></p> \n <p></p> \n <p></p> \n <h1><strong>&nbsp;像素级换脸技术任重道远，仍需行业规范&nbsp;</strong></h1> \n <p></p> \n <p>「流浪地球 2」中，年轻刘培强和图恒宇的呈现，虽然是基于 Deepfake 算法实现，然而通过考察众多相关论文，结合视效总监徐建的介绍，<strong>我们得知在电影制作的后期，仍需专业后期人员对换脸后的角色进行繁复的完善和修复。</strong></p> \n <p></p> \n <p>这是因为换脸技术在一些细节处理上仍存在不足，如表情生硬、眼神表情不自然，这些「不协调」在电影大荧幕上无疑会被放大，给观众带来不适。</p> \n <p></p> \n <p>减龄及增龄算法的发展，要实现与影视作品中的角色「完美适配」，恐怕还有很长的路要走，<strong>而如何监控 Deepfake 这项技术不被滥用，也是工业界、科技界乃至普通用户不得不面临的一个潜在风险和挑战。</strong></p> \n <p></p> \n <p></p> \n <p></p> \n <p><strong>参考链接：</strong></p> \n <p>[1]&nbsp;https://www.zhihu.com/question/579613527</p> \n <p>[2]&nbsp;https://onlinelibrary.wiley.com/doi/full/10.1111/oli.12302</p> \n <p>[3]&nbsp;https://www.respeecher.com/blog/de-aging-technology-changing-hollywood-future-film-making</p> \n <p></p> \n <p></p> \n</div>', 'https://profile.csdnimg.cn/9/F/4/3_hyperai', 6987);
INSERT INTO `crawlerblog` VALUES (123124008, '尼恩Java面试宝典', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <p>40岁老架构师 尼恩 梳理，不断迭代， 持续更新， 收入最新 面试题。</p> \n <h1><a id=\"Java____2\"></a>尼恩Java面试宝典： 体系化，形象化 梳理面试题，且 持续升级</h1> \n <p>尼恩梳理这些Java面试题， 致力于体系化， 系统化，形象化 梳理，形成一个大的知识体系，从而， 帮助大家<strong>薪酬猛涨， 进入大厂</strong></p> \n <p>举个例子：spring三级缓存是技术的难点，非常不好记忆， 但是，又是面试的<strong>重点，要点</strong></p> \n <p><strong>spring三级缓存的知识，社群好几个小伙伴和我反应，挂在这个问题上了，非常可惜</strong></p> \n <p>对spring三级缓存， 尼恩首创<strong>使用成品、半成品、原材料工厂，这样的浅显易懂的模式解读</strong>， 使得复杂的概念 ，变得更容易好懂</p> \n <p><img src=\"https://img-blog.csdnimg.cn/22a7ddcce0314d5b9f0829734bd21188.png\" alt=\"在这里插入图片描述\"></p> \n <p>关于 以上成品、半成品、原材料工厂 的详细介绍， 请参见： pdf 中的专题5。</p> \n <h1><a id=\"Java_32PDF_16\"></a>送：尼恩Java面试宝典 32个专题PDF（极致经典+史上最全+面试必备）</h1> \n <blockquote> \n  <p>加尼恩微信，免费领取此书， 尼恩微信二维码请参见 <a href=\"https://www.yuque.com/crazymakercircle/gkkw8s/khigna\"><strong>疯狂创客圈总目录 语雀版</strong></a> | <a href=\"https://gitee.com/crazymaker/SimpleCrayIM/blob/master/%E7%96%AF%E7%8B%82%E5%88%9B%E5%AE%A2%E5%9C%88%E6%80%BB%E7%9B%AE%E5%BD%95.md\"><strong>总目录 码云版</strong></a>| <a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\"><strong>总目录 博客园版</strong></a></p> \n </blockquote> \n <p><img src=\"https://img-blog.csdnimg.cn/729b33f6bc37429385edbef85fd805c3.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"_22\"></a>升级记录</h1> \n <p>会持续升级， 更新记录具体请关注 <a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\">博客园 尼恩Java面试宝典V2（卷王专供+ 史上最全 + 2022面试必备）</a></p> \n <h2><a id=\"2022518_1_24\"></a>2022-5-18升级说明 ：增加1个专题</h2> \n <p>新增了一个专题，第32专题， <strong>大厂面试的基本流程‌和面试准备</strong>，</p> \n <p>这个非常重要，帮助大家更好的备战大厂</p> \n <h2><a id=\"2022517_1_29\"></a>2022-5-17升级说明 ：增加1个专题</h2> \n <p>新增了一个专题，第31专题， <strong>Hash连环炮面试题</strong>，</p> \n <p><strong>Hash连环炮面试题</strong>，介绍了hashmap、cocurrenthashmap1.7、cocurrenthashmap1.8的内部结构、avl树、红黑树</p> \n <p><strong>这个非常重要，是面试的重点，绝对重点</strong></p> \n <h2><a id=\"2022516_3_37\"></a>2022-5-16升级说明 ：增加3个面试连环炮</h2> \n <p><strong>JVM内存连环炮：</strong></p> \n <p>JVM内存包括哪些？什么是堆内存? 什么是非堆内存? 什么是直接内存? 方法区和永久代有何区别?</p> \n <p><strong>对象结构连环炮：</strong></p> \n <p>给定一个具体的类，请分析对象的内存占用? 怎么计算出来一个对象的内存占用?对象头中包含哪些部分？</p> \n <p><strong>JVM调优连环炮：</strong></p> \n <p>常用的JVM启动参数有哪些? 调优命令有哪些？设置堆内存XMX应该考虑哪些因素？</p> \n <p>假设物理内存是8G，设置多大堆内存比较合适? 怎样开启GC日志？</p> \n <h1><a id=\"01JVM____2022_55\"></a>专题01：JVM面试题（卷王专供 + 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/3147521b3f984473ae1130926e87310b.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"02Java____2022_59\"></a>专题02：Java算法面试题（卷王专供 + 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/c22d13868ad14d41b5d648daabd7c394.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"03Java___2022_63\"></a>专题03：Java基础面试题（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/a346fa98bf60405a8f649dd56698709b.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"04___2022_66\"></a>专题04：架构设计面试题（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/939d95ab84034f4ebfaddcf3a8878649.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"05Spring__06SpringMVC__07Tomcat____70\"></a>专题05：Spring面试题__专题06：SpringMVC__专题07：Tomcat面试题（ 史上最全 + 面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/cbd6a32811444a05aada9ed3be6f13e2.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"08SpringBoot___2022_74\"></a>专题08：SpringBoot面试题（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/4682cc04b20e4eb29a908b5a3edef4ba.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"09___2022_78\"></a>专题09：网络协议面试题（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/4f00669a7fdc47129779920f300451d1.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"10TCPIP___2022_82\"></a>专题10：TCP-IP协议（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/d50926558d214794abed653e34728911.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"11JUC___2022_87\"></a>专题11：JUC并发包与容器类（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/95ca77a4fe4e41d8a749034e7431ac22.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"12____2022_90\"></a>专题12：设计模式面试题 （卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/d15b7f5692804f3d8359aefb5992ca73.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"13___2022_96\"></a>专题13：死锁面试题（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/d29c7d1066cf41fabb61f39dc690b44e.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"14Redis_____2022_100\"></a>专题14：Redis 面试题 （卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/9dde7f462dae442f9f328da7fff2fc14.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"15____2022_105\"></a>专题15：分布式锁 面试题（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/7e5620fea5e64e45899409738aee2b31.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"16Zookeeper____2022_110\"></a>专题16：Zookeeper 面试题（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/9d05e9c9173c4b5b8fa0b4d012bc4392.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"17____2022_115\"></a>专题17：分布式事务面试题（卷王专供 + 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/4d853d5275294ced8c87502cd9622ed4.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"18____2022_120\"></a>专题18：一致性协议 （卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/2968bbe9985d4579aacc1671b8796571.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"19Zab___2022_125\"></a>专题19：Zab协议（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/2cec5f595ce24e83befd20bb4bd914cb.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"20Paxos____2022_130\"></a>专题20：Paxos 协议（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/6525845236ba4e16b092d7cf5ddfde5b.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"21raft____2022_135\"></a>专题21：raft 协议（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/c0d2566813e14f87a156a4aa823ee989.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"22Linux___2022_139\"></a>专题22：Linux面试题（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/8679667ed36f478d9f45ba93c7913dad.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"23Mysql____2022_144\"></a>专题23：Mysql 面试题（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/c6210651842b4b44bfd0a690885946f2.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"24SpringCloud____2022_148\"></a>专题24：SpringCloud 面试题（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/fc83b67415f047c3935b15ce35762930.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"25Netty_____2022_153\"></a>专题25：Netty 面试题 （卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/75d398b705a04c4e9fffac6dcfc2e69a.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"26RabbitMQKafkaRocketMQ___2022_158\"></a>专题26：消息队列面试题：RabbitMQ、Kafka、RocketMQ（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/7decee925a6a45c7aaa62b8d043fdf26.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"27____2022_162\"></a>专题27：内存泄漏 内存溢出（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/5fb108dea5234e6087353d9a50b24ae9.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"28JVM_____2022_167\"></a>专题28：JVM 内存溢出 实战（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/711de19b057844d0b1b1b8aa14d2fff4.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"29___2022_172\"></a>专题29：多线程面试题（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/a990cd5c130947899979ffe24811a07d.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"30HR_177\"></a>专题30：HR面试题：过五关斩六将后，小心阴沟翻船！（史上最全、避坑宝典）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/c29f8dee6ec14db98aba2487156784cc.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"31Hash___2022_182\"></a>专题31：Hash连环炮面试题（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/5fa66cff7e1e483cacfd9e7270bd5a42.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"32___2022_186\"></a>专题32：大厂面试的基本流程‌和面试准备（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/5d4f36d379204de2b8ca8fdbeee2f72e.png\" alt=\"在这里插入图片描述\"></p> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 2718);
INSERT INTO `crawlerblog` VALUES (123124009, '峰值21WQps、亿级DAU，小游戏《羊了个羊》是怎么架构的？', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <p>小游戏《羊了个羊》 短短的7天内，DAU突破了1亿、吞吐量峰值21WQps。</p> \n <p>《羊了个羊》运营后台数据显示，在短短的7天内，这款小游戏的DAU就突破了1亿。</p> \n <p>要知道，除了王者荣耀、原神等屈指可数的现象级手游之外，1亿DAU是这个行业的天花板，</p> \n <p>可是，它却被一个看上去设计粗糙的小程序游戏轻松实现了。</p> \n <p>然而，其最初技术架构仅支撑 <strong>5000QPS并发</strong>，7天内突破了1亿、吞吐量峰值21WQps</p> \n <p><img src=\"https://img-blog.csdnimg.cn/fb7c94381162496b918a614af66e122c.png\" alt=\"\"></p> \n <p>如何通过架构优化，让一款小程序游戏可以在短时间内实现对上亿DAU的支持？</p> \n <p>技术架构、运维体系、以及安全防范等技术体系都存在巨大的挑战。</p> \n <p>那么：峰值21WQps、亿级DAU，超高吞吐小游戏，是怎么架构的？</p> \n <h2><a id=\"1__23\"></a>1 低吞吐、低可用的最初技术架构</h2> \n <p>《羊了个羊》最开始的技术架构，</p> \n <p>因为技术以及时间等因素，在设计上有些简单，</p> \n <p>如下图1所示，</p> \n <p><img src=\"https://img-blog.csdnimg.cn/2d0ced68cc034ffdbe45d5164824f037.png\" alt=\"\"></p> \n <p>玩家流量通过一个接入层 LB进入，</p> \n <p>传输给服务层几个 POD 进行游戏逻辑处理，</p> \n <p>再将数据进行存储，</p> \n <p>其中，热数据存储在Redis中, 持久化数据存在MongoDB。</p> \n <p>最初的服务层几个 POD ，都是单点服务</p> \n <p><strong>单点服务的性能瓶颈，再加上代码未进行充分优化，造成当时的系统最高只能承受5000的QPS</strong>，</p> \n <p>但实际流量增长很快， 并且持续升高并到达性能瓶颈，游戏服务开始瘫痪，全部玩家无法再进行游戏。</p> \n <h2><a id=\"2__51\"></a>2 技术架构全面升级</h2> \n <p>大部分项目，都存在低吞吐、低可用的最初技术架构</p> \n <p>但是，如果吞吐量一上来，就面临着优化</p> \n <p>so，</p> \n <p>面对服务中断， 《羊了个羊》团队在详细分析原来架构的不足之后，</p> \n <p>《羊了个羊》 做了 技术架构全面升级</p> \n <p>具体如下图：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/62ccfa9156354bb49b6d238d01c5f63f.png\" alt=\"\"></p> \n <h3><a id=\"_67\"></a>接入层的架构优化：</h3> \n <ul>\n  <li>启用CDN做游戏动静态资源分离，让玩家使用的游戏资源实现就近下载，减轻网络端压力；</li>\n  <li>设计多LB入口实现入口高可用和限流，避免系统被超额流量过载；</li>\n </ul> \n <h3><a id=\"_72\"></a>服务层的架构优化：</h3> \n <ul>\n  <li>优化服务层的自动扩容，应对巨量的 突发流量</li>\n  <li>具体措施上，首先通过引入腾讯云TKE Serverless 的弹性机制，实现游戏服自动纵向和横向扩展，</li>\n  <li>实现服务解藕，增加容错和熔断机制；</li>\n </ul> \n <h3><a id=\"Cache_78\"></a>Cache层的架构优化：</h3> \n <ul>\n  <li>Redis缓存热数据，分担数据库查询压力等。</li>\n </ul> \n <h3><a id=\"_82\"></a>存储层的架构优化：</h3> \n <ul>\n  <li>把MongoDB转换为读写分离模式，配合代码逻辑优化实现性能提升，</li>\n  <li>引入分库实现业务分层与隔离，</li>\n </ul> \n <p>优化之后，《羊了个羊》最新技术架构</p> \n <p><img src=\"https://img-blog.csdnimg.cn/0a11d190a91b4146a7dc22a1570d18d8.png\" alt=\"\"></p> \n <p>经过上述一系列技术升级， 新架构经受住了一波又一波的流量峰值考验，</p> \n <p>在高峰期DAU过亿后，游戏技术系统依旧表现稳定，</p> \n <p>这对于一个发布才几个月的小游戏来说，在国内也很难再找到这样的例子。</p> \n <h2><a id=\"3__105\"></a>3 运维体系的升级</h2> \n <p>通过技术架构的迭代以及不断激增的用户，《羊了个羊》技术团队也认识到，因为爆火太快，更需要快速补齐运维能力，才能更好的持续调整和提升游戏体验。</p> \n <p>在运维体系这块，包括 业务日志、性能监测等。</p> \n <p>为快速补齐运维能力，通过<strong>业务日志诊断</strong>程序性能，配合业务调优以减少服务器压力；</p> \n <p>《羊了个羊》选择了开箱即用的日志服务 云服务度 CLS，</p> \n <p>当然，有条件的团队，使用自建的 elk平台，或者基于clickhouse的高并发分布式日志监测平台，也是可以的。</p> \n <p>CLS 对游戏接口稳定性、异常调用趋势的监控可帮助他们快速观测产品质量 ，并第一时间获取到异常panic统计分析和告警 ；</p> \n <p>在游戏运营方面，玩家登录链路耗时/对局时间等数据亦可通过 CLS 分析、校验及处理，进而调整和提升游戏体验；同时还能满足游戏用户行为及审计对账等需求。</p> \n <p><strong>CLS的云原生特性，辅助进行稳定性和程序性能调优。另外，CLS用作简单运维工具查日志、做接口调用告警</strong></p> \n <p>借助CLS的SQL分析、仪表盘、监控告警能力，</p> \n <p>可以分析出程序可优化点，解决游戏开发商在初期和爆发期对游戏稳定性和运营数据分析的难题。</p> \n <p>除了运维数据外，</p> \n <p>CLS还提供了数据观测功能</p> \n <p>在游戏调整玩法、分析活动数据时，运营人员可借助CLS快速观测数据变化，并作出应对策略。</p> \n <p>另外，还将游戏的通关数据、用户行为分析、审计对账等运营数据在CLS中存储分析。</p> \n <h2><a id=\"4__141\"></a>4 安全防范领域的升级</h2> \n <p>哪里有流量，哪里就有黑产。</p> \n <p>许多恶意BOT流量大量涌入到游戏中，导致游戏服务器 QPS、带宽快速升高，影响服务可用性等情况</p> \n <p>由于设计之初没有充分考虑安全问题，因此引来大量不法分子通过恶意BOT抢刷游戏排行，</p> \n <p>几乎每分每秒，都有恶意流量访问游戏接口，</p> \n <p>并且这一部分恶意群体通过互联网、QQ群和微信群中传播恶意刷排行的脚本，</p> \n <p>极大的破坏了游戏公平性，让本该属于游戏对抗的乐趣被恶意BOT抹杀。</p> \n <p>而且更重要的是随着羊了个羊热度的不但攀升，许多恶意BOT流量的大量涌入，导致游戏服务器 QPS、带宽快速升高，一度影响服务可用性。</p> \n <p><strong>《羊了个羊》接入腾讯云WAF进行防护，</strong></p> \n <p><strong>一开始接入WAF的时候，相关 QPS 峰值已达 21W，</strong></p> \n <p><strong>接入WAF之前CPU一直处于临界值水位 、网络链接打满的导致服务不可用的情况。</strong></p> \n <p><img src=\"https://img-blog.csdnimg.cn/c9365826cbb34d86bfc72c11ef7ecedc.png\" alt=\"\"></p> \n <p>通过选择负载均衡型WAF, 即可在不改动网络架构的情况下3秒完成业务接入WAF，实现在用户无感的情况下对恶意流量进行清洗及防护。</p> \n <p>为了有效打击攻击者的恶意流量，</p> \n <p>WAF 中 BOT 行为管理也提供了全链路、全生命周期的的恶意行为流量体系，实现快速高效的恶意流量治理。</p> \n <p>最后在安全防范领域，通过安全方案抵抗异常流量攻击。</p> \n <blockquote> \n  <p>注：本文以 PDF 持续更新，最新尼恩 架构笔记、面试题 的PDF文件，请从这里获取：<a href=\"https://gitee.com/crazymaker/SimpleCrayIM/blob/master/%E7%96%AF%E7%8B%82%E5%88%9B%E5%AE%A2%E5%9C%88%E6%80%BB%E7%9B%AE%E5%BD%95.md\">码云</a></p> \n </blockquote> \n <h2><a id=\"5__180\"></a>5 互联网应用设计的“三高”原则</h2> \n <p>通过《羊了个羊》团队在小游戏架构扩容、系统运维以及安全防范领域的实战经验，可以给大家一些参考。</p> \n <p>面对突发流量，互联网应用在设计的过程中需要考虑以下能力：</p> \n <p>第一是<strong>高并发</strong>，能够承载瞬时爆发流量，保证响应时长在可接受的范围；</p> \n <p>其次是<strong>高可用</strong>，系统持续提供服务，小概率发生宕机时，过载保护将故障控制在可承受范围内，不影响核心业务；</p> \n <p>最后是<strong>高扩展</strong>，服务系统应该具备水平和垂直扩展能力，在成本和可用性中实现最佳平衡点。</p> \n <h2><a id=\"_195\"></a>推荐阅读：</h2> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128670335\">Docker面试题（史上最全 + 持续更新）</a>》</p> \n <p>《 <a href=\"https://blog.csdn.net/crazymakercircle/article/details/128533821\">场景题：假设10W人突访，你的系统如何做到不 雪崩？</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124790425\">尼恩Java面试宝典</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057567\">Springcloud gateway 底层原理、核心实战 (史上最全)</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124120506\">Flux、Mono、Reactor 实战（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125059491\">sentinel （史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057545\">Nacos (史上最全)</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/123420859\">分库分表 Sharding-JDBC 底层原理、核心实战（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/114527369\">TCP协议详解 (史上最全)</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126992542\">clickhouse 超底层原理 + 高可用实操 （史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120702536\">nacos高可用（图解+秒懂+史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264803\">队列之王： Disruptor 原理、架构、源码 一文穿透</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264508\">环形队列、 条带环形队列 Striped-RingBuffer （史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125135726\">一文搞定：SpringBoot、SLF4j、Log4j、Logback、Netty之间混乱关系（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128265067\">单例模式（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125017316\">红黑树（ 图解 + 秒懂 + 史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/109459593\">分布式事务 （秒懂）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128123114\">缓存之王：Caffeine 源码、架构、原理（史上最全，10W字 超级长文）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/113751575\">缓存之王：Caffeine 的使用（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126579528\">Java Agent 探针、字节码增强 ByteBuddy（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120747767\">Docker原理（图解+秒懂+史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/116425814\">Redis分布式锁（图解 - 秒懂 - 史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85956246\">Zookeeper 分布式锁 - 图解 - 秒懂</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85922561\">Zookeeper Curator 事件监听 - 10分钟看懂</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83957259\">Netty 粘包 拆包 | 史上最全解读</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83758107\">Netty 100万级高并发服务器配置</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/102557988\">Springcloud 高并发 配置 （一文全懂）</a>》</p> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 1943);
INSERT INTO `crawlerblog` VALUES (123124010, '场景题：假设10W人突访，你的系统如何做到不 雪崩？', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <p>文章很长，而且持续更新，建议收藏起来，慢慢读！<a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\"><strong>疯狂创客圈总目录 博客园版</strong></a> 为您奉上珍贵的学习资源 ：</p> \n <p>免费赠送 :<a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\"><strong>《尼恩Java面试宝典》</strong></a> 持续更新+ 史上最全 + 面试必备 2000页+ 面试必备 + 大厂必备 +涨薪必备<br> 免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\"><strong>《Java高并发核心编程（卷1）加强版》</strong></a> 面试必备 + 大厂必备 +涨薪必备 加尼恩免费领<br> 免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\"><strong>《Java高并发核心编程（卷2）加强版》</strong> </a>面试必备 + 大厂必备 +涨薪必备 加尼恩免费领<br> 免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\"><strong>《Java高并发核心编程（卷3）加强版》</strong></a> 面试必备 + 大厂必备 +涨薪必备 加尼恩免费领<br> 免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\">《<strong>尼恩Java面试宝典 V11</strong>》 </a>面试必备 + 大厂必备 +涨薪必备 加尼恩免费领<br> 免费赠送 资源宝库： <strong>Java 必备 百度网盘资源大合集 价值</strong>&gt;10000元 加尼恩领取</p> \n <h2><a id=\"10W__9\"></a>一个普通系统，假设10W人同时访问，如何保证不 雪崩？</h2> \n <p><strong>这个，是面试当中，一道非常场景的： 场景题。</strong></p> \n <p>如果面试遇到这个问题，很多小伙伴的第一反应：</p> \n <p><strong>怎么可能，我们的系统，总体的用户量，不到1万， 怎么可能会有10W人同时访问。</strong></p> \n <p>这个问题，如果遇到了，只能会硬着头皮作答。</p> \n <p>如果直接用这个疑问，去反问面试官，那么 ，面试官一定会说这小子 没有遇到过事情。</p> \n <p>为啥呢？</p> \n <p>因为哪怕用户不到1万，还是可能会有10W人同时访问。</p> \n <p>这些人包括：</p> \n <ul>\n  <li>爬虫</li>\n  <li>刷子（羊毛党）</li>\n </ul> \n <h3><a id=\"_31\"></a>爬虫对访问量的贡献</h3> \n <p>大家应该听过一句话吧，整个互联网上大概有 50%以上的流量其实是爬虫。</p> \n <p>一个做反爬虫哥们，发现了一个极端案例，</p> \n <p>某个页面12000次点击里边，98%的点击率，是爬虫贡献的。</p> \n <p>爬虫和用户的比例是 19比1.</p> \n <p>那么 1W用户， 可能会对应到19W 爬虫，</p> \n <p>那么 1W用户， 有没有 10W的 同时访问的可能呢？</p> \n <p>因为 大量爬虫的存着， 当然有的。</p> \n <h3><a id=\"_47\"></a>刷子用户（羊毛党）对访问量的贡献</h3> \n <p>“羊毛党”战术之一：开启机器人批量注册新账号，招募“新兵”。</p> \n <p>“这是个‘昏招’，批量注册的账号很容易识别。</p> \n <p>“羊毛党”战术之二：提前囤积账号，囤积的老账号”。</p> \n <p>但通过注册时间、注册地与下单地比对等方式，很快识别出来。</p> \n <p>某年的“618”电商节活动期间，某电商公司，平均每天拦截“羊毛党”账号2000万个。</p> \n <p>那么 1W用户， 可能会对应到多少羊毛党用户呢？</p> \n <p>其中，可能会包含部分 <strong>提前囤积账号</strong></p> \n <p>另外，在 活动执行的过程中， 还是有 可能 <strong>批量注册大量的新账号</strong></p> \n <p>那么 1W用户， 有没有 10W的 同时访问的可能呢？</p> \n <p>只要有利可图，就会有 刷子用户（羊毛党），他们会通过群体人手，或者 <strong>自动化工具</strong>，<strong>制造大量的瞬间流量</strong>。</p> \n <p>这些自动化工具，在 1s之内， 尝试10W次。</p> \n <p>所以，只要是有利可图，如 秒杀等， 那么 1W用户， 有没有 10W的 同时访问的可能呢？</p> \n <p>当然有的。</p> \n <h2><a id=\"10W_77\"></a>假设10W人突然访问，现有架构能否扛住？</h2> \n <p>按照之前尼恩和大家分析的架构理论</p> \n <p>一个系统10W人同时访问 ， 也就是：并发量为 10w Qps</p> \n <p><strong>那么 10w Qps ，对应到多少用户量呢 ?</strong></p> \n <p><strong>是 一个1亿的用户量。</strong></p> \n <p>而 ，我们很多同学手上的 系统， 总体的用户量 不到1万，</p> \n <p>不到1万的用户，对应到多少 的 吞吐量呢？</p> \n <p>是 10。</p> \n <p>没错，如果 总体的用户量 不到1万，按照 正常估算， 吞吐量就只有 10。</p> \n <p>也就是说， 如果我们按照 1万 做系统架构</p> \n <p><img src=\"https://img-blog.csdnimg.cn/5f79eddf0b5b4d7489257e2d266321f7.png\" alt=\"在这里插入图片描述\"></p> \n <p>这种架构，对于 qps 为10 的小流量来说，可以说是 小菜一碟。</p> \n <p>可以说，用牛刀 在 杀鸡。</p> \n <img src=\"https://inews.gtimg.com/newsapp_bt/0/13738654191/1000.jpg\" alt=\"img\"> \n <p>那么，如果发生突发情况，</p> \n <p>假设10W人突然访问，我们的架构，如何抵抗？</p> \n <p><img src=\"https://img-blog.csdnimg.cn/fe36ff8dff9742fa836fdc97df11b818.png\" alt=\"在这里插入图片描述\"></p> \n <p>大家看看，上面的架构， 能抵抗吗？</p> \n <h3><a id=\"_127\"></a>接入层和服务层如何抵抗？</h3> \n <p>方式之一： 扩容</p> \n <p>方式之二：限流</p> \n <h3><a id=\"__137\"></a>首先能用到的策略： 扩容</h3> \n <p>大家首先会想到的策略，就是扩容。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/87b83c89142a4e2290514ab46682b454.png\" alt=\"在这里插入图片描述\"></p> \n <p>但是，如果流量是突发的， 又不知道什么时候扩， 怎么办呢？</p> \n <p>那么就是<strong>自动扩容</strong>。</p> \n <p><strong>自动扩容</strong>虽然比较难，办法总是有的，只要稍微想想，就出来了。</p> \n <p>大致有两种自动扩容方式，具体请参见 《java 高并发核心编程 卷3》 第 1.5.3 小节。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/af502ec939274e9baa22621ca8adedf9.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"__161\"></a>其次能用到的策略： 限流</h3> \n <ul>\n  <li>nginx 限流</li>\n  <li>SpringCloud gateway 限流</li>\n </ul> \n <p>接入层限流可以进行 nginx 限流</p> \n <p><img src=\"https://img-blog.csdnimg.cn/65da6367f8a04f3f9810ea346916be53.png\" alt=\"在这里插入图片描述\"></p> \n <p>微服务 SpringCloud gateway 里边，</p> \n <p>还 可以使用 redis lua进行分布式限流， 或者使用 sentinel 进行 限流，</p> \n <p>经过 扩容和限流， 咱们的系统，应该可以扛住 10Wqps， 因为可以把流量限制到 1Wqps，甚至是 1 K qps。</p> \n <p>谁怪 有那么多刷子流量，或者 爬虫流量呢。</p> \n <p>但是，限流是无奈之举。</p> \n <p>或者说，如果10Wqps，都是有效流量， 不能使用限流这 简单粗暴的方式 ， 而是这个 10Wqps 必须进入到服务层。</p> \n <h3><a id=\"Redis_194\"></a>分布式Redis集群如何抵抗？</h3> \n <p>这个 10Wqps 必须进入到服务层。</p> \n <p>怎么办？</p> \n <p>服务层 倒是好说，和网关一样， 可以通过扩容解决。</p> \n <p>所以，后面的 流量就进入 redis集群。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/9f8e30f9ed254029ae2311bf7e2299d5.png\" alt=\"在这里插入图片描述\"></p> \n <p>redis 集群一般搭建的是 3主3从：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/bd1960e818f9640d3800b1c7ddf56b8d.png\" alt=\"img\"></p> \n <p>一般来说，主节点提供服务， 从节点是做冗余的， 并不提供数据的写入服务。</p> \n <p>redis cluster模式官方默认主节点提供读写, 从节点提供slot数据备份以及故障转移。默认情况下，从节点并不提供数据读写服务。</p> \n <p>单个redis 的吞吐量，一般就是 2W左右。</p> \n <p>那么 10Wqps，访问 redis cluster，分布到 3个节点， 还是不够。</p> \n <p>如果 10Wqps 访问的是同一个key， 那就问题更大了。</p> \n <p>因为 单个redis 的吞吐量，一般就是 2W左右。 怎么可能扛住 5倍的吞吐量。</p> \n <p>于是就很容易出现 redis cpu 100%， 请求排队， 没有响应，严重的情况 出现 redis 雪崩。</p> \n <p>于是乎，改怎么办?</p> \n <p>大概也有两种方案：</p> \n <p>方法一： redis 扩容</p> \n <p>方法二： 本地缓存</p> \n <p>方法一 redis 扩容 可以解决 key 的访问量比较 均匀的问题。比如扩容到 10主10从，就可以承担 20Wqps的 流量。</p> \n <p>但是方法一 要求每个key的访问量 必须分布得比较均匀。如果20w qps 的流量，全部来自一个key， 则方案一 无效。</p> \n <p>方法二 本地缓存 可以解决 单个key 访问量 巨大的问题。这种 占据大量流量的 单个key，叫做 hotkey（热key）。</p> \n <p>所以，接下来，还是得调整系统的架构， 加入本地缓存的 环节。</p> \n <h2><a id=\"_10WQps__254\"></a>解决 10WQps 突发流量的本地缓存架构</h2> \n <p>解决 10WQps 突发流量的本地缓存架构，大致有两种：</p> \n <ul>\n  <li>二级缓存架构</li>\n  <li>三级缓存架构</li>\n </ul> \n <h3><a id=\"_265\"></a>二级缓存架构：</h3> \n <p>java 本地缓存+ redis 分布式缓存，具体如下图：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/38fb9161986240fc93436c7fcaf34b8b.png\" alt=\"在这里插入图片描述\"></p> \n <p>先发问一级缓存caffeine ，如果 没有找到，再访问 二级缓存 redis 集群</p> \n <h3><a id=\"_281\"></a>三级缓存架构：</h3> \n <p>nginx本地缓存+ java 本地缓存+ redis 分布式缓存，具体如下图：</p> \n <img src=\"https://img-blog.csdnimg.cn/cf89eb4e346646448403df675b6c73f1.png\" alt=\"在这里插入图片描述\"> \n <h3><a id=\"_289\"></a>本地缓存的优缺点</h3> \n <p><strong>1. 快但是量少：访问速度快，但无法进行大数据存储</strong></p> \n <p>本地缓存相对于分布式缓存的好处是，由于数据不需要跨网络传输，故性能更好，</p> \n <p>但是由于占用了应用进程的内存空间，如 Java 进程的 JVM 内存空间，故不能进行大数据量的数据存储。</p> \n <p><strong>2. 需要解决数据一致性问题：本地缓存、分布式缓存、DB数据一致性问题</strong></p> \n <p>与此同时，本地缓存只支持被该应用进程访问，一般无法被其他应用进程访问，故在应用进程的集群部署当中，</p> \n <p>如果对应的数据库数据，存在数据更新，则需要<strong>同步更新不同部署节点的缓存数据</strong>来包保证数据一致性，</p> \n <p>复杂度较高并且容易出错，如基于 rocketmq 的发布订阅机制来同步更新各个部署节点。</p> \n <p><strong>3.未持久化，容易丢失： 数据随应用进程的重启而丢失</strong></p> \n <p>由于本地缓存的数据是存储在应用进程的内存空间的，所以当应用进程重启时，本地缓存的数据会丢失。</p> \n <p>所以对于需要更改然后持久化的数据，需要注意及时保存，否则可能会造成数据丢失。</p> \n <p><strong>4.需要尽量缓存热点key，而提升缓存的命中率</strong></p> \n <p>由于本地缓存太小，从而很容易被淘汰，</p> \n <p>如果还没有来得及访问，本地缓存中的数据，就被淘汰了，那就失去了本地缓存的价值， 当然，本地缓存的命中率也会很低。</p> \n <h3><a id=\"_317\"></a>如何提升缓存的命中率？</h3> \n <p><strong>方式1： 采用更好的 缓存淘汰策略</strong></p> \n <p>比如caffeine中，使用了 w-tinylfu 策略。</p> \n <p>这种策略的 缓存的命中率，比较简单的 lfu、lru 都 高出很多。</p> \n <p>有测试表明： caffeine 比 guava 的命中率，不同场景，都会高出10%以上。</p> \n <p><strong>方式2： 尽量识别和缓存 热点数据</strong></p> \n <p>简单的说，把热点数据， 加载到本地缓存。</p> \n <h2><a id=\"HotKey_337\"></a>什么是HotKey？</h2> \n <p>在某个Key接收到的访问次数、显著高于其它Key时，我们可以将其称之为HotKey，</p> \n <p>从访问量上来说，常见的HotKey如：</p> \n <ul>\n  <li>某Redis实例的每秒总访问量为10000，而其中一个Key的每秒访问量达到了7000（访问次数显著高于其它Key）</li>\n  <li>对一个拥有上千个成员且总大小为1MB的HASH Key每秒发送大量的HGETALL（带宽占用显著高于其它Key）</li>\n  <li>对一个拥有数万个成员的ZSET Key每秒发送大量的ZRANGE（CPU时间占用显著高于其它Key）</li>\n </ul> \n <p>从业务上来说， 常见的HotKey如：</p> \n <p><strong>1 、MySQL等数据库会被频繁访问的热数据</strong></p> \n <p>如爆款商品的skuId。</p> \n <p><strong>2 、redis的被密集访问的key</strong></p> \n <p>如爆款商品的各维度信息，skuId、shopId等。</p> \n <p><strong>3 、机器人、爬虫、刷子用户</strong></p> \n <p>如用户的userId、uuid、ip等。</p> \n <p><strong>4 、某个接口地址</strong></p> \n <p>如/sku/query或者更精细维度的。</p> \n <p>注意，我们的HotKey探测框架只关心key，其实就是一个字符串，</p> \n <h3><a id=\"HotKey_375\"></a>HotKey对服务层和数据层的风险</h3> \n <p>在拥有大量并发用户的系统中，HotKey一直以来都是一个不可避免的问题。</p> \n <ul>\n  <li> <p>或许是突然某些商品成了爆款，</p> </li>\n  <li> <p>或许是海量用户突然涌入某个店铺，</p> </li>\n  <li> <p>或许是秒杀时瞬间大量开启的爬虫用户，</p> </li>\n  <li> <p><strong>突发大批机器人</strong>以远超正常用户的速度发起极其密集的请求，这些机器人只需要很小的代价，就能发出百倍于普通用户的请求量，从而大幅挤占正常用户的资源。</p> </li>\n </ul> \n <p>以京东为例的这些头部互联网公司，动辄某个爆品，会瞬间引入每秒上百万甚至数百万的请求，当然流量多数会在几秒内就消失。</p> \n <p>但就是这短短的几秒的HotKey，就会瞬间造成其所在redis分片集群瘫痪。</p> \n <p>原因也很简单，redis作为一个单线程的结构，所有的请求到来后都会去排队，当请求量远大于自身处理能力时，后面的请求会陷入等待、超时。</p> \n <p>由于该redis分片完全被这个key的请求给打满，导致该分片上所有其他数据操作都无法继续提供服务，也就是HotKey不仅仅影响自己，还会影响和它合租的数据。</p> \n <p>这样，redis 缓存没有响应之后，相当于 redis 击穿， 请求直接转向DB</p> \n <p>DB的吞吐量，比如会低很多，DB 就会雪崩。</p> \n <h4><a id=\"HotKey_400\"></a>总结一下，HotKey带来的常见问题</h4> \n <ul>\n  <li>HotKey占用大量的Redis CPU时间，使其性能变差并影响其它请求；</li>\n  <li>Redis Cluster中各node流量不均衡造成Redis Cluster的分布式优势无法被Client利用，一个分片负载很高而其它分片十分空闲从而产生读/写热点问题；</li>\n  <li>在抢购、秒杀活动中，由于商品对应库存Key的请求量过大，超出Redis处理能力造成超卖；</li>\n  <li>HotKey的请求压力数量超出Redis的承受能力造成缓存击穿，此时大量强求将直接指向后端存储，将后端存储打挂并影响到其它业务；</li>\n </ul> \n <h4><a id=\"HotKey_407\"></a><strong>HotKey问题的根本：</strong></h4> \n <p>HotKey问题归根到底就是如何找到HotKey，并将HotKey放到本地内存的问题。</p> \n <p>只要该key在内存里，我们就能极快地来对它做逻辑，内存访问和redis访问的速度不在一个量级。</p> \n <p>如果该key是在本地内存中，读取一个内存中的值，每秒多少个万次都是很正常的，不存在任何数据层的瓶颈。</p> \n <p>但问题是事先不知道HotKey在哪里？</p> \n <p>那么，问题就来了，如何进行 HotKey的探测？</p> \n <h3><a id=\"HotKey_421\"></a>HotKey探测关键指标</h3> \n <p><strong>1、实时性</strong></p> \n <p>这个很容易理解，key往往是突发性瞬间就热了，根本不给你再慢悠悠手工去配置中心添加HotKey再推送到jvm的机会。</p> \n <p>它大部分时间不可预知，来得也非常迅速，可能某个商家上个活动，瞬间HotKey就出现了。如果短时间内没能进到内存，就有redis集群被打爆的风险。</p> \n <p>所以HotKey探测框架最重要的就是实时性，最好是某个key刚有热的苗头，在1秒内它就已经进到整个服务集群的内存里了，1秒后就不会再去密集访问redis了。</p> \n <p>同理，对于刷子用户也一样，刚开始刷，1秒内我就把它给禁掉了。</p> \n <p><strong>2、准确性</strong></p> \n <p>这个很重要，也容易实现，累加数量，做到不误探，精准探测，保证探测出的HotKey是完全符合用户自己设定的阈值。</p> \n <p><strong>3、集群一致性</strong></p> \n <p>这个比较重要，尤其是某些带删除key的场景，要能做到删key时整个集群内的该key都会删掉，以避免数据的错误。</p> \n <p><strong>4、高性能</strong></p> \n <p>这个是核心之一，高性能带来的就是低成本，做HotKey探测目的就是为了降低数据层的负载，提升应用层的性能，节省服务器资源。不然，大家直接去整体扩充redis集群规模就好了。</p> \n <p>理论上，在不影响实时性的情况下，要完成实时HotKey探测，所消耗的机器资源越少，那么经济价值就越大。</p> \n <h2><a id=\"HotKey_451\"></a>如何实现HotKey探测？</h2> \n <h4><a id=\"HotKey1___455\"></a>HotKey探测方案1： 流计算集群</h4> \n <p>通过 流式计算集群 storm/ flink 集群，进行 topkey</p> \n <p><img src=\"https://img-blog.csdnimg.cn/3d0e120e4ef74232bd74aa8cc0490778.png\" alt=\"在这里插入图片描述\"></p> \n <p>java 应用将访问 记录发送到 消息队列，如 kafka</p> \n <p>storm、flink 集群，进行top N 的计算，把top N 结果存在 redis</p> \n <p>其中的 top N 的key，就是热点 key</p> \n <h4><a id=\"HotKey2___473\"></a>HotKey探测方案2： 流计算集群</h4> \n <p>有赞透明多级缓存解决方案</p> \n <h4><a id=\"HotKey3__hotkey_481\"></a>HotKey探测方案3： 结合开源hotkey，做热点探测</h4> \n <p>比如：结合京东开源hotkey，做热点探测</p> \n <h2><a id=\"HotKey2TMC_489\"></a>HotKey探测方案2：有赞透明多级缓存解决方案（TMC）</h2> \n <h3><a id=\"TMC_491\"></a>一、TMC简介</h3> \n <h4><a id=\"11_TMC__493\"></a>1-1. TMC 是什么</h4> \n <p>TMC ，即“透明多级缓存（ Transparent Multilevel Cache ）”，是有赞 PaaS 团队给公司内应用提供的整体缓存解决方案。</p> \n <p>TMC 在通用“分布式缓存解决方案（如 CodisProxy + Redis ，如有赞自研分布式缓存系统 zanKV ）”基础上，增加了以下功能：</p> \n <ul>\n  <li>应用层热点探测</li>\n  <li>应用层本地缓存</li>\n  <li>应用层缓存命中统计</li>\n </ul> \n <p>以帮助应用层解决缓存使用过程中出现的热点访问问题。</p> \n <h4><a id=\"12__TMC_505\"></a>1-2. 为什么要做 TMC</h4> \n <p>使用有赞服务的电商商家数量和类型很多，商家会不定期做一些“商品秒杀”、“商品推广”活动，导致“营销活动”、“商品详情”、“交易下单”等链路应用出现 <strong>缓存热点访问</strong> 的情况：</p> \n <ul>\n  <li>活动时间、活动类型、活动商品之类的信息不可预期，导致 <em>缓存热点访问</em> 情况不可提前预知；</li>\n  <li><em>缓存热点访问</em> 出现期间，应用层少数 <strong>热点访问 key</strong> 产生大量缓存访问请求：冲击分布式缓存系统，大量占据内网带宽，最终影响应用层系统稳定性；</li>\n </ul> \n <p>为了应对以上问题，需要一个能够 <em>自动发现热点</em> 并 <em>将热点缓存访问请求前置在应用层本地缓存</em> 的解决方案，这就是 TMC 产生的原因。</p> \n <h4><a id=\"13__514\"></a>1-3. 多级缓存解决方案的痛点</h4> \n <p>基于上述描述，我们总结了下列 <strong>多级缓存解决方案</strong> 需要解决的需求痛点：</p> \n <ul>\n  <li>热点探测：如何快速且准确的发现 <strong>热点访问 key</strong> ？</li>\n  <li>数据一致性：前置在应用层的本地缓存，如何保障与分布式缓存系统的数据一致性？</li>\n  <li>效果验证：如何让应用层查看本地缓存命中率、热点 key 等数据，验证多级缓存效果？</li>\n  <li>透明接入：整体解决方案如何减少对应用系统的入侵，做到快速平滑接入？</li>\n </ul> \n <p>TMC 聚焦上述痛点，设计并实现了整体解决方案。</p> \n <p>以支持“热点探测”和“本地缓存”，减少热点访问时对下游分布式缓存服务的冲击，避免影响应用服务的性能及稳定性。</p> \n <h3><a id=\"_TMC__527\"></a>二、 TMC 整体架构</h3> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/d6ec25bff00b047fef725f0b0328bd22.png\" alt=\"图片描述\"></p> \n <p>TMC 整体架构如上图，共分为三层：</p> \n <ul>\n  <li>存储层：提供基础的kv数据存储能力，针对不同的业务场景选用不同的存储服务（ codis / zankv / aerospike ）；</li>\n  <li>代理层：为应用层提供统一的缓存使用入口及通信协议，承担分布式数据水平切分后的路由功能转发工作；</li>\n  <li>应用层：提供统一客户端给应用服务使用，内置“热点探测”、“本地缓存”等功能，对业务透明；</li>\n </ul> \n <h3><a id=\"_TMC__541\"></a>三、 TMC 本地缓存</h3> \n <h4><a id=\"31__543\"></a>3-1. 如何透明</h4> \n <p>TMC 是如何减少对业务应用系统的入侵，做到透明接入的？</p> \n <p>对于公司 Java 应用服务，在缓存客户端使用方式上分为两类：</p> \n <ul>\n  <li>基于<code>spring.data.redis</code>包，使用<code>RedisTemplate</code>编写业务代码；</li>\n  <li>基于<code>youzan.framework.redis</code>包，使用<code>RedisClient</code>编写业务代码；</li>\n </ul> \n <p>不论使用以上那种方式，最终通过<code>JedisPool</code>创建的<code>Jedis</code>对象与缓存服务端代理层做请求交互。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/3831041bc339fcea2f09ae1126817099.png\" alt=\"图片描述\"></p> \n <p>TMC 对原生jedis包的<code>JedisPool</code>和<code>Jedis</code>类做了改造，</p> \n <p>在JedisPool初始化过程中, 集成TMC“热点发现”+“本地缓存”功能<code>Hermes-SDK</code>包的初始化逻辑，</p> \n <p>使<code>Jedis</code>客户端与缓存服务端代理层交互时, 先与<code>Hermes-SDK</code>交互，从而完成 “热点探测”+“本地缓存”功能的透明接入。</p> \n <p>对于 Java 应用服务，只需使用特定版本的 jedis-jar 包，无需修改代码，即可接入 TMC 使用“热点发现”+“本地缓存”功能，做到了对应用系统的最小入侵。</p> \n <h4><a id=\"32__566\"></a>3-2. 整体结构</h4> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/dbf1157261101a8676a4cb9a63922894.png\" alt=\"图片描述\"></p> \n <h5><a id=\"321__572\"></a>3-2-1. 模块划分</h5> \n <p>TMC 本地缓存整体结构分为如下模块：</p> \n <ul>\n  <li><strong>Jedis-Client</strong>： Java 应用与缓存服务端交互的直接入口，接口定义与原生 Jedis-Client 无异；</li>\n  <li><strong>Hermes-SDK</strong>：自研“热点发现+本地缓存”功能的SDK封装， Jedis-Client 通过与它交互来集成相应能力；</li>\n  <li><strong>Hermes服务端集群</strong>：接收 Hermes-SDK 上报的缓存访问数据，进行热点探测，将热点 key 推送给 Hermes-SDK 做本地缓存；</li>\n  <li><strong>缓存集群</strong>：由代理层和存储层组成，为应用客户端提供统一的分布式缓存服务入口；</li>\n  <li><strong>基础组件</strong>： etcd 集群、 Apollo 配置中心，为 TMC 提供“集群推送”和“统一配置”能力；</li>\n </ul> \n <h5><a id=\"322__582\"></a>3-2-2. 基本流程</h5> \n <p>1） key 值获取</p> \n <ul>\n  <li>Java 应用调用 <strong>Jedis-Client</strong> 接口获取key的缓存值时，<strong>Jedis-Client</strong> 会询问 <strong>Hermes-SDK</strong> 该 key 当前是否是 <strong>热点key</strong>；</li>\n  <li>对于 <strong>热点key</strong> ，直接从 <strong>Hermes-SDK</strong> 的 <em>热点模块</em> 获取热点 key 在本地缓存的 value 值，不去访问 <strong>缓存集群</strong> ，从而将访问请求前置在应用层；</li>\n  <li>对于非 <strong>热点key</strong> ，<strong>Hermes-SDK</strong> 会通过<code>Callable</code>回调 <strong>Jedis-Client</strong> 的原生接口，从 <strong>缓存集群</strong> 拿到 value 值；</li>\n  <li>对于 <strong>Jedis-Client</strong> 的每次 key 值访问请求，<strong>Hermes-SDK</strong> 都会通过其 <em>通信模块</em> 将 <strong>key访问事件</strong> 异步上报给 <strong>Hermes服务端集群</strong> ，以便其根据上报数据进行“热点探测”；</li>\n </ul> \n <p>2）key值过期</p> \n <ul>\n  <li>Java 应用调用 <strong>Jedis-Client</strong> 的<code>set()</code> <code>del()</code> <code>expire()</code>接口时会导致对应 key 值失效，<strong>Jedis-Client</strong> 会同步调用 <strong>Hermes-SDK</strong> 的<code>invalid()</code>方法告知其“ key 值失效”事件；</li>\n  <li>对于 <strong>热点key</strong> ，<strong>Hermes-SDK</strong> 的 <em>热点模块</em> 会先将 key 在本地缓存的 value 值失效，以达到本地数据<strong>强一致</strong>。同时 <em>通信模块</em> 会异步将“ key 值失效”事件通过 <strong>etcd集群</strong> 推送给 Java 应用集群中其他 <strong>Hermes-SDK</strong> 节点；</li>\n  <li>其他<strong>Hermes-SDK</strong>节点的 <em>通信模块</em> 收到 “ key 值失效”事件后，会调用 <em>热点模块</em> 将 key 在本地缓存的 value 值失效，以达到集群数据<strong>最终一致</strong>；</li>\n </ul> \n <p>3）热点发现</p> \n <ul>\n  <li><strong>Hermes服务端集群</strong> 不断收集 <strong>Hermes-SDK</strong>上报的 <strong>key访问事件</strong>，对不同业务应用集群的缓存访问数据进行周期性（3s一次）分析计算，以探测业务应用集群中的<strong>热点key</strong>列表；</li>\n  <li>对于探测到的<strong>热点key</strong>列表，<strong>Hermes服务端集群</strong> 将其通过 <strong>etcd集群</strong> 推送给不同业务应用集群的 <strong>Hermes-SDK</strong> <em>通信模块</em>，通知其对<strong>热点key</strong>列表进行本地缓存；</li>\n </ul> \n <p>4）配置读取</p> \n <ul>\n  <li><strong>Hermes-SDK</strong> 在启动及运行过程中，会从 <strong>Apollo配置中心</strong> 读取其关心的配置信息（如：启动关闭配置、黑白名单配置、etcd地址…）；</li>\n  <li><strong>Hermes服务端集群</strong> 在启动及运行过程中，会从 <strong>Apollo配置中心</strong> 读取其关心的配置信息（如：业务应用列表、热点阈值配置、 etcd 地址…）；</li>\n </ul> \n <h5><a id=\"323__607\"></a>3-2-3. 稳定性</h5> \n <p>TMC本地缓存稳定性表现在以下方面：</p> \n <ul>\n  <li>数据上报异步化：<strong>Hermes-SDK</strong> 使用<code>rsyslog技术</code>对“ key 访问事件”进行异步化上报，不会阻塞业务；</li>\n  <li>通信模块线程隔离：<strong>Hermes-SDK</strong> 的 <em>通信模块</em> 使用独立线程池+有界队列，保证事件上报&amp;监听的I/O操作与业务执行线程隔离，即使出现非预期性异常也不会影响基本业务功能；</li>\n  <li>缓存管控：<strong>Hermes-SDK</strong> 的 <em>热点模块</em> 对本地缓存大小上限进行了管控，使其占用内存不超过 64MB（LRU），杜绝 JVM 堆内存溢出的可能；</li>\n </ul> \n <h4><a id=\"324__615\"></a>3-2-4. 一致性</h4> \n <p>TMC 本地缓存一致性表现在以下方面：</p> \n <ul>\n  <li><strong>Hermes-SDK</strong> 的 <em>热点模块</em> 仅缓存 <strong>热点key</strong> 数据，绝大多数非热点 key 数据由 <strong>缓存集群</strong> 存储；</li>\n  <li><strong>热点key</strong> 变更导致 value 失效时，<strong>Hermes-SDK</strong> 同步失效本地缓存，保证 <strong>本地强一致</strong>；</li>\n  <li><strong>热点key</strong> 变更导致 value 失效时，<strong>Hermes-SDK</strong> 通过 <strong>etcd集群</strong> 广播事件，异步失效业务应用集群中其他节点的本地缓存，保证 <strong>集群最终一致</strong>；</li>\n </ul> \n <h3><a id=\"TMC_623\"></a>四、TMC热点发现</h3> \n <h4><a id=\"41__625\"></a>4-1. 整体流程</h4> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/9314a40b5f685e0dcb229d04e95ba07a.png\" alt=\"图片描述\"></p> \n <p>TMC 热点发现流程分为四步：</p> \n <ul>\n  <li><strong>数据收集</strong>：收集 <strong>Hermes-SDK</strong> 上报的 <em>key访问事件</em>；</li>\n  <li><strong>热度滑窗</strong>：对 App 的每个 Key ，维护一个时间轮，记录基于当前时刻滑窗的访问热度；</li>\n  <li><strong>热度汇聚</strong>：对 App 的所有 Key ，以<code>&lt;key,热度&gt;</code>的形式进行 <em>热度排序汇总</em>；</li>\n  <li><strong>热点探测</strong>：对 App ，从 <em>热Key排序汇总</em> 结果中选出 <em>TopN的热点Key</em> ，推送给 <strong>Hermes-SDK</strong>；</li>\n </ul> \n <h4><a id=\"42__636\"></a>4-2. 数据收集</h4> \n <p><strong>Hermes-SDK</strong> 通过本地<code>rsyslog</code>将 <strong>key访问事件</strong> 以协议格式放入 <strong>kafka</strong> ，<strong>Hermes服务端集群</strong> 的每个节点消费 kafka 消息，实时获取 <strong>key访问事件</strong>。</p> \n <p>访问事件协议格式如下：</p> \n <ul>\n  <li>appName：集群节点所属业务应用</li>\n  <li>uniqueKey：业务应用 <em>key访问事件</em> 的 key</li>\n  <li>sendTime：业务应用 <em>key访问事件</em> 的发生时间</li>\n  <li>weight：业务应用 <em>key访问事件</em> 的访问权值</li>\n </ul> \n <p><strong>Hermes服务端集群</strong> 节点将收集到的 <strong>key访问事件</strong> 存储在本地内存中，</p> \n <p>内存数据结构为<code>Map&lt;String, Map&lt;String, LongAdder&gt;&gt;</code>，</p> \n <p>对应业务含义映射为<code>Map&lt; appName , Map&lt; uniqueKey , 热度 &gt;&gt;</code>。</p> \n <h4><a id=\"43__653\"></a>4-3. 热度滑窗</h4> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/13b85b1aa6e4c6a1cd015aa45f52f003.png\" alt=\"图片描述\"></p> \n <h5><a id=\"431__657\"></a>4-3-1. 时间滑窗</h5> \n <p><strong>Hermes服务端集群</strong> 节点，对每个App的每个 key ，维护了一个 <strong>时间轮</strong>：</p> \n <ul>\n  <li>时间轮中共10个 <strong>时间片</strong>，每个时间片记录当前 key 对应 3 秒时间周期的总访问次数；</li>\n  <li>时间轮10个时间片的记录累加即表示当前 key 从当前时间向前 30 秒时间窗口内的总访问次数；</li>\n </ul> \n <h5><a id=\"432__664\"></a>4-3-2. 映射任务</h5> \n <p><strong>Hermes服务端集群</strong> 节点，对每个 App <em>每3秒</em> 生成一个 <strong>映射任务</strong> ，交由节点内 <em>“缓存映射线程池”</em> 执行。</p> \n <p><strong>映射任务</strong> 内容如下：</p> \n <ul>\n  <li>对当前 App ，从<code>Map&lt; appName , Map&lt; uniqueKey , 热度 &gt;&gt;</code>中取出 <em>appName</em> 对应的Map <code>Map&lt; uniqueKey , 热度 &gt;&gt;</code>；</li>\n  <li>遍历<code>Map&lt; uniqueKey , 热度 &gt;&gt;</code>中的 key ，对每个 key 取出其热度存入其 <strong>时间轮</strong> 对应的时间片中；</li>\n </ul> \n <h4><a id=\"44__673\"></a>4-4. 热度汇聚</h4> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/c2f01e09eb99a84c64fc94ecef5c4735.jpeg\" alt=\"图片描述\"></p> \n <p>完成第二步“热度滑窗”后，<strong>映射任务</strong> 继续对当前 App 进行“热度汇聚”工作：</p> \n <ul>\n  <li>遍历 App 的 key ，将每个 key 的 <strong>时间轮</strong> 热度进行汇总（即30秒时间窗口内总热度）得到探测时刻 <strong>滑窗总热度</strong>；</li>\n  <li>将 <code>&lt; key , 滑窗总热度 &gt;</code> 以排序集合的方式存入 <em>Redis存储服务</em> 中，即 <strong>热度汇聚结果</strong>；</li>\n </ul> \n <h4><a id=\"45__682\"></a>4-5. 热点探测</h4> \n <ul>\n  <li>在前几步，<strong>每3秒</strong> 一次的 <strong>映射任务</strong> 执行，对每个 App 都会产生一份当前时刻的 <strong>热度汇聚结果</strong> ；</li>\n  <li><strong>Hermes服务端集群</strong> 中的“热点探测”节点，对每个 App ，只需周期性从其最近一份 <strong>热度汇聚结果</strong> 中取出达到热度阈值的 TopN 的 key 列表，即可得到本次探测的 <strong>热点key列表</strong>；</li>\n </ul> \n <p>TMC 热点发现整体流程如下图：<br> <img src=\"https://img-blog.csdnimg.cn/img_convert/862a9b09061181d3de724bb3e6864d35.png\" alt=\"图片描述\"></p> \n <h4><a id=\"46__690\"></a>4-6. 特性总结</h4> \n <h5><a id=\"461__692\"></a>4-6-1. 实时性</h5> \n <p><strong>Hermes-SDK</strong>基于rsyslog + kafka 实时上报 <strong>key访问事件</strong>。<br> <strong>映射任务</strong> 3秒一个周期完成“热度滑窗” + “热度汇聚”工作，当有 <strong>热点访问场景</strong> 出现时最长3秒即可探测出对应 <strong>热点key</strong>。</p> \n <h5><a id=\"462__697\"></a>4-6-2. 准确性</h5> \n <p>key 的<strong>热度汇聚结果</strong>由“基于时间轮实现的滑动窗口”汇聚得到，相对准确地反应当前及最近正在发生访问分布。</p> \n <h5><a id=\"463_701\"></a>4-6-3.扩展性</h5> \n <p><strong>Hermes服务端集群</strong> 节点无状态，节点数可基于 kafka 的 partition 数量横向扩展。</p> \n <p>“热度滑窗” + “热度汇聚” 过程基于 App 数量，在单节点内多线程扩展。</p> \n <h3><a id=\"TMC_707\"></a>五、TMC实战效果</h3> \n <h4><a id=\"51__709\"></a>5-1. 快手商家某次商品营销活动</h4> \n <p>有赞商家通过快手直播平台为某商品搞活动，造成该商品短时间内被集中访问产生访问热点，活动期间 TMC 记录的实际热点访问效果数据如下：</p> \n <p>5-1-1. 某核心应用的缓存请求&amp;命中率曲线图</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/bb1d2e284c3cdf73b7fb37f487a58189.png\" alt=\"图片描述\"></p> \n <ul>\n  <li>上图蓝线为应用集群调用<code>get()</code>方法访问缓存次数</li>\n  <li>上图绿线为获取缓存操作命中 TMC 本地缓存的次数</li>\n </ul> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/51ea19d068a1556ed2fb887b4c0738a0.png\" alt=\"图片描述\"></p> \n <ul>\n  <li>上图为本地缓存命中率曲线图</li>\n </ul> \n <p>可以看出活动期间缓存请求量及本地缓存命中量均有明显增长，本地缓存命中率达到近 80% （即应用集群中 80% 的缓存查询请求被 TMC 本地缓存拦截）。</p> \n <h4><a id=\"512__726\"></a>5-1-2. 热点缓存对应用访问的加速效果</h4> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/c78797dde51d8c0cc5ceb567fb5134da.png\" alt=\"图片描述\"></p> \n <ul>\n  <li>上图为应用接口QPS曲线</li>\n </ul> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/0990c08e079651b86f46c1e1d5833933.png\" alt=\"图片描述\"></p> \n <ul>\n  <li>上图为应用接口RT曲线</li>\n </ul> \n <p>可以看出活动期间应用接口的请求量有明显增长，由于 TMC 本地缓存的效果应用接口的 RT 反而出现下降。</p> \n <h4><a id=\"52__TMC__738\"></a>5-2. 双十一期间部分应用 TMC 效果展示</h4> \n <h5><a id=\"521__740\"></a>5-2-1. 商品域核心应用效果</h5> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/df6a1b7c354a45b65cf5c3e517f5df04.png\" alt=\"图片描述\"></p> \n <h5><a id=\"522__744\"></a>5-2-2. 活动域核心应用效果</h5> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/2d35f592b31b258660a9537a6d094965.png\" alt=\"图片描述\"><br> <img src=\"https://img-blog.csdnimg.cn/img_convert/04b5dd68b1a0661cd7e9aad1887ee540.png\" alt=\"图片描述\"></p> \n <h3><a id=\"TMC_751\"></a>六、TMC功能展望</h3> \n <p>在有赞， TMC 目前已为商品中心、物流中心、库存中心、营销活动、用户中心、网关&amp;消息等多个核心应用模块提供服务，后续应用也在陆续接入中。</p> \n <p>TMC 在提供“热点探测” + “本地缓存”的核心能力同时，也为应用服务提供了灵活的配置选择，应用服务可以结合实际业务情况在“热点阈值”、“热点key探测数量”、“热点黑白名单”维度进行自由配置以达到更好的使用效果。</p> \n <p>配合三级缓存的使用，需要进行 热key的 探测，有赞平台通过 热key的探测和 支持，</p> \n <p><strong>其中：活动期间，本地缓存命中率达到近 80%的命中率</strong>， 并且， 响应时间，和平峰时段，没有变化。</p> \n <h2><a id=\"HotKey3__hotkey_769\"></a>HotKey探测方案3： 结合开源hotkey，做热点探测</h2> \n <p>基于开源hotkey进行 热点探测，有很多小伙伴，在生产系统进行了 缓存系统的重构</p> \n <p>下面将重构前与重构后做下对照，来说明这套机制的优缺点。</p> \n <table>\n  <thead>\n   <tr>\n    <th>特性</th>\n    <th>重构系统前</th>\n    <th>使用京东hotkey重构系统后</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>机器资源</td>\n    <td>高配物理机/虚拟机</td>\n    <td>普通物理机/虚拟机/容器</td>\n   </tr>\n   <tr>\n    <td>管控复杂</td>\n    <td>无法控制热点，不易监控</td>\n    <td>热点数据可以监控统计，可以手动刷新</td>\n   </tr>\n   <tr>\n    <td>资源利用率</td>\n    <td>资源利用率低，无论是否是热点数据都占用资源</td>\n    <td>资源利用率高，大部分热点数据持有资源</td>\n   </tr>\n   <tr>\n    <td>突发流量</td>\n    <td>无法弹性应对突发流量</td>\n    <td>弹性应对突发流量</td>\n   </tr>\n   <tr>\n    <td>预发流量</td>\n    <td>预设所有数据</td>\n    <td>只提前预设热点数据</td>\n   </tr>\n   <tr>\n    <td>数据一致性</td>\n    <td>集群内数据不一致情况时常发生，出现“横跳”现象</td>\n    <td>集群内数据一致性高，极少或不发生不一致性情况</td>\n   </tr>\n  </tbody>\n </table> \n <p>以上内容的视频介绍，将在 《第26章 百万qps 三级缓存 组件实操》 中 详细介绍。</p> \n <h2><a id=\"10W__792\"></a>假设10W人同时访问，如何保证不 雪崩？</h2> \n <ul>\n  <li> <p>扩容</p> </li>\n  <li> <p>限流</p> </li>\n  <li> <p>三级缓存</p> </li>\n </ul> \n <p>三级缓存 强烈推荐进行 热点探测 相结合， 主要的优势是：</p> \n <ul>\n  <li> <p>通过热点探测，既能提升 本地缓存命中率，</p> </li>\n  <li> <p>除此之外，还能识别 刷子用户， 把刷子用户加入 黑名单， 并且利用 bloom 过滤器进行缓存。 从而提升系统的安全性。</p> </li>\n </ul> \n <p>以上内容的视频介绍，将在 《第26章 百万qps 三级缓存 组件实操》 中 详细介绍。</p> \n <h2><a id=\"_816\"></a>参考文献</h2> \n <ol>\n  <li> <p><a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\">疯狂创客圈 JAVA 高并发 总目录</a></p> <p><a href=\"https://www.cnblogs.com/crazymakercircle/p/14491965.html\">ThreadLocal 史上最全</a></p> </li>\n  <li> <p><a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\">4000页《尼恩 Java 面试宝典 》的 35个面试专题</a></p> </li>\n  <li> <p><a href=\"https://www.processon.com/view/link/60fb9421637689719d246739\">价值10W的架构师知识图谱</a></p> </li>\n </ol> \n <p>4、<a href=\"https://www.processon.com/view/link/616f801963768961e9d9aec8\">尼恩 架构师哲学</a></p> \n <p>5、<a href=\"https://www.processon.com/view/link/635097d2e0b34d40be778ab4\">尼恩 3高架构知识宇宙</a></p> \n <p>https://segmentfault.com/a/1190000017142556</p> \n <p>https://gitee.com/jd-platform-opensource/hotkey</p> \n <h2><a id=\"_838\"></a>推荐阅读：</h2> \n <ul>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124790425\">尼恩Java面试宝典</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057567\">Springcloud gateway 底层原理、核心实战 (史上最全)</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124120506\">Flux、Mono、Reactor 实战（史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125059491\">sentinel （史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057545\">Nacos (史上最全)</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/123420859\">分库分表 Sharding-JDBC 底层原理、核心实战（史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/114527369\">TCP协议详解 (史上最全)</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126992542\">clickhouse 超底层原理 + 高可用实操 （史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120702536\">nacos高可用（图解+秒懂+史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264803\">队列之王： Disruptor 原理、架构、源码 一文穿透</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264508\">环形队列、 条带环形队列 Striped-RingBuffer （史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125135726\">一文搞定：SpringBoot、SLF4j、Log4j、Logback、Netty之间混乱关系（史上最全）</a></p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128265067\">单例模式（史上最全）</a></p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125017316\">红黑树（ 图解 + 秒懂 + 史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/109459593\">分布式事务 （秒懂）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128123114\">缓存之王：Caffeine 源码、架构、原理（史上最全，10W字 超级长文）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/113751575\">缓存之王：Caffeine 的使用（史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126579528\">Java Agent 探针、字节码增强 ByteBuddy（史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120747767\">Docker原理（图解+秒懂+史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/116425814\">Redis分布式锁（图解 - 秒懂 - 史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85956246\">Zookeeper 分布式锁 - 图解 - 秒懂</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85922561\">Zookeeper Curator 事件监听 - 10分钟看懂</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83957259\">Netty 粘包 拆包 | 史上最全解读</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83758107\">Netty 100万级高并发服务器配置</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/102557988\">Springcloud 高并发 配置 （一文全懂）</a>》</p> </li>\n </ul> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 15662);
INSERT INTO `crawlerblog` VALUES (123124011, '2个大厂 100亿级 超大流量 红包 架构方案', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <h2><a id=\"2_100____0\"></a>2个大厂 100亿级 超大流量 红包 架构方案</h2> \n <p></p> \n <div class=\"toc\"> \n  <h3>文章目录</h3> \n  <ul>\n   <li>\n    <ul>\n     <li><a href=\"#2_100____0\">2个大厂 100亿级 超大流量 红包 架构方案</a></li>\n     <li><a href=\"#100_____2\">100亿级 红包 应用 场景</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#_3\">概述</a></li>\n      </ul> </li>\n     <li><a href=\"#__21\">百亿级 微信红包技术架构</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#_29\">架构</a></li>\n       <li>\n        <ul>\n         <li><a href=\"#_39\">**南北分布**</a></li>\n         <li><a href=\"#_81\">**拆红包入账异步化**</a></li>\n         <li><a href=\"#cache_105\">**发拆落地，其他操作双层cache**</a></li>\n        </ul> </li>\n       <li><a href=\"#_121\">高并发</a></li>\n       <li>\n        <ul>\n         <li><a href=\"#_191\">**红包算法**</a></li>\n         <li><a href=\"#_207\">**柔性降级方案**</a></li>\n        </ul> </li>\n      </ul> </li>\n     <li><a href=\"#360w_QPS__100___253\">360w QPS 100亿级 字节红包 体系架构</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#1__255\">1. 背景&amp;挑战&amp;目标</a></li>\n       <li>\n        <ul>\n         <li><a href=\"#11__257\">1.1 业务背景</a></li>\n         <li><a href=\"#12__271\">1.2 核心挑战</a></li>\n         <li><a href=\"#13__279\">1.3 最终目标</a></li>\n        </ul> </li>\n       <li><a href=\"#2__291\">2. 产品需求介绍</a></li>\n       <li><a href=\"#3__312\">3. 钱包资产中台设计与实现</a></li>\n       <li>\n        <ul>\n         <li><a href=\"#31__326\">3.1 春节资产资产中台总体架构图如下：</a></li>\n         <li><a href=\"#32__348\">3.2 资产订单中心设计</a></li>\n        </ul> </li>\n       <li><a href=\"#4___389\">4. 核心难点问题解决</a></li>\n       <li>\n        <ul>\n         <li><a href=\"#41__391\">4.1 难点一：支持八端奖励数据互通</a></li>\n         <li><a href=\"#42__408\">4.2 难点二：高场景下的奖励入账实现</a></li>\n         <li>\n          <ul>\n           <li><a href=\"#421__token__443\">4.2.1 红包雨 token 方案：</a></li>\n          </ul> </li>\n         <li><a href=\"#43__504\">4.3 难点三：发奖励链路依赖多的稳定性保障</a></li>\n         <li><a href=\"#44__536\">4.4 难点四：大流量发卡券预算控制</a></li>\n         <li><a href=\"#45__QPS__key__558\">4.5 难点五：高 QPS 场景下的热 key 的读取和写入稳定性保障</a></li>\n         <li>\n          <ul>\n           <li><a href=\"#451__568\">4.5.1 方案一</a></li>\n           <li><a href=\"#452__598\">4.5.2 方案二</a></li>\n           <li><a href=\"#453__654\">4.5.3 方案对比</a></li>\n          </ul> </li>\n         <li><a href=\"#46__665\">4.6 难点六：大流量场景下资金安全保障</a></li>\n        </ul> </li>\n       <li><a href=\"#5__688\">5. 通用模式抽象</a></li>\n       <li>\n        <ul>\n         <li><a href=\"#51__692\">5.1 容灾降级层面</a></li>\n         <li>\n          <ul>\n           <li><a href=\"#511__698\">5.1.1 限流层面</a></li>\n           <li><a href=\"#512__724\">5.1.2 降级层面</a></li>\n           <li><a href=\"#513__732\">5.1.3 资源隔离层面</a></li>\n           <li><a href=\"#514__742\">5.1.4 存储预估</a></li>\n           <li><a href=\"#515__752\">5.1.5 压测层面</a></li>\n          </ul> </li>\n         <li><a href=\"#52__768\">5.2 微服务思考</a></li>\n        </ul> </li>\n       <li><a href=\"#6__776\">6. 系统的未来演进方向</a></li>\n      </ul> </li>\n     <li><a href=\"#_790\">推荐阅读：</a></li>\n    </ul> </li>\n  </ul> \n </div> \n <p></p> \n <h2><a id=\"100_____2\"></a>100亿级 红包 应用 场景</h2> \n <h3><a id=\"_3\"></a>概述</h3> \n <p>话说每逢双十一节或春节等节假日，对大家来讲是最欢乐的日子，可以在微信群中收发红包，此外今年微信还推出了面对面红包，让大家拜年时可直接收发，对于用户来讲很爽也很方便。但对于技术架构侧的考量，这使得微信红包的收发数据成几何倍数上升，处理的复杂度也增加了很多。</p> \n <p>2017年微信红包发送量最大的时间段是除夕夜，达到了142亿个。</p> \n <p>如此大规模、高并发、高峰值的业务场景，怕是在美帝互联网的技术团队，包括EBay、Amazon等也无法想象，在这种巨大的流量与并发后面，需要什么样级别的技术架构支撑？</p> \n <p>当达百亿级别的资金交易规模时，我们该怎样来保证系统的并发性能和交易安全？</p> \n <p>当今中国的互联网平台，有两个场景称得上亿级以上的并发量：</p> \n <p>一个是微信的红包，</p> \n <p>一个是字节的红包，</p> \n <p>都是在一个单位时间达到亿万以以上的请求负载。</p> \n <h2><a id=\"__21\"></a>百亿级 微信红包技术架构</h2> \n <blockquote> \n  <p>与传统意义上的红包相比，近两年火起来的“红包”，似乎才是如今春节的一大重头戏。历经上千年时代传承与变迁，春节发红包早已成为历史沉淀的文化习俗，融入了民族的血脉。按照各家公布的数据，除夕全天微信用户红包总发送量达到80.8亿个，红包峰值收发量为40.9万个/秒。春晚直播期间讨论春晚的微博达到5191万条，网友互动量达到1.15亿，网友抢微博红包的总次数超过8亿次。</p> \n </blockquote> \n <p>微信红包在经过15年春晚摇一摇之后，2015年上半年业务量一度呈指数级增长。尤其是微信红包活跃用户数的大量增长，使得2016除夕跨年红包成为极大挑战。为了应对16年春节可预知的红包海量业务，红包系统在架构上进行了一系列调整和优化。主要包括异地架构、cache系统优化、拆红包并发策略优化、存储优化一系列措施，为迎接2016春节红包挑战做好准备。 下面介绍最主要的一些思路。</p> \n <h3><a id=\"_29\"></a>架构</h3> \n <p>微信用户在国内有深圳、上海两个接入点，习惯性称之为南、北（即深圳为南，上海为北）。用户请求接入后，不同业务根据业务特性选择部署方式。微信红包在信息流上可以分为订单纬度与用户纬度。</p> \n <p>其中订单是贯穿红包发、抢、拆、详情列表等业务的关键信息，属于交易类信息；而用户纬度指的是红包用户的收红包列表、发红包列表，属于展示类信息。红包系统在架构上，有以下几个方面：</p> \n <h4><a id=\"_39\"></a><strong>南北分布</strong></h4> \n <p>1、订单层南北独立体系，数据不同步</p> \n <p>用户就近接入，请求发红包时分配订单南北，并在单号打上南北标识。抢红包、拆红包、查红包详情列表时，接入层根据红包单号上的南北标识将流量分别引到南北系统闭环。根据发红包用户和抢红包用户的所属地不同，有以下四种情况：</p> \n <p>1）深圳用户发红包，深圳用户抢</p> \n <p>订单落在深圳，深圳用户抢红包时不需要跨城，在深圳完成闭环。</p> \n <p>2）深圳用户发红包，上海用户抢</p> \n <p>订单落在深圳，上海用户抢红包，在上海接入后通过专线跨城到深圳，最后在深圳闭环完成抢红包。</p> \n <p>3）上海用户发红包，上海用户抢</p> \n <p>订单落在上海，上海用户抢红包时不需要跨城，在上海完成闭环。</p> \n <p>4）上海用户发红包，深圳用户抢</p> \n <p>订单落在上海，深圳用户抢红包，从深圳接入后通过专线跨城到上海，最后在上海闭环完成抢红包。</p> \n <p>系统这样设计，好处是南北系统分摊流量，降低系统风险。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/d4a234477da446b29aec4e1fd89f272e.png\" alt=\"\"></p> \n <p>2、用户数据写多读少，全量存深圳，异步队列写入，查时一边跨城</p> \n <p>用户数据的查询入口，在微信钱包中，隐藏的很深。这决定了用户数据的访问量不会太大，而且也被视为可旁路的非关键信息，实时性要求不高。因此，只需要在发红包、拆红包时，从订单纬度拆分出用户数据写入请求，由MQ异步写入深圳。后台将订单与用户进行定时对账保证数据完整性即可。</p> \n <p>3、支持南北流量灵活调控</p> \n <p>红包系统南北分布后，订单落地到深圳还是上海，是可以灵活分配的，只需要在接入层上做逻辑。例如，可以在接入层中，实现让所有红包请求，都落地到深圳（无论用户从上海接入，还是深圳接入），这样上海的红包业务系统将不会有请求量。提升了红包系统的容灾能力。同时，实现了接入层上的后台管理系统，实现了秒级容量调控能力。可根据南北请求量的实时监控，做出对应的调配。</p> \n <p>4、DB故障时流量转移能力 基于南北流量的调控能力，当发现DB故障时，可将红包业务流量调到另外一边，实现DB故障的容灾。</p> \n <p>预订单</p> \n <p>支付前订单落cache，同时利用cache的原子incr操作顺序生成红包订单号。优点是cache的轻量操作，以及减少DB废单。在用户请求发红包与真正支付之间，存在一定的转化率，部分用户请求发红包后，并不会真正去付款。</p> \n <h4><a id=\"_81\"></a><strong>拆红包入账异步化</strong></h4> \n <p>信息流与资金流分离。</p> \n <p>拆红包时，DB中记下拆红包凭证，然后异步队列请求入账。</p> \n <p>入账失败通过补偿队列补偿，最终通过红包凭证与用户账户入账流水对账，保证最终一致性。如下图所示：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/983c9680875c4e3a9ce172c261565285.png\" alt=\"\"></p> \n <p>这个架构设计，理论基础是快慢分离。</p> \n <p>红包的入账是一个分布事务，属于慢接口。</p> \n <p>而拆红包凭证落地则速度快。</p> \n <p>实际应用场景中，用户抢完红包，只关心详情列表中谁是“最佳手气”，很少关心抢到的零是否已经到账。</p> \n <p>因为只需要展示用户的拆红包凭证即可。</p> \n <h4><a id=\"cache_105\"></a><strong>发拆落地，其他操作双层cache</strong></h4> \n <p>1、Cache住所有查询，两层cache</p> \n <p>除了使用ckv做全量缓存，还在数据访问层dao中增加本机内存cache做二级缓存，cache住所有读请求。</p> \n <p>查询失败或者查询不存在时，降级内存cache；内存cache查询失败或记录不存在时降级DB。</p> \n <p><strong>DB本身不做读写分离。</strong></p> \n <p>2、DB写同步cache，容忍少量不一致， DB写操作完成后，dao中同步内存cache，业务服务层同步ckv，失败由异步队列补偿，</p> \n <p>定时的ckv与DB备机对账，保证最终数据一致。</p> \n <h3><a id=\"_121\"></a>高并发</h3> \n <p>微信红包的并发挑战，主要在于微信大群，多人同时抢同一个红包。</p> \n <p>以上这种情况，存在竞争MySQL行锁。为了控制这种并发，团队做了以下一些事情：</p> \n <p><strong>1、请求按红包订单路由，逻辑块垂直sticky，事务隔离</strong></p> \n <p>按红包订单划分逻辑单元，单元内业务闭环。服务rpc调用时，使用红包订单号的hash值为key寻找下一跳地址。对同一个红包的所有拆请求、查询请求，都路由到同一台逻辑机器、同一台DB中处理。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/78c0bc00c06c4b8ba86372887f657de2.png\" alt=\"\"></p> \n <p><strong>2、Dao搭建本机Memcache内存cache，控制同一红包并发个数</strong></p> \n <p>在DB的接入机dao中，搭建本机内存cache。以红包订单号为key，对同一个红包的拆请求做原子计数，控制同一时刻能进DB中拆红包的并发请求数。</p> \n <p>这个策略的实施，依赖于请求路由按红包订单hash值走，确保同一红包的所有请求路由到同一逻辑层机器。</p> \n <p><strong>3、多层级并发量控制</strong></p> \n <p>1）发红包控制</p> \n <p>发红包是业务流程的入口，控制了这里的并发量，代表着控制了红包业务整体的并发量。在发红包的业务链路里，做了多层的流量控制，确保产生的有效红包量级在可控范围。</p> \n <p>2）抢红包控制</p> \n <p>微信红包领取时分为两个步骤，抢和拆。</p> \n <p>抢红包这个动作本身就有控制拆并发的作用。因为抢红包时，只需要查cache中的数据，不需要请求DB。</p> \n <p>对于红包已经领完、用户已经领过、红包已经过期等流量可以直接拦截。而对于有资格进入拆红包的请求量，也做流量控制。通过这些处理，最后可进入拆环节的流量大大减少，并且都是有效请求。</p> \n <p>3）拆时内存cache控制</p> \n <p>针对同一个红包并发拆的控制，上面的文章已介绍。</p> \n <p><strong>4、DB简化和拆分</strong></p> \n <p>DB的并发能力，有很多影响因素。红包系统结合红包使用情境，进行了一些优化。比较有借鉴意义的，主要有以下两点：</p> \n <p>1）订单表只存关键字段，其他字段只在cache中存储，可柔性。</p> \n <p>红包详情的展示中，除了订单关键信息（用户、单号、金额、时间、状态）外，还有用户头像、昵称、祝福语等字段。这些字段对交易来说不是关键信息，却占据大量的存储空间。</p> \n <p>将这些非关键信息拆出来，只存在cache，用户查询展示，而订单中不落地。</p> \n <p>这样可以维持订单的轻量高效，同时cache不命中时，又可从实时接口中查询补偿，达到优化订单DB容量的效果。</p> \n <p>2）DB双重纬度分库表，冷热分离</p> \n <p>使用订单hash、订单日期，两个纬度分库表，也即db_xxx.t_x_dd这样的格式。</p> \n <p>其中，x表示订单hash值，dd表示01-31循环日。</p> \n <p>订单hash纬度，是为了将订单打散到不同的DB服务器中，均衡压力。</p> \n <p>订单日期循环日纬度，是为了避免单表数据无限扩张，使每天都是一张空表。</p> \n <p>另外，红包的订单访问热度，是非常典型的冷热型。</p> \n <p>热数据集中在一两天内，且随时间急剧消减。</p> \n <p>线上热数据库只需要存几天的数据，其他数据可以定时移到成本低的冷数据库中。</p> \n <p>循环日表也使得历史数据的迁移变得方便。</p> \n <h4><a id=\"_191\"></a><strong>红包算法</strong></h4> \n <p>首先，如果红包只有一个，本轮直接使用全部金额，确保红包发完。</p> \n <p>然后，计算出本轮红包最少要领取多少，才能保证红包领完，即本轮下水位；轮最多领取多少，才能保证每个人都领到，即本轮上水位。主要方式如下：</p> \n <p>计算本轮红包金额下水位：假设本轮领到最小值1分，那接下来每次都领到200元红包能领完，那下水位为1分；如果不能领完，那按接下来每次都领200元，剩下的本轮应全部领走，是本轮的下水位。</p> \n <p>计算本轮红包上水位：假设本轮领200元，剩下的钱还足够接下来每轮领1分钱，那本轮上水位为200元；如果已经不够领，那按接下来每轮领1分，计算本轮的上水位。</p> \n <p>为了使红包金额不要太悬殊，使用红包均值调整上水位。如果上水位金额大于两倍红包均值，那么使用两倍红包均值作为上水位。换句话说，每一轮抢到的红包金额，最高为两倍剩下红包的均值。</p> \n <p>最后，获取随机数并用上水位取余，如果结果比下水位还小，则直接使用下水位，否则使用随机金额为本轮拆到金额。</p> \n <h4><a id=\"_207\"></a><strong>柔性降级方案</strong></h4> \n <p>系统到处存在发生异常的可能，需要对所有的环节做好应对的预案。</p> \n <p>下面列举微信红包对系统异常的主要降级考虑。</p> \n <p>1、 下单cache故障降级DB</p> \n <p>下单cache有两个作用，生成红包订单与订单缓存。</p> \n <p>缓存故障情况下，降级为直接落地DB，并使用id生成器独立生成订单号。</p> \n <p>2、 抢时cache故障降级DB</p> \n <p>抢红包时，查询cache，拦截红包已经抢完、用户已经抢过、红包已经过期等无效请求。当cache故障时，降级DB查询，同时打开DB限流保护开关，防止DB压力过大导致服务不可用。</p> \n <p>另外，cache故障降级DB时，DB不存储用户头像、用户昵称等（上文提到的优化），此时一并降级为实时接口查询。查询失败，继续降级为展示默认头像与昵称。</p> \n <p>3、 拆时资金入账多级柔性</p> \n <p>拆红包时，DB记录拆红包单据，然后执行资金转账。单据需要实时落地，而资金转账，这里做了多个层级的柔性降级方案：</p> \n <p>大额红包实时转账，小额红包入队列异步转账 所有红包进队列异步转账 实时流程不执行转账，事后凭单据批量入账。</p> \n <p>总之，单据落地后，真实入账可实时、可异步，最终保证一致即可。</p> \n <p>4、 用户列表降级</p> \n <p>用户列表数据在微信红包系统中，属于非关键路径信息，属于可被降级部分。</p> \n <p>首先，写入时通过MQ异步写，通过定时对账保证一致性。</p> \n <p>其次，cache中只缓存两屏，用户查询超过两屏则查用户列表DB。在系统压力大的情况下，可以限制用户只查两屏。</p> \n <p>调整后的系统经过了2016年春节的实践检验，平稳地度过了除夕业务高峰，保障了红包用户的体验。</p> \n <blockquote> \n  <p>上文参考来源：架构说公众号，作者：方乐明</p> \n  <p>方乐明，2011年毕业于华南理工大学通信与信息系统专业，毕业后就职于财付通科技有限公司。微信支付团队组建后，主要负责微信红包、微信转账、AA收款等支付应用产品的后台架构。</p> \n </blockquote> \n <h2><a id=\"360w_QPS__100___253\"></a>360w QPS 100亿级 字节红包 体系架构</h2> \n <h3><a id=\"1__255\"></a>1. 背景&amp;挑战&amp;目标</h3> \n <h4><a id=\"11__257\"></a>1.1 业务背景</h4> \n <p>（1）<strong>支持八端</strong>：</p> \n <p>2022 年字节系产品春节活动需要支持八端 APP 产品（包含抖音/抖音火山/抖音极速版/西瓜/头条/头条极速版/番茄小说/番茄畅听）的奖励互通。用户在上述任意一端都可以参与活动，得到的奖励在其他端都可以提现与使用。</p> \n <p>（2）<strong>玩法多变</strong>：</p> \n <p>主要有集卡、朋友页红包雨、红包雨、集卡开奖与烟火大会等。</p> \n <p>（3）<strong>多种奖励</strong>：</p> \n <p>奖励类型包含现金红包、补贴视频红包、商业化广告券、电商券、支付券、消费金融券、保险券、信用卡优惠券、喜茶券、电影票券、dou+券、抖音文创券、头像挂件等。</p> \n <h4><a id=\"12__271\"></a>1.2 核心挑战</h4> \n <p>（1）超高吞吐，超大并发，最高预估 360w QPS 发奖。</p> \n <p>（2）奖励类型多，共 10 余种奖励。多种发奖励的场景，玩法多变；</p> \n <p>（3）从奖励系统稳定性、用户体验、资金安全与运营基础能力全方位保障，确保活动顺利进行 。</p> \n <h4><a id=\"13__279\"></a>1.3 最终目标</h4> \n <p>（1）<strong>奖励入账</strong>：数据高可靠。提供统一的错误处理机制，入账幂等能力和奖励预算控制。</p> \n <p>（2）**奖励展示/使用：**支持用户查看、提现（现金），使用卡券/挂件等能力。</p> \n <p>（3）<strong>稳定性保障</strong>：在大流量的入账场景下，保证钱包核心路径稳定性与完善，通过常用稳定性保障手段如资源扩容、限流、熔断、降级、兜底、资源隔离等方式保证用户奖励方向的核心体验。</p> \n <p>（4）<strong>资金安全</strong>：通过幂等、对账、监控与报警等机制，保证资金安全，保证用户资产应发尽发，不少发。</p> \n <p>（5）<strong>活动隔离</strong>：实现内部测试、灰度放量和正式春节活动三个阶段的奖励入账与展示的数据隔离，不互相影响。</p> \n <h3><a id=\"2__291\"></a>2. 产品需求介绍</h3> \n <p>用户可以在任意一端参与字节的春节活动获取奖励，以抖音红包雨现金红包入账场景为例，具体的业务流程如下：</p> \n <p>登录抖音 → 参与活动 → 活动钱包页 → 点击提现按钮 → 进入提现页面 → 进行提现 → 提现结果页，</p> \n <p>另外从钱包页也可以进入活动钱包页。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/4d3df05e8e8dac360c03e20d36601d29.png\" alt=\"\"></p> \n <p>奖励发放核心场景：</p> \n <ol>\n  <li><strong>集卡</strong>：集卡抽卡时发放各类卡券，集卡锦鲤还会发放大额现金红包，集卡开奖时发放瓜分奖金和优惠券；</li>\n  <li><strong>红包雨</strong>：发红包、卡券以及视频补贴红包，其中红包和卡券最高分别 180w QPS；</li>\n </ol> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/dd6af98d51f5db710872248ae51a30e4.png\" alt=\"\"></p> \n <h3><a id=\"3__312\"></a>3. 钱包资产中台设计与实现</h3> \n <p>在 2022 年春节活动中，业务方分为：</p> \n <p>UG、激励中台、视频红包、钱包方向、资产中台等</p> \n <p>其中，UG 主要负责活动的玩法实现，包含集卡、红包雨以及烟火大会等具体的活动相关业务逻辑和稳定性保障。</p> \n <p>而钱包方向定位是大流量场景下实现奖励入账、奖励展示、奖励使用与资金安全保障的相关任务。</p> \n <p>其中资产中台负责<strong>奖励发放与奖励展示</strong>部分。</p> \n <h4><a id=\"31__326\"></a>3.1 春节资产资产中台总体架构图如下：</h4> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/768d79e164975d1794d875abaf74b627.png\" alt=\"\"></p> \n <p>钱包资产中台核心系统划分如下：</p> \n <ol>\n  <li> <p><strong>资产订单层</strong>：</p> <p>收敛八端奖励入账链路，</p> <p>提供统一的接口协议，对接上游活动业务方的奖励发放功能，</p> <p>同时，支持预算控制、补偿、订单号幂等。</p> </li>\n  <li> <p><strong>活动钱包 api 层</strong>：</p> <p>统一奖励展示链路，同时支持大流量场景</p> </li>\n </ol> \n <h4><a id=\"32__348\"></a>3.2 资产订单中心设计</h4> \n <p><strong>核心发放模型：</strong></p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/37c250c4a4b5e91b0dc4ce1e236ae00f.png\" alt=\"\"></p> \n <p><strong>说明：</strong></p> \n <p>活动 ID 唯一区分一个活动，</p> \n <p>本次春节分配了一个单独的母活动 ID</p> \n <p>场景 ID 和具体的一种奖励类型一一对应，</p> \n <p>定义该场景下发奖励的唯一配置，</p> \n <p>场景 ID 可以配置的能力有：</p> \n <ul>\n  <li>发奖励账单文案；</li>\n  <li>是否需要补偿；</li>\n  <li>限流配置；</li>\n  <li>是否进行库存控制；</li>\n  <li>是否要进行对账。</li>\n  <li>提供可插拔的能力，供业务可选接入。</li>\n </ul> \n <p><strong>订单号设计：</strong></p> \n <p>资产订单层支持订单号维度的发奖幂等，订单号设计逻辑为</p> \n <p><code>${actID}_${scene_id}_${rain_id}_${award_type}_${statge}</code></p> \n <p>从单号设计层面保证不超发，每个场景的奖励用户最多只领一次。</p> \n <h3><a id=\"4___389\"></a>4. 核心难点问题解决</h3> \n <h4><a id=\"41__391\"></a>4.1 难点一：支持八端奖励数据互通</h4> \n <p>有八个产品端，需要统一对接，</p> \n <p>其中抖音系和头条系 APP 是不同的账号体系，所以不能通过用户 ID 打通奖励互通。</p> \n <p>具体解决方案是：</p> \n <ul>\n  <li>给每个用户生成唯一的 actID</li>\n  <li>手机号优先级最高，如果不同端登录的手机号一样，在不同端的 actID 是一致的。</li>\n </ul> \n <p>在唯一 actID 基础上，每个用户的奖励数据是绑定在 actID 上的，入账和查询是通过 actID 维度实现的，即可实现八端奖励互通。</p> \n <p>示意图如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/d5e9bb782bba0c3e5fd950a64664d2c6.png\" alt=\"\"></p> \n <h4><a id=\"42__408\"></a>4.2 难点二：高场景下的奖励入账实现</h4> \n <p>超高并发场景，发现金红包都是最关键的一环。有几个原因如下：</p> \n <ol>\n  <li>预估发现金红包最大流量有 180w TPS。</li>\n  <li>现金红包本身价值高，需要保证资金安全。</li>\n  <li>用户对现金的敏感度很高，在保证用户体验与功能完整性同时也要考虑成本问题。</li>\n </ol> \n <p>终上所述，<strong>发现金红包面临比较大的技术挑战。</strong></p> \n <p>发红包其实是一种交易行为，资金流走向是从公司成本出然后进入个人账户。</p> \n <p>（1）从技术方案上是要支持订单号维度的幂等，同一订单号多次请求只入账一次。订单号生成逻辑为</p> \n <p><code>${actID}_${scene_id}_${rain_id}_${award_type}_${statge}</code></p> \n <p>从单号设计层面保证不超发。</p> \n <p>（2）支持高并发，有以下 2 个传统方案：</p> \n <table>\n  <thead>\n   <tr>\n    <th>具体方案类型</th>\n    <th>实现思路</th>\n    <th>优点</th>\n    <th>缺点</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>同步入账</td>\n    <td>申请和预估流量相同的计算和存储资源</td>\n    <td>1.开发简单； 2.不容易出错；</td>\n    <td><strong>浪费存储成本。</strong> 拿账户数据库举例，经实际压测结果：支持 30w 发红包需要 152 个数据库实例，如果支持 180w 发红包，至少需要 1152 个数据库实例，还没有算上 tce 和 redis 等其他计算和存储资源。</td>\n   </tr>\n   <tr>\n    <td>异步入账</td>\n    <td>申请部分计算和存储资源资源，实际入账能力与预估有一定差值</td>\n    <td>1.开发简单； 2.不容易出错； 3.不浪费资源；</td>\n    <td><strong>用户体验受到很大影响。</strong> 入账延迟较大，以今年活动举例会有十几分钟延迟。用户参与玩法得到奖励后在活动钱包页看不到奖励，也无法进行提现，会有大量客诉，影响抖音活动的效果。</td>\n   </tr>\n  </tbody>\n </table> \n <p>以上两种传统意义上的技术方案都有明显的缺点，</p> \n <p>那么进行思考，既能相对节约资源又能保证用户体验的方案是什么？</p> \n <p>最终采用的是红包雨 token 方案，具体方案是：</p> \n <p><strong>使用异步入账加较少量分布式存储和较复杂方案来实现，</strong></p> \n <p>下面具体介绍一下。</p> \n <h5><a id=\"421__token__443\"></a>4.2.1 红包雨 token 方案：</h5> \n <p><strong>根据预估发放红包估算</strong>，红包雨 token 方案, 计算实际入账最低要支持的 TPS 为 30w，所以实际发放中有压单的过程。</p> \n <p><strong>设计目标：</strong></p> \n <p>在活动预估给用户发放（180w）与实际入账（30w）有很大 gap 的情况下，保证用户的核心体验。</p> \n <p>用户在前端页面查看与使用过当中不能感知压单的过程，即查看与使用体验不能受到影响，相关展示的数据包含余额，累计收入与红包流水，使用包含提现等。</p> \n <p><strong>具体设计方案：</strong></p> \n <p>我们在大流量场景下每次给用户发红包会生成一个加密 token（<strong>使用非对称加密</strong>，包含发红包的元信息：红包金额，actID，与发放时间等），</p> \n <p>分别存储在客户端和服务端（<strong>容灾互备</strong>），每个用户有个 token 列表。</p> \n <p>每次发红包的时候会在 Redis 里记录该 token 的入账状态，</p> \n <p>然后用户在活动钱包页看到的现金红包流水、余额等数据，是合并已入账红包列表+token 列表-已入账/入账中 token 列表的结果。</p> \n <p>同时为保证用户提现体验不感知红包压单流程，</p> \n <p>在进入提现页或者点击提现时，将未入账的 token 列表进行强制入账，</p> \n <p>保证用户提现时账户的余额为应入账总金额，不 block 用户提现流程。</p> \n <p><strong>示意图如下：</strong></p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/fcf21c86fa2ef5ea8c132ca58883cf91.png\" alt=\"\"></p> \n <p><strong>token 数据结构：</strong></p> \n <p>token 使用的是 protobuf 格式，</p> \n <p>经单测验证存储消耗实际比使用 json 少了一倍，节约请求网络的带宽和存储成本；</p> \n <p>同时序列化与反序列化消耗 cpu 也有降低。</p> \n <pre><code class=\"prism language-go\"><span class=\"token comment\">// 红包雨token结构</span>\n<span class=\"token keyword\">type</span> RedPacketToken <span class=\"token keyword\">struct</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n   AppID      <span class=\"token builtin\">int64</span>  <span class=\"token string\">`protobuf: varint,1,opt json: AppID,omitempty `</span> <span class=\"token comment\">// 端ID</span>\n   ActID     <span class=\"token builtin\">int64</span>  <span class=\"token string\">`protobuf: varint,2,opt json: UserID,omitempty `</span> <span class=\"token comment\">// ActID</span>\n   ActivityID <span class=\"token builtin\">string</span> <span class=\"token string\">`protobuf: bytes,3,opt json: ActivityID,omitempty `</span> <span class=\"token comment\">// 活动ID</span>\n   SceneID    <span class=\"token builtin\">string</span> <span class=\"token string\">`protobuf: bytes,4,opt json: SceneID,omitempty `</span> <span class=\"token comment\">// 场景ID</span>\n   Amount     <span class=\"token builtin\">int64</span>  <span class=\"token string\">`protobuf: varint,5,opt json: Amount,omitempty `</span> <span class=\"token comment\">// 红包金额</span>\n   OutTradeNo <span class=\"token builtin\">string</span> <span class=\"token string\">`protobuf: bytes,6,opt json: OutTradeNo,omitempty `</span> <span class=\"token comment\">// 订单号</span>\n   OpenTime   <span class=\"token builtin\">int64</span>  <span class=\"token string\">`protobuf: varint,7,opt json: OpenTime,omitempty `</span> <span class=\"token comment\">// 开奖时间</span>\n   RainID     <span class=\"token builtin\">int32</span>  <span class=\"token string\">`protobuf: varint,8,opt,name=rainID json: rainID,omitempty `</span> <span class=\"token comment\">// 红包雨ID</span>\n   Status     <span class=\"token builtin\">int64</span>  <span class=\"token string\">`protobuf: varint,9,opt,name=status json: status,omitempty `</span> <span class=\"token comment\">//入账状态</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p><strong>token 安全性保障：</strong></p> \n <p>采用非对称加密算法，保障存储在的客户端尽可能不被破解。</p> \n <p>如果 token 加密算法被黑产破译，可监控报警发现，可降级。</p> \n <h4><a id=\"43__504\"></a>4.3 难点三：发奖励链路依赖多的稳定性保障</h4> \n <p>发红包流程降级示意图如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/8677db831f49ccf481df9fc43f6fcd6e.png\" alt=\"\"></p> \n <p>根据历史经验，实现的功能越复杂，依赖会变多，对应的稳定性风险就越高，那么如何保证高依赖的系统稳定性呢？</p> \n <p><strong>解决方案：</strong></p> \n <p>现金红包入账最基础要保障的功能，</p> \n <p>是将用户得到的红包进行入账，</p> \n <p>核心的功能，需要支持幂等与预算控制（避免超发），</p> \n <p>红包账户的幂等设计强依赖数据库保持事务一致性。</p> \n <p>但是如果极端情况发生，中间的链路可能会出现问题，如果是弱依赖，需要支持降级掉，不影响发放主流程。</p> \n <p>钱包方向发红包<strong>最短路径</strong>为依赖服务实例计算资源和 MySQL 存储资源实现现金红包入账。</p> \n <p>发红包强弱依赖梳理图示：</p> \n <table>\n  <thead>\n   <tr>\n    <th>psm</th>\n    <th>依赖服务</th>\n    <th>是否强依赖</th>\n    <th>降级方案</th>\n    <th>降级后影响</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>资产中台</td>\n    <td>tcc</td>\n    <td><strong>是</strong></td>\n    <td>降级读本地缓存</td>\n    <td>无</td>\n   </tr>\n   <tr>\n    <td></td>\n    <td>bytkekv</td>\n    <td>否</td>\n    <td>主动降级开关，跳过 bytekv，依赖下游做幂等</td>\n    <td>无</td>\n   </tr>\n   <tr>\n    <td>资金交易层</td>\n    <td>分布式锁 Redis</td>\n    <td>否</td>\n    <td>被动降级，调用失败，直接跳过</td>\n    <td>基本无</td>\n   </tr>\n   <tr>\n    <td></td>\n    <td>token Redis</td>\n    <td>否</td>\n    <td>主动降级开关，不调用 Redis</td>\n    <td>用户能感知到入账有延迟，会有很多客诉</td>\n   </tr>\n   <tr>\n    <td></td>\n    <td>MySQL</td>\n    <td><strong>是</strong></td>\n    <td>主有问题，联系 dba 切主</td>\n    <td>故障期间发红包不可用</td>\n   </tr>\n  </tbody>\n </table> \n <h4><a id=\"44__536\"></a>4.4 难点四：大流量发卡券预算控制</h4> \n <p>大流量集中发券的一个场景，钱包侧与算法策略配合进行卡券发放库存控制，防止超发。</p> \n <p><strong>具体实现：</strong></p> \n <p>（1）钱包资产中台维护每个卡券模板 ID 的消耗发放量。</p> \n <p>（2）每次卡券发放前，读取该卡券模板 ID 的消耗量以及总库存数。同时会设置一个阈值，如果卡券剩余量小于 10%后不发这个券（使用兜底券或者祝福语进行兜底）。</p> \n <p>（3） 发券流程 累计每个券模板 ID 的消耗量（使用 Redis incr 命令原子累加消耗量），然后与总活动库存进行比对，如果消耗量大于总库存数则拒绝掉，防止超发，也是一个兜底流程。</p> \n <p><strong>具体流程图：</strong></p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/9074ea1e5bc8d3a06b7958c380876833.png\" alt=\"\"></p> \n <p><strong>优化方向：</strong></p> \n <p>（1）大流量下使用 Redis 计数，单 key 会存在热 key 问题，需要拆分 key 来解决。</p> \n <p>（2）大流量场景下，<strong>操作 Redis 会存在超时问题</strong>，返回上游处理中，上游继续重试发券，会多消耗库存少发，本次春节活动实际活动库存在预估库存基础上加了 5%的量级来缓解超时带来的少发问题。</p> \n <h4><a id=\"45__QPS__key__558\"></a>4.5 难点五：高 QPS 场景下的热 key 的读取和写入稳定性保障</h4> \n <p>最大流量预估读取有 180wQPS，写入 30wQPS。</p> \n <p>这是典型的超大流量，热点 key、更新延迟不敏感，非数据强一致性场景（数字是一直累加），</p> \n <p>同时要做好<strong>容灾降级处理</strong>，最后实际活动展示的金额与产品预计发放数值误差小于 1%。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/bad435d6650fdb6b002016da05a29b1d.png\" alt=\"\"></p> \n <h5><a id=\"451__568\"></a>4.5.1 方案一</h5> \n <p>高 QPS 下的读取和写入单 key，比较容易想到的是使用 Redis 分布式缓存来进行实现，但是单 key 读取和写入的会打到一个实例上，压测过单实例的瓶颈为 3w QPS。</p> \n <p>所以做的一个优化是拆分多个 key，然后用本地缓存兜底。</p> \n <p><strong>具体写入流程：</strong></p> \n <p>设计拆分 100 个 key，每次发红包根据请求的 actID%100 使用 incr 命令累加该数字，因为不能保证幂等性，所以超时不重试。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/8029924d3b366d73aff105bf7b2874bc.png\" alt=\"\"></p> \n <p><strong>读取流程：</strong></p> \n <p>与写入流程类似，优先读取本地缓存，</p> \n <p>如果本地缓存值为为 0，那么去读取各个 Redis 的 key 值累加到一起，进行返回。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/73a7b7c3a4dfd9c721119a3a55e511a5.png\" alt=\"\"></p> \n <p><strong>问题：</strong></p> \n <p>（1）拆分 100 个 key 会出现读扩散的问题，需要申请较多 Redis 资源，存储成本比较高。</p> \n <p>而且可能存在读取超时问题，不能保证一次读取所有 key 都读取成功，故返回的结果可能会较上一次有减少。</p> \n <p>（2）容灾方案方面，如果申请备份 Redis，也需要较多的存储资源，需要的额外存储成本。</p> \n <h5><a id=\"452__598\"></a>4.5.2 方案二</h5> \n <p><strong>设计思路：</strong></p> \n <p>在方案一实现的基础上进行优化，</p> \n <p>在写场景，通过本地缓存进行合并写请求，进行原子性累加，</p> \n <p>读场景返回本地缓存的值，减少额外的存储资源占用。</p> \n <p>使用 Redis 实现中心化存储，最终大家读到的值都是一样的。</p> \n <p><strong>具体设计方案：</strong></p> \n <p>每个 docker 实例启动时都会执行定时任务，分为读 Redis 任务和写 Redis 任务。</p> \n <p><strong>读取流程：</strong></p> \n <ol>\n  <li> <p>本地的定时任务每秒执行一次，</p> <p>读取 Redis 单 key 的值，如果获取到的值大于本地缓存那么更新本地缓存的值。</p> </li>\n  <li> <p>对外暴露的 sdk 直接返回本地缓存的值即可。</p> </li>\n  <li> <p>有个问题需要注意下，每次实例启动第一秒内是没有数据的，所以会阻塞读，等有数据再返回。</p> </li>\n </ol> \n <p><strong>写入流程：</strong></p> \n <ol>\n  <li> <p>因为读取都是读取本地缓存（本地缓存不过期），所以处理好并发情况下的写即可。</p> </li>\n  <li> <p>本地缓存写变量使用 go 的 atomic.AddInt64 支持原子性累加本地写缓存的值。</p> </li>\n  <li> <p>每次执行更新 Redis 的定时任务，</p> <p>先将本地写缓存复制到 amount 变量，最后将 amount 的值 incr 到 Redis 单 key 上，实现 Redis 的单 key 的值一直累加。</p> </li>\n  <li> <p>容灾方案是使用备份 Redis 集群，写入时进行双写，</p> <p>一旦主机群挂掉，设计了一个配置开关支持读取备份 Redis。两个 Redis 集群的数据一致性，通过定时任务兜底实现。</p> </li>\n </ol> \n <p>具体写入流程图如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/e109f0690f711922dc101c6702e3eaaf.png\" alt=\"\"></p> \n <p><strong>本方案调用 Redis 的流量是跟实例数成正比</strong>，</p> \n <p>经调研读取侧的服务为主会场实例数 2 万个，写入侧服务为资产中台实例数 8 千个，</p> \n <p>所以实际 Redis 要支持的 QPS 为 2.8 万/定时任务执行间隔（单位为 s），</p> \n <p>经压测验证 Redis 单实例可以支持单 key2 万 get，8k incr 的操作，</p> \n <p>所以设置定时任务的<strong>执行时间间隔是 1s</strong>，如果实例数更多可以考虑延长执行时间间隔。</p> \n <h5><a id=\"453__654\"></a>4.5.3 方案对比</h5> \n <table>\n  <thead>\n   <tr>\n    <th></th>\n    <th>优点</th>\n    <th>缺点</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>方案一</td>\n    <td>1. 实现成本简单</td>\n    <td>1. 浪费存储资源； 2. 难以做容灾； 3. 不能做到一直累加；</td>\n   </tr>\n   <tr>\n    <td>方案二</td>\n    <td>1. 节约资源； 2. 容灾方案比较简单，同时也节约资源成本；</td>\n    <td>1. 实现稍复杂，需要考虑好并发原子性累加问题</td>\n   </tr>\n  </tbody>\n </table> \n <p><strong>结论：</strong></p> \n <p>从实现效果，资源成本和容灾等方面考虑，最终选择了方案二上线。</p> \n <h4><a id=\"46__665\"></a>4.6 难点六：大流量场景下资金安全保障</h4> \n <p>钱包方向在本次春节活动期间做了三件事情来保障大流量大预算的现金红包发放的资金安全：</p> \n <ol>\n  <li>现金红包发放整体预算控制的拦截</li>\n  <li>单笔现金红包发放金额上限的拦截</li>\n  <li>大流量发红包场景的资金对账</li>\n </ol> \n <ul>\n  <li>小时级别对账：支持红包雨/集卡/烟火红包发放 h+1 小时级对账，并针对部分场景设置兜底 h+2 核对。</li>\n  <li>准实时对账：红包雨已入账的红包数据反查钱包资产中台和活动侧做准实时对账</li>\n </ul> \n <p>多维度核对示意图：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/ac8168ba12977b430d33d7a5f3c27f3c.png\" alt=\"\"></p> \n <p>准实时对账流程图：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/2e0ae5cd61906fc5d264ae6f5fa4e411.png\" alt=\"\"></p> \n <p><strong>说明：</strong></p> \n <p>准实时对账监控和报警可以及时发现是否异常入账情况，如果报警发现会有紧急预案处理。</p> \n <h3><a id=\"5__688\"></a>5. 通用模式抽象</h3> \n <p>在经历过春节超大流量活动后的设计与实现后，有一些总结和经验与大家一起分享一下。</p> \n <h4><a id=\"51__692\"></a>5.1 容灾降级层面</h4> \n <p>大流量场景，为了保证活动最终上线效果，容灾是一定要做好的。</p> \n <p>参考业界通用实现方案，如降级、限流、熔断、资源隔离，根据预估活动参与人数和效果进行使用存储预估等。</p> \n <h5><a id=\"511__698\"></a>5.1.1 限流层面</h5> \n <p>（1）限流方面应用了 api 层 nginx 入流量限流，分布式入流量限流，分布式出流量限流。</p> \n <p>这几个限流器都是字节跳动公司层面公共的中间件，经过大流量的验证。</p> \n <p>（2）首先进行了实际单实例压测，根据单实例扛住的流量与本次春节活动预估流量打到该服务的流量进行扩容，并结合下游能抗住的情况，</p> \n <p>在 tlb 入流量、入流量限流以及出流量限流分别做好了详细完整的配置并同。</p> \n <p><strong>限流目标：</strong></p> \n <p>保证自身服务稳定性，防止外部预期外流量把本身服务打垮，防止造成雪崩效应，保证核心业务和用户核心体验。</p> \n <p>简单集群限流是实例维度的限流，</p> \n <p>每个实例限流的 QPS=总配置限流 QPS/实例数，</p> \n <p>对于多机器低 QPS 可能会有不准的情况，要<strong>经过实际压测并且及时调整配置值。</strong></p> \n <p>对于分布式入流量和出流量限流，两种使用方式如下，每种方式都支持高低 QPS，区别只是 SDK 使用方式和功能不同。</p> \n <p>一般低 QPS 精度要求高，采用 redis 计数方式，使用方提供自己的 redis 集群。</p> \n <p>高 QPS 精度要求低，退化为总 QPS/tce 实例数的单实例限流。</p> \n <h5><a id=\"512__724\"></a>5.1.2 降级层面</h5> \n <p>对于高流量场景，每个核心功能都要有对应的<strong>降级方案</strong>来保证突发情况核心链路的稳定性。</p> \n <p>（1）本次春节奖励入账与活动活动钱包页方向做好了充分的操作预案，一共有 26 个降级开关，关键时刻弃车保帅，防止有单点问题影响核心链路。</p> \n <p>（2）以发现金红包链路举例，钱包方向最后完全降级的方案是只依赖 docker 和 MySQL，其他依赖都是可以降级掉的，MySQL 主有问题可以紧急联系切主，虽说最后一个都没用上，但是前提要设计好保证活动的万无一失。</p> \n <h5><a id=\"513__732\"></a>5.1.3 资源隔离层面</h5> \n <p>（1）提升开发效率<strong>不重复造轮子</strong>。</p> \n <p>因为钱包资产中台也日常支持抖音资产发放的需求，本次春节活动也复用了现有的接口和代码流程支持发奖。</p> \n <p>（2）同时针对本次春节活动，服务层面做了<strong>集群隔离</strong>，</p> \n <p>创建专用活动集群，底层存储资源隔离，活动流量和常规流量互不影响。</p> \n <h5><a id=\"514__742\"></a>5.1.4 存储预估</h5> \n <p>（1）不但要考虑和验证了 Redis 或者 MySQL 存储能抗住对应的流量，同时也要按照实际的获取参与和发放数据等预估存储资源是否足够。</p> \n <p>（2）对于字节跳动公司的 Redis 组件来讲，</p> \n <p>可以进行<strong>垂直扩容</strong>（每个实例增加存储，最大 10G），也可以进行<strong>水平扩容</strong>（单机房上限是 500 个实例），因为 Redis 是三机房同步的，所以计算存储时只考虑一个机房的存储上限即可。</p> \n <p>要留足 buffer，因为水平扩容是很慢的一个过程，突发情况遇到存储资源不足只能通过配置开关提前下掉依赖存储，需要提前设计好。</p> \n <h5><a id=\"515__752\"></a>5.1.5 压测层面</h5> \n <p>本次春节活动，钱包奖励入账和活动钱包页做了充分的全链路压测验证，下面是一些经验总结。</p> \n <ol>\n  <li>在压测前要建立好压测整条链路的监控大盘，在压测过程当中及时和方便的发现问题。</li>\n  <li>对于 MySQL 数据库，在红包雨等大流量正式活动开始前，进行小流量压测预热数据库，峰值流量前提前建链，减少正式活动时的大量建链耗时，保证发红包链路数据库层面的稳定性。</li>\n  <li>压测过程当中一定要传压测标，支持全链路识别压测流量做特殊逻辑处理，与线上正常业务互不干扰。</li>\n  <li>针对压测流量不做特殊处理，压测流量处理流程保持和线上流量一致。</li>\n  <li>压测中要验证计算资源与存储资源是否能抗住预估流量</li>\n </ol> \n <ul>\n  <li><strong>梳理好压测计划</strong>，基于历史经验，设置合理初始流量，渐进提升压测流量，实时观察各项压测指标。</li>\n  <li><strong>存储资源压测数据要与线上数据隔离</strong>，对于 MySQL 和 Bytekv 这种来讲是建压测表，对于 Redis 和 Abase 这种来讲是压测 key 在线上 key 基础加一下压测前缀标识 。</li>\n  <li><strong>压测数据要及时清理</strong>，Redis 和 Abase 这种加短时间的过期时间，过期机制处理比较方便，如果忘记设置过期时间，可以根据写脚本识别压测标前缀去删除。</li>\n </ul> \n <ol>\n  <li>压测后也要关注存储资源各项指标是否符合预期。</li>\n </ol> \n <h4><a id=\"52__768\"></a>5.2 微服务思考</h4> \n <p>在日常技术设计中，大家都会遵守微服务设计原则和规范，根据系统职责和核心数据模型拆分不同模块，提升开发迭代效率并不互相影响。</p> \n <p>但是微服务也有它的弊端，对于超大流量的场景功能也比较复杂，会经过多个链路，这样是极其消耗计算资源的。</p> \n <p>本次春节活动<strong>资产中台提供了 sdk 包代替 rpc 进行微服务链路聚合对外提供基础能力</strong>，如查询余额、判断用户是否获取过奖励，强制入账等功能。访问流量最高上千万，与使用微服务架构对比节约了上万核 CPU 的计算资源。</p> \n <h3><a id=\"6__776\"></a>6. 系统的未来演进方向</h3> \n <p>（1）梳理上下游需求和痛点，优化资产中台设计实现，完善基础能力，优化服务架构，提供一站式服务，让接入活动方可以更专注进行活动业务逻辑的研发工作。</p> \n <p>（2）加强实时和离线数据看板能力建设，让奖励发放数据展示的更清晰更准确。</p> \n <p>（3）加强配置化和文档建设，对内减少对接活动的对接成本，对外提升活动业务方接入效率。</p> \n <blockquote> \n  <p>上文参考来源：字节跳动技术团队：春节钱包大流量奖励系统入账及展示的设计与实现</p> \n </blockquote> \n <h2><a id=\"_790\"></a>推荐阅读：</h2> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128670335\">Docker面试题（史上最全 + 持续更新）</a>》<br> 《 <a href=\"https://blog.csdn.net/crazymakercircle/article/details/128533821\">场景题：假设10W人突访，你的系统如何做到不 雪崩？</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124790425\">尼恩Java面试宝典</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057567\">Springcloud gateway 底层原理、核心实战 (史上最全)</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124120506\">Flux、Mono、Reactor 实战（史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125059491\">sentinel （史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057545\">Nacos (史上最全)</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/123420859\">分库分表 Sharding-JDBC 底层原理、核心实战（史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/114527369\">TCP协议详解 (史上最全)</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126992542\">clickhouse 超底层原理 + 高可用实操 （史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120702536\">nacos高可用（图解+秒懂+史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264803\">队列之王： Disruptor 原理、架构、源码 一文穿透</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264508\">环形队列、 条带环形队列 Striped-RingBuffer （史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125135726\">一文搞定：SpringBoot、SLF4j、Log4j、Logback、Netty之间混乱关系（史上最全）</a><br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128265067\">单例模式（史上最全）</a><br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125017316\">红黑树（ 图解 + 秒懂 + 史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/109459593\">分布式事务 （秒懂）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128123114\">缓存之王：Caffeine 源码、架构、原理（史上最全，10W字 超级长文）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/113751575\">缓存之王：Caffeine 的使用（史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126579528\">Java Agent 探针、字节码增强 ByteBuddy（史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120747767\">Docker原理（图解+秒懂+史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/116425814\">Redis分布式锁（图解 - 秒懂 - 史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85956246\">Zookeeper 分布式锁 - 图解 - 秒懂</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85922561\">Zookeeper Curator 事件监听 - 10分钟看懂</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83957259\">Netty 粘包 拆包 | 史上最全解读</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83758107\">Netty 100万级高并发服务器配置</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/102557988\">Springcloud 高并发 配置 （一文全懂）</a>》</p> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 1684);
INSERT INTO `crawlerblog` VALUES (123124012, 'Nginx面试题（史上最全 + 持续更新）', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <h2><a id=\"39Nginx_0\"></a>尼恩面试宝典专题39：Nginx面试题（史上最全、持续更新）</h2> \n <h4><a id=\"V27_1\"></a>本文版本说明：V27</h4> \n <h2><a id=\"_3\"></a>《尼恩面试宝典》升级规划为：</h2> \n <p>后续基本上，<strong>每一个月，都会发布一次</strong>，最新版本，可以联系构师尼恩获取， 发送 “领取电子书” 获取。<br> <img src=\"https://img-blog.csdnimg.cn/img_convert/9cab24afac032e4952398bf2f84a867f.png\" alt=\"\"></p> \n <p>Nginx的并发能力在同类型网页服务器中的表现，相对而言是比较好的，因此受到了很多企业的青睐，我国使用Nginx网站的知名用户包括腾讯、淘宝、百度、京东、新浪、网易等等。</p> \n <p>Nginx是系统架构师、开发人员、网页服务器运维人员必备技能之一，下面的面试题，为大家提供系统化、体系化的学习资料， 比一般的专业书籍，更有价值</p> \n <p>最新版本，可以联系构师尼恩获取， 发送 “领取电子书” 获取。</p> \n <h2><a id=\"Nginx_15\"></a>聊聊：什么是Nginx?</h2> \n <p>Nginx是一个web服务器和反向代理服务器，用于HTTP、HTTPS、SMTP、POP3和IMAP协议。</p> \n <p>Nginx—Ngine X，是一款免费的、自由的、开源的、高性能HTTP服务器和反向代理服务器；</p> \n <p>也是一个IMAP、POP3、SMTP代理服务器；</p> \n <p>Nginx以其高性能、稳定性、丰富的功能、简单的配置和低资源消耗而闻名。</p> \n <p>也就是说Nginx本身就可以托管网站（类似于Tomcat一样），进行Http服务处理，也可以作为反向代理服务器 、负载均衡器和HTTP缓存。</p> \n <p>Nginx 解决了服务器的C10K（就是在一秒之内连接客户端的数目为10k即1万）问题。</p> \n <p>它的设计不像传统的服务器那样使用线程处理请求，而是一个更加高级的机制—事件驱动机制，是一种异步事件驱动结构。</p> \n <h2><a id=\"Nginx_35\"></a>聊聊：Nginx的一些特性。</h2> \n <p>Nginx服务器的特性包括：</p> \n <ul>\n  <li>反向代理/L7负载均衡器</li>\n  <li>嵌入式Perl解释器</li>\n  <li>动态二进制升级</li>\n  <li>可用于重新编写URL，具有非常好的PCRE支持</li>\n </ul> \n <h2><a id=\"Nginx_46\"></a>聊聊：Nginx的优缺点？</h2> \n <p>核心优点：</p> \n <ul>\n  <li>占内存小，可实现高并发连接，处理响应快</li>\n  <li>可实现http服务器、虚拟主机、方向代理、负载均衡</li>\n  <li>Nginx配置简单</li>\n  <li>可以不暴露正式的服务器IP地址</li>\n </ul> \n <p>核心缺点：</p> \n <ul>\n  <li>动态处理差：</li>\n </ul> \n <p>nginx处理静态文件好,耗费内存少，但是处理动态页面则很鸡肋，</p> \n <p>现在一般前端用nginx作为反向代理抗住压力。</p> \n <h2><a id=\"Nginx_65\"></a>聊聊：Nginx应用场景？</h2> \n <ul>\n  <li>http服务器。</li>\n </ul> \n <p>Nginx是一个http服务可以独立提供http服务。可以做网页静态服务器。</p> \n <ul>\n  <li>虚拟主机。</li>\n </ul> \n <p>可以实现在一台服务器虚拟出多个网站，例如个人网站使用的虚拟机。</p> \n <ul>\n  <li>反向代理，负载均衡。</li>\n </ul> \n <p>当网站的访问量达到一定程度后，单台服务器不能满足用户的请求时，需要用多台服务器集群可以使用nginx做反向代理。</p> \n <p>并且多台服务器可以平均分担负载，不会应为某台服务器负载高宕机而某台服务器闲置的情况。</p> \n <p>nginz 中也可以配置安全管理、比如可以使用Nginx搭建API接口网关,对每个接口服务进行拦截。</p> \n <h2><a id=\"_87\"></a>聊聊：使用“反向代理服务器”的优点是什么?</h2> \n <p>反向代理服务器可以隐藏源服务器的存在和特征。</p> \n <p>它充当互联网云和web服务器之间的中间层。</p> \n <p>这对于安全方面来说是很好的，特别是当您使用web托管服务时。</p> \n <h2><a id=\"_97\"></a>聊聊：什么是正向代理和反向代理？</h2> \n <p>首先，代理服务器一般指局域网内部的机器通过代理服务器发送请求到互联网上的服务器，代理服务器一般作用在客户端。例如：GoAgent翻墙软件。</p> \n <p>我们的客户端在进行翻墙操作的时候，我们使用的正是正向代理，通过正向代理的方式，在我们的客户端运行一个软件，将我们的HTTP请求转发到其他不同的服务器端，实现请求的分发。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/f9f5b077d05fc0ce06315cbb858ed2e2.png\" alt=\"\"></p> \n <p>反向代理服务器作用在服务器端，它在服务器端接收客户端的请求，然后将请求分发给具体的服务器进行处理，然后再将服务器的相应结果反馈给客户端。Nginx就是一个反向代理服务器软件。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/1ff61e511967bb0f0d59c9a83dcf1897.png\" alt=\"\"></p> \n <p>从上图可以看出：客户端必须设置正向代理服务器，当然前提是要知道正向代理服务器的IP地址，还有代理程序的端口。</p> \n <p>反向代理正好与正向代理相反，对于客户端而言代理服务器就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理的命名空间（name-space）中的内容发送普通请求，接着反向代理将判断向何处（原始服务器）转交请求，并将获得的内容返回给客户端。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/567f7de140fb416d8abeb72c0879e568.png\" alt=\"\"></p> \n <h2><a id=\"_121\"></a>聊聊：反向代理好处</h2> \n <ol>\n  <li>保护了真实的 web 服务器，web 服务器对外不可见，外网只能看到反向代理服务器，而反向代理服务器上并没有真实数据，因此，保证了 web 服务器的资源安全。</li>\n  <li>反向代理为基础产生了动静资源分离以及负载均衡的方式，减轻 web 服务器的负担，加速了对网站访问速度。</li>\n  <li>节约了有限的 IP 地址资源，企业内所有的网站共享一个在 internet 中注册的IP地址，这些服务器分配私有地址，采用虚拟主机的方式对外提供服务。</li>\n </ol> \n <h2><a id=\"Nginx___131\"></a>聊聊：什么是Nginx? 它的优势和功能?</h2> \n <p>Nginx是一个web服务器和方向代理服务器，用于HTTP、HTTPS、SMTP、POP3和IMAP协议。因它的稳定性、丰富的功能集、示例配置文件和低系统资源的消耗而闻名。<br> 优点：</p> \n <p><strong>（1）更快</strong></p> \n <p>这表现在两个方面：一方面，在正常情况下，单次请求会得到更快的响应；另一方面，在高峰期（如有数以万计的并发请求），Nginx可以比其他Web服务器更快地响应请求。</p> \n <p><strong>（2）高扩展性，跨平台</strong></p> \n <p>Nginx的设计极具扩展性，它完全是由多个不同功能、不同层次、不同类型且耦合度极低的模块组成。因此，当对某一个模块修复Bug或进行升级时，可以专注于模块自身，无须在意其他。而且在HTTP模块中，还设计了HTTP过滤器模块：一个正常的HTTP模块在处理完请求后，会有一串HTTP过滤器模块对请求的结果进行再处理。这样，当我们开发一个新的HTTP模块时，不但可以使用诸如HTTP核心模块、events模块、log模块等不同层次或者不同类型的模块，还可以原封不动地复用大量已有的HTTP过滤器模块。这种低耦合度的优秀设计，造就了Nginx庞大的第三方模块，当然，公开的第三方模块也如官方发布的模块一样容易使用。<br> Nginx的模块都是嵌入到二进制文件中执行的，无论官方发布的模块还是第三方模块都是如此。这使得第三方模块一样具备极其优秀的性能，充分利用Nginx的高并发特性，因此，许多高流量的网站都倾向于开发符合自己业务特性的定制模块。</p> \n <p><strong>（3）高可靠性：用于反向代理，宕机的概率微乎其微</strong></p> \n <p>高可靠性是我们选择Nginx的最基本条件，因为Nginx的可靠性是大家有目共睹的，很多家高流量网站都在核心服务器上大规模使用Nginx。Nginx的高可靠性来自于其核心框架代码的优秀设计、模块设计的简单性；另外，官方提供的常用模块都非常稳定，每个worker进程相对独立，master进程在1个worker进程出错时可以快速“拉起”新的worker子进程提供服务。</p> \n <p><strong>（4）低内存消耗</strong></p> \n <p>一般情况下，10 000个非活跃的HTTP Keep-Alive连接在Nginx中仅消耗2.5MB的内存，这是Nginx支持高并发连接的基础。</p> \n <p><strong>（5）单机支持10万以上的并发连接</strong></p> \n <p>这是一个非常重要的特性！</p> \n <p>随着互联网的迅猛发展和互联网用户数量的成倍增长，各大公司、网站都需要应付海量并发请求，一个能够在峰值期顶住10万以上并发请求的Server，无疑会得到大家的青睐。</p> \n <p>理论上，Nginx支持的并发连接上限取决于内存，10万远未封顶。当然，能够及时地处理更多的并发请求，是与业务特点紧密相关的。</p> \n <p><strong>（6）热部署</strong></p> \n <p>master管理进程与worker工作进程的分离设计，使得Nginx能够提供热部署功能，即可以在7×24小时不间断服务的前提下，升级Nginx的可执行文件。</p> \n <p>当然，它也支持不停止服务就更新配置项、更换日志文件等功能。</p> \n <p><strong>（7）最自由的BSD许可协议</strong></p> \n <p>这是Nginx可以快速发展的强大动力。</p> \n <p>BSD许可协议不只是允许用户免费使用Nginx，它还允许用户在自己的项目中直接使用或修改Nginx源码，然后发布。这吸引了无数开发者继续为Nginx贡献自己的智慧。</p> \n <p>以上7个特点当然不是Nginx的全部，拥有无数个官方功能模块、第三方功能模块使得Nginx能够满足绝大部分应用场景，这些功能模块间可以叠加以实现更加强大、复杂的功能，有些模块还支持Nginx与Perl、Lua等脚本语言集成工作，大大提高了开发效率。这些特点促使用户在寻找一个Web服务器时更多考虑Nginx。</p> \n <p>选择Nginx的核心理由还是它能在支持高并发请求的同时保持高效的服务</p> \n <h2><a id=\"Nginx_179\"></a>聊聊：为什么要用Nginx？</h2> \n <ul>\n  <li> <p>跨平台、配置简单、方向代理、高并发连接：处理2-3万并发连接数，官方监测能支持5万并发，内存消耗小：开启10个nginx才占150M内存 ，nginx处理静态文件好，耗费内存少，</p> </li>\n  <li> <p>而且Nginx内置的健康检查功能：如果有一个服务器宕机，会做一个健康检查，再发送的请求就不会发送到宕机的服务器了。重新将请求提交到其他的节点上。</p> </li>\n  <li> <p>使用Nginx的话还能：</p> \n   <ol>\n    <li>节省宽带：支持GZIP压缩，可以添加浏览器本地缓存</li>\n    <li>稳定性高：宕机的概率非常小</li>\n    <li>接收用户请求是异步的</li>\n   </ol> </li>\n </ul> \n <h2><a id=\"C10K_189\"></a>聊聊：请解释什么是C10K问题?</h2> \n <p>C10K问题是指无法同时处理大量客户端(10,000)的网络套接字。</p> \n <h2><a id=\"C10K_195\"></a>聊聊：C10K问题的本质和解决方案</h2> \n <h3><a id=\"C10K_197\"></a>什么是C10K问题</h3> \n <p>所谓 c10k 问题，指的是服务器如何支持 10k 个并发连接，也就是 concurrent 10000 connection（这也是 c10k 这个名字的由来）。</p> \n <p>由于硬件成本的大幅度降低和硬件技术的进步，如果一台服务器能够同时服务更多的客户端，那么也就意味着服务每一个客户端的成本大幅度降低。从这个角度来看，c10k 问题显得非常有意义。</p> \n <h4><a id=\"C10K_203\"></a>C10K问题由来</h4> \n <p>互联网的基础是网络通信，早期的互联网可以说是一个小群体的集合。互联网还不够普及，用户也不多，一台服务器同时在线 100 个用户，在当时已经算是大型应用了，所以并不存在 C10K 的难题。互联网的爆发期是在 www 网站、浏览器出现后。最早的互联网称之为 Web1.0，大部分的使用场景是下载一个 HTML 页面，用户在浏览器中查看网页上的信息，这个时期也不存在 C10K 问题。</p> \n <p>Web2.0 时代到来后，就不同了。一方面是，互联网普及率大大提高了，用户群体几何倍增长。另一方面是，互联网不再是单纯地浏览 www 网页，逐渐开始进行交互，而且应用程序的逻辑也变得更复杂。从简单的表单提交，到即时通信和在线实时互动，C10K 的问题才体现出来了。因为每一个用户都必须与服务器保持连接，才能进行实时数据交互。诸如 Facebook 这样的网站，同一时间的并发 TCP 连接很可能已经过亿。</p> \n <pre><code>早期的腾讯QQ也同样面临C10K问题，只不过他们是用了UDP这种原始的包交换协议来实现的，绕开了这个难题，当然过程肯定是痛苦的。如果当时有 epoll 技术，他们肯定会用 TCP。众所周之，后来的手机 QQ、微信都采用 TCP 协议。\n实际上，当时也有异步模式，如：select/poll 模型。这些技术都有一定的缺点：selelct 最大不能超过 1024；poll 没有限制，但每次收到数据时，需要遍历每一个连接，查看哪个连接有数据请求。\n</code></pre> \n <p>这时候问题就来了，最初的服务器都是基于进程/线程模型的，新到来一个 TCP 连接，就需要分配 1 个进程（或者线程）。进程又是操作系统最昂贵的资源，一台机器无法创建很多进程。如果是 C10K，就要创建 1 万个进程，那么就单机而言，操作系统是无法承受的（往往出现效率低下、甚至完全瘫痪）。如果是采用分布式系统，维持 1 亿用户在线需要 10 万台服务器，成本巨大，也只有 Facebook、Google、Apple 等巨头，才有财力购买如此多的服务器。</p> \n <p>基于上述考虑，如何突破单机性能局限，是高性能网络编程所必须要直面的问题。这些局限和问题，最早被 Dan Kegel 进行了归纳和总结，并首次系统地分析和提出了解决方案。后来，这种普遍的网络现象和技术局限，都被大家称为 C10K 问题。</p> \n <h3><a id=\"C10K_218\"></a>C10K问题的本质</h3> \n <p>C10K 问题，本质上是操作系统的问题。对于 Web1.0/2.0 时代的操作系统而言，传统的同步阻塞 I/O 模型都是一样的，处理的方式都是 requests per second，并发 10K 和 100 的区别关键在于 CPU。</p> \n <p>创建的进程、线程多了，数据拷贝频繁（缓存 I/O、内核将数据拷贝到用户进程空间、阻塞）， 进程/线程上下文切换消耗大， 导致操作系统崩溃，这就是 C10K 问题的本质！</p> \n <p>可见，解决 C10K 问题的关键就是：尽可能减少 CPU 等核心资源消耗，从而榨干单台服务器的性能，突破 C10K 问题所描述的瓶颈。</p> \n <h3><a id=\"C10K_226\"></a>C10K问题的解决方案探讨</h3> \n <p>从网络编程技术的角度来说，主要思路为：</p> \n <ol>\n  <li>为每个连接分配一个独立的线程/进程。</li>\n  <li>同一个线程/进程同时处理多个连接（IO 多路复用）。</li>\n </ol> \n <h4><a id=\"_233\"></a>为每个连接分配一个独立的线程/进程</h4> \n <p>这一思路最为直接。但是，由于申请进程/线程会占用相当可观的系统资源，同时对于多进程/线程的管理会对系统造成压力，因此，这种方案不具备良好的可扩展性。</p> \n <p>这一思路在服务器资源还没有富裕到足够程度的时候，是不可行的。即便资源足够富裕，效率也不够高。</p> \n <p>总之，此思路技术实现会使得资源占用过多，可扩展性差，在实际应用中已被抛弃。</p> \n <h4><a id=\"IO_241\"></a>同一个线程/进程同时处理多个连接（IO多路复用）</h4> \n <p>IO 多路复用，从技术实现上，又分很多种。我们逐一来看看下述各种实现方式的优劣。</p> \n <p><strong>实现方式1：循环逐个处理各个连接，每个连接对应一个 socket</strong></p> \n <p>循环逐个处理各个连接，每个连接对应一个 socket。当所有 socket 都有数据的时候，这种方法是可行的。但是，当应用读取某个 socket 的文件数据不 ready 的时候，整个应用会阻塞在这里，等待该文件句柄 ready，即使别的文件句柄 ready，也无法往下处理。</p> \n <p>实现小结：直接循环处理多个连接。</p> \n <p>问题归纳：任一文件句柄的不成功会阻塞住整个应用。</p> \n <p><strong>实现方式2：使用 select 方法</strong></p> \n <p>使用 select 方法解决上面阻塞的问题，思路比较简单。在读取文件句柄之前，先查下它的状态，如果 ready 了，就进行处理；如果不 ready， 就不进行处理；这不就解决了这个问题了嘛？于是，有了 select 方案。用一个 fd_set 结构体来告诉内核同时监控多个文件句柄，当其中有文件句柄的状态发生指定变化（例如某句柄由不可用变为可用）或超时，则调用返回。</p> \n <p>之后，应用可以使用 FD_ISSET 来逐个查看，确定哪个文件句柄的状态发生了变化。这样做，小规模的连接问题不大，但当连接数很多（文件句柄个数很多）的时候，逐个检查状态就很慢了。因此，select 往往存在管理的句柄上限（FD_SETSIZE）。同时，在使用上，因为只有一个字段记录关注和发生事件，所以每次调用之前，要重新初始化 fd_set 结构体。</p> \n <pre><code class=\"prism language-bash\">intselect<span class=\"token punctuation\">(</span>intnfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds,structtimeval *timeout<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre> \n <p>实现小结：有连接请求抵达了，再检查处理。</p> \n <p>问题归纳：句柄上限+重复初始化+逐个排查所有文件句柄状态，效率不高。</p> \n <p><strong>实现方式3：使用 poll 方法</strong></p> \n <p>poll 主要解决 select 的前两个问题：</p> \n <ol>\n  <li>通过一个 pollfd 数组，向内核传递需要关注的事件，以消除文件句柄上限。</li>\n  <li>使用不同字段分别标注 “关注事件和发生事件”，来避免重复初始化。</li>\n </ol> \n <p>实现小结：设计新的数据结构，提高使用效率。</p> \n <p>问题归纳：逐个排查所有文件句柄状态，效率不高。</p> \n <p><strong>实现方式4：使用 epoll 方法</strong></p> \n <p>既然 “poll 逐个排查所有文件句柄状态” 效率不高，很自然的，在调用返回的时候，如果只给应用提供发生了状态变化（很可能是数据 ready）的文件句柄，进行排查的效率就高很多。epoll 采用了这种设计，适用于大规模的应用场景。实验表明：当文件句柄数目超过10之后，epoll 性能将优于 select 和 poll；当文件句柄数目达到 10K 的时候，epoll 已经超过 select 和 poll 两个数量级。</p> \n <p>实现小结：只返回状态变化的文件句柄。</p> \n <p>问题归纳：依赖特定平台（Linux）。</p> \n <p>因为 Linux 是互联网企业中使用率最高的操作系统，所以 Epoll 就成为 “C10K killer、高并发、高性能、异步非阻塞” 这些技术的代名词了。FreeBSD 推出了 kqueue，Linux 推出了 epoll，Windows 推出了 IOCP，Solaris 推出了 /dev/poll。这些操作系统提供的功能，就是为了解决 C10K 问题。epoll 技术的编程模型就是异步非阻塞回调，也可以叫做 Reactor、事件驱动、事件轮循（EventLoop）。Nginx、libevent、node.js 这些就是 Epoll 时代的产物。</p> \n <p><strong>实现方式5：使用 libevent 库</strong></p> \n <p>由于 epoll,、kqueue、IOCP 每个接口都有自己的特点，程序移植非常困难，所以需要对这些接口进行封装，以让它们易于使用和移植，其中 libevent 库就是其中之一。跨平台，封装底层平台的调用，提供统一的 API，但底层在不同平台上自动选择合适的调用。</p> \n <p>按照 libevent 的官方网站，libevent 库提供了以下功能：当一个文件描述符的特定事件（如可读，可写或出错）发生了，或一个定时事件发生了，libevent 就会自动执行用户指定的回调函数，来处理事件。目前，libevent 已支持以下接口 /dev/poll、kqueue、event ports、select、poll 和 epoll。Libevent 的内部事件机制完全是基于所使用的接口的。因此，libevent 非常容易移植，也使它的扩展性非常容易。目前，libevent 已在以下操作系统中编译通过：Linux、BSD、Mac OS X、Solaris 和 Windows。使用 libevent 库进行开发非常简单，也很容易在各种 unix 平台上移植。</p> \n <h2><a id=\"Nginx_298\"></a>聊聊：Nginx如何实现超高并发？</h2> \n <h4><a id=\"_300\"></a>面试官心理分析</h4> \n <p>主要是看应聘人员的对NGINX的基本原理是否熟悉，因为大多数人多多少少都懂点NGINX，但是真正其明白原理的可能少之又少。</p> \n <p>明白其原理，才能做优化，否则只能照样搬样，出了问题也无从下手。</p> \n <p>懂皮毛的人，一般会做个 Web Server，搭建一个 Web 站点；</p> \n <p>初级运维可能搞个 HTTPS 、配置一个反向代理; 中级运维定义个 upstream、写个正则判断；</p> \n <p>老鸟做个性能优化、写个ACL，还有可能改改源码。</p> \n <h4><a id=\"_312\"></a>面试题剖析</h4> \n <p>异步，非阻塞，使用了epoll 和大量的底层代码优化。</p> \n <p>如果一个server采用一个进程负责一个request的方式，那么进程数就是并发数。正常情况下，会有很多进程一直在等待中。</p> \n <p>而nginx采用一个master进程，多个woker进程的模式。</p> \n <ul>\n  <li>master进程主要负责收集、分发请求。每当一个请求过来时，master就拉起一个worker进程负责处理这个请求。</li>\n  <li>同时master进程也负责监控woker的状态，保证高可靠性</li>\n  <li>woker进程一般设置为跟cpu核心数一致。nginx的woker进程在同一时间可以处理的请求数只受内存限制，可以处理多个请求。</li>\n  <li>Nginx 的异步非阻塞工作方式正把当中的等待时间利用起来了。在需要等待的时候，这些进程就空闲出来待命了，因此表现为少数几个进程就解决了大量的并发问题。</li>\n </ul> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/75f53c1f410adb8a740fc11ba49bce6a.png\" alt=\"\"></p> \n <p>每进来一个request，会有一个worker进程去处理。但不是全程的处理，处理到什么程度呢？处理到可能发生阻塞的地方，比如向上游（后端）服务器转发request，并等待请求返回。那么，这个处理的worker很聪明，他会在发送完请求后，注册一个事件：“如果upstream返回了，告诉我一声，我再接着干”。于是他就休息去了。</p> \n <p>此时，如果再有request 进来，他就可以很快再按这种方式处理。而一旦上游服务器返回了，就会触发这个事件，worker才会来接手，这个request才会接着往下走。</p> \n <h2><a id=\"Nginx_333\"></a>聊聊：Nginx如何实现超高并发？</h2> \n <p>Nginx 是一个高性能的 Web 服务器，能够同时处理大量的并发请求。</p> \n <p>它结合多进程机制和异步机制 ，异步机制使用的是异步非阻塞方式，</p> \n <p>接下来就给大家介绍一下 Nginx 的多线程机制和异步非阻塞机制。</p> \n <h4><a id=\"1_341\"></a>1、多进程机制</h4> \n <p>服务器每当收到一个客户端时，就有 服务器主进程 （ master process ）生成一个 子进程（ worker process ）出来和客户端建立连接进行交互，直到连接断开，该子进程就结束了。</p> \n <p>使用进程的好处是各个进程之间相互独立，不需要加锁，减少了使用锁对性能造成影响，同时降低编程的复杂度，降低开发成本。其次，采用独立的进程，可以让进程互相之间不会影响 ，如果一个进程发生异常退出时，其它进程正常工作， master 进程则很快启动新的 worker 进程，确保服务不会中断，从而将风险降到最低。</p> \n <p>缺点是操作系统生成一个子进程需要进行 内存复制等操作，在资源和时间上会产生一定的开销。当有大量请求时，会导致系统性能下降 。</p> \n <h4><a id=\"2_349\"></a>2、异步非阻塞机制</h4> \n <p>每个工作进程 使用 异步非阻塞方式 ，可以处理 多个客户端请求 。</p> \n <p>当某个 工作进程 接收到客户端的请求以后，调用 IO 进行处理，如果不能立即得到结果，就去 处理其他请求 （即为 非阻塞 ）；而 客户端 在此期间也 无需等待响应 ，可以去处理其他事情（即为 异步 ）。</p> \n <p>当 IO 返回时，就会通知此 工作进程 ；该进程得到通知，暂时 挂起 当前处理的事务去 响应客户端请求 。</p> \n <h2><a id=\"NginxMasterWorker_359\"></a>聊聊：请解释Nginx服务器上的Master和Worker进程分别是什么?</h2> \n <ul>\n  <li>主程序 Master process 启动后，通过一个 for 循环来 接收 和 处理外部信号 ；</li>\n  <li>主进程通过 fork() 函数产生 worker 子进程 ，每个子进程执行一个 for循环来实现Nginx服务器对事件的接收和处理 。</li>\n </ul> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/d34ed01f3db431d7f075675043a586a4.png\" alt=\"\"></p> \n <p>一般推荐 worker 进程数与CPU内核数一致，这样一来不存在大量的子进程生成和管理任务，避免了进程之间竞争CPU 资源和进程切换的开销。而且 Nginx 为了更好的利用 多核特性 ，提供了 CPU 亲缘性的绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来 Cache 的失效。</p> \n <p>对于每个请求，有且只有一个工作进程 对其处理。首先，每个 worker 进程都是从 master进程 fork 过来。在 master 进程里面，先建立好需要 listen 的 socket（listenfd） 之后，然后再 fork 出多个 worker 进程。</p> \n <p>所有 worker 进程的 listenfd 会在新连接到来时变得可读 ，为保证只有一个进程处理该连接，所有 worker 进程在注册 listenfd 读事件前抢占 accept_mutex ，抢到互斥锁的那个进程注册 listenfd 读事件 ，在读事件里调用 accept 接受该连接。</p> \n <p>当一个 worker 进程在 accept 这个连接之后，就开始读取请求、解析请求、处理请求，产生数据后，再返回给客户端 ，最后才断开连接。这样一个完整的请求就是这样的了。我们可以看到，一个请求，完全由 worker 进程来处理，而且只在一个 worker 进程中处理。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/993151b4b04b09b25f8472087adcb422.png\" alt=\"\"></p> \n <p>在 Nginx 服务器的运行过程中， 主进程和工作进程 需要进程交互。交互依赖于 Socket 实现的管道来实现。</p> \n <h2><a id=\"Nginx_384\"></a>聊聊：请列举Nginx服务器的最佳用途。</h2> \n <p>Nginx服务器的最佳用法是在网络上部署动态HTTP内容，使用SCGI、WSGI应用程序服务器、用于脚本的FastCGI处理程序。</p> \n <p>它还可以作为负载均衡器。</p> \n <h2><a id=\"Nginx_394\"></a>聊聊：Nginx负载均衡实现过程</h2> \n <p>首先在http模块中配置使用upstream模块定义后台的webserver的池子，并且给池子命名， 比如命名为proxy-web，</p> \n <p>在池子中我们可以添加多台后台webserver，其中状态检查、调度算法都是在池子中配置；</p> \n <p>然后在server模块中定义虚拟 location 地址，但是这个虚拟location 地址 不指定自己的web目录站点，</p> \n <p>它将使用location 匹配url然后转发到上面定义好的web池子中，</p> \n <p>后台的webserver的池子，最后根据调度策略再转发到后台web server上。</p> \n <h2><a id=\"Nginx_408\"></a>聊聊：Nginx负载均衡配置</h2> \n <pre><code class=\"prism language-bash\">Upstream proxy_nginx <span class=\"token punctuation\">{\n    <!-- --></span>\n	server <span class=\"token number\">192.168</span>.0.254 <span class=\"token assign-left variable\">weight</span><span class=\"token operator\">=</span>1max_fails<span class=\"token operator\">=</span><span class=\"token number\">2</span> <span class=\"token assign-left variable\">fail_timeout</span><span class=\"token operator\">=</span>10s <span class=\"token punctuation\">;</span> \n	server <span class=\"token number\">192.168</span>.0.253 <span class=\"token assign-left variable\">weight</span><span class=\"token operator\">=</span><span class=\"token number\">2</span> <span class=\"token assign-left variable\">max_fails</span><span class=\"token operator\">=</span>2fail_timeout<span class=\"token operator\">=</span>10s<span class=\"token punctuation\">;</span>\n	server192.168.0.252 backup<span class=\"token punctuation\">;</span> server192.168.0.251 down<span class=\"token punctuation\">;</span> \n<span class=\"token punctuation\">}</span>\n\nserver<span class=\"token punctuation\">{\n    <!-- --></span>\n	listen <span class=\"token number\">80</span><span class=\"token punctuation\">;</span>\n	server_name xiaoka.com<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\nlocation / <span class=\"token punctuation\">{\n    <!-- --></span>\n	proxy_pass http:// proxy_nginx<span class=\"token punctuation\">;</span>\n	proxy_set_header Host\n	proxy_set_header X-Real-IP\n	proxy_set_header X-Forwarded-For <span class=\"token variable\">$proxy_add_x_forwarded_for</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"nginx_432\"></a>聊聊：nginx的常用的负载均衡算法？</h2> \n <h4><a id=\"1roundrobin_434\"></a>1、round-robin</h4> \n <p>round-robin的意思是循环轮询。</p> \n <p>Nginx最简单的负载均衡配置如下</p> \n <pre><code class=\"prism language-bash\">http <span class=\"token punctuation\">{\n    <!-- --></span>\nupstream app1 <span class=\"token punctuation\">{\n    <!-- --></span>\n    server <span class=\"token number\">10.10</span>.10.1<span class=\"token punctuation\">;</span>\n    server <span class=\"token number\">10.10</span>.10.2<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\nserver <span class=\"token punctuation\">{\n    <!-- --></span>\n    listen <span class=\"token number\">80</span><span class=\"token punctuation\">;</span>\n    location / <span class=\"token punctuation\">{\n    <!-- --></span>\n        proxy_pass http://app1<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>upstream app1用来指定一个服务器组，该组的名字是app1，包含两台服务器。在指定服务器组里面包含的服务器时以形式“server ip/domain：port”的形式指定，其中80端口可以忽略。然后在接收到请求时通过“proxy_pass http://app1”把对应的请求转发到组app1上。Nginx默认的负载均衡算法就是循环轮询，如上配置我们采用的就是循环轮询，其会把接收到的请求循环的分发给其包含的（当前可用的）服务器。使用如上配置时，Nginx会把第1个请求给10.10.10.1，把第2个请求给10.10.10.2，第3个请求给10.10.10.1，以此类推。</p> \n <h4><a id=\"2leastconnected_456\"></a>2、least-connected</h4> \n <p>least-connected算法的中文翻译是最少连接，即每次都找连接数最少的服务器来转发请求。例如Nginx负载中有两台服务器，A和B，当Nginx接收到一个请求时，A正在处理的请求数是10，B正在处理的请求数是20，则Nginx会把当前请求交给A来处理。要启用最少连接负载算法只需要在定义服务器组时加上“least_conn”，如：</p> \n <pre><code class=\"prism language-bash\">upstream app1 <span class=\"token punctuation\">{\n    <!-- --></span>\n    least_conn<span class=\"token punctuation\">;</span>\n    server <span class=\"token number\">10.10</span>.10.1<span class=\"token punctuation\">;</span>\n    server <span class=\"token number\">10.10</span>.10.2<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h4><a id=\"3iphash_468\"></a>3、ip-hash</h4> \n <p>ip-hash算法会根据请求的客户端IP地址来决定当前请求应该交给谁。使用ip-hash算法时Nginx会确保来自同一客户端的请求都分发到同一服务器。要使用ip-hash算法时只需要在定义服务器组时加上“ip-hash ”指令，如：</p> \n <pre><code class=\"prism language-bash\">upstream app1 <span class=\"token punctuation\">{\n    <!-- --></span>\n    ip_hash<span class=\"token punctuation\">;</span>\n    server <span class=\"token number\">10.10</span>.10.1<span class=\"token punctuation\">;</span>\n    server <span class=\"token number\">10.10</span>.10.2<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h4><a id=\"4weighted_480\"></a>4、weighted</h4> \n <p>weighted算法也就是权重算法，会根据每个服务的权重来分发请求，权重大的请求相对会多分发一点，权重小的会少分发一点。这通常应用于多个服务器的性能不一致时。需要使用权重算法时只需要在定义服务器组时在服务器后面指定参数weight，如：</p> \n <pre><code class=\"prism language-bash\">upstream app1 <span class=\"token punctuation\">{\n    <!-- --></span>\n    server <span class=\"token number\">10.10</span>.10.1 <span class=\"token assign-left variable\">weight</span><span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">;</span>\n    server <span class=\"token number\">10.10</span>.10.2<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"Nginx__493\"></a>聊聊：Nginx 有哪些负载均衡策略</h2> \n <p>Nginx 默认提供的负载均衡策略：</p> \n <h4><a id=\"1round_robin_497\"></a>1、轮询（默认）round_robin</h4> \n <p>每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 down 掉，能自动剔除。</p> \n <h4><a id=\"2IP__ip_hash_501\"></a>2、IP 哈希 ip_hash</h4> \n <p>每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决 session 共享的问题。</p> \n <p>当然，实际场景下，一般不考虑使用 ip_hash 解决 session 共享。</p> \n <h4><a id=\"3_least_conn_507\"></a>3、最少连接 least_conn</h4> \n <p>下一个请求将被分派到活动连接数量最少的服务器</p> \n <h4><a id=\"4_weight_511\"></a>4、权重 weight</h4> \n <p>weight的值越大分配到的访问概率越高，主要用于后端每台服务器性能不均衡的情况下，达到合理的资源利用率。 还可以通过插件支持其他策略。</p> \n <h2><a id=\"ngx_http_upstream_module_515\"></a>聊聊：ngx_http_upstream_module的作用是什么?</h2> \n <p>ngx_http_upstream_module用于定义可通过fastcgi传递、proxy传递、uwsgi传递、memcached传递和scgi传递指令来引用的服务器组。</p> \n <h3><a id=\"Nginx_521\"></a>聊聊：Nginx配置高可用性怎么配置？</h3> \n <ul>\n  <li>当上游服务器(真实访问服务器)，一旦出现故障或者是没有及时相应的话，应该直接轮训到下一台服务器，保证服务器的高可用</li>\n  <li>Nginx配置代码：</li>\n </ul> \n <pre><code class=\"prism language-bash\">server <span class=\"token punctuation\">{\n    <!-- --></span>\n    listen       <span class=\"token number\">80</span><span class=\"token punctuation\">;</span>\n    server_name  www.lijie.com<span class=\"token punctuation\">;</span>\n    location / <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token comment\">### 指定上游服务器负载均衡服务器</span>\n        proxy_pass http://backServer<span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">###nginx与上游服务器(真实访问的服务器)超时时间 后端服务器连接的超时时间_发起握手等候响应超时时间</span>\n        proxy_connect_timeout 1s<span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">###nginx发送给上游服务器(真实访问的服务器)超时时间</span>\n        proxy_send_timeout 1s<span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">### nginx接受上游服务器(真实访问的服务器)超时时间</span>\n        proxy_read_timeout 1s<span class=\"token punctuation\">;</span>\n        index  index.html index.htm<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"Nginx_548\"></a>聊聊：Nginx为什么不使用多线程？</h2> \n <h4><a id=\"apache_550\"></a>apache:</h4> \n <p>创建多个进程或线程，而每个进程或线程都会为其分配cpu和内存（线程要比进程小的多，所以worker支持比perfork高的并发），并发过大会榨干服务器资源。</p> \n <h4><a id=\"Nginx_554\"></a>Nginx:</h4> \n <p>采用单线程来异步非阻塞处理请求（管理员可以配置Nginx主进程的工作进程的数量）(epoll)，不会为每个请求分配cpu和内存资源，节省了大量资源，同时也减少了大量的CPU的上下文切换。</p> \n <p>所以才使得Nginx支持更高的并发。</p> \n <h2><a id=\"Nginx_560\"></a>聊聊：Nginx为什么不使用多线程？</h2> \n <p>答：</p> \n <p>Nginx:</p> \n <p>采用单线程来异步非阻塞处理请求（管理员可以配置Nginx主进程的工作进程的数量），</p> \n <p>不会为每个请求分配cpu和内存资源，节省了大量资源，同时也减少了大量的CPU的上下文切换，所以才使得Nginx支持更高的并发。</p> \n <h2><a id=\"Nginx_570\"></a>聊聊：Nginx主要特性</h2> \n <ol>\n  <li>支持SSL 和TLSSNI.<br> Nginx它支持内核Poll模型，能经受高负载的考验,有报告表明能支持高达50,000个并发连接数。</li>\n  <li>Nginx具有很高的稳定性。<br> 例如当前 apache一旦上到200个以上进程，web响应速度就明显非常缓慢了。而Nginx采取了分阶段资源分配技术，使得它的CPU与内存占用率非常低。nginx官方表示保持10,000个没有活动的连接，它只占2.5M内存，所以类似DOS这样的攻击对nginx来说基本上是毫无用处的。</li>\n  <li>Nginx支持热部署。<br> 它的启动特别容易，并且几乎可以做到7*24不间断运行，即使运行数个月也不需要重新启动。对软件版本进行进行热升级。</li>\n  <li>Nginx采用master-slave模型,能够充分利用SMP的优势，且能够减少工作进程在磁盘IO的阻塞延迟。<br> 当采用select()/poll()调用时，还可以限制每个进程的连接数。</li>\n  <li>Nginx采用master-slave模型,能够充分利用SMP的优势，且能够减少工作进程在磁盘IO的阻塞延迟。<br> 当采用select()/poll()调用时，还可以限制每个进程的连接数。</li>\n  <li>Nginx采用了一些os提供的最新特性如对sendfile (Linux2.2+)， accept-filter<br> (FreeBSD4.1+)，TCP_DEFER_ACCEPT (Linux 2.4+)的支持,从而大大提高了性能。</li>\n  <li>免费开源，可以做高并发负载均衡。</li>\n </ol> \n <h2><a id=\"Nginx_592\"></a>聊聊：Nginx常用命令</h2> \n <h4><a id=\"1_594\"></a>1、启动</h4> \n <pre><code class=\"prism language-bash\">nginx\n</code></pre> \n <h4><a id=\"2_600\"></a>2、停止</h4> \n <pre><code class=\"prism language-bash\">nginx <span class=\"token parameter variable\">-s</span> stop \n或\nnginx <span class=\"token parameter variable\">-s</span> quit\n</code></pre> \n <h4><a id=\"3_608\"></a>3、重载配置</h4> \n <pre><code class=\"prism language-bash\">./sbin/nginx <span class=\"token parameter variable\">-s</span> reload<span class=\"token punctuation\">(</span>平滑重启 <span class=\"token punctuation\">)</span> \n或\n<span class=\"token function\">service</span> nginx reload\n</code></pre> \n <h4><a id=\"4_616\"></a>4、重载指定配置文件</h4> \n <pre><code class=\"prism language-shell\">.nginx <span class=\"token parameter variable\">-c</span> /usr/local/nginx/conf/nginx.conf\n</code></pre> \n <h4><a id=\"5_622\"></a>5、查看版本</h4> \n <pre><code class=\"prism language-shell\">nginx <span class=\"token parameter variable\">-v</span>\n</code></pre> \n <h4><a id=\"6_628\"></a>6、检查配置文件是否正确</h4> \n <pre><code class=\"prism language-shell\">nginx <span class=\"token parameter variable\">-t</span>\n</code></pre> \n <h4><a id=\"7_634\"></a>7、显示帮助命令</h4> \n <pre><code class=\"prism language-shell\">nginx <span class=\"token parameter variable\">-h</span>\n</code></pre> \n <h2><a id=\"Nginx_IO_642\"></a>聊聊：Nginx IO事件模型以及连接数上限</h2> \n <pre><code class=\"prism language-powershell\">events <span class=\"token punctuation\">{\n    <!-- --></span>\n    use epoll<span class=\"token punctuation\">;</span> <span class=\"token comment\">#epoll 是多路复⽤ IO(I/O Multiplexing)中的⼀种⽅式,但是仅⽤于 linux2.6 </span>\n    <span class=\"token comment\">#以上内核,可以⼤⼤提⾼ nginx 的性能</span>\n    worker_connections 1024<span class=\"token punctuation\">;</span><span class=\"token comment\">#单个后台 worker process 进程的最⼤并发链接数</span>\n    <span class=\"token comment\"># multi_accept on; </span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"_655\"></a>聊聊：动态资源、静态资源分离的原因</h2> \n <p>动态资源、静态资源分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，</p> \n <p>动静资源做好了拆分以后，我们就可以根据静态资源的特点将其做缓存操作，这就是网站静态化处理的核心思路</p> \n <p>动态资源、静态资源分离简单的概括是：动态文件与静态文件的分离</p> \n <p>二者分离的原因<br> 在我们的软件开发中，</p> \n <ul>\n  <li>有些请求是需要后台处理的（如：.jsp,.do等等），</li>\n  <li>有些请求是不需要经过后台处理的（如：css、html、jpg、js等等文件）</li>\n </ul> \n <p>这些不需要经过后台处理的文件称为静态文件，否则动态文件。</p> \n <p>因此我们后台处理忽略静态文件。这会有人又说那我后台忽略静态文件不就完了吗</p> \n <p>当然这是可以的，但是这样后台的请求次数就明显增多了。</p> \n <p>在我们对资源的响应速度有要求的时候，我们应该使用这种动静分离的策略去解决</p> \n <p>动、静分离将网站静态资源（HTML，JavaScript，CSS，img等文件）与后台应用分开部署，提高用户访问静态代码的速度，降低对后台应用访问</p> \n <p>这里我们将静态资源放到nginx中，动态资源转发到tomcat服务器中</p> \n <h2><a id=\"Nginx_685\"></a>聊聊：Nginx怎么做的动静分离？</h2> \n <p>只需要指定路径对应的目录。</p> \n <p>location/可以使用正则表达式匹配。并指定对应的硬盘中的目录。如下：</p> \n <pre><code class=\"prism language-bash\">location /image/ <span class=\"token punctuation\">{\n    <!-- --></span>\n    root /usr/local/static/<span class=\"token punctuation\">;</span>\n    autoindex on<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>创建目录</p> \n <pre><code class=\"prism language-bash\"><span class=\"token function\">mkdir</span> /usr/local/static/image\n</code></pre> \n <p>进入目录</p> \n <pre><code class=\"prism language-bash\"><span class=\"token builtin class-name\">cd</span> /usr/local/static/image\n</code></pre> \n <p>放一张照片上去</p> \n <pre><code class=\"prism language-bash\"><span class=\"token number\">1</span>.jpg\n</code></pre> \n <p>重启 nginx</p> \n <p>sudo nginx -s reload</p> \n <p>打开浏览器 输入 server_name/image/1.jpg 就可以访问该静态图片了</p> \n <h2><a id=\"_724\"></a>聊聊：什么是动静分离？</h2> \n <p>动静分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后，我们就可以根据静态资源的特点将其做缓存操作，这就是网站静态化处理的核心思路，实际上，何谓动？何谓静呢？拿我们 Java 来说 jsp、servlet 等就是动，因为他们离开我们的 web 服务器的支持就会无法正常工作。而 js、css 等文件就是静了。因为离开 web 服务器他一样能正常的工作。</p> \n <p>动静分离简单的概括是：动态文件与静态文件的分离。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/20e01a98a2284acc885cb6e43d55b9c7.png\" alt=\"Nginx动静分离\"></p> \n <h2><a id=\"Nginx_736\"></a>聊聊：Nginx动静态资源分离做过吗，为什么要这样做？</h2> \n <p>动态资源、静态资源分离，是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来。</p> \n <p>比如说 js、css、hrml从A服务器返回。图片从B服务器返回，其他请求从Tomcat服务器C返回。</p> \n <p>后台应用分开部署，提高用户访问静态代码的速度。而且现在还有CDN服务，不需要限制于服务器的带宽。</p> \n <h2><a id=\"Nginx_746\"></a>聊聊：Nginx如何做动静分离</h2> \n <p>Nginx 根据客户端请求的 url 来判断请求的是否是静态资源，如果请求的 url 包含 jpg、png，则由 Nginx 处理。如果请求的 url 是 .php 或者 .jsp 等等，这个时候这个请求是动态的，将转发给 tomcat 处理。</p> \n <p>总结来说，Nginx 是通过 url 来区分请求的类型，并转发给不同的服务端。</p> \n <h2><a id=\"Nginx_754\"></a>聊聊：Nginx动静分离的好处</h2> \n <ul>\n  <li>api 接口服务化：动静分离之后，后端应用更为服务化，只需要通过提供 api 接口即可，可以为多个功能模块甚至是多个平台的功能使用，可以有效的节省后端人力，更便于功能维护。</li>\n  <li>前后端开发并行：前后端只需要关心接口协议即可，各自的开发相互不干扰，并行开发，并行自测，可以有效的提高开发时间，也可以有些的减少联调时间</li>\n  <li>减轻后端服务器压力，提高静态资源访问速度：后端不用再将模板渲染为 html 返回给用户端，且静态服务器可以采用更为专业的技术提高静态资源的访问速度。</li>\n </ul> \n <h2><a id=\"Nginx__ApacheTomcat__764\"></a>聊聊：Nginx 和 Apache、Tomcat 之间的不同点</h2> \n <p><strong>Tomcat 和Nginx/Apache区别：</strong></p> \n <p>1、Nginx/Apache 是Web Server,而Apache Tomact是一个servlet container</p> \n <p>2、tomcat可以对jsp进行解析，nginx和apache只是web服务器，可以简单理解为只能提供html静态文件服务。</p> \n <p><strong>Nginx和Apache区别：</strong></p> \n <p>1）Nginx轻量级，同样起web 服务，比apache占用更少的内存及资源 。</p> \n <p>2）Nginx 抗并发，nginx 处理请求是异步非阻塞的，而apache 则是阻塞型的，在高并发下nginx 能保持低资源低消耗高性能 。</p> \n <p>3）Nginx提供负载均衡，可以做做反向代理，前端服务器</p> \n <p>4）Nginx多进程单线程，异步非阻塞；Apache多进程同步，阻塞。</p> \n <h2><a id=\"NginxApache__784\"></a>聊聊：Nginx和Apache 之间的不同点</h2> \n <table>\n  <thead>\n   <tr>\n    <th>nginx</th>\n    <th>apache</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>1.nginx 是一个基于web服务器</td>\n    <td>1.Apache 是一个基于流程的服务器</td>\n   </tr>\n   <tr>\n    <td>2.所有请求都由一个线程来处理</td>\n    <td>2.单线程处理单个请求</td>\n   </tr>\n   <tr>\n    <td>3.nginx避免子进程的概念</td>\n    <td>3.apache是基于子进程的</td>\n   </tr>\n   <tr>\n    <td>4.nginx类似于速度</td>\n    <td>4.apache类似于功率</td>\n   </tr>\n   <tr>\n    <td>5.nginx在内存消耗和连接方面比较好</td>\n    <td>5.apache在内存消耗和连接方面并没有提高</td>\n   </tr>\n   <tr>\n    <td>6.nginx在负载均衡方面表现较好</td>\n    <td>6.apache当流量达到进程的极限时，apache将拒绝新的连接</td>\n   </tr>\n   <tr>\n    <td>7.对于PHP来说，nginx更可取，因为他支持PHP</td>\n    <td>7.apache支持的php python Perl和其他语言，使用插件，当应用程序基于python和ruby时，它非常有用</td>\n   </tr>\n   <tr>\n    <td>8.nginx 不支持像ibmi 和 openvms 一样的os</td>\n    <td>8.apache支持更多的os</td>\n   </tr>\n   <tr>\n    <td>9.nginx 只具有核心功能</td>\n    <td>9.apache 提供了比Nginx更多的功能</td>\n   </tr>\n   <tr>\n    <td>10.nginx 性能和可伸缩性不依赖于硬件</td>\n    <td>10.apache 依赖于CPU和内存等硬件组件</td>\n   </tr>\n  </tbody>\n </table> \n <h2><a id=\"NginxApache_803\"></a>聊聊：Nginx与Apache对比</h2> \n <h3><a id=\"_805\"></a>优点</h3> \n <ol>\n  <li>轻量级，采用 C 语言 进行编写，同样的 web 服务，会占用更少的内存及资源。</li>\n  <li>抗并发，nginx 以 epoll and kqueue 作为开发模型，处理请求是异步非阻塞的，多个连接对应一个进程，负载能力比 apache 高很多，而 apache 则是同步多进程模型，只能一个连接对应一个进程，当压力过大时，它是会被阻塞型的。<br> 在高并发下 nginx 能保持低资源低消耗高性能 ，而 apache 在 PHP 处理慢或者前端压力很大的情况下，很容易出现进程数飙升，从而拒绝服务的现象。</li>\n  <li>设计高度模块化，编写模块相对简单。</li>\n  <li>配置简洁，正则配置让很多事情变得简单，而且改完配置能使用 -t 测试配置有没有问题，apache 配置复杂 ，重启的时候发现配置出错了，会很崩溃。</li>\n  <li>一般用于处理静态文件，静态处理性能比 apache 高三倍以上。</li>\n  <li>作为负载均衡服务器，支持 7 层负载均衡。</li>\n  <li>本身就是一个反向代理服务器，而且可以作为非常优秀的邮件代理服务器。</li>\n  <li>nginx 启动特别容易, 并且几乎可以做到 7*24 不间断运行，即使运行数个月也不需要重新启动，支持热部署，比如：实现不间断服务的情况下进行软件版本的升级与版本的回退。</li>\n  <li>社区活跃，各种高性能模块出品迅速。</li>\n </ol> \n <h3><a id=\"_818\"></a>缺点</h3> \n <ol>\n  <li>apache 的 rewrite 比 nginx 强大，在 rewrite 频繁的情况下，用 apache。</li>\n  <li>apache 发展到现在，模块超多，基本想到的都可以找到。</li>\n  <li>apache 更为成熟，少 bug ，nginx 的 bug 相对较多。</li>\n  <li>apache 超稳定，Nginx 一个进程死掉时，会影响到多个用户的使用，稳定性差。</li>\n  <li>apache 对 PHP 支持比较简单，nginx 需要配合其他后端用。</li>\n  <li>apache 在处理动态请求有优势，nginx 在这方面是鸡肋，一般动态请求要 apache 去做，nginx 适合静态和反向。</li>\n  <li>apache 仍然是目前的主流，拥有丰富的特性，成熟的技术和开发社区。</li>\n </ol> \n <h2><a id=\"NginxApache_830\"></a>聊聊：Nginx与Apache选择</h2> \n <h3><a id=\"Apache_832\"></a>Apache</h3> \n <p>●　apache 的 rewrite 比 <strong>nginx</strong> 强大，在 rewrite 频繁的情况下，用 apache</p> \n <p>●　apache 发展到现在，模块超多，基本想到的都可以找到</p> \n <p>●　apache 更为成熟，少 bug ，nginx 的 bug 相对较多</p> \n <p>●　apache 超稳定</p> \n <p>●　apache 对 <strong>PHP</strong> 支持比较简单，nginx 需要配合其他后端用</p> \n <p>●　apache 在处理动态请求有优势，nginx 在这方面是鸡肋，一般动态请求要 apache 去做，nginx 适合静态和反向。</p> \n <p>●　apache 仍然是目前的主流，拥有丰富的特性，成熟的技术和开发社区</p> \n <h3><a id=\"Nginx_850\"></a>Nginx</h3> \n <p>●　轻量级，采用 C 语言 进行编写，同样的 web 服务，会占用更少的内存及资源</p> \n <p>●　抗并发，nginx 以 epoll and kqueue 作为开发模型，处理请求是异步非阻塞的，负载能力比 apache 高很多，而 apache 则是阻塞型的。在高并发下 nginx 能保持低资源低消耗高性能 ，而 apache 在 PHP 处理慢或者前端压力很大的情况下，很容易出现进程数飙升，从而拒绝服务的现象。</p> \n <p>●　nginx 处理静态文件好，静态处理性能比 apache 高三倍以上</p> \n <p>●　nginx 的设计高度模块化，编写模块相对简单</p> \n <p>●　nginx 配置简洁，正则配置让很多事情变得简单，而且改完配置能使用 -t 测试配置有没有问题，apache 配置复杂 ，重启的时候发现配置出错了，会很崩溃</p> \n <p>●　nginx 作为负载均衡服务器，支持 7 层负载均衡</p> \n <p>●　nginx 本身就是一个反向代理服务器，而且可以作为非常优秀的邮件代理服务器</p> \n <p>●　启动特别容易, 并且几乎可以做到 7*24 不间断运行，即使运行数个月也不需要重新启动，还能够不间断服务的情况下进行软件版本的升级</p> \n <p>●　社区活跃，各种高性能模块出品迅速</p> \n <h2><a id=\"NginxHTTP_874\"></a>聊聊：Nginx如何处理HTTP请求。</h2> \n <p>Nginx使用反应器模式。</p> \n <p>主事件循环等待操作系统发出准备事件的信号，这样数据就可以从套接字读取，在该实例中读取到缓冲区并进行处理。</p> \n <p>单个线程可以提供数万个并发连接。</p> \n <h2><a id=\"Nginx_884\"></a>聊聊：Nginx是如何处理一个请求的呢？</h2> \n <p>首先，nginx在启动时，会解析配置文件，得到需要监听的端口与ip地址，</p> \n <p>然后在nginx的master进程里面，先初始化好这个监控的socket，再进行listen</p> \n <p>然后再fork出多个子进程出来, 子进程会竞争accept新的连接。</p> \n <p>此时，客户端就可以向nginx发起连接了。</p> \n <p>当客户端与nginx进行三次握手，与nginx建立好一个连接后，</p> \n <p>此时，某一个子进程会accept成功，然后创建nginx对连接的封装，即ngx_connection_t结构体，</p> \n <p>接着，根据事件调用相应的事件处理模块，如http模块与客户端进行数据的交换，</p> \n <p>最后，nginx或客户端来主动关掉连接，到此，一个连接就寿终正寝了</p> \n <h2><a id=\"NginxHTTP_11__906\"></a>聊聊：Nginx处理HTTP请求过程的 11 个阶段？</h2> \n <p>Nginx 处理 HTTP 请求的过程大概可以分为 11 个阶段，如下：</p> \n <ol>\n  <li>Read Request Headers：解析请求头。</li>\n  <li>Identify Configuration Block：识别由哪一个 location 进行处理，匹配 URL。</li>\n  <li>Apply Rate Limits：判断是否限速。例如可能这个请求并发的连接数太多超过了限制，或者 QPS 太高。</li>\n  <li>Perform Authentication：连接控制，验证请求。例如可能根据 Referrer 头部做一些防盗链的设置，或者验证用户的权限。</li>\n  <li>Generate Content：生成返回给用户的响应。为了生成这个响应，做反向代理的时候可能会和上游服务（Upstream Services）进行通信，然后这个过程中还可能会有些子请求或者重定向，那么还会走一下这个过程（Internal redirects and subrequests）。</li>\n  <li>Response Filters：过滤返回给用户的响应。比如压缩响应，或者对图片进行处理。</li>\n  <li>Log：记录日志。</li>\n </ol> \n <p>以上这七个步骤从整体上介绍了一下处理流程，下面还会再说一下实际的处理过程。</p> \n <h2><a id=\"NginxHTTP11_924\"></a>聊聊：Nginx处理HTTP请求的11个阶段</h2> \n <p>下面介绍一下详细的 11 个阶段，每个阶段都可能对应着一个甚至多个 HTTP 模块，通过这样一个模块对比，我们也能够很好的理解这些模块具体是怎么样发挥作用的。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/008e26c6502d4ab99da4290c9ea9d9ba.png\" alt=\"Nginx处理HTTP请求过程.png\"></p> \n <ol>\n  <li>POST_READ：在 read 完请求的头部之后，在没有对头部做任何处理之前，想要获取到一些原始的值，就应该在这个阶段进行处理。这里面会涉及到一个 realip 模块。</li>\n  <li>SERVER_REWRITE：和下面的 REWRITE 阶段一样，都只有一个模块叫 rewrite 模块，一般没有第三方模块会处理这个阶段。</li>\n  <li>FIND_CONFIG：做 location 的匹配，暂时没有模块会用到。</li>\n  <li>REWRITE：对 URL 做一些处理。</li>\n  <li>POST_WRITE：处于 REWRITE 之后，也是暂时没有模块会在这个阶段出现。</li>\n </ol> \n <p>接下来是确认用户访问权限的三个模块：</p> \n <ol>\n  <li>PREACCESS：是在 ACCESS 之前要做一些工作，例如并发连接和 QPS 需要进行限制，涉及到两个模块：limt_conn 和 limit_req</li>\n  <li>ACCESS：核心要解决的是用户能不能访问的问题，例如 auth_basic 是用户名和密码，access 是用户访问 IP，auth_request 根据第三方服务返回是否可以去访问。</li>\n  <li>POST_ACCESS：是在 ACCESS 之后会做一些事情，同样暂时没有模块会用到。</li>\n </ol> \n <p>最后的三个阶段处理响应和日志：</p> \n <ol>\n  <li>PRECONTENT：在处理 CONTENT 之前会做一些事情，例如会把子请求发送给第三方的服务去处理，try_files 模块也是在这个阶段中。</li>\n  <li>CONTENT：这个阶段涉及到的模块就非常多了，例如 index, autoindex, concat 等都是在这个阶段生效的。</li>\n  <li>LOG：记录日志 access_log 模块。</li>\n </ol> \n <p>以上的这些阶段都是严格按照顺序进行处理的，当然，每个阶段中各个 HTTP 模块的处理顺序也很重要，如果某个模块不把请求向下传递，后面的模块是接收不到请求的。</p> \n <p>而且每个阶段中的模块也不一定所有都要执行一遍，下面就接着讲一下各个阶段模块之间的请求顺序。</p> \n <h2><a id=\"NginxHTTP11_952\"></a>聊聊：Nginx处理HTTP请求的11个阶段的顺序处理</h2> \n <p>如下图所示，每一个模块处理之间是有序的，那么这个顺序怎么才能得到呢？其实非常简单，在源码 ngx_module.c 中，有一个数组 ngx_module_name，其中包含了在编译 Nginx 的时候的 with 指令所包含的所有模块，它们之间的顺序非常关键，在数组中顺序是相反的。</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">char</span> <span class=\"token operator\">*</span>ngx_module_names<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n    … …\n    <span class=\"token string\">\"ngx_http_static_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_autoindex_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_index_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_random_index_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_mirror_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_try_files_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_auth_request_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_auth_basic_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_access_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_limit_conn_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_limit_req_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_realip_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_referer_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_rewrite_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_concat_module\"</span><span class=\"token punctuation\">,</span>\n    … …\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>灰色部分的模块是 Nginx 的框架部分去执行处理的，第三方模块没有机会在这里得到处理。</p> \n <p>在依次向下执行的过程中，也可能不按照这样的顺序。例如，在 access 阶段中，有一个指令叫 satisfy，它可以指示当有一个满足的时候就直接跳到下一个阶段进行处理，例如当 access 满足了，就直接跳到 try_files 模块进行处理，而不会再执行 auth_basic、auth_request 模块。</p> \n <p>在 content 阶段中，当 index 模块执行了，就不会再执行 auto_index 模块，而是直接跳到 log 模块。整个 11 个阶段所涉及到的模块和先后顺序如下图所示：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/f505b315ebc34be3bbc420c3a12fa9d2.png\" alt=\"Nginx处理HTTP请求过程.png\"></p> \n <h2><a id=\"Nginxnginxconf_990\"></a>聊聊：Nginx配置文件nginx.conf有哪些属性模块?</h2> \n <pre><code class=\"prism language-bash\">worker_processes  <span class=\"token number\">1</span>；                					<span class=\"token comment\"># worker进程的数量</span>\nevents <span class=\"token punctuation\">{\n    <!-- --></span>                              					<span class=\"token comment\"># 事件区块开始</span>\n    worker_connections  <span class=\"token number\">1024</span>；            				<span class=\"token comment\"># 每个worker进程支持的最大连接数</span>\n<span class=\"token punctuation\">}</span>                                    					<span class=\"token comment\"># 事件区块结束</span>\nhttp <span class=\"token punctuation\">{\n    <!-- --></span>                               					<span class=\"token comment\"># HTTP区块开始</span>\n    include       mime.types；            				<span class=\"token comment\"># Nginx支持的媒体类型库文件</span>\n    default_type  application/octet-stream；     		<span class=\"token comment\"># 默认的媒体类型</span>\n    sendfile        on；       							<span class=\"token comment\"># 开启高效传输模式</span>\n    keepalive_timeout  <span class=\"token number\">65</span>；       						<span class=\"token comment\"># 连接超时</span>\n    server <span class=\"token punctuation\">{\n    <!-- --></span>            								<span class=\"token comment\"># 第一个Server区块开始，表示一个独立的虚拟主机站点</span>\n        listen       <span class=\"token number\">80</span>；      							<span class=\"token comment\"># 提供服务的端口，默认80</span>\n        server_name  localhost；       					<span class=\"token comment\"># 提供服务的域名主机名</span>\n        location / <span class=\"token punctuation\">{\n    <!-- --></span>            						<span class=\"token comment\"># 第一个location区块开始</span>\n            root   html；       						<span class=\"token comment\"># 站点的根目录，相当于Nginx的安装目录</span>\n            index  index.html index.htm；      			<span class=\"token comment\"># 默认的首页文件，多个用空格分开</span>\n        <span class=\"token punctuation\">}</span>          										<span class=\"token comment\"># 第一个location区块结果</span>\n        error_page   <span class=\"token number\">500502503504</span>  /50x.html；     		<span class=\"token comment\"># 出现对应的http状态码时，使用50x.html回应客户</span>\n        location <span class=\"token operator\">=</span> /50x.html <span class=\"token punctuation\">{\n    <!-- --></span>          				<span class=\"token comment\"># location区块开始，访问50x.html</span>\n            root   html；      							<span class=\"token comment\"># 指定对应的站点目录为html</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>  \n    <span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span>\n</code></pre> \n <h2><a id=\"Nginx_1019\"></a>聊聊：在Nginx中，如何使用未定义的服务器名称来阻止处理请求?</h2> \n <p>只需将请求删除的服务器, 可以定义为：</p> \n <pre><code class=\"prism language-bash\">Server <span class=\"token punctuation\">{\n    <!-- --></span>\n    listen <span class=\"token number\">80</span><span class=\"token punctuation\">;</span>\n    server_name “ “ <span class=\"token punctuation\">;</span>\n    <span class=\"token builtin class-name\">return</span> <span class=\"token number\">444</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>这里，服务器名被保留为一个空字符串，它将在没有“主机”头字段的情况下匹配请求，而一个特殊的Nginx的非标准代码444被返回，从而终止连接。</p> \n <h2><a id=\"Nginx_1035\"></a>聊聊：Nginx的进程模型</h2> \n <ol>\n  <li>master-worker模式<br> 在master-worker模式下，有一个master进程和至少一个的worker进程。</li>\n  <li>单进程模式。<br> 单进程模式只有一个进程。</li>\n </ol> \n <h2><a id=\"NginxMasterWorker_1044\"></a>聊聊：Nginx服务器上的Master和Worker进程分别是什么?</h2> \n <p>Master进程：读取及评估配置和维持</p> \n <p>Worker进程：处理请求</p> \n <h2><a id=\"Nginx_1052\"></a>聊聊：Nginx惊群</h2> \n <p>惊群效应（thundering herd）是指多进程（多线程）在同时阻塞等待同一个事件的时候（休眠状态），</p> \n <p>如果等待的这个事件发生，那么他就会唤醒等待的所有进程（或者线程），但是最终却只能有一个进程（线程）获得这个时间的 “控制权”，对该事件进行处理，</p> \n <p>而其他进程（线程）获取 “控制权” 失败，只能重新进入休眠状态，这种现象和性能浪费就叫做惊群效应。</p> \n <h2><a id=\"_1062\"></a>聊聊：惊群效应消耗了什么</h2> \n <p>Linux 内核对用户进程（线程）频繁地做无效的调度、上下文切换等使系统性能大打折扣。上下文切换（context switch）过高会导致 CPU 像个搬运工，频繁地在寄存器和运行队列之间奔波，更多的时间花在了进程（线程）切换，而不是在真正工作的进程（线程）上面。</p> \n <p>直接的消耗包括 CPU 寄存器要保存和加载（例如程序计数器）、系统调度器的代码需要执行。间接的消耗在于多核 cache 之间的共享数据。为了确保只有一个进程（线程）得到资源，需要对资源操作进行加锁保护，加大了系统的开销。目前一些常见的服务器软件有的是通过锁机制解决的，比如 Nginx（它的锁机制是默认开启的，可以关闭）；还有些认为惊群对系统性能影响不大，没有去处理，比如 Lighttpd。</p> \n <h2><a id=\"Nginx__1070\"></a>聊聊：Nginx惊群效应? 以及解决方案</h2> \n <p>对于 Nginx 的惊群问题，我们首先需要理解的是，在 Nginx 启动过程中，master 进程会监听配置文件中指定的各个端口，然后 master 进程就会调用 fork() 方法创建各个子进程，根据进程的工作原理，子进程是会继承父进程的全部内存数据以及监听的端口的，也就是说 worker 进程在启动之后也是会监听各个端口的。</p> \n <p>关于惊群，指的就是当客户端有新建连接的请求到来时，就会触发各个 worker 进程的连接建立事件，但是只有一个 worker 进程能够正常处理该事件，而其他的 worker 进程会发现事件已经失效，从而重新循环进入等待状态。这种由于一个事件而 “惊” 起了所有 worker 进程的现象就是惊群问题。很明显，如果所有的 worker 进程都被触发了，那么这将消耗大量的资源。</p> \n <h3><a id=\"_1076\"></a>解决方案</h3> \n <p>在 Nginx 中，每个 worker 进程被创建的时候，都会调用 ngx_worker_process_init() 方法初始化当前 worker 进程，这个过程中有一个非常重要的步骤，即每个 worker 进程都会调用 epoll_create() 方法为自己创建一个独有的 epoll 句柄。</p> \n <p>对于每一个需要监听的端口，都有一个文件描述符与之对应，而 worker 进程只有将该文件描述符通过 epoll_ctl() 方法添加到当前进程的 epoll 句柄中，并且监听 accept 事件，此时才会被客户端的连接建立事件触发，从而处理该事件。从这里也可以看出，worker 进程如果没有将所需要监听的端口对应的文件描述符添加到该进程的 epoll 句柄中，那么其是无法被触发对应的事件的。</p> \n <p>基于这个原理，nginx 就使用了一个共享锁来控制当前进程是否有权限将需要监听的端口添加到当前进程的 epoll 句柄中，也就是说，只有获取锁的进程才会监听目标端口。通过这种方式，就保证了每次事件发生时，只有一个 worker 进程会被触发。如下图所示为 worker 进程工作循环的一个示意图：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/0bbbdaaa2ce74bb1a57f6f34acd8232c.png\" alt=\"Nginx惊群\"></p> \n <p>这里关于图中的流程，需要说明的一点是，每个 worker 进程在进入循环之后就会尝试获取共享锁，如果没有获取到，就会将所监听的端口的文件描述符从当前进程的 epoll 句柄中移除（即使并不存在也会移除），这么做的主要目的是防止丢失客户端连接事件，即使这可能造成少量的惊群问题，但是并不严重。</p> \n <p>试想一下，如果按照理论，在当前进程释放锁的时候就将监听的端口的文件描述符从 epoll 句柄中移除，那么在下一个 worker 进程获取锁之前，这段时间各个端口对应的文件描述符是没有任何 epoll 句柄进行监听的，此时就会造成事件的丢失。如果反过来，按照图中的在获取锁失败的时候才移除监听的文件描述符，由于获取锁失败，则说明当前一定有一个进程已经监听了这些文件描述符，因而此时移除是安全的。</p> \n <p>但是这样会造成的一个问题是，按照上图，当前进程在一个循环执行完毕的时候，会释放锁，然后处理其他的事件，注意这个过程中其是没有释放所监听的文件描述符的。此时，如果另一个进程获取到了锁，并且监听了文件描述符，那么这个时候就有两个进程监听了文件描述符，因而此时如果客户端发生连接建立事件，那么就会触发两个 worker 进程。这个问题是可以容忍的，主要原因有两点：</p> \n <ul>\n  <li>这个时候发生的惊群现象只触发了更少的 worker 进程，比起每次都惊起所有的 worker 进程要好很多；</li>\n  <li>会发生这种惊群问题的主要原因是，当前进程释放了锁，但是没有释放所监听的文件描述符，但是 worker 进程在释放锁之后主要是处理客户端连接的读写事件和检查标志位，这个过程是非常短的，在处理完之后，其就会尝试获取锁，这个时候就会释放所监听的文件描述符了，而相较而言，获取锁的 worker 进程在等待处理客户端的连接建立事件的事件就更长了，因而会发生惊群问题的概率还是比较小的。</li>\n </ul> \n <h3><a id=\"_1097\"></a>源码讲解</h3> \n <p>worker 进程初始事件的方法主要是在 ngx_process_events_and_timers() 方法中进行的，下面我们就来看看该方法是如何处理整个流程的，如下是该方法的源码：</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">void</span> <span class=\"token function\">ngx_process_events_and_timers</span><span class=\"token punctuation\">(</span>ngx_cycle_t <span class=\"token operator\">*</span>cycle<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n  ngx_uint_t flags<span class=\"token punctuation\">;</span>\n  ngx_msec_t timer<span class=\"token punctuation\">,</span> delta<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token function\">ngx_trylock_accept_mutex</span><span class=\"token punctuation\">(</span>cycle<span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token constant\">NGX_ERROR</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token keyword\">return</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token comment\">// 这里开始处理事件，对于kqueue模型，其指向的是ngx_kqueue_process_events()方法，</span>\n  <span class=\"token comment\">// 而对于epoll模型，其指向的是ngx_epoll_process_events()方法</span>\n  <span class=\"token comment\">// 这个方法的主要作用是，在对应的事件模型中获取事件列表，然后将事件添加到ngx_posted_accept_events</span>\n  <span class=\"token comment\">// 队列或者ngx_posted_events队列中</span>\n  <span class=\"token punctuation\">(</span><span class=\"token keyword\">void</span><span class=\"token punctuation\">)</span> <span class=\"token function\">ngx_process_events</span><span class=\"token punctuation\">(</span>cycle<span class=\"token punctuation\">,</span> timer<span class=\"token punctuation\">,</span> flags<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token comment\">// 这里开始处理accept事件，将其交由ngx_event_accept.c的ngx_event_accept()方法处理；</span>\n  <span class=\"token function\">ngx_event_process_posted</span><span class=\"token punctuation\">(</span>cycle<span class=\"token punctuation\">,</span> <span class=\"token operator\">&amp;</span>ngx_posted_accept_events<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token comment\">// 开始释放锁</span>\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>ngx_accept_mutex_held<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token function\">ngx_shmtx_unlock</span><span class=\"token punctuation\">(</span><span class=\"token operator\">&amp;</span>ngx_accept_mutex<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token comment\">// 如果不需要在事件队列中进行处理，则直接处理该事件</span>\n  <span class=\"token comment\">// 对于事件的处理，如果是accept事件，则将其交由ngx_event_accept.c的ngx_event_accept()方法处理；</span>\n  <span class=\"token comment\">// 如果是读事件，则将其交由ngx_http_request.c的ngx_http_wait_request_handler()方法处理；</span>\n  <span class=\"token comment\">// 对于处理完成的事件，最后会交由ngx_http_request.c的ngx_http_keepalive_handler()方法处理。</span>\n  <span class=\"token comment\">// 这里开始处理除accept事件外的其他事件</span>\n  <span class=\"token function\">ngx_event_process_posted</span><span class=\"token punctuation\">(</span>cycle<span class=\"token punctuation\">,</span> <span class=\"token operator\">&amp;</span>ngx_posted_events<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>	\n</code></pre> \n <p>上面的代码中，我们省略了大部分的检查工作，只留下了骨架代码。首先，worker 进程会调用 ngx_trylock_accept_mutex() 方法获取锁，这其中如果获取到了锁就会监听各个端口对应的文件描述符。然后会调用 ngx_process_events() 方法处理 epoll 句柄中监听到的事件。接着会释放共享锁，最后就是处理已建立连接的客户端的读写事件。下面我们来看一下 ngx_trylock_accept_mutex() 方法是如何获取共享锁的：</p> \n <pre><code class=\"prism language-java\">ngx_int_t <span class=\"token function\">ngx_trylock_accept_mutex</span><span class=\"token punctuation\">(</span>ngx_cycle_t <span class=\"token operator\">*</span>cycle<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n  <span class=\"token comment\">// 尝试使用CAS算法获取共享锁</span>\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token function\">ngx_shmtx_trylock</span><span class=\"token punctuation\">(</span><span class=\"token operator\">&amp;</span>ngx_accept_mutex<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token comment\">// ngx_accept_mutex_held为1表示当前进程已经获取到了锁</span>\n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>ngx_accept_mutex_held <span class=\"token operator\">&amp;&amp;</span> ngx_accept_events <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n      <span class=\"token keyword\">return</span> <span class=\"token constant\">NGX_OK</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token comment\">// 这里主要是将当前连接的文件描述符注册到对应事件的队列中，比如kqueue模型的change_list数组</span>\n    <span class=\"token comment\">// nginx在启用各个worker进程的时候，默认情况下，worker进程是会继承master进程所监听的socket句柄的，</span>\n    <span class=\"token comment\">// 这就导致一个问题，就是当某个端口有客户端事件时，就会把监听该端口的进程都给唤醒，</span>\n    <span class=\"token comment\">// 但是只有一个worker进程能够成功处理该事件，而其他的进程被唤醒之后发现事件已经过期，</span>\n    <span class=\"token comment\">// 因而会继续进入等待状态，这种现象称为\"惊群\"现象。</span>\n    <span class=\"token comment\">// nginx解决惊群现象的方式一方面是通过这里的共享锁的方式，即只有获取到锁的worker进程才能处理</span>\n    <span class=\"token comment\">// 客户端事件，但实际上，worker进程是通过在获取锁的过程中，为当前worker进程重新添加各个端口的监听事件，</span>\n    <span class=\"token comment\">// 而其他worker进程则不会监听。也就是说同一时间只有一个worker进程会监听各个端口，</span>\n    <span class=\"token comment\">// 这样就避免了\"惊群\"问题。</span>\n    <span class=\"token comment\">// 这里的ngx_enable_accept_events()方法就是为当前进程重新添加各个端口的监听事件的。</span>\n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token function\">ngx_enable_accept_events</span><span class=\"token punctuation\">(</span>cycle<span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token constant\">NGX_ERROR</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n      <span class=\"token function\">ngx_shmtx_unlock</span><span class=\"token punctuation\">(</span><span class=\"token operator\">&amp;</span>ngx_accept_mutex<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n      <span class=\"token keyword\">return</span> <span class=\"token constant\">NGX_ERROR</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token comment\">// 标志当前已经成功获取到了锁</span>\n    ngx_accept_events <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n    ngx_accept_mutex_held <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">return</span> <span class=\"token constant\">NGX_OK</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token comment\">// 前面获取锁失败了，因而这里需要重置ngx_accept_mutex_held的状态，并且将当前连接的事件给清除掉</span>\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>ngx_accept_mutex_held<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token comment\">// 如果当前进程的ngx_accept_mutex_held为1，则将其重置为0，并且将当前进程在各个端口上的监听</span>\n    <span class=\"token comment\">// 事件给删除掉</span>\n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token function\">ngx_disable_accept_events</span><span class=\"token punctuation\">(</span>cycle<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token constant\">NGX_ERROR</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n      <span class=\"token keyword\">return</span> <span class=\"token constant\">NGX_ERROR</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    ngx_accept_mutex_held <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token keyword\">return</span> <span class=\"token constant\">NGX_OK</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>上面的代码中，本质上主要做了三件事：</p> \n <ol>\n  <li>通过 ngx_shmtx_trylock() 方法尝试使用CAS方法获取共享锁；</li>\n  <li>获取锁之后则调用 ngx_enable_accept_events() 方法监听目标端口对应的文件描述符；</li>\n  <li>如果没有获取到锁，则调用 ngx_disable_accept_events() 方法释放所监听的文件描述符；</li>\n </ol> \n <h3><a id=\"_1176\"></a>总结</h3> \n <p>惊群现象指所有的工作进程都在等待一个 socket，当 socket 客户端连接时，所有工作线程都被唤醒，但最终有且仅有一个工作线程去处理该连接，其他进程又要进入睡眠状态。</p> \n <p>Nginx 通过控制争抢处理 socket 的进程数量和抢占 ngx_accept_mutex 锁解决惊群现象。只有一个 ngx_accept_mutex 锁，谁拿到锁，谁处理该 socket 的请求。</p> \n <h2><a id=\"Nginx_IO_1184\"></a>聊聊：Nginx IO模型</h2> \n <p>Nginx 支持多种并发模型，并发模型的具体实现根据系统平台而有所不同。</p> \n <p>在支持多种并发模型的平台上，Nginx 自动选择最高效的模型。</p> \n <p>但我们也可以使用 use 指令在配置文件中显式地定义某个并发模型。</p> \n <h2><a id=\"Nginx_IO_1192\"></a>聊聊：Nginx IO模型</h2> \n <p>Nginx 支持多种并发模型，并发模型的具体实现根据系统平台而有所不同。在支持多种并发模型的平台上，Nginx 自动选择最高效的模型。但我们也可以使用 use 指令在配置文件中显式地定义某个并发模型。</p> \n <p>Nginx中支持的并发模型</p> \n <h3><a id=\"select_1198\"></a>select</h3> \n <p>IO 多路复用、标准并发模型。在编译 Nginx 时，如果所使用的系统平台没有更高效的并发模型，select 模块将被自动编译。configure 脚本的选项：–with-select_module 和 --without-select_module 可被用来强制性地开启或禁止 select 模块的编译。</p> \n <h3><a id=\"poll_1202\"></a>poll</h3> \n <p>IO 多路复用、标准并发模型。与 select 类似，在编译 Nginx 时，如果所使用的系统平台没有更高效的并发模型，poll 模块将被自动编译。configure 脚本的选项：–with-poll_module 和 --without-poll_module 可用于强制性地开启或禁止 poll 模块的编译。</p> \n <h3><a id=\"epoll_1206\"></a>epoll</h3> \n <p>IO 多路复用、高效并发模型，可在 Linux 2.6+ 及以上内核可以使用。</p> \n <h3><a id=\"kqueue_1210\"></a>kqueue</h3> \n <p>IO 多路复用、高效并发模型，可在 FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0, and Mac OS X 平台中使用。</p> \n <h3><a id=\"devpoll_1214\"></a>/dev/poll</h3> \n <p>高效并发模型，可在 Solaris 7 11/99+, HP/UX 11.22+ (eventport), IRIX 6.5.15+, and Tru64 UNIX 5.1A+ 平台使用。</p> \n <h3><a id=\"eventport_1218\"></a>eventport</h3> \n <p>高效并发模型，可用于 Solaris 10 平台，PS：由于一些已知的问题，建议使用/dev/poll替代。</p> \n <h2><a id=\"_epoll__Apache__select__Nginx__epoll_1222\"></a>聊聊：为什么 epoll 快，比较一下 Apache 常用的 select 和 Nginx 常用的 epoll：</h2> \n <h3><a id=\"select_1224\"></a>select</h3> \n <ol>\n  <li> <p>最大并发数限制，因为一个进程所打开的 FD （文件描述符）是有限制的，由 FD_SETSIZE 设置，默认值是 1024/2048，因此 Select 模型的最大并发数就被相应限制了。自己改改这个 FD_SETSIZE？ 想法虽好，可是先看看下面吧。</p> </li>\n  <li> <p>效率问题，select 每次调用都会线性扫描全部的 FD 集合，这样效率就会呈现线性下降，把 FD_SETSIZE 改大的后果就是，大家都慢慢来，什么？都超时了。</p> </li>\n  <li> <p>内核/用户空间，内存拷贝问题，如何让内核把 FD 消息通知给用户空间呢？在这个问题上 select 采取了内存拷贝方法，在 FD 非常多的时候，非常的耗费时间。</p> </li>\n </ol> \n <p>总结为：</p> \n <ol>\n  <li>连接数受限</li>\n  <li>查找配对速度慢</li>\n  <li>数据由内核拷贝到用户态消耗时间。</li>\n </ol> \n <h3><a id=\"epoll_1237\"></a>epoll</h3> \n <ol>\n  <li> <p>Epoll 没有最大并发连接的限制，上限是最大可以打开文件的数目，这个数字一般远大于 2048, 一般来说这个数目和系统内存关系很大 ，具体数目可以 cat /proc/sys/fs/file-max 查看。</p> </li>\n  <li> <p>效率提升，Epoll 最大的优点就在于它只管你 “活跃” 的连接 ，而跟连接总数无关，因此在实际的网络环境中，Epoll 的效率就会远远高于 select 和 poll。</p> </li>\n  <li> <p>内存共享，Epoll 在这点上使用了 “共享内存”，这个内存拷贝也省略了。</p> </li>\n </ol> \n <h2><a id=\"80Nginx_1249\"></a>聊聊：你如何通过不同于80的端口开启Nginx?</h2> \n <p>为了通过一个不同的端口开启Nginx，你必须进入/etc/Nginx/sites-enabled/，如果这是默认文件，那么你必须打开名为“default”的文件。</p> \n <p>编辑文件，并放置在你想要的端口 ：</p> \n <pre><code class=\"prism language-bash\">server <span class=\"token punctuation\">{\n    <!-- --></span>\n  listen <span class=\"token number\">81</span><span class=\"token punctuation\">;</span> \n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"location_1263\"></a>聊聊：location的作用是什么？</h2> \n <p>location指令的作用是根据用户请求的URI来执行不同的应用，也就是根据用户请求的网站URL进行匹配，匹配成功即进行相关的操作。</p> \n <h2><a id=\"location_1269\"></a>聊聊：location的语法能说出来吗？</h2> \n <p>location主要用于URI的匹配。</p> \n <pre><code>什么是 uri：\nURI：Uniform Resource Identifier，统一资源标识符；如下图的data.html;\nURN：Uniform Resource Name，统一资源名称，如下图的ste.org/img.png，比URI多个域名;\nURL：Uniform Resource Locator，统一资源定位符，如下面，URL包含了http协议、端口、域名、文件名。\n</code></pre> \n <p>URI的匹配， 示例如下:</p> \n <pre><code class=\"prism language-bash\"><span class=\"token comment\">#优先级1,精确匹配，根路径</span>\nlocation <span class=\"token operator\">=</span>/ <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token builtin class-name\">return</span> <span class=\"token number\">400</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\">#优先级2,以某个字符串开头,以av开头的，优先匹配这里，区分大小写</span>\nlocation ^~ /av <span class=\"token punctuation\">{\n    <!-- --></span>\n    root /data/av/<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\">#优先级3，区分大小写的正则匹配，匹配/media*****路径</span>\nlocation ~ /media <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token builtin class-name\">alias</span> /data/static/<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\">#优先级4 ，不区分大小写的正则匹配，所有的****.jpg|gif|png 都走这里</span>\nlocation ~* .*<span class=\"token punctuation\">\\</span>.<span class=\"token punctuation\">(</span>jpg<span class=\"token operator\">|</span>gif<span class=\"token operator\">|</span>png<span class=\"token operator\">|</span>js<span class=\"token operator\">|</span>css<span class=\"token punctuation\">)</span>$ <span class=\"token punctuation\">{\n    <!-- --></span>\n    root  /data/av/<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\">#优先7，通用匹配</span>\nlocation / <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token builtin class-name\">return</span> <span class=\"token number\">403</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"Nginx_1313\"></a>聊聊：Nginx如何定义错误提示页面</h2> \n <pre><code class=\"prism language-bash\"><span class=\"token comment\">#error_page 500 502 503 504 /50x.html;</span>\nlocation <span class=\"token operator\">=</span> /50x.html <span class=\"token punctuation\">{\n    <!-- --></span>\n    root /root<span class=\"token punctuation\">;</span> \n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"Nginx502503_1324\"></a>聊聊：是否有可能将Nginx的错误替换为502错误、503?</h2> \n <p>502 =错误网关</p> \n <p>503 =服务器超载</p> \n <p>有可能，但是您可以确保fastcgi_intercept_errors被设置为ON，并使用错误页面指令。</p> \n <pre><code class=\"prism language-bash\">Location / <span class=\"token punctuation\">{\n    <!-- --></span>\n    fastcgi_pass <span class=\"token number\">127.0</span>.01:9001<span class=\"token punctuation\">;</span>\n    fastcgi_intercept_errors on<span class=\"token punctuation\">;</span>\n    error_page <span class=\"token number\">502</span> <span class=\"token operator\">=</span><span class=\"token number\">503</span>/error_page.html<span class=\"token punctuation\">;</span>\n</code></pre> \n <h2><a id=\"nginx500502503504__1341\"></a>聊聊：nginx中500、502、503、504 有什么区别？</h2> \n <p><strong>500：</strong></p> \n <p>Internal Server Error 内部服务错误，比如脚本错误，编程语言语法错误。</p> \n <p><strong>502：</strong></p> \n <p>Bad Gateway错误，网关错误。比如服务器当前连接太多，响应太慢，页面素材太多、带宽慢。</p> \n <p><strong>503：</strong></p> \n <p>Service Temporarily Unavailable，服务不可用，web服务器不能处理HTTP请求，可能是临时超载或者是服务器进行停机维护。</p> \n <p><strong>504：</strong></p> \n <p>Gateway timeout 网关超时，程序执行时间过长导致响应超时，例如程序需要执行20秒，而nginx最大响应等待时间为10秒，这样就会出现超时。</p> \n <h2><a id=\"Nginx_1361\"></a>聊聊：Nginx如何精准匹配路径</h2> \n <pre><code class=\"prism language-bash\">location <span class=\"token operator\">=</span> /get <span class=\"token punctuation\">{\n    <!-- --></span> \n   <span class=\"token comment\">#规则 A </span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"Nginx_1371\"></a>聊聊：Nginx路径匹配优先级</h2> \n <p>多个location 配置的情况下匹配顺序为</p> \n <ol>\n  <li> <p>首先匹配 =</p> </li>\n  <li> <p>其次匹配 ^~</p> </li>\n  <li> <p>再其次是按文件中顺序的正则匹配</p> </li>\n  <li> <p>最后是交给 / 通用匹配。</p> </li>\n </ol> \n <p>当有匹配成功时候，停止匹配，按当前匹配规则处理请求。</p> \n <h2><a id=\"_1387\"></a>聊聊：如何将请求转发给后端应用服务器</h2> \n <pre><code class=\"prism language-bash\">location <span class=\"token operator\">=</span> / <span class=\"token punctuation\">{\n    <!-- --></span>\n	proxy_pass http://tomcat:8080/index\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"_1397\"></a>聊聊：如何根据文件类型设置过期时间</h2> \n <pre><code class=\"prism language-bash\">location ~* <span class=\"token punctuation\">\\</span>.<span class=\"token punctuation\">(</span>js<span class=\"token operator\">|</span>css<span class=\"token operator\">|</span>jpg<span class=\"token operator\">|</span>jpeg<span class=\"token operator\">|</span>gif<span class=\"token operator\">|</span>png<span class=\"token operator\">|</span>swf<span class=\"token punctuation\">)</span>$ <span class=\"token punctuation\">{\n    <!-- --></span>\n	<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>-f <span class=\"token variable\">$request_filename</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n		expires 1h<span class=\"token punctuation\">;</span>\n		<span class=\"token builtin class-name\">break</span><span class=\"token punctuation\">;</span> \n	<span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"_1410\"></a>聊聊：如何禁止访问某个目录</h2> \n <pre><code class=\"prism language-bash\">location ^~/path/ <span class=\"token punctuation\">{\n    <!-- --></span>\n    deny all<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"NginxURL_1420\"></a>聊聊：在Nginx中，解释如何在URL中保留双斜线?</h2> \n <p>要在URL中保留双斜线，就必须使用merge_slashes_off;</p> \n <p>语法:merge_slashes [on/off]</p> \n <p>默认值: merge_slashes on</p> \n <p>环境: http，server</p> \n <h2><a id=\"Nginx_rewrite_1432\"></a>聊聊：Nginx rewrite全局变量</h2> \n <p>Nginx rewrite 常用的全局变量如下：</p> \n <table>\n  <thead>\n   <tr>\n    <th>变量</th>\n    <th>说明</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>$args</td>\n    <td>存放了请求 url 中的请求指令。比如 <code>http://www.myweb.name/server/source?arg1=value1&amp;arg2=value2</code> 中的arg1=value1&amp;arg2=value2</td>\n   </tr>\n   <tr>\n    <td>$content_length</td>\n    <td>存放请求头中的 Content-length 字段</td>\n   </tr>\n   <tr>\n    <td>$content_type</td>\n    <td>存放了请求头中的 Content-type 字段</td>\n   </tr>\n   <tr>\n    <td>$document_root</td>\n    <td>存放了针对当前请求的根路径</td>\n   </tr>\n   <tr>\n    <td>$document_uri</td>\n    <td>请求中的 uri，不包含请求指令 ，比如比如 <code>http://www.myweb.name/server/source?arg1=value1&amp;arg2=value2</code> 中的 /server/source</td>\n   </tr>\n   <tr>\n    <td>$host</td>\n    <td>存放了请求 url 中的主机字段，比如 <code>http://www.myweb.name/server/source?arg1=value1&amp;arg2=value2</code> 中的 <code>www.myweb.name</code>。如果请求中的主机部分字段不可用或者为空，则存放 nginx 配置中该 server 块中 server_name 指令的配置值</td>\n   </tr>\n   <tr>\n    <td>$http_user_agent</td>\n    <td>存放客户端的代理</td>\n   </tr>\n   <tr>\n    <td>$http_cookie</td>\n    <td>cookie</td>\n   </tr>\n   <tr>\n    <td>$limit_rate</td>\n    <td>nginx 配置中 limit_rate 指令的配置值</td>\n   </tr>\n   <tr>\n    <td>$remote_addr</td>\n    <td>客户端的地址</td>\n   </tr>\n   <tr>\n    <td>$remote_port</td>\n    <td>客户端与服务器端建立连接的端口号</td>\n   </tr>\n   <tr>\n    <td>$remote_user</td>\n    <td>变量中存放了客户端的用户名</td>\n   </tr>\n   <tr>\n    <td>$request_body_file</td>\n    <td>存放了发给后端服务器的本地文件资源的名称</td>\n   </tr>\n   <tr>\n    <td>$request_method</td>\n    <td>存放了客户端的请求方式，如 get,post 等</td>\n   </tr>\n   <tr>\n    <td>$request_filename</td>\n    <td>存放当前请求的资源文件的路径名</td>\n   </tr>\n   <tr>\n    <td>$requset_uri</td>\n    <td>当前请求的 uri,并且带有指令</td>\n   </tr>\n   <tr>\n    <td>$query_string</td>\n    <td><code>$args</code>含义相同</td>\n   </tr>\n   <tr>\n    <td>$scheme</td>\n    <td>客户端请求使用的协议，如 http, https, ftp 等</td>\n   </tr>\n   <tr>\n    <td>$server_protocol</td>\n    <td>客户端请求协议的版本，如 ”HTTP/1.0”, ”HTTP/1.1”</td>\n   </tr>\n   <tr>\n    <td>$server_addr</td>\n    <td>服务器的地址</td>\n   </tr>\n   <tr>\n    <td>$server_name</td>\n    <td>客户端请求到达的服务器的名称</td>\n   </tr>\n   <tr>\n    <td>$server_port</td>\n    <td>客户端请求到达的服务器的端口号</td>\n   </tr>\n   <tr>\n    <td>$uri</td>\n    <td>同 <code>$document_uri</code></td>\n   </tr>\n  </tbody>\n </table> \n <h2><a id=\"ngx_http_upstream_module_1464\"></a>请解释ngx_http_upstream_module的作用是什么?</h2> \n <p>ngx_http_upstream_module用于定义可通过fastcgi传递、proxy传递、uwsgi传递、memcached传递和scgi传递指令来引用的服务器组。</p> \n <h2><a id=\"stub_statussub_filter_1470\"></a>聊聊：stub_status和sub_filter指令的作用是什么?</h2> \n <p>Stub_status指令：该指令用于了解Nginx当前状态的当前状态，如当前的活动连接，接受和处理当前读/写/等待连接的总数</p> \n <p>Sub_filter指令：它用于搜索和替换响应中的内容，并快速修复陈旧的数据</p> \n <h2><a id=\"Nginx__1478\"></a>聊聊：Nginx 压缩了解吗，如何开启压缩？</h2> \n <p>开启nginx gzip压缩后，图片、css、js等静态资源的大小会减小，可节省带宽，提高传输效率，但是会消耗CPU资源。</p> \n <pre><code class=\"prism language-yaml\">gzip on;  \n<span class=\"token comment\">#开启gzip压缩功能</span>\ngzip_min_length 1k;\n<span class=\"token comment\">#设置允许压缩的页面最小字节数，页面字节数从header头的content-length中获取。默认值是0,不管页面多大都进行压缩。建议设置成大于1k。如果小于1k可能会越压越大。</span>\ngzip_buffers 4 16k;\n<span class=\"token comment\">#压缩缓冲区大小。表示申请4个单位为16k的内容作为压缩结果流缓存，默认值是申请与原始数据大小相同的内存空间来存储gzip压缩结果。</span>\ngzip_http_version 1.0;\n<span class=\"token comment\">#压缩版本（默认1.1，前端为squid2.5时使用1.0）用于设置识别http协议版本，默认是1.1,目前大部分浏览器已经支持gzip解压，使用默认即可。</span>\ngzip_comp_level 2;\n<span class=\"token comment\">#压缩比率。用来指定gzip压缩比，1压缩比量小，处理速度快；9压缩比量大，传输速度快，但处理最慢，也必将消耗cpu资源。</span>\ngzip_types text/plain application/x<span class=\"token punctuation\">-</span>javascript text/css application/xml;\n<span class=\"token comment\">#用来指定压缩的类型，“text/html”类型总是会被压缩。</span>\ngzip_vary on;\n<span class=\"token comment\">#vary header支持。该选项可以让前端的缓存服务器缓存经过gzip压缩的页面，例如用squid缓存经过nginx压缩的数据。</span>\n</code></pre> \n <p>要注意：需要和不需要压缩的对象</p> \n <p>（1）大于1k的纯文本文件html,js,css,xml,html.</p> \n <p>（2）图片，视频等不要压缩，因为不但不会减小，在压缩时消耗cpu和内存资源。</p> \n <h2><a id=\"Nginxgzip_1507\"></a>聊聊：Nginx开启gzip压缩</h2> \n <p>Nginx 开启 Gzip 压缩功能， 可以使网站的 css、js 、xml、html 文件在传输时进行压缩，提高访问速度, 进而优化 Nginx 性能。</p> \n <p>网站加载的速度取决于浏览器必须下载的所有文件的大小。减少要传输的文件的大小可以使网站不仅加载更快，而且对于那些宽带是按量计费的人来说也更友好。</p> \n <p>gzip 是一种流行的数据压缩程序。</p> \n <p>您可以使用 gzip 压缩 Nginx 实时文件。这些文件在检索时由支持它的浏览器解压缩，好处是 web 服务器和浏览器之间传输的数据量更小，速度更快。</p> \n <p>gzip 不一定适用于所有文件的压缩。例如，文本文件压缩得非常好，通常会缩小两倍以上。</p> \n <p>另一方面，诸如 JPEG或 PNG 文件之类的图像已经按其性质进行压缩，使用 gzip 压缩很难有好的压缩效果或者甚至没有效果。压缩文件会占用服务器资源，因此最好只压缩那些压缩效果好的文件。</p> \n <h2><a id=\"_1523\"></a>聊聊：开启压缩功能的好坏</h2> \n <ol>\n  <li> <p>好处:</p> <p>压缩是可以节省带宽，提高传输效率。</p> </li>\n  <li> <p>坏处:</p> <p>但是由于是在服务器上进行压缩，会消耗服务器起源</p> </li>\n </ol> \n <h2><a id=\"Nginxgzip_1537\"></a>聊聊：Nginx的gzip压缩的原理和优点</h2> \n <p>Nginx 开启 Gzip 压缩功能， 可以使网站的 css、js 、xml、html 文件在传输时进行压缩，提高访问速度, 进而优化 Nginx 性能。</p> \n <p>网站加载的速度取决于浏览器必须下载的所有文件的大小。减少要传输的文件的大小可以使网站不仅加载更快，而且对于那些宽带是按量计费的人来说也更友好。</p> \n <p>gzip 是一种流行的数据压缩程序。您可以使用 gzip 压缩 Nginx 实时文件。这些文件在检索时由支持它的浏览器解压缩，好处是 web 服务器和浏览器之间传输的数据量更小，速度更快。</p> \n <p>gzip 不一定适用于所有文件的压缩。例如，文本文件压缩得非常好，通常会缩小两倍以上。另一方面，诸如 JPEG或 PNG 文件之类的图像已经按其性质进行压缩，使用 gzip 压缩很难有好的压缩效果或者甚至没有效果。压缩文件会占用服务器资源，因此最好只压缩那些压缩效果好的文件。</p> \n <h3><a id=\"Nginx_gzip_1547\"></a>Nginx gzip配置作用</h3> \n <p>Nginx 开启 Gzip 压缩功能， 可以使网站的 css、js 、xml、html 文件在传输时进行压缩，提高访问速度, 进而优化 Nginx 性能! Web 网站上的图片，视频等其它多媒体文件以及大文件，因为压缩效果不好，所以对于图片没有必要支压缩，如果想要优化，可以图片的生命周期设置长一点，让客户端来缓存。</p> \n <p>开启 Gzip 功能后，Nginx 服务器会根据配置的策略对发送的内容, 如 css、js、xml、html 等静态资源进行压缩, 使得这些内容大小减少，在用户接收到返回内容之前对其进行处理，以压缩后的数据展现给客户。这样不仅可以节约大量的出口带宽，提高传输效率，还能提升用户快的感知体验, 一举两得; 尽管会消耗一定的 cpu 资源，但是为了给用户更好的体验还是值得的。</p> \n <p>经过 Gzip 压缩后页面大小可以变为原来的 30% 甚至更小，这样，用户浏览页面的时候速度会快得多。Gzip 的压缩页面需要浏览器和服务器双方都支持，实际上就是服务器端压缩，传到浏览器后浏览器解压并解析。浏览器那里不需要我们担心，因为目前的巨大多数浏览器 都支持解析 Gzip 过的页面。</p> \n <h3><a id=\"Nginx_gzip_1555\"></a>Nginx gzip配置参数</h3> \n <h4><a id=\"_1557\"></a>参数</h4> \n <table>\n  <thead>\n   <tr>\n    <th>参数</th>\n    <th>描述</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>gzip on</td>\n    <td>决定是否开启 gzip 模块，on 表示开启，off 表示关闭</td>\n   </tr>\n   <tr>\n    <td>gzip_min_length 1k</td>\n    <td>设置允许压缩的页面最小字节(从 header 头的 Content-Length 中获取) ，当返回内容大于此值时才会使用 gzip 进行压缩,以 K 为单位,当值为 0 时，所有页面都进行压缩。建议大于 1k</td>\n   </tr>\n   <tr>\n    <td>gzip_buffers 4 16k</td>\n    <td>设置 gzip 申请内存的大小，其作用是按块大小的倍数申请内存空间,param2:int(k) 后面单位是 k。这里设置以 16k 为单位,按照原始数据大小以 16k 为单位的 4 倍申请内存</td>\n   </tr>\n   <tr>\n    <td>gzip_http_version 1.1</td>\n    <td>识别 http 协议的版本,早起浏览器可能不支持 gzip 自解压,用户会看到乱码</td>\n   </tr>\n   <tr>\n    <td>gzip_comp_level 2</td>\n    <td>设置 gzip 压缩等级，等级越底压缩速度越快文件压缩比越小，反之速度越慢文件压缩比越大；等级1-9，最小的压缩最快 但是消耗 cpu</td>\n   </tr>\n   <tr>\n    <td>gzip_types text/plain</td>\n    <td>设置需要压缩的 MIME 类型,非设置值不进行压缩，即匹配压缩类型</td>\n   </tr>\n   <tr>\n    <td>gzip_vary on</td>\n    <td>启用应答头\"Vary: Accept-Encoding\"</td>\n   </tr>\n   <tr>\n    <td>gzip_proxied off</td>\n    <td>nginx 做为反向代理时启用</td>\n   </tr>\n   <tr>\n    <td>gzip_disable msie6</td>\n    <td>IE5.5 和 IE6 SP1 使用 msie6 参数来禁止 gzip 压缩 )指定哪些不需要 gzip 压缩的浏览器(将和User-Agents进行匹配),依赖于 PCRE 库</td>\n   </tr>\n  </tbody>\n </table> \n <h3><a id=\"Nginx_gzip_1571\"></a>Nginx gzip参数介绍</h3> \n <h4><a id=\"gzip_on_1573\"></a>gzip on</h4> \n <pre><code class=\"prism language-yaml\">打开或关闭gzip\n默认 off 关闭\n代码块 http<span class=\"token punctuation\">,</span> server<span class=\"token punctuation\">,</span> location<span class=\"token punctuation\">,</span> if in location\n</code></pre> \n <h4><a id=\"gzip_buffers_1581\"></a>gzip_buffers</h4> \n <p>设置用于处理请求压缩的缓冲区数量和大小。比如 32 4K 表示按照内存页（one memory page）大小以 4K 为单位（即一个系统中内存页为 4K），申请 32 倍的内存空间。建议此项不设置，使用默认值。</p> \n <pre><code class=\"prism language-yaml\"><span class=\"token key atrule\">Syntax</span><span class=\"token punctuation\">:</span> gzip_buffers number size;\n<span class=\"token key atrule\">Default</span><span class=\"token punctuation\">:</span>    \ngzip_buffers 32 4k<span class=\"token punctuation\">|</span>16 8k;\n<span class=\"token key atrule\">Context</span><span class=\"token punctuation\">:</span>    http<span class=\"token punctuation\">,</span> server<span class=\"token punctuation\">,</span> location\n</code></pre> \n <h4><a id=\"gzip_comp_level_1592\"></a>gzip_comp_level</h4> \n <p>设置 gzip 压缩级别，级别越底压缩速度越快文件压缩比越小，反之速度越慢文件压缩比越大</p> \n <pre><code class=\"prism language-yaml\"><span class=\"token key atrule\">Syntax</span><span class=\"token punctuation\">:</span> gzip_comp_level level;\n<span class=\"token key atrule\">Default</span><span class=\"token punctuation\">:</span>    \ngzip_comp_level 1;\n<span class=\"token key atrule\">Context</span><span class=\"token punctuation\">:</span>    http<span class=\"token punctuation\">,</span> server<span class=\"token punctuation\">,</span> location\n</code></pre> \n <p>不是压缩级别越高越好，其实 gzip_comp_level 1 的压缩能力已经够用了，后面级别越高，压缩的比例其实增长不大，反而很吃处理性能。</p> \n <p>另一方面，压缩一定要和静态资源缓存相结合，缓存压缩后的版本，否则每次都压缩高负载下服务器肯定吃不住。</p> \n <h4><a id=\"gzip_disable_1607\"></a>gzip_disable</h4> \n <p>通过表达式，表明哪些 UA 头不使用 gzip 压缩</p> \n <pre><code class=\"prism language-yaml\"><span class=\"token key atrule\">Syntax</span><span class=\"token punctuation\">:</span> gzip_disable regex <span class=\"token punctuation\">...</span>;\n<span class=\"token key atrule\">Default</span><span class=\"token punctuation\">:</span>    —\n<span class=\"token key atrule\">Context</span><span class=\"token punctuation\">:</span>    http<span class=\"token punctuation\">,</span> server<span class=\"token punctuation\">,</span> location\nThis directive appeared in version 0.6.23.\n</code></pre> \n <h4><a id=\"gzip_min_length_1618\"></a>gzip_min_length</h4> \n <p>当返回内容大于此值时才会使用gzip进行压缩,以 K 为单位,当值为 0 时，所有页面都进行压缩。</p> \n <pre><code class=\"prism language-yaml\"><span class=\"token key atrule\">Syntax</span><span class=\"token punctuation\">:</span> gzip_min_length length;\n<span class=\"token key atrule\">Default</span><span class=\"token punctuation\">:</span>    \ngzip_min_length 20;\n<span class=\"token key atrule\">Context</span><span class=\"token punctuation\">:</span>    http<span class=\"token punctuation\">,</span> server<span class=\"token punctuation\">,</span> location\n</code></pre> \n <h4><a id=\"gzip_http_version_1629\"></a>gzip_http_version</h4> \n <p>用于识别 http 协议的版本，早期的浏览器不支持 gzip 压缩，用户会看到乱码，所以为了支持前期版本加了此选项。默认在 http/1.0 的协议下不开启 gzip 压缩。</p> \n <pre><code class=\"prism language-yaml\"><span class=\"token key atrule\">Syntax</span><span class=\"token punctuation\">:</span> gzip_http_version 1.0 <span class=\"token punctuation\">|</span> 1.1;\n<span class=\"token key atrule\">Default</span><span class=\"token punctuation\">:</span>    \ngzip_http_version 1.1;\n<span class=\"token key atrule\">Context</span><span class=\"token punctuation\">:</span>    http<span class=\"token punctuation\">,</span> server<span class=\"token punctuation\">,</span> location\n</code></pre> \n <p>在应用服务器前，如果还有一层 Nginx 的集群作为负载均衡，在这一层上，若果没有开启 gzip。</p> \n <p>如果我们使用了proxy_pass 进行反向代理，那么 nginx 和后端的 upstream server 之间默认是用 HTTP/1.0 协议通信的。</p> \n <p>如果我们的 Cache Server 也是 nginx，而前端的 nginx 没有开启 gzip。同时，我们后端的 nginx 上没有设置gzip_http_version 为 1.0，那么 Cache 的 url 将不会进行 gzip 压缩。</p> \n <h4><a id=\"gzip_proxied_1646\"></a>gzip_proxied</h4> \n <p>Nginx 做为反向代理的时候启用：</p> \n <ol>\n  <li>off – 关闭所有的代理结果数据压缩</li>\n  <li>expired – 如果header中包含”Expires”头信息，启用压缩</li>\n  <li>no-cache – 如果header中包含”Cache-Control:no-cache”头信息，启用压缩</li>\n  <li>no-store – 如果header中包含”Cache-Control:no-store”头信息，启用压缩</li>\n  <li>private – 如果header中包含”Cache-Control:private”头信息，启用压缩</li>\n  <li>no_last_modified – 启用压缩，如果header中包含”Last_Modified”头信息，启用压缩</li>\n  <li>no_etag – 启用压缩，如果header中包含“ETag”头信息，启用压缩</li>\n  <li>auth – 启用压缩，如果header中包含“Authorization”头信息，启用压缩</li>\n  <li>any – 无条件压缩所有结果数据</li>\n </ol> \n <pre><code class=\"prism language-yaml\"><span class=\"token key atrule\">Syntax</span><span class=\"token punctuation\">:</span> gzip_proxied off <span class=\"token punctuation\">|</span> expired <span class=\"token punctuation\">|</span> no<span class=\"token punctuation\">-</span>cache <span class=\"token punctuation\">|</span> no<span class=\"token punctuation\">-</span>store <span class=\"token punctuation\">|</span> private <span class=\"token punctuation\">|</span> no_last_modified <span class=\"token punctuation\">|</span> no_etag <span class=\"token punctuation\">|</span> auth <span class=\"token punctuation\">|</span> any <span class=\"token punctuation\">...</span>;\n<span class=\"token key atrule\">Default</span><span class=\"token punctuation\">:</span>    \ngzip_proxied off;\n<span class=\"token key atrule\">Context</span><span class=\"token punctuation\">:</span>    http<span class=\"token punctuation\">,</span> server<span class=\"token punctuation\">,</span> location\n</code></pre> \n <h4><a id=\"gzip_types_1668\"></a>gzip_types</h4> \n <p>设置需要压缩的 MIME 类型,如果不在设置类型范围内的请求不进行压缩</p> \n <pre><code class=\"prism language-yaml\"><span class=\"token key atrule\">Syntax</span><span class=\"token punctuation\">:</span> gzip_types mime<span class=\"token punctuation\">-</span>type <span class=\"token punctuation\">...</span>;\n<span class=\"token key atrule\">Default</span><span class=\"token punctuation\">:</span>    \ngzip_types text/html;\n<span class=\"token key atrule\">Context</span><span class=\"token punctuation\">:</span>    http<span class=\"token punctuation\">,</span> server<span class=\"token punctuation\">,</span> location\n</code></pre> \n <h4><a id=\"gzip_vary_1679\"></a>gzip_vary</h4> \n <p>增加响应头”Vary: Accept-Encoding”，告诉接收方发送的数据经过了压缩处理，开启后的效果是在响应头部添加了Accept-Encoding:gzip，这对于本身不支持 gzip 压缩的客户端浏览器有用。</p> \n <pre><code class=\"prism language-yaml\"><span class=\"token key atrule\">Syntax</span><span class=\"token punctuation\">:</span> gzip_vary on <span class=\"token punctuation\">|</span> off;\n<span class=\"token key atrule\">Default</span><span class=\"token punctuation\">:</span>    \ngzip_vary off;\n<span class=\"token key atrule\">Context</span><span class=\"token punctuation\">:</span>    http<span class=\"token punctuation\">,</span> server<span class=\"token punctuation\">,</span> location\n</code></pre> \n <h3><a id=\"Nginx_gzip__1690\"></a>Nginx gzip 案例</h3> \n <p>我们首先，使用 vim 打开 nginx 的默认配置路径，具体命令如下：</p> \n <pre><code class=\"prism language-sh\"><span class=\"token function\">vim</span> /etc/nginx/conf.d/default.conf\n</code></pre> \n <p>我们执行如上命令，打开配置文件，此时配置文件如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/6b4a9894108f478daf942875fd2a14e2.png\" alt=\"\"></p> \n <p>现在，我们在 nginx 的根路径下新建一个 index.html，并写入内容，并使用浏览器访问，此时，浏览器输出如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/9dcc813e2cdb4fb6a94a3a6da9cc104e.png\" alt=\"\"></p> \n <p>现在，我们打开 nginx.conf 配置文件，如下图所示：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/a8d2dc6000dd4f26b7df84f45e18bc73.png\" alt=\"\"></p> \n <p>在 nginx 的 http 模块的配置里面，开启 gzip 配置，具体配置如下：</p> \n <pre><code class=\"prism language-yaml\">gzip  on;\ngzip_min_length  1k;\ngzip_buffers     4 16k;\ngzip_http_version 1.1;\ngzip_comp_level 9;\ngzip_types       text/plain application/x<span class=\"token punctuation\">-</span>javascript text/css application/xml text/javascript application/x<span class=\"token punctuation\">-</span>httpd<span class=\"token punctuation\">-</span>php application/javascript application/json;\ngzip_disable \"MSIE <span class=\"token punctuation\">[</span>1<span class=\"token punctuation\">-</span><span class=\"token number\">6</span><span class=\"token punctuation\">]</span>\\.\";\ngzip_vary on;\n</code></pre> \n <p>配置完成后，如下图所示：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/c7369cf7f6084293a7654db200eb1c35.png\" alt=\"\"></p> \n <p>现在，我们使用 reload 重新加载配置，具体命令如下：</p> \n <pre><code class=\"prism language-bash\">nginx <span class=\"token parameter variable\">-s</span> reload\n</code></pre> \n <p>执行完毕后，我们再次使用浏览器访问，此时输出如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/3ebe84bb07a646838b263123459f49d4.png\" alt=\"\"></p> \n <p>我们看到，此时输出了 gzip，并且浏览器的内容如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/157b8e5ce58d4348b82a38d94567488c.png\" alt=\"\"></p> \n <p>我们看到，浏览器的内容也正常输出了。</p> \n <h3><a id=\"Nginx_gzip_1743\"></a>Nginx gzip配置总结</h3> \n <p>Nginx 开启 Gzip 压缩功能， 可以使网站的 css、js 、xml、html 文件在传输时进行压缩，提高访问速度, 进而优化 Nginx 性能。</p> \n <h2><a id=\"Nginx_1749\"></a>聊聊：Nginx是否支持将请求压缩到上游?</h2> \n <p>您可以使用Nginx模块gunzip将请求压缩到上游。</p> \n <p>gunzip模块是一个过滤器，它可以对不支持“gzip”编码方法的客户机或服务器使用“内容编码:gzip”来解压缩响应。</p> \n <h2><a id=\"Nginx_1757\"></a>聊聊：如何在Nginx中获得当前的时间?</h2> \n <p>要获得Nginx的当前时间，必须使用SSI模块、$date_gmt和 $date_local的变量。<br> Proxy_set_header THE-TIME $date_gmt;</p> \n <h2><a id=\"Nginxs_1764\"></a>聊聊：用Nginx服务器解释-s的目的是什么?</h2> \n <p>用于运行Nginx -s参数的可执行文件。</p> \n <h2><a id=\"Nginx_1770\"></a>聊聊：如何在Nginx服务器上添加模块?</h2> \n <p>在编译过程中，必须选择Nginx模块，因为Nginx不支持模块的运行时间选择。</p> \n <p><strong>Nginx动态添加模块</strong></p> \n <p>很多时候，我们根据当时的项目情况和业务需求安装完 Nginx 后，后续随着业务的发展，往往会给安装好的 Nginx 添加其他的功能模块。在为 Nginx 添加功能模块时，要求 Nginx 不停机。</p> \n <p>这就涉及到如何为已安装的 Nginx 动态添加模块的问题。本文，就和小伙伴们一起探讨如何为已安装的 Nginx 动态添加模块的问题。</p> \n <h2><a id=\"Nginx_1780\"></a>聊聊：如何为Nginx动态添加模块</h2> \n <p>这里以安装第三方 ngx_http_google_filter_module 模块为例。</p> \n <p>Nginx 的模块是需要重新编译 Nginx，而不是像 Apache 一样配置文件引用 .so。</p> \n <h3><a id=\"_1786\"></a>下载扩展</h3> \n <p>下载第三方扩展模块 ngx_http_google_filter_module</p> \n <pre><code class=\"prism language-bash\"><span class=\"token comment\"># cd /data/software/</span>\n<span class=\"token comment\"># git clone https://github.com/cuber/ngx_http_google_filter_module</span>\n</code></pre> \n <h3><a id=\"_1795\"></a>查看安装模块</h3> \n <p>查看 Nginx 编译安装时安装了哪些模块，将命令行切换到 Nginx 执行程序所在的目录并输入 ./nginx -V，具体如下：</p> \n <pre><code class=\"prism language-bash\"><span class=\"token punctuation\">[</span>root@binghe sbin<span class=\"token punctuation\">]</span><span class=\"token comment\"># ./nginx -V</span>\nnginx version: nginx/1.19.1\nbuilt by gcc <span class=\"token number\">4.4</span>.7 <span class=\"token number\">20120313</span> <span class=\"token punctuation\">(</span>Red Hat <span class=\"token number\">4.4</span>.7-17<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">(</span>GCC<span class=\"token punctuation\">)</span> \nbuilt with OpenSSL <span class=\"token number\">1.0</span>.2 <span class=\"token number\">22</span> Jan <span class=\"token number\">2015</span>\nTLS SNI support enabled\nconfigure arguments: <span class=\"token parameter variable\">--prefix</span><span class=\"token operator\">=</span>/usr/local/nginx-1.19.1 --with-openssl<span class=\"token operator\">=</span>/usr/local/src/openssl-1.0.2 --with-pcre<span class=\"token operator\">=</span>/usr/local/src/pcre-8.37 --with-zlib<span class=\"token operator\">=</span>/usr/local/src/zlib-1.2.8 --with-http_ssl_module\n<span class=\"token punctuation\">[</span>root@binghe sbin<span class=\"token punctuation\">]</span><span class=\"token comment\"># </span>\n</code></pre> \n <p>可以看出编译安装 Nginx 使用的参数如下：</p> \n <pre><code class=\"prism language-bash\"><span class=\"token parameter variable\">--prefix</span><span class=\"token operator\">=</span>/usr/local/nginx-1.19.1 --with-openssl<span class=\"token operator\">=</span>/usr/local/src/openssl-1.0.2 --with-pcre<span class=\"token operator\">=</span>/usr/local/src/pcre-8.37 --with-zlib<span class=\"token operator\">=</span>/usr/local/src/zlib-1.2.8 --with-http_ssl_module\n</code></pre> \n <h3><a id=\"_1815\"></a>重新编译</h3> \n <p>加入需要安装的模块，重新编译，这里添加 --add-module=/data/software/ngx_http_google_filter_module，具体如下：</p> \n <pre><code class=\"prism language-bash\">./configure  <span class=\"token parameter variable\">--prefix</span><span class=\"token operator\">=</span>/usr/local/nginx-1.19.1 --with-openssl<span class=\"token operator\">=</span>/usr/local/src/openssl-1.0.2 --with-pcre<span class=\"token operator\">=</span>/usr/local/src/pcre-8.37 --with-zlib<span class=\"token operator\">=</span>/usr/local/src/zlib-1.2.8 --with-http_ssl_module -–add-module<span class=\"token operator\">=</span>/data/software/ngx_http_google_filter_module\n</code></pre> \n <p>如上，将之前安装Nginx的参数全部加上，最后添加 --add-module=/data/software/ngx_http_google_filter_module，之后，我们要进行编译操作，如下：</p> \n <pre><code class=\"prism language-bash\"><span class=\"token comment\"># make //千万不要make install，不然就真的覆盖</span>\n</code></pre> \n <p>这里，需要注意的是：不要执行 make install 命令。</p> \n <h3><a id=\"nginx_1831\"></a>替换nginx二进制文件</h3> \n <pre><code class=\"prism language-bash\"><span class=\"token comment\"># 备份原来的nginx执行程序</span>\n<span class=\"token comment\"># mv /usr/local/nginx-1.19.1/sbin/nginx /usr/local/nginx-1.19.1/sbin/nginx.bak</span>\n<span class=\"token comment\"># 将新编译的nginx执行程序复制到/usr/local/nginx-1.19.1/sbin/目录下</span>\n<span class=\"token comment\"># cp /opt/nginx/sbin/nginx /usr/local/nginx-1.19.1/sbin/</span>\n</code></pre> \n <h2><a id=\"_1842\"></a>聊聊：如何设置超时时间</h2> \n <pre><code class=\"prism language-bash\">http <span class=\"token punctuation\">{\n    <!-- --></span>\n	keepalive_timeout <span class=\"token number\">60</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">###设置客户端连接保持会话的超时时间，超过这个时间，服务器会关闭该连接。 </span>\n	\n	tcp_nodelay on<span class=\"token punctuation\">;</span> <span class=\"token comment\">####打开 tcp_nodelay，在包含了 keepalive 参数才有效</span>\n	\n	client_header_timeout <span class=\"token number\">15</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">####设置客户端请求头读取超时时间，如果超过这个时间，客户端还没有发送任何数据， Nginx 将返回“Request time out(408)”错误</span>\n	\n	client_body_timeout <span class=\"token number\">15</span><span class=\"token punctuation\">;</span><span class=\"token comment\">####设置客户端请求主体读取超时时间，如果超过这个时间，客户端还没有发送任何数据， Nginx 将返回“Request time out(408)”错误</span>\n	\n	send_timeout <span class=\"token number\">15</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">####指定响应客户端的超时时间。这个超过仅限于两个连接活动之间的时间，如果超过这个时间，客户端没有任何活动，Nginx 将会关闭连接。</span>\n\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"Nginx_1861\"></a>聊聊：Nginx如何限制浏览器和爬虫</h2> \n <h3><a id=\"Nginx_1863\"></a>Nginx限制爬虫</h3> \n <p>修改 nginx.conf，禁止网络爬虫的 ua，返回 403，具体配置如下：</p> \n <pre><code class=\"prism language-bash\">server<span class=\"token punctuation\">{\n    <!-- --></span>\n	listen <span class=\"token number\">80</span><span class=\"token punctuation\">;</span>\n	server_name <span class=\"token number\">127.0</span>.0.1<span class=\"token punctuation\">;</span> \n	<span class=\"token comment\"># 添加如下内容即可防止爬虫</span>\n	<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$http_user_agent</span> ~* <span class=\"token string\">\"qihoobot|Baiduspider|Googlebot|Googlebot-Mobile|Googlebot-Image|Mediapartners-Google|Adsbot-Google|Feedfetcher-Google|Yahoo! Slurp|Yahoo! Slurp China|YoudaoBot|Sosospider|Sogou spider|Sogou web spider|MSNBot|ia_archiver|Tomato Bot\"</span><span class=\"token punctuation\">)</span> \n	<span class=\"token punctuation\">{\n    <!-- --></span>\n		<span class=\"token builtin class-name\">return</span> <span class=\"token number\">403</span><span class=\"token punctuation\">;</span>\n	<span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h3><a id=\"Nginx_1879\"></a>Nginx限制浏览器访问</h3> \n <p>限制浏览器访问：</p> \n <pre><code class=\"prism language-bash\"><span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$http_user_agent</span> ~* <span class=\"token string\">\"Firefox|MSIE\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">{\n    <!-- --></span>\n     <span class=\"token builtin class-name\">return</span> <span class=\"token number\">403</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h3><a id=\"NginxIP_1892\"></a>Nginx限制IP访问</h3> \n <p>有时候我们需要针对屏蔽某些恶意的 IP 访问我们的网站，或者限制仅仅某些白名单 IP 才能访问我们的网站。</p> \n <p>这时候我们就可以在Nginx中通过简单的配置来达到目的。</p> \n <pre><code class=\"prism language-bash\"><span class=\"token comment\">#添加IP至allow（例如我们将10.208.96.192和10.208.96.193加入)</span>\nlocation <span class=\"token operator\">=</span> /index.html\n <span class=\"token punctuation\">{\n    <!-- --></span> \n  allow <span class=\"token number\">10.208</span>.96.192<span class=\"token punctuation\">;</span> \n   allow <span class=\"token number\">10.208</span>.96.193<span class=\"token punctuation\">;</span> \n   deny all<span class=\"token punctuation\">;</span> \n   root /work/weichuangli<span class=\"token punctuation\">;</span> \n  <span class=\"token punctuation\">}</span>\n</code></pre> \n <p>屏蔽单个ip访问</p> \n <pre><code class=\"prism language-css\"># 格式： deny ip<span class=\"token punctuation\">;</span>\ndeny 123.68.23.5<span class=\"token punctuation\">;</span>\n</code></pre> \n <p>允许单个ip访问</p> \n <pre><code class=\"prism language-css\"># 格式： allow ip<span class=\"token punctuation\">;</span>\nallow 123.68.25.6<span class=\"token punctuation\">;</span>\n</code></pre> \n <p>屏蔽所有ip访问</p> \n <pre><code class=\"prism language-undefined\">deny all;\n</code></pre> \n <p>允许所有ip访问</p> \n <pre><code class=\"prism language-undefined\">allow all;\n</code></pre> \n <p>屏蔽ip段访问</p> \n <pre><code class=\"prism language-bash\"><span class=\"token comment\"># deny ip/mask</span>\n<span class=\"token comment\"># 屏蔽172.12.62.0到172.45.62.255访问的命令 </span>\ndeny <span class=\"token number\">172.12</span>.62.0/24<span class=\"token punctuation\">;</span>\n</code></pre> \n <p>允许ip段访问</p> \n <pre><code class=\"prism language-bash\"><span class=\"token comment\"># allow ip/mask</span>\n<span class=\"token comment\"># 屏蔽172.102.0.0到172.102.255.255访问的命令 </span>\nallow <span class=\"token number\">172.102</span>.0.0/16<span class=\"token punctuation\">;</span>\n</code></pre> \n <h2><a id=\"502_1953\"></a>聊聊：502报错可能原因有哪些？</h2> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/b2f1e7f3edd54720703b2648512ee3e2.png\" alt=\"\"></p> \n <p>1）FastCGI进程是否已经启动</p> \n <p>2）FastCGI worker进程数是否不够</p> \n <p>3）FastCGI执行时间过长</p> \n <p>4）FastCGI Buffer不够</p> \n <p>nginx和apache一样，有前端缓冲限制，可以调整缓冲参数</p> \n <pre><code class=\"prism language-bash\">fastcgi_buffer_size 32k<span class=\"token punctuation\">;</span>   \nfastcgi_buffers <span class=\"token number\">8</span> 32k<span class=\"token punctuation\">;</span>\n</code></pre> \n <p>5）Proxy Buffer不够</p> \n <p>如果你用了Proxying，调整</p> \n <pre><code class=\"prism language-bash\">proxy_buffer_size 16k<span class=\"token punctuation\">;</span>  \nproxy_buffers <span class=\"token number\">4</span> 16k<span class=\"token punctuation\">;</span>\n</code></pre> \n <p>6）php脚本执行时间过长</p> \n <p>将php-fpm.conf的<code>&lt;value name=\"request_terminate_timeout\"&gt;0s&lt;/value&gt;</code>的0s改成一个时间</p> \n <h2><a id=\"Nginx__1987\"></a>聊聊：Nginx 如何解决跨域问题</h2> \n <p>跨域是前端开发中经常会遇到的问题，前端调用后台服务时，通常会遇到 No ‘Access-Control-Allow-Origin’ header is present on the requested resource 的错误，这是因为浏览器的同源策略拒绝了我们的请求。</p> \n <p>所谓同源是指，域名，协议，端口相同，浏览器执行一个脚本时同源的脚本才会被执行。</p> \n <p>如果非同源，那么在请求数据时，浏览器会在控制台中报一个异常，提示拒绝访问。</p> \n <p>这个问题我们通常会使用 CORS(跨源资源共享)或者 JSONP 去解决，这两种方法也是使用较多的方法。</p> \n <h2><a id=\"Nginx___1999\"></a>细聊：Nginx 如何 解决跨域问题</h2> \n <h3><a id=\"_2001\"></a>什么是跨域</h3> \n <p>跨域是前端开发中经常会遇到的问题，前端调用后台服务时，通常会遇到 No ‘Access-Control-Allow-Origin’ header is present on the requested resource 的错误，这是因为浏览器的同源策略拒绝了我们的请求。</p> \n <p>所谓同源是指，域名，协议，端口相同，浏览器执行一个脚本时同源的脚本才会被执行。如果非同源，那么在请求数据时，浏览器会在控制台中报一个异常，提示拒绝访问。这个问题我们通常会使用 CORS(跨源资源共享)或者 JSONP 去解决，这两种方法也是使用较多的方法。</p> \n <h3><a id=\"Nginx_2007\"></a>Nginx解决跨域方案一</h3> \n <h4><a id=\"_2009\"></a>解决跨域</h4> \n <p>这个使用 Nginx 的代理功能即可，在 a 服务器的 Nginx 添加如下示例配置：</p> \n <pre><code class=\"prism language-bash\">location ~ /xxx/ <span class=\"token punctuation\">{\n    <!-- --></span>\n	proxy_pass http://b.com<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>这样就把路径中带有 /xxx/ 的请求都转到了 b.com。如果不需要保存 cookie，保持 session 这样的功能，这样就可以了。</p> \n <p>然而，本项目就是要用到 cookie，所以就有了下边的内容。</p> \n <h4><a id=\"domain_2023\"></a>设置domain</h4> \n <p>因为 cookie 当中是有 domain 的，两个服务器的一般不同，比如 a 服务器返回的 Response Headers 中是</p> \n <pre><code>Set-Cookie:JSESSIONID=_3y4u02v4cbpBw10DoCrMSnjg7m34xuum1XRWBF1Uno; path=/; domain=a.com\n</code></pre> \n <p>而 b 服务器返回的是</p> \n <pre><code>Set-Cookie:JSESSIONID=_3y4u02v4cbpBw10DoCrMSnjg7m34xuum1XRWBF1Uno; path=/; domain=b.com\n</code></pre> \n <p>这时候如果 a 项目的页面调用了 b 的接口，浏览器发现接口返回的 domain 不是 a.com，就不会把 cookie 保存起来，session 也就失效了。Nginx 引入了 proxy_cookie_domain 来解决这个问题。示例：</p> \n <pre><code class=\"prism language-bash\">location ~ /xxx/ <span class=\"token punctuation\">{\n    <!-- --></span>\n	proxy_cookie_domain b.com a.com<span class=\"token punctuation\">;</span>\n	proxy_pass http://b.com<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>这样就可以在 Nginx 转接请求的时候自动把 domain 中的 b.com 转换成 a.com，这样 cookie 就可以设置成功了。</p> \n <p>但是，对于有些情况这样转换不灵光。比如，b 项目的 domain 是 .b.com，前边多了一个小点，那对应的改为 proxy_cookie_domain .b.com a.com; 可以不？通过实践，不行！！！</p> \n <p>通过查看 Nginx 文档，找到了解决办法。其实，除了上边那种配置方式外，Nginx 还支持正则配置：</p> \n <pre><code class=\"prism language-bash\">location ~ /xxx/ <span class=\"token punctuation\">{\n    <!-- --></span>\n	proxy_cookie_domain ~<span class=\"token punctuation\">\\</span>.?b.com a.com<span class=\"token punctuation\">;</span>\n	proxy_pass http://b.com<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>这样就可以把 domain 中的 .b.com 转换成 a.com 啦。</p> \n <h4><a id=\"path_2061\"></a>设置path</h4> \n <p>正常情况下完成以上两步就可以了，因为 cookie 中的 path 一般默认的是 path=/，也就是所有请求都可以访问本 cookie。但有些服务器会指定，只允许某个层级下的请求可以访问 cookie，比如：</p> \n <pre><code>Set-Cookie:JSESSIONID=_3y4u02v4cbpBw10DoCrMSnjg7m34xuum1XRWBF1Uno; path=/sub/; domain=b.com\n</code></pre> \n <p>这样就只允许相对根路径，以 /sub/ 开头的请求路径才能访问 cookie。这时候就又可能出现 cookie 无效的问题了，为了解决这个问题，可以使用 proxy_cookie_path。示例：</p> \n <pre><code class=\"prism language-bash\">location ~ /xxx/ <span class=\"token punctuation\">{\n    <!-- --></span>\n	proxy_cookie_domain ~<span class=\"token punctuation\">\\</span>.?b.com a.com<span class=\"token punctuation\">;</span>\n	proxy_cookie_path /sub/ /<span class=\"token punctuation\">;</span>\n	proxy_pass http://b.com<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>这样就把只允许 /sub/ 层级下的请求访问 cookie，改为允许所有请求访问 cookie 了。</p> \n <h3><a id=\"Nginx_2081\"></a>Nginx解决跨域方案二</h3> \n <p>或者，我们也可以直接简单粗暴的设置全局配置了，如下：</p> \n <pre><code class=\"prism language-bash\">http <span class=\"token punctuation\">{\n    <!-- --></span>\n    include       mime.types<span class=\"token punctuation\">;</span>\n    default_type  application/octet-stream<span class=\"token punctuation\">;</span>\n    sendfile        on<span class=\"token punctuation\">;</span>\n    <span class=\"token comment\">#连接超时时间，服务器会在这个时间过后关闭连接。</span>\n    keepalive_timeout  <span class=\"token number\">10</span><span class=\"token punctuation\">;</span>\n    <span class=\"token comment\"># gizp压缩</span>\n    <span class=\"token function\">gzip</span>  on<span class=\"token punctuation\">;</span>\n    <span class=\"token comment\"># 直接请求nginx也是会报跨域错误的这里设置允许跨域</span>\n    <span class=\"token comment\"># 如果代理地址已经允许跨域则不需要这些, 否则报错(虽然这样nginx跨域就没意义了)</span>\n    add_header Access-Control-Allow-Origin *<span class=\"token punctuation\">;</span>\n    add_header Access-Control-Allow-Headers X-Requested-With<span class=\"token punctuation\">;</span>\n    add_header Access-Control-Allow-Methods GET,POST,OPTIONS<span class=\"token punctuation\">;</span>\n    <span class=\"token comment\"># srever模块配置是http模块中的一个子模块，用来定义一个虚拟访问主机</span>\n    server <span class=\"token punctuation\">{\n    <!-- --></span>\n        listen       <span class=\"token number\">80</span><span class=\"token punctuation\">;</span>\n        server_name  localhost<span class=\"token punctuation\">;</span>\n        <span class=\"token comment\"># 根路径指到index.html</span>\n        location / <span class=\"token punctuation\">{\n    <!-- --></span>\n            root   html<span class=\"token punctuation\">;</span>\n            index  index.html index.htm<span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token comment\"># localhost/api 的请求会被转发到192.168.0.103:8080</span>\n        location /api <span class=\"token punctuation\">{\n    <!-- --></span>\n            rewrite ^/b/<span class=\"token punctuation\">(</span>.*<span class=\"token punctuation\">)</span>$ /<span class=\"token variable\">$1</span> <span class=\"token builtin class-name\">break</span><span class=\"token punctuation\">;</span> <span class=\"token comment\"># 去除本地接口/api前缀, 否则会出现404</span>\n            proxy_set_header Host <span class=\"token variable\">$host</span><span class=\"token punctuation\">;</span>\n            proxy_set_header X-Real-IP <span class=\"token variable\">$remote_addr</span><span class=\"token punctuation\">;</span>\n            proxy_set_header X-Forwarded-For <span class=\"token variable\">$proxy_add_x_forwarded_for</span><span class=\"token punctuation\">;</span>\n            proxy_pass http://192.168.0.103:8080<span class=\"token punctuation\">;</span> <span class=\"token comment\"># 转发地址</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token comment\"># 重定向错误页面到/50x.html</span>\n        error_page   <span class=\"token number\">500</span> <span class=\"token number\">502</span> <span class=\"token number\">503</span> <span class=\"token number\">504</span>  /50x.html<span class=\"token punctuation\">;</span>\n        location <span class=\"token operator\">=</span> /50x.html <span class=\"token punctuation\">{\n    <!-- --></span>\n            root   html<span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"_2129\"></a>聊聊：漏桶流算法和令牌桶算法知道？</h2> \n <h3><a id=\"_2131\"></a>漏桶算法</h3> \n <p>漏桶算法是网络世界中流量整形或速率限制时经常使用的一种算法，它的主要目的是控制数据注入到网络的速率，平滑网络上的突发流量。漏桶算法提供了一种机制，通过它，突发流量可以被整形以便为网络提供一个稳定的流量。也就是我们刚才所讲的情况。漏桶算法提供的机制实际上就是刚才的案例：突发流量会进入到一个漏桶，漏桶会按照我们定义的速率依次处理请求，如果水流过大也就是突发流量过大就会直接溢出，则多余的请求会被拒绝。所以漏桶算法能控制数据的传输速率。</p> \n <h3><a id=\"_2135\"></a>令牌桶算法</h3> \n <p>令牌桶算法是网络流量整形和速率限制中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送。Google开源项目Guava中的RateLimiter使用的就是令牌桶控制算法。令牌桶算法的机制如下：存在一个大小固定的令牌桶，会以恒定的速率源源不断产生令牌。如果令牌消耗速率小于生产令牌的速度，令牌就会一直产生直至装满整个令牌桶。</p> \n <p>参考 ：</p> \n <p><a href=\"https://www.cnblogs.com/crazymakercircle/p/15187184.html\">限流：计数器、漏桶、令牌桶 三大算法的原理与实战（史上最全）</a></p> \n <h2><a id=\"Nginx_2145\"></a>聊聊：Nginx限流怎么做的？</h2> \n <p>Nginx限流就是限制用户请求速度，防止服务器受不了</p> \n <p>限流有3种</p> \n <ol>\n  <li>正常限制访问频率（正常流量）</li>\n  <li>突发限制访问频率（突发流量）</li>\n  <li>限制并发连接数</li>\n </ol> \n <p>Nginx的限流都是基于漏桶流算法，底下会说道什么是漏桶流</p> \n <h3><a id=\"_2157\"></a>正常限制访问频率（正常流量）</h3> \n <p>限制一个用户发送的请求，我Nginx多久接收一个请求。</p> \n <p>Nginx中使用ngx_http_limit_req_module模块来限制的访问频率，限制的原理实质是基于漏桶算法原理来实现的。在nginx.conf配置文件中可以使用limit_req_zone命令及limit_req命令限制单个IP的请求处理频率。</p> \n <pre><code class=\"prism language-bash\"><span class=\"token comment\">#定义限流维度，一个用户一分钟一个请求进来，多余的全部漏掉</span>\nlimit_req_zone <span class=\"token variable\">$binary_remote_addr</span> <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>one:10m <span class=\"token assign-left variable\">rate</span><span class=\"token operator\">=</span>1r/m<span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">#绑定限流维度</span>\nserver<span class=\"token punctuation\">{\n    <!-- --></span>\n		\n	location/seckill.html<span class=\"token punctuation\">{\n    <!-- --></span>\n		limit_req <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>zone<span class=\"token punctuation\">;</span>	\n		proxy_pass http://lj_seckill<span class=\"token punctuation\">;</span>\n	<span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h3><a id=\"_2177\"></a>突发限制访问频率（突发流量）</h3> \n <p>限制一个用户发送的请求，我Nginx多久接收一个。</p> \n <p>上面的配置一定程度可以限制访问频率，但是也存在着一个问题：如果突发流量超出请求被拒绝处理，无法处理活动时候的突发流量，这时候应该如何进一步处理呢？Nginx提供burst参数结合nodelay参数可以解决流量突发的问题，可以设置能处理的超过设置的请求数外能额外处理的请求数。我们可以将之前的例子添加burst参数以及nodelay参数：</p> \n <pre><code class=\"prism language-bash\"><span class=\"token comment\">#定义限流维度，一个用户一分钟一个请求进来，多余的全部漏掉</span>\nlimit_req_zone <span class=\"token variable\">$binary_remote_addr</span> <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>one:10m <span class=\"token assign-left variable\">rate</span><span class=\"token operator\">=</span>1r/m<span class=\"token punctuation\">;</span>\n  \n<span class=\"token comment\">#绑定限流维度</span>\nserver<span class=\"token punctuation\">{\n    <!-- --></span>\n  		\n  	location/seckill.html<span class=\"token punctuation\">{\n    <!-- --></span>\n  		limit_req <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>zone <span class=\"token assign-left variable\">burst</span><span class=\"token operator\">=</span><span class=\"token number\">5</span> nodelay<span class=\"token punctuation\">;</span>\n  		proxy_pass http://lj_seckill<span class=\"token punctuation\">;</span>\n  	<span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n</code></pre> \n <p>为什么就多了一个 burst=5 nodelay; 呢，多了这个可以代表Nginx对于一个用户的请求会立即处理前五个，多余的就慢慢来落，没有其他用户的请求我就处理你的，有其他的请求的话我Nginx就漏掉不接受你的请求</p> \n <h3><a id=\"_2199\"></a>限制并发连接数</h3> \n <p>Nginx中的ngx_http_limit_conn_module模块提供了限制并发连接数的功能，可以使用limit_conn_zone指令以及limit_conn执行进行配置。接下来我们可以通过一个简单的例子来看下：</p> \n <pre><code class=\"prism language-bash\">http <span class=\"token punctuation\">{\n    <!-- --></span>\n    limit_conn_zone <span class=\"token variable\">$binary_remote_addr</span> <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>myip:10m<span class=\"token punctuation\">;</span>\n    limit_conn_zone <span class=\"token variable\">$server_name</span> <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>myServerName:10m<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n    \nserver <span class=\"token punctuation\">{\n    <!-- --></span>\n    location / <span class=\"token punctuation\">{\n    <!-- --></span>\n        limit_conn myip <span class=\"token number\">10</span><span class=\"token punctuation\">;</span>\n        limit_conn myServerName <span class=\"token number\">100</span><span class=\"token punctuation\">;</span>\n        rewrite / http://www.lijie.net permanent<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>上面配置了单个IP同时并发连接数最多只能10个连接，并且设置了整个虚拟服务器同时最大并发数最多只能100个链接。当然，只有当请求的header被服务器处理后，虚拟服务器的连接数才会计数。刚才有提到过Nginx是基于漏桶算法原理实现的，实际上限流一般都是基于漏桶算法和令牌桶算法实现的。接下来我们来看看两个算法的介绍：</p> \n <h2><a id=\"_2222\"></a>聊聊：限流了解吗，怎么限流的？</h2> \n <p>Nginx 提供两种限流方式，一是控制速率，二是控制并发连接数。</p> \n <h3><a id=\"1__2226\"></a>1、控制速率 限流</h3> \n <p>ngx_http_limit_req_module 模块提供了漏桶算法(leaky bucket)，可以限制单个IP的请求处理频率。</p> \n <p>Nginx限流使用的是leaky bucket算法，</p> \n <p><a href=\"https://www.cnblogs.com/crazymakercircle/p/15187184.html\">限流：计数器、漏桶、令牌桶 三大算法的原理与实战（史上最全）</a></p> \n <h4><a id=\"_2234\"></a>控制速率基本原理</h4> \n <p>我们从最简单的限流配置开始：</p> \n <pre><code class=\"prism language-bash\">limit_req_zone <span class=\"token variable\">$binary_remote_addr</span> <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>ip_limit:10m <span class=\"token assign-left variable\">rate</span><span class=\"token operator\">=</span>10r/s<span class=\"token punctuation\">;</span>\n\nserver <span class=\"token punctuation\">{\n    <!-- --></span>\n    location /login/ <span class=\"token punctuation\">{\n    <!-- --></span>\n        limit_req <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>ip_limit<span class=\"token punctuation\">;</span>\n        proxy_pass http://login_upstream<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <ul>\n  <li>$binary_remote_addr 针对客户端ip限流；</li>\n  <li>zone=ip_limit:10m 限流规则名称为ip_limit，允许使用10MB的内存空间来记录ip对应的限流状态；</li>\n  <li>rate=10r/s 限流速度为每秒10次请求</li>\n  <li>location /login/ 对登录进行限流</li>\n </ul> \n <p>限流速度为每秒10次请求，如果有10次请求同时到达一个空闲的nginx，他们都能得到执行吗？</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/46b0ec8af1d1904ffc7d510cad095395.png\" alt=\"空桶\"></p> \n <p>漏桶漏出请求是匀速的。</p> \n <p>10r/s是怎样匀速的呢？每100ms漏出一个请求。</p> \n <p>在这样的配置下，桶是空的，所有不能实时漏出的请求，都会被拒绝掉。</p> \n <p>所以如果10次请求同时到达，那么只有一个请求能够得到执行，其它的，都会被拒绝。</p> \n <p>这不太友好，大部分业务场景下我们希望这10个请求都能得到执行。</p> \n <h5><a id=\"Burst_2268\"></a>Burst</h5> \n <p>我们把配置改一下，解决上一节的问题</p> \n <pre><code class=\"prism language-bash\">limit_req_zone <span class=\"token variable\">$binary_remote_addr</span> <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>ip_limit:10m <span class=\"token assign-left variable\">rate</span><span class=\"token operator\">=</span>10r/s<span class=\"token punctuation\">;</span>\n\nserver <span class=\"token punctuation\">{\n    <!-- --></span>\n    location /login/ <span class=\"token punctuation\">{\n    <!-- --></span>\n        limit_req <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>ip_limit <span class=\"token assign-left variable\">burst</span><span class=\"token operator\">=</span><span class=\"token number\">12</span><span class=\"token punctuation\">;</span>\n        proxy_pass http://login_upstream<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <ul>\n  <li>burst=12 漏桶的大小设置为12</li>\n </ul> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/baad0cf2ce345dee99effbc11b182e7d.png\" alt=\"Burst\"></p> \n <p>逻辑上叫漏桶，实现起来是FIFO队列，把得不到执行的请求暂时缓存起来。</p> \n <p>这样漏出的速度仍然是100ms一个请求，但并发而来，暂时得不到执行的请求，可以先缓存起来。只有当队列满了的时候，才会拒绝接受新请求。</p> \n <p>这样漏桶在限流的同时，也起到了削峰填谷的作用。</p> \n <p>在这样的配置下，如果有10次请求同时到达，它们会依次执行，每100ms执行1个。</p> \n <p>虽然得到执行了，但因为排队执行，延迟大大增加，在很多场景下仍然是不能接受的。</p> \n <h5><a id=\"NoDelay_2297\"></a>NoDelay</h5> \n <p>继续修改配置，解决Delay太久导致延迟增加的问题</p> \n <pre><code class=\"prism language-bash\">limit_req_zone <span class=\"token variable\">$binary_remote_addr</span> <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>ip_limit:10m <span class=\"token assign-left variable\">rate</span><span class=\"token operator\">=</span>10r/s<span class=\"token punctuation\">;</span>\n\nserver <span class=\"token punctuation\">{\n    <!-- --></span>\n    location /login/ <span class=\"token punctuation\">{\n    <!-- --></span>\n        limit_req <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>ip_limit <span class=\"token assign-left variable\">burst</span><span class=\"token operator\">=</span><span class=\"token number\">12</span> nodelay<span class=\"token punctuation\">;</span>\n        proxy_pass http://login_upstream<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>nodelay 把开始执行请求的时间提前，以前是delay到从桶里漏出来才执行，现在不delay了，只要入桶就开始执行</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/6b554fae6e4de96fb76314cc80c2c9a8.png\" alt=\"NoDelay\"></p> \n <p>要么立刻执行，要么被拒绝，请求不会因为限流而增加延迟了。</p> \n <p>因为请求从桶里漏出来还是匀速的，桶的空间又是固定的，最终平均下来，还是每秒执行了5次请求，限流的目的还是达到了。</p> \n <p>但这样也有缺点，限流是限了，但是限得不那么匀速。以上面的配置举例，如果有12个请求同时到达，那么这12个请求都能够立刻执行，然后后面的请求只能匀速进桶，100ms执行1个。如果有一段时间没有请求，桶空了，那么又可能出现并发的12个请求一起执行。</p> \n <p>大部分情况下，这种限流不匀速，不算是大问题。不过nginx也提供了一个参数才控制并发执行也就是nodelay的请求的数量。</p> \n <pre><code class=\"prism language-bash\">limit_req_zone <span class=\"token variable\">$binary_remote_addr</span> <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>ip_limit:10m <span class=\"token assign-left variable\">rate</span><span class=\"token operator\">=</span>10r/s<span class=\"token punctuation\">;</span>\n\nserver <span class=\"token punctuation\">{\n    <!-- --></span>\n    location /login/ <span class=\"token punctuation\">{\n    <!-- --></span>\n        limit_req <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>ip_limit <span class=\"token assign-left variable\">burst</span><span class=\"token operator\">=</span><span class=\"token number\">12</span> <span class=\"token assign-left variable\">delay</span><span class=\"token operator\">=</span><span class=\"token number\">4</span><span class=\"token punctuation\">;</span>\n        proxy_pass http://login_upstream<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>delay=4 从桶内第5个请求开始delay</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/48e8e36bf9e0b69a03666a247f3bb36a.png\" alt=\"DelayNum\"></p> \n <p>这样通过控制delay参数的值，可以调整允许并发执行的请求的数量，使得请求变的均匀起来，在有些耗资源的服务上控制这个数量，还是有必要的。</p> \n <p>控制速率 基本原理讲完了，</p> \n <p>接下来，开始 控制速率 限流 的基础配置</p> \n <h4><a id=\"11____2349\"></a>1.1 控制速率 限流 的基础配置：</h4> \n <p>基于客户端192.168.1.1进行限流，</p> \n <p>定义了一个大小为10M，名称为myLimit的内存区，用于存储IP地址访问信息。<br> rate设置IP访问频率，rate=5r/s表示每秒只能处理每个IP地址的5个请求。</p> \n <pre><code class=\"prism language-bash\">http <span class=\"token punctuation\">{\n    <!-- --></span>\n	limit_req_zone <span class=\"token number\">192.168</span>.1.1 <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>myLimit:10m <span class=\"token assign-left variable\">rate</span><span class=\"token operator\">=</span>5r/s<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\nserver <span class=\"token punctuation\">{\n    <!-- --></span>\n	location / <span class=\"token punctuation\">{\n    <!-- --></span>\n		limit_req <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>myLimit<span class=\"token punctuation\">;</span>\n		rewrite / http://www.hac.cn permanent<span class=\"token punctuation\">;</span>\n	<span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>参数解释：</p> \n <blockquote> \n  <p>limit_req_zone: 定义需要限流的对象。<br> zone: 定义共享内存区来存储访问信息。<br> rate: 用于设置最大访问速率。</p> \n </blockquote> \n <p>Nginx限流是按照毫秒级为单位的，也就是说1秒处理5个请求会变成每200ms只处理一个请求。如果200ms内已经处理完1个请求，但是还是有有新的请求到达，这时候Nginx就会拒绝处理该请求。</p> \n <h4><a id=\"12____2379\"></a>1.2 突发流量限制 访问频率</h4> \n <p>上面rate设置了 5r/s，</p> \n <p>如果有时候流量突然变大，超出的请求就被拒绝返回503了，突发的流量影响业务就不好了。</p> \n <p>这时候可以加上burst 参数，一般再结合 nodelay 一起使用。</p> \n <pre><code class=\"prism language-bash\">server <span class=\"token punctuation\">{\n    <!-- --></span>\n	location / <span class=\"token punctuation\">{\n    <!-- --></span>\n		limit_req <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>myLimit <span class=\"token assign-left variable\">burst</span><span class=\"token operator\">=</span><span class=\"token number\">20</span> nodelay<span class=\"token punctuation\">;</span>\n		rewrite / http://www.hac.cn permanent<span class=\"token punctuation\">;</span>\n	<span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>burst=20 nodelay 表示这20个请求立马处理，不能延迟，相当于特事特办。不过，即使这20个突发请求立马处理结束，后续来了请求也不会立马处理。</p> \n <p>burst=20 相当于缓存队列中占了20个坑，即使请求被处理了，这20个位置也只能按 100ms一个来释放。</p> \n <h3><a id=\"2_2402\"></a><strong>2、控制并发连接数</strong></h3> \n <p>ngx_http_limit_conn_module 提供了限制连接数功能。</p> \n <p>主要是利用limit_conn_zone和limit_conn两个指令。</p> \n <p>利用连接数限制 某一个用户的ip连接的数量来控制流量。</p> \n <pre><code class=\"prism language-bash\">limit_conn_zone <span class=\"token variable\">$binary_remote_addr</span> <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>perip:10m<span class=\"token punctuation\">;</span>\nlimit_conn_zone <span class=\"token variable\">$server_name</span> <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>perserver:10m<span class=\"token punctuation\">;</span> \n\nserver <span class=\"token punctuation\">{\n    <!-- --></span>  \n    listen       <span class=\"token number\">80</span><span class=\"token punctuation\">;</span>\n    server_name  localhost<span class=\"token punctuation\">;</span>\n    charset utf-8<span class=\"token punctuation\">;</span>\n    location / <span class=\"token punctuation\">{\n    <!-- --></span>\n        limit_conn perip <span class=\"token number\">10</span><span class=\"token punctuation\">;</span>      <span class=\"token comment\"># 单个客户端ip与服务器的连接数．</span>\n        limit_conn perserver <span class=\"token number\">100</span><span class=\"token punctuation\">;</span> ＃限制与服务器的总连接数\n        root   html<span class=\"token punctuation\">;</span>\n        index  index.html index.htm<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <blockquote> \n  <p>limit_conn perip 10 作用的key 是 $binary_remote_addr，表示限制单个IP同时最多能持有10个连接。<br> limit_conn perserver 100 作用的key是 $server_name，表示虚拟主机(server) 同时能处理并发连接的总数。</p> \n </blockquote> \n <h2><a id=\"nginxhttps_2434\"></a>聊聊：nginx如何配置https</h2> \n <pre><code class=\"prism language-bash\"><span class=\"token comment\">#server端基本配置 server {\n    <!-- --></span>\nlisten <span class=\"token number\">80</span><span class=\"token punctuation\">;</span>\nlisten <span class=\"token number\">443</span> ssl spdy<span class=\"token punctuation\">;</span>\nserver_name io.123.com<span class=\"token punctuation\">;</span>\ninclude   ssl/io.com<span class=\"token punctuation\">;</span>　　　　　　<span class=\"token comment\">#注意看下一个文件</span>\nlocation / <span class=\"token punctuation\">{\n    <!-- --></span>\nproxy_pass http:`<span class=\"token variable\"><span class=\"token variable\">`</span>//lb_io<span class=\"token punctuation\">;</span> <span class=\"token keyword\">if</span><span class=\"token variable\">`</span></span><span class=\"token variable\"><span class=\"token variable\">`</span><span class=\"token punctuation\">(</span>$scheme <span class=\"token operator\">=</span> http <span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n     <!-- --></span> <span class=\"token builtin class-name\">return</span><span class=\"token variable\">`</span></span><span class=\"token variable\"><span class=\"token variable\">`</span><span class=\"token number\">301</span> https:<span class=\"token variable\">`</span></span><span class=\"token variable\"><span class=\"token variable\">`</span>//$host$request_uri<span class=\"token punctuation\">;</span>　　　　<span class=\"token comment\">#此项配置为转换为https的基本配置</span> <span class=\"token punctuation\">}</span> proxy_set_header X-Real-IP $remote_addr<span class=\"token punctuation\">;</span> proxy_set_header Host $host<span class=\"token punctuation\">;</span> proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for<span class=\"token punctuation\">;</span> proxy_set_header X-Forwarded-Proto $scheme<span class=\"token punctuation\">;</span> proxy_http_version <span class=\"token number\">1.1</span><span class=\"token punctuation\">;</span> proxy_set_header Upgrade $http_upgrade<span class=\"token punctuation\">;</span> proxy_set_header Connection<span class=\"token variable\">`</span></span><span class=\"token variable\"><span class=\"token variable\">`</span>\"upgrade\"<span class=\"token variable\">`</span></span><span class=\"token variable\"><span class=\"token variable\">`</span><span class=\"token punctuation\">;</span> <span class=\"token punctuation\">}</span> access_log /data/logs/nginx/access/niuaero.log main<span class=\"token punctuation\">;</span> <span class=\"token punctuation\">}</span> ssl_certificate ssl/ca/io.com.pem<span class=\"token punctuation\">;</span>　　　　<span class=\"token comment\">#这个为购买的https证书，供应商会生成</span> ssl_certificate_key ssl/ca/io.com.key<span class=\"token punctuation\">;</span> ssl_session_timeout 5m<span class=\"token punctuation\">;</span> ssl_protocols TLSv1 TLSv1.1 TLSv1.2<span class=\"token punctuation\">;</span> <span class=\"token comment\">#启用TLS1.1、TLS1.2要求OpenSSL1.0.1及以上版本，若您的OpenSSL版本低于要求，请使用 ssl_protocols TLSv1;</span> ssl_ciphers HIGH:<span class=\"token operator\">!</span>RC4:<span class=\"token operator\">!</span>MD5:<span class=\"token operator\">!</span>aNULL:<span class=\"token operator\">!</span>eNULL:<span class=\"token operator\">!</span>NULL:<span class=\"token operator\">!</span>DH:<span class=\"token operator\">!</span>EDH:<span class=\"token operator\">!</span>EXP:+MEDIUM<span class=\"token punctuation\">;</span> ssl_prefer_server_ciphers <span class=\"token variable\">`</span></span><span class=\"token variable\"><span class=\"token variable\">`</span>on<span class=\"token variable\">`</span></span>`<span class=\"token punctuation\">;</span>\n\n</code></pre> \n <h2><a id=\"Nginx_2469\"></a>聊聊：Nginx常用优化配置</h2> \n <ol>\n  <li>调整worker_processes指定Nginx需要创建的worker进程数量，刚才有提到worker进程数一般设置为和CPU核心数一致。</li>\n  <li>调整worker_connections设置Nginx最多可以同时服务的客户端数。结合worker_processes配置可以获得每秒可以服务的最大客户端数。</li>\n  <li>启动gzip压缩，可以对文件大小进行压缩，减少了客户端http的传输带宽，可以大幅度提高页面的加载速度。</li>\n  <li>启用缓存，如果请求静态资源，启用缓存是可以大幅度提升性能的。</li>\n </ol> \n <h2><a id=\"Nginx_2478\"></a>聊聊：Nginx常见的优化配置有哪些？</h2> \n <p><strong>1、调整worker_processes</strong></p> \n <p>指Nginx要生成的worker数量,最佳实践是每个CPU运行1个工作进程。</p> \n <p>了解系统中的CPU核心数，输入</p> \n <pre><code class=\"prism language-bash\">$ <span class=\"token function\">grep</span> processor / proc / cpuinfo <span class=\"token operator\">|</span> <span class=\"token function\">wc</span> <span class=\"token parameter variable\">-l</span>\n</code></pre> \n <p><strong>2、最大化worker_connections</strong></p> \n <p>Nginx Web服务器可以同时提供服务的客户端数。与worker_processes结合使用时，获得每秒可以服务的最大客户端数</p> \n <pre><code>最大客户端数/秒=工作进程*工作者连接数\n</code></pre> \n <p>为了最大化Nginx的全部潜力，应将工作者连接设置为核心一次可以运行的允许的最大进程数1024。</p> \n <p><strong>3、启用Gzip压缩</strong></p> \n <p>压缩文件大小，减少了客户端http的传输带宽，因此提高了页面加载速度</p> \n <p>建议的gzip配置示例如下:( 在http部分内）</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/0ca5a7b7bdd1200ecdf0b32bbc54f9ea.png\" alt=\"\"></p> \n <p><strong>4、为静态文件启用缓存</strong></p> \n <p>为静态文件启用缓存，以减少带宽并提高性能，可以添加下面的命令，限定计算机缓存网页的静态文件：</p> \n <pre><code class=\"prism language-bash\">location ~* .<span class=\"token punctuation\">(</span>jpg<span class=\"token operator\">|</span>jpeg<span class=\"token operator\">|</span>png<span class=\"token operator\">|</span>gif<span class=\"token operator\">|</span>ico<span class=\"token operator\">|</span>css<span class=\"token operator\">|</span>js<span class=\"token punctuation\">)</span>$ <span class=\"token punctuation\">{\n    <!-- --></span>  \n    expires 365d<span class=\"token punctuation\">;</span>  \n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p><strong>5、Timeouts</strong></p> \n <p>keepalive连接减少了打开和关闭连接所需的CPU和网络开销，获得最佳性能需要调整的变量可参考：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/26084d9712acffd259ace46c39f3b4a9.png\" alt=\"\"></p> \n <p><strong>6、禁用access_logs</strong></p> \n <p>访问日志记录，它记录每个nginx请求，因此消耗了大量CPU资源，从而降低了nginx性能。</p> \n <p>完全禁用访问日志记录</p> \n <pre><code class=\"prism language-bash\">access_log off<span class=\"token punctuation\">;</span>\n</code></pre> \n <p>如果必须具有访问日志记录，则启用访问日志缓冲</p> \n <p>配置如下：</p> \n <pre><code class=\"prism language-bash\">access_log /var/log/nginx/access.log main <span class=\"token assign-left variable\">buffer</span><span class=\"token operator\">=</span>32k <span class=\"token assign-left variable\">flush</span><span class=\"token operator\">=</span>1m<span class=\"token punctuation\">;</span>\n</code></pre> \n <p>当系统处于负载状态时，启用日志缓冲区以降低 nginx worker 进程阻塞。</p> \n <p>大量的磁盘读写和 cpu 资源使用对于服务器资源也是一种巨大消耗。</p> \n <p>将日志数据缓冲到内存中可能是很小的一个优化手段， buffer 参数意义是缓冲区的大小，功能是当缓冲区已经写满时，日志会被写入文件中；</p> \n <p>flush 参数意义是缓冲区内日志在缓冲区内存中保存的最长时间，功能即当缓存中的日志超过最大缓存时间，也会被写入到文件中， 不足的地方即写入到日志文件的日志有些许延迟，即时调试中应当关闭日志缓冲。 。</p> \n <p><strong>7、指令定义错误日志目录及记录错误日志的等级</strong></p> \n <p>为了精确定位 nginx 的错误日志，使用自带的 error_log 指令定义错误日志目录及记录错误日志的等级，配置如下：</p> \n <p>Bash</p> \n <pre><code class=\"prism language-bash\">error_log /var/log/nginx/error.log warn<span class=\"token punctuation\">;</span>\n</code></pre> \n <p>error_log 指令配置时需要一个必选的日志目录和一个可选的错误等级选项。</p> \n <p>除 if 指令外， error_log 指令能在所有的上下文中使用。错误日志等级包括：</p> \n <p>debug、info、notice、warn、error、crit、alert 和 emerg。给出的日志</p> \n <p>等级顺序就是记录最小到最严谨的日志等级顺序。需要注意的是 debug 日志</p> \n <p>需要在编译 nginx 服务器时，带上 --with-debug 标识才能使用。</p> \n <p>当服务器配置出错时，首先需要查看错误日志以定位问题。错误日志</p> \n <p>也是定位应用服务器(如 FastCGI 服务)的利器。</p> \n <p>通过错误日志，我们可以调试 worker 进程连接错误、内存分配、客户端 IP 和 应用服务器等问题。</p> \n <p>错误日志格式不支持自定义日志格式 ；但他同样记录当前时间、日志等级和具体信息等数据。</p> \n <p>注意：错误日志的默认设置适用于全局。</p> \n <p>要覆盖它，请将 error_log 指令放在 main （顶级）配置上下文中。 error_log 在开源 NGINX 1.5.2 版中添加了在同一配置级别指定多个指令的功能。</p> \n <h2><a id=\"Nginx_2592\"></a>细致聊聊：如何进行Nginx的调优</h2> \n <p><strong>1、worker_processes的进程数，数量要与CPU数量一致，通过lscpu查看</strong></p> \n <pre><code class=\"prism language-sql\">worker_processes <span class=\"token number\">1</span><span class=\"token punctuation\">;</span> \n</code></pre> \n <p>2.1 worker process打开文件数的优化</p> \n <pre><code class=\"prism language-sql\">worker_rlimit_nofile <span class=\"token number\">65535</span><span class=\"token punctuation\">;</span>\n</code></pre> \n <p>2.2 优化了nginx的worker进程最多打开数量的参数之后，还需要优化系统内核参数（允许打开最多文件的参数）</p> \n <pre><code class=\"prism language-bash\">临时配置：\n<span class=\"token builtin class-name\">ulimit</span> <span class=\"token parameter variable\">-Hn</span> <span class=\"token number\">100000</span>\n<span class=\"token builtin class-name\">ulimit</span> <span class=\"token parameter variable\">-Sn</span> <span class=\"token number\">100000</span>     \n永久配置：\n<span class=\"token function\">vim</span> /etc/security/limits.conf\n* soft nofile <span class=\"token number\">100000</span>\n* hard nofile <span class=\"token number\">100000</span>\n</code></pre> \n <p><strong>3、单个进程最大连接数的优化</strong></p> \n <pre><code class=\"prism language-bash\">events <span class=\"token punctuation\">{\n    <!-- --></span>\n    worker_connections <span class=\"token number\">2048</span><span class=\"token punctuation\">;</span>\n    multi_accept on<span class=\"token punctuation\">;</span>\n    use epoll<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p><strong>4、隐藏版本信息的优化</strong></p> \n <pre><code class=\"prism language-bash\">server_tokens off<span class=\"token punctuation\">;</span>\n</code></pre> \n <p><strong>5、高效文件传输模式的</strong></p> \n <pre><code class=\"prism language-bash\">sendfile on<span class=\"token punctuation\">;</span>\ntcp_nopush on<span class=\"token punctuation\">;</span>\ntcp_nodelay on<span class=\"token punctuation\">;</span>\n</code></pre> \n <p><strong>6、访问日志关闭的优化</strong></p> \n <pre><code class=\"prism language-bash\">access_log off<span class=\"token punctuation\">;</span>\n</code></pre> \n <p><strong>7、超时时间的优化</strong></p> \n <pre><code class=\"prism language-bash\">keepalive_timeout <span class=\"token number\">10</span><span class=\"token punctuation\">;</span> //设置客户端保持活动状态的超时时间\nclient_header_timeout <span class=\"token number\">10</span><span class=\"token punctuation\">;</span> //客户端请求头读取超时时间\nclient_body_timeout <span class=\"token number\">10</span><span class=\"token punctuation\">;</span> //客户端请求体读取超时时间\nreset_timedout_connection on<span class=\"token punctuation\">;</span> //在客户端停止响应之后,允许服务器关闭连接,释放socket关联的内存\nsend_timeout <span class=\"token number\">10</span><span class=\"token punctuation\">;</span> //指定客户端的超时时间，如果在10s内客户端没有任何响应，nginx会自动断开连接\n</code></pre> \n <p><strong>8、gzip的优化</strong></p> \n <pre><code class=\"prism language-bash\"><span class=\"token function\">gzip</span> on<span class=\"token punctuation\">;</span>//开启压缩\ngzip_min_length <span class=\"token number\">1000</span><span class=\"token punctuation\">;</span>//小文件不压缩\ngzip_comp_level <span class=\"token number\">6</span><span class=\"token punctuation\">;</span>//压缩比例\ngzip_types text/plain text/css application/json application/x-javascript text/xml\napplication/xml application/xml+rss text/javascript<span class=\"token punctuation\">;</span>//对指定文件类型进行压缩\n</code></pre> \n <p><strong>9、缓存静态页面的优化 （文件句柄是打开文件的唯一标示）</strong></p> \n <pre><code class=\"prism language-bash\">open_file_cache <span class=\"token assign-left variable\">max</span><span class=\"token operator\">=</span><span class=\"token number\">100000</span> <span class=\"token assign-left variable\">inactive</span><span class=\"token operator\">=</span>20s<span class=\"token punctuation\">;</span> //设置服务器最大缓存10万个文件句柄，关闭20s内无请求的句柄\nopen_file_cache_valid 30s<span class=\"token punctuation\">;</span>//文件句柄的有效期为30s\nopen_file_cache_min_uses <span class=\"token number\">2</span><span class=\"token punctuation\">;</span>//最少打开2次才会被缓存\nopen_file_cache_errors on<span class=\"token punctuation\">;</span>\n</code></pre> \n <h2><a id=\"_2679\"></a>参考文献</h2> \n <p><a href=\"https://www.cnblogs.com/crazymakercircle/p/15187184.html\">限流：计数器、漏桶、令牌桶 三大算法的原理与实战（史上最全）</a></p> \n <h2><a id=\"_2686\"></a>推荐阅读：</h2> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128670335\">Docker面试题（史上最全 + 持续更新）</a>》<br> 《 <a href=\"https://blog.csdn.net/crazymakercircle/article/details/128533821\">场景题：假设10W人突访，你的系统如何做到不 雪崩？</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124790425\">尼恩Java面试宝典</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057567\">Springcloud gateway 底层原理、核心实战 (史上最全)</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124120506\">Flux、Mono、Reactor 实战（史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125059491\">sentinel （史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057545\">Nacos (史上最全)</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/123420859\">分库分表 Sharding-JDBC 底层原理、核心实战（史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/114527369\">TCP协议详解 (史上最全)</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126992542\">clickhouse 超底层原理 + 高可用实操 （史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120702536\">nacos高可用（图解+秒懂+史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264803\">队列之王： Disruptor 原理、架构、源码 一文穿透</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264508\">环形队列、 条带环形队列 Striped-RingBuffer （史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125135726\">一文搞定：SpringBoot、SLF4j、Log4j、Logback、Netty之间混乱关系（史上最全）</a><br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128265067\">单例模式（史上最全）</a><br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125017316\">红黑树（ 图解 + 秒懂 + 史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/109459593\">分布式事务 （秒懂）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128123114\">缓存之王：Caffeine 源码、架构、原理（史上最全，10W字 超级长文）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/113751575\">缓存之王：Caffeine 的使用（史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126579528\">Java Agent 探针、字节码增强 ByteBuddy（史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120747767\">Docker原理（图解+秒懂+史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/116425814\">Redis分布式锁（图解 - 秒懂 - 史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85956246\">Zookeeper 分布式锁 - 图解 - 秒懂</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85922561\">Zookeeper Curator 事件监听 - 10分钟看懂</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83957259\">Netty 粘包 拆包 | 史上最全解读</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83758107\">Netty 100万级高并发服务器配置</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/102557988\">Springcloud 高并发 配置 （一文全懂）</a>》</p> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 4693);
INSERT INTO `crawlerblog` VALUES (123124013, 'K8S面试题（史上最全 + 持续更新）', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <h2><a id=\"38K8S_0\"></a>尼恩面试宝典专题38：K8S面试题（史上最全、持续更新）</h2> \n <h4><a id=\"V26_1\"></a>本文版本说明：V26</h4> \n <h2><a id=\"_3\"></a>《尼恩面试宝典》升级规划为：</h2> \n <p>后续基本上，<strong>每一个月，都会发布一次</strong>，最新版本，可以联系构师尼恩获取， 发送 “领取电子书” 获取。</p> \n <h2><a id=\"k8s_9\"></a>什么是k8s？说出你的理解</h2> \n <p>K8s是kubernetes的简称，其本质是一个开源的容器编排系统，主要用于管理容器化的应用，</p> \n <p>其目标是让部署容器化的应用简单并且高效（powerful）,Kubernetes提供了应用部署，规划，更新，维护的一种机制。</p> \n <p>说简单点：k8s就是一个编排容器的系统，一个可以管理容器应用全生命周期的工具，从创建应用，应用的部署，应用提供服务，扩容缩容应用，应用更新，都非常的方便，而且还可以做到故障自愈，</p> \n <p>所以，k8s是一个非常强大的容器编排系统。</p> \n <h2><a id=\"k8s_21\"></a>k8s的组件有哪些，作用分别是什么？</h2> \n <p>k8s主要由master节点和node节点构成。</p> \n <p>master节点负责管理集群，node节点是容器应用真正运行的地方。</p> \n <p>master节点包含的组件有：kube-api-server、kube-controller-manager、kube-scheduler、etcd。</p> \n <p>node节点包含的组件有：kubelet、kube-proxy、container-runtime。</p> \n <p><strong>kube-api-server：</strong></p> \n <p>以下简称api-server，api-server是k8s最重要的核心组件之一，它是k8s集群管理的统一访问入口，提供了RESTful API接口, 实现了认证、授权和准入控制等安全功能；api-server还是其他组件之间的数据交互和通信的枢纽，其他组件彼此之间并不会直接通信，其他组件对资源对象的增、删、改、查和监听操作都是交由api-server处理后，api-server再提交给etcd数据库做持久化存储，只有api-server才能直接操作etcd数据库，其他组件都不能直接操作etcd数据库，其他组件都是通过api-server间接的读取，写入数据到etcd。</p> \n <p><strong>kube-controller-manager：</strong></p> \n <p>以下简称controller-manager，controller-manager是k8s中各种控制器的的管理者，是k8s集群内部的管理控制中心，也是k8s自动化功能的核心；controller-manager内部包含replication controller、node controller、deployment controller、endpoint controller等各种资源对象的控制器，每种控制器都负责一种特定资源的控制流程，而controller-manager正是这些controller的核心管理者。</p> \n <p><strong>kube-scheduler：</strong></p> \n <p>以下简称scheduler，scheduler负责集群资源调度，其作用是将待调度的pod通过一系列复杂的调度算法计算出最合适的node节点，然后将pod绑定到目标节点上。shceduler会根据pod的信息，全部节点信息列表，过滤掉不符合要求的节点，过滤出一批候选节点，然后给候选节点打分，选分最高的就是最佳节点，scheduler就会把目标pod安置到该节点。</p> \n <p><strong>Etcd：</strong></p> \n <p>etcd是一个分布式的键值对存储数据库，主要是用于保存k8s集群状态数据，比如，pod，service等资源对象的信息；etcd可以是单个也可以有多个，多个就是etcd数据库集群，etcd通常部署奇数个实例，在大规模集群中，etcd有5个或7个节点就足够了；另外说明一点，etcd本质上可以不与master节点部署在一起，只要master节点能通过网络连接etcd数据库即可。</p> \n <p><strong>kubelet：</strong></p> \n <p>每个node节点上都有一个kubelet服务进程，kubelet作为连接master和各node之间的桥梁，负责维护pod和容器的生命周期，当监听到master下发到本节点的任务时，比如创建、更新、终止pod等任务，kubelet 即通过控制docker来创建、更新、销毁容器；<br> 每个kubelet进程都会在api-server上注册本节点自身的信息，用于定期向master汇报本节点资源的使用情况。</p> \n <p><strong>kube-proxy：</strong></p> \n <p>kube-proxy运行在node节点上，在Node节点上实现Pod网络代理，维护网络规则和四层负载均衡工作，kube-proxy会监听api-server中从而获取service和endpoint的变化情况，创建并维护路由规则以提供服务IP和负载均衡功能。简单理解此进程是Service的透明代理兼负载均衡器，其核心功能是将到某个Service的访问请求转发到后端的多个Pod实例上。</p> \n <p>container-runtime：容器运行时环境，即运行容器所需要的一系列程序，目前k8s支持的容器运行时有很多，如docker、rkt或其他，比较受欢迎的是docker，但是新版的k8s已经宣布弃用docker。</p> \n <h2><a id=\"Kubernetes_60\"></a>简述Kubernetes相关基础概念?</h2> \n <p>答：</p> \n <p><strong>master：</strong></p> \n <p>k8s集群的管理节点，负责管理集群，提供集群的资源数据访问入口。拥有Etcd存储服务（可选），运行Api Server进程，Controller Manager服务进程及Scheduler服务进程；</p> \n <p><strong>node（worker）：</strong></p> \n <p>Node（worker）是Kubernetes集群架构中运行Pod的服务节点，是Kubernetes集群操作的单元，用来承载被分配Pod的运行，是Pod运行的宿主机。运行docker eninge服务，守护进程kunelet及负载均衡器kube-proxy；</p> \n <p><strong>pod：</strong></p> \n <p>运行于Node节点上，若干相关容器的组合。Pod内包含的容器运行在同一宿主机上，使用相同的网络命名空间、IP地址和端口，能够通过localhost进行通信。Pod是Kurbernetes进行创建、调度和管理的最小单位，它提供了比容器更高层次的抽象，使得部署和管理更加灵活。一个Pod可以包含一个容器或者多个相关容器；</p> \n <p><strong>label：</strong></p> \n <p>Kubernetes中的Label实质是一系列的Key/Value键值对，其中key与value可自定义。Label可以附加到各种资源对象上，如Node、Pod、Service、RC等。一个资源对象可以定义任意数量的Label，同一个Label也可以被添加到任意数量的资源对象上去。Kubernetes通过Label Selector（标签选择器）查询和筛选资源对象；</p> \n <p><strong>Replication Controller：</strong></p> \n <p>Replication Controller用来管理Pod的副本，保证集群中存在指定数量的Pod副本。</p> \n <p>集群中副本的数量大于指定数量，则会停止指定数量之外的多余容器数量。反之，则会启动少于指定数量个数的容器，保证数量不变。</p> \n <p>Replication Controller是实现弹性伸缩、动态扩容和滚动升级的核心；</p> \n <p><strong>Deployment：</strong></p> \n <p>Deployment在内部使用了RS来实现目的，Deployment相当于RC的一次升级，其最大的特色为可以随时获知当前Pod的部署进度；</p> \n <p><strong>HPA（Horizontal Pod Autoscaler）：</strong></p> \n <p>Pod的横向自动扩容，也是Kubernetes的一种资源，通过追踪分析RC控制的所有Pod目标的负载变化情况，来确定是否需要针对性的调整Pod副本数量；</p> \n <p><strong>Service：</strong></p> \n <p>Service定义了Pod的逻辑集合和访问该集合的策略，是真实服务的抽象。</p> \n <p>Service提供了一个统一的服务访问入口以及服务代理和发现机制，关联多个相同Label的Pod，用户不需要了解后台Pod是如何运行；</p> \n <p><strong>Volume：</strong></p> \n <p>Volume是Pod中能够被多个容器访问的共享目录，Kubernetes中的Volume是定义在Pod上，可以被一个或多个Pod中的容器挂载到某个目录下；</p> \n <p><strong>Namespace：</strong></p> \n <p>Namespace用于实现多租户的资源隔离，可将集群内部的资源对象分配到不同的Namespace中，形成逻辑上的不同项目、小组或用户组，便于不同的Namespace在共享使用整个集群的资源的同时还能被分别管理；</p> \n <h2><a id=\"KubernetesDocker_110\"></a>简述Kubernetes和Docker的关系?</h2> \n <p>答：</p> \n <p>Docker开源的容器引擎，一种更加轻量级的虚拟化技术；</p> \n <p>K8s，容器管理工具，用来管理容器pod的集合，它可以实现容器集群的自动化部署、自动扩缩容、维护等功能；</p> \n <h2><a id=\"Kubernetes_124\"></a>简述Kubernetes如何实现集群管理?</h2> \n <p>答：在集群管理方面，Kubernetes将集群中的机器划分为一个Master节点和一群工作节点Node。</p> \n <p>其中，在Master节点运行着集群管理相关的一组进程kube-apiserver、kube-controller-manager和kube-scheduler，这些进程实现了整个集群的资源管理、Pod调度、弹性伸缩、安全控制、系统监控和纠错等管理能力，并且都是全自动完成的；</p> \n <h2><a id=\"Kubernetes_134\"></a>简述Kubernetes的优势、适应场景及其特点?</h2> \n <p>答：</p> \n <p>优势：容器编排、轻量级、开源、弹性伸缩、负载均衡；</p> \n <p>场景：快速部署应用、快速扩展应用、无缝对接新的应用功能、节省资源，优化硬件资源的使用；</p> \n <p>特点：</p> \n <p>可移植: 支持公有云、私有云、混合云、多重云（multi-cloud）、</p> \n <p>可扩展: 模块化,、插件化、可挂载、可组合、</p> \n <p>自动化: 自动部署、自动重启、自动复制、自动伸缩/扩展；</p> \n <h2><a id=\"Kubernetes_154\"></a>简述Kubernetes的缺点或当前的不足之处?</h2> \n <p>​ 答：</p> \n <p>安装过程和配置相对困难复杂、管理服务相对繁琐、运行和编译需要很多时间、它比其他替代品更昂贵、对于简单的应用程序来说，可能不需要涉及Kubernetes即可满足；</p> \n <h2><a id=\"KubernetesMinikubeKubectlKubelet_160\"></a>简述Kubernetes中什么是Minikube、Kubectl、Kubelet?</h2> \n <p>答：</p> \n <p>Minikube 是一种可以在本地轻松运行一个单节点 Kubernetes 群集的工具；</p> \n <p>Kubectl 是一个命令行工具，可以使用该工具控制Kubernetes集群管理器，如检查群集资源，创建、删除和更新组件，查看应用程序；</p> \n <p>Kubelet 是一个代理服务，它在每个节点上运行，并使从服务器与主服务器通信；</p> \n <h2><a id=\"kubelet_172\"></a>kubelet的功能、作用是什么？（重点，经常会问）</h2> \n <p>答：kubelet部署在每个node节点上的，它主要有4个功能：<br> 1、节点管理。</p> \n <p>kubelet启动时会向api-server进行注册，然后会定时的向api-server汇报本节点信息状态，资源使用状态等，这样master就能够知道node节点的资源剩余，节点是否失联等等相关的信息了。master知道了整个集群所有节点的资源情况，这对于 pod 的调度和正常运行至关重要。<br> 2、pod管理。</p> \n <p>kubelet负责维护node节点上pod的生命周期，当kubelet监听到master的下发到自己节点的任务时，比如要创建、更新、删除一个pod，kubelet 就会通过CRI（容器运行时接口）插件来调用不同的容器运行时来创建、更新、删除容器；常见的容器运行时有docker、containerd、rkt等等这些容器运行时，我们最熟悉的就是docker了，但在新版本的k8s已经弃用docker了，k8s1.24版本中已经使用containerd作为容器运行时了。</p> \n <p>3、容器健康检查。</p> \n <p>pod中可以定义启动探针、存活探针、就绪探针等3种，我们最常用的就是存活探针、就绪探针，kubelet 会定期调用容器中的探针来检测容器是否存活，是否就绪，如果是存活探针，则会根据探测结果对检查失败的容器进行相应的重启策略；</p> \n <p>4、Metrics Server资源监控。</p> \n <p>在node节点上部署Metrics Server用于监控node节点、pod的CPU、内存、文件系统、网络使用等资源使用情况，而kubelet则通过Metrics Server获取所在节点及容器的上的数据。</p> \n <h2><a id=\"kubeapiserverpodkubeapiserver_190\"></a>kube-api-server的端口是多少？各个pod是如何访问kube-api-server的？</h2> \n <p>kube-api-server的端口是8080和6443，前者是http的端口，后者是https的端口，以我本机使用kubeadm安装的k8s为例：</p> \n <p>在命名空间的kube-system命名空间里，有一个名称为kube-api-master的pod，</p> \n <p>这个pod就是运行着kube-api-server进程，它绑定了master主机的ip地址和6443端口，但是在default命名空间下，存在一个叫kubernetes的服务，该服务对外暴露端口为443，目标端口6443，</p> \n <p>这个服务的ip地址是clusterip地址池里面的第一个地址，同时这个服务的yaml定义里面并没有指定标签选择器，</p> \n <p>也就是说这个kubernetes服务所对应的endpoint是手动创建的，该endpoint也是名称叫做kubernetes，该endpoint的yaml定义里面代理到master节点的6443端口，也就是kube-api-server的IP和端口。</p> \n <p>这样一来，其他pod访问kube-api-server的整个流程就是：pod创建后嵌入了环境变量，pod获取到了kubernetes这个服务的ip和443端口，请求到kubernetes这个服务其实就是转发到了master节点上的6443端口的kube-api-server这个pod里面。</p> \n <h2><a id=\"k8s_206\"></a>k8s中命名空间的作用是什么？</h2> \n <p>amespace是kubernetes系统中的一种非常重要的资源，namespace的主要作用是用来实现多套环境的资源隔离，或者说是多租户的资源隔离。</p> \n <p>k8s通过将集群内部的资源分配到不同的namespace中，可以形成逻辑上的隔离，以方便不同的资源进行隔离使用和管理。</p> \n <p>不同的命名空间可以存在同名的资源，命名空间为资源提供了一个作用域。</p> \n <p>可以通过k8s的授权机制，将不同的namespace交给不同的租户进行管理，这样就实现了多租户的资源隔离，还可以结合k8s的资源配额机制，限定不同的租户能占用的资源，例如CPU使用量、内存使用量等等来实现租户可用资源的管理。</p> \n <h2><a id=\"k8sRESTKubernetes_Proxy_APIProxy_218\"></a>k8s提供了大量的REST接口，其中有一个是Kubernetes Proxy API接口，简述一下这个Proxy接口的作用，已经怎么使用。</h2> \n <p>kubernetes proxy api接口，从名称中可以得知，proxy是代理的意思，其作用就是代理rest请求；</p> \n <p>Kubernets API server 将接收到的rest请求转发到某个node上的kubelet守护进程的rest接口，由该kubelet进程负责响应。</p> \n <p>我们可以使用这种Proxy接口来直接访问某个pod，这对于逐一排查pod异常问题很有帮助。<br> 下面是一些简单的例子：</p> \n <pre><code class=\"prism language-bash\">http://<span class=\"token operator\">&lt;</span>kube-api-server<span class=\"token operator\">&gt;</span>:<span class=\"token operator\">&lt;</span>api-sever-port<span class=\"token operator\">&gt;</span>/api/v1/nodes/node名称/proxy/pods  	<span class=\"token comment\">#查看指定node的所有pod信息</span>\nhttp://<span class=\"token operator\">&lt;</span>kube-api-server<span class=\"token operator\">&gt;</span>:<span class=\"token operator\">&lt;</span>api-sever-port<span class=\"token operator\">&gt;</span>/api/v1/nodes/node名称/proxy/stats  	<span class=\"token comment\">#查看指定node的物理资源统计信息</span>\nhttp://<span class=\"token operator\">&lt;</span>kube-api-server<span class=\"token operator\">&gt;</span>:<span class=\"token operator\">&lt;</span>api-sever-port<span class=\"token operator\">&gt;</span>/api/v1/nodes/node名称/proxy/spec  	<span class=\"token comment\">#查看指定node的概要信息</span>\n\nhttp://<span class=\"token operator\">&lt;</span>kube-api-server<span class=\"token operator\">&gt;</span>:<span class=\"token operator\">&lt;</span>api-sever-port<span class=\"token operator\">&gt;</span>/api/v1/namespace/命名名称/pods/pod名称/pod服务的url/  	<span class=\"token comment\">#访问指定pod的程序页面</span>\nhttp://<span class=\"token operator\">&lt;</span>kube-api-server<span class=\"token operator\">&gt;</span>:<span class=\"token operator\">&lt;</span>api-sever-port<span class=\"token operator\">&gt;</span>/api/v1/namespace/命名名称/servers/svc名称/url/  	<span class=\"token comment\">#访问指定server的url程序页面</span>\n\n</code></pre> \n <h2><a id=\"pod_239\"></a>pod是什么？</h2> \n <p>在kubernetes的世界中，k8s并不直接处理容器，而是使用多个容器共存的理念，这组容器就叫做pod。</p> \n <p>pod是k8s中可以创建和管理的最小单元，是资源对象模型中由用户创建或部署的最小资源对象模型，其他的资源对象都是用来支撑pod对象功能的，比如，pod控制器就是用来管理pod对象的，service或者imgress资源对象是用来暴露pod引用对象的，persistentvolume资源是用来为pod提供存储等等，</p> \n <p>简而言之，k8s不会直接处理容器，而是pod，pod才是k8s中可以创建和管理的最小单元，也是基本单元。</p> \n <h2><a id=\"pod_247\"></a>pod的原理是什么？</h2> \n <p>在微服务的概念里，一般的，一个容器会被设计为运行一个进程，除非进程本身产生子进程，</p> \n <p>这样，由于不能将多个进程聚集在同一个单独的容器中，所以需要一种更高级的结构将容器绑定在一起，并将它们作为一个单元进行管理，这就是k8s中pod的背后原理。</p> \n <h2><a id=\"pod_253\"></a>pod有什么特点？</h2> \n <p>1、每个pod就像一个独立的逻辑机器，k8s会为每个pod分配一个集群内部唯一的IP地址，所以每个pod都拥有自己的IP地址、主机名、进程等；<br> 2、一个pod可以包含1个或多个容器，1个容器一般被设计成只运行1个进程，1个pod只可能运行在单个节点上，即不可能1个pod跨节点运行，pod的生命周期是短暂，也就是说pod可能随时被消亡（如节点异常，pod异常等情况）；<br> 2、每一个pod都有一个特殊的被称为\"根容器\"的pause容器，也称info容器，pause容器对应的镜像属于k8s平台的一部分，除了pause容器，每个pod还包含一个或多个跑业务相关组件的应用容器；<br> 3、一个pod中的容器共享network命名空间；<br> 4、一个pod里的多个容器共享pod IP，这就意味着1个pod里面的多个容器的进程所占用的端口不能相同，否则在这个pod里面就会产生端口冲突；既然每个pod都有自己的IP和端口空间，那么对不同的两个pod来说就不可能存在端口冲突；<br> 5、应该将应用程序组织到多个pod中，而每个pod只包含紧密相关的组件或进程；<br> 6、pod是k8s中扩容、缩容的基本单位，也就是说k8s中扩容缩容是针对pod而言而非容器。</p> \n <h2><a id=\"pod_265\"></a>pod的重启策略有哪些？</h2> \n <p>pod重启容器策略是指针对pod内所有容器的重启策略，不是重启pod，其可以通过restartPolicy字段配置pod重启容器的策略，如下：</p> \n <ul>\n  <li> <p>Always: 当容器终止退出后，总是重启容器，默认策略就是Always。</p> </li>\n  <li> <p>OnFailure: 当容器异常退出，退出状态码非0时，才重启容器。</p> </li>\n  <li> <p>Never: 当容器终止退出，不管退出状态码是什么，从不重启容器。</p> </li>\n </ul> \n <h2><a id=\"pod_274\"></a>pod的镜像拉取策略有哪几种？</h2> \n <p>pod镜像拉取策略可以通过imagePullPolicy字段配置镜像拉取策略，</p> \n <p>主要有3中镜像拉取策略，如下：</p> \n <ul>\n  <li>IfNotPresent: 默认值，镜像在node节点宿主机上不存在时才拉取。</li>\n  <li>Always: 总是重新拉取，即每次创建pod都会重新从镜像仓库拉取一次镜像。</li>\n  <li>Never: 永远不会主动拉取镜像，仅使用本地镜像，需要你手动拉取镜像到node节点，如果node节点不存在镜像则pod启动失败。</li>\n </ul> \n <h2><a id=\"kubenetespod3_288\"></a>kubenetes针对pod资源对象的健康监测机制?（必须记住3重探测方式，重点，经常问）</h2> \n <p>提供了三类probe（探针）来执行对pod的健康监测：</p> \n <ul>\n  <li>livenessProbe探针 （存活探针）:</li>\n </ul> \n <p>可以根据用户自定义规则来判定pod是否健康，用于判断容器是否处于Running状态，</p> \n <p>如果不是，kubelet就会杀掉该容器，并根据重启策略做相应的处理。如果容器不包含该探针，那么kubelet就会默认返回值都是success;</p> \n <ul>\n  <li>ReadinessProbe探针:</li>\n </ul> \n <p>同样是可以根据用户自定义规则来判断pod是否健康，容器服务是否可用（Ready），如果探测失败，控制器会将此pod从对应service的endpoint列表中移除，从此不再将任何请求调度到此Pod上，直到下次探测成功;</p> \n <ul>\n  <li>startupProbe探针:</li>\n </ul> \n <p>启动检查机制，应用一些启动缓慢的业务，避免业务长时间启动而被上面两类探针kill掉，</p> \n <p>这个问题也可以换另一种方式解决，就是定义上面两类探针机制时，初始化时间定义的长一些即可;</p> \n <p>备注：每种探测方法能支持以下几个相同的检查参数，用于设置控制检查时间：</p> \n <ul>\n  <li> <p>initialDelaySeconds：初始第一次探测间隔，用于应用启动的时间，防止应用还没启动而健康检查失败；</p> </li>\n  <li> <p>periodSeconds：检查间隔，多久执行probe检查，默认为10s；</p> </li>\n  <li> <p>timeoutSeconds：检查超时时长，探测应用timeout后为失败；</p> </li>\n  <li> <p>successThreshold：成功探测阈值，表示探测多少次为健康正常，默认探测1次。</p> </li>\n </ul> \n <h2><a id=\"ReadinessProbelivenessProbe_322\"></a>就绪探针（ReadinessProbe探针）与存活探针（livenessProbe探针）区别是什么？</h2> \n <p>两者作用不一样，</p> \n <p>存活探针是将检查失败的容器杀死，创建新的启动容器来保持pod正常工作；</p> \n <p>就绪探针是，当就绪探针检查失败，并不重启容器，而是将pod移出endpoint，就绪探针确保了service中的pod都是可用的，确保客户端只与正常的pod交互并且客户端永远不会知道系统存在问题。</p> \n <h2><a id=\"_334\"></a>存活探针的属性参数有哪几个？</h2> \n <p>存活探针的附加属性参数有以下几个：</p> \n <ul>\n  <li> <p>initialDelaySeconds：表示在容器启动后延时多久秒才开始探测；</p> </li>\n  <li> <p>periodSeconds：表示执行探测的频率，即间隔多少秒探测一次，默认间隔周期是10秒，最小1秒；</p> </li>\n  <li> <p>timeoutSeconds：表示探测超时时间，默认1秒，最小1秒，表示容器必须在超时时间范围内做出响应，否则视为本次探测失败；</p> </li>\n  <li> <p>successThreshold：表示最少连续探测成功多少次才被认定为成功，默认是1，对于liveness必须是1，最小值是1；</p> </li>\n  <li> <p>failureThreshold：表示连续探测失败多少次才被认定为失败，默认是3，连续3次失败，k8s 将根据pod重启策略对容器做出决定；</p> </li>\n </ul> \n <p>注意：定义存活探针时，一定要设置initialDelaySeconds属性，该属性为初始延时，如果不设置，默认容器启动时探针就开始探测了，这样可能会存在<br> 应用程序还未启动就绪，就会导致探针检测失败，k8s就会根据pod重启策略杀掉容器然后再重新创建容器的莫名其妙的问题。<br> 在生产环境中，一定要定义一个存活探针。</p> \n <h2><a id=\"pod_354\"></a>pod的就绪探针有哪几种？</h2> \n <p>我们知道，当一个pod启动后，就会立即加入service的endpoint ip列表中，并开始接收到客户端的链接请求，</p> \n <p>假若此时pod中的容器的业务进程还没有初始化完毕，那么这些客户端链接请求就会失败，为了解决这个问题，kubernetes提供了就绪探针来解决这个问题的。</p> \n <p>在pod中的容器定义一个就绪探针，就绪探针周期性检查容器，</p> \n <p>如果就绪探针检查失败了，说明该pod还未准备就绪，不能接受客户端链接，则该pod将从endpoint列表中移除，</p> \n <p>pod被剔除了, service就不会把请求分发给该pod，</p> \n <p>然后就绪探针继续检查，如果随后容器就绪，则再重新把pod加回endpoint列表。</p> \n <p>kubernetes提供了3种探测容器的存活探针，如下：</p> \n <ul>\n  <li> <p>httpGet：通过容器的IP、端口、路径发送http 请求，返回200-400范围内的状态码表示成功。</p> </li>\n  <li> <p>exec：在容器内执行shell命令，根据命令退出状态码是否为0进行判断，0表示健康，非0表示不健康。</p> </li>\n  <li> <p>TCPSocket：与容器的IP、端口建立TCP Socket链接，能建立则说明探测成功，不能建立则说明探测失败</p> </li>\n </ul> \n <h2><a id=\"pod_378\"></a>pod的就绪探针的属性参数有哪些</h2> \n <p>就绪探针的附加属性参数有以下几个：</p> \n <ul>\n  <li> <p>initialDelaySeconds：延时秒数，即容器启动多少秒后才开始探测，不写默认容器启动就探测；</p> </li>\n  <li> <p>periodSeconds ：执行探测的频率（秒），默认为10秒，最低值为1；</p> </li>\n  <li> <p>timeoutSeconds ：超时时间，表示探测时在超时时间内必须得到响应，负责视为本次探测失败，默认为1秒，最小值为1；</p> </li>\n  <li> <p>failureThreshold ：连续探测失败的次数，视为本次探测失败，默认为3次，最小值为1次；</p> </li>\n  <li> <p>successThreshold ：连续探测成功的次数，视为本次探测成功，默认为1次，最小值为1次；</p> </li>\n </ul> \n <h2><a id=\"pod_398\"></a>pod的重启策略是什么？</h2> \n <p>答：通过命令“<a href=\"https://so.csdn.net/so/search?q=kubectl&amp;spm=1001.2101.3001.7020\">kubectl</a> explain pod.spec”查看pod的重启策略;</p> \n <ul>\n  <li> <p>Always：但凡pod对象终止就重启，此为默认策略;</p> </li>\n  <li> <p>OnFailure：仅在pod对象出现错误时才重启;</p> </li>\n </ul> \n <h2><a id=\"_pod_410\"></a>简单讲一下 pod创建过程</h2> \n <p>情况一、使用kubectl run命令创建的pod：</p> \n <pre><code>注意：\nkubectl run 在旧版本中创建的是deployment，\n但在新的版本中创建的是pod则其创建过程不涉及deployment\n</code></pre> \n <p>如果是单独的创建一个pod，则其创建过程是这样的：<br> 1、首先，用户通过kubectl或其他api客户端工具提交需要创建的pod信息给apiserver；<br> 2、apiserver验证客户端的用户权限信息，验证通过开始处理创建请求生成pod对象信息，并将信息存入etcd，然后返回确认信息给客户端；<br> 3、apiserver开始反馈etcd中pod对象的变化，其他组件使用watch机制跟踪apiserver上的变动；<br> 4、scheduler发现有新的pod对象要创建，开始调用内部算法机制为pod分配最佳的主机，并将结果信息更新至apiserver；<br> 5、node节点上的kubelet通过watch机制跟踪apiserver发现有pod调度到本节点，尝试调用docker启动容器，并将结果反馈apiserver；<br> 6、apiserver将收到的pod状态信息存入etcd中。<br> 至此，整个pod创建完毕。</p> \n <p>情况二、使用deployment来创建pod：</p> \n <p>1、首先，用户使用kubectl create命令或者kubectl apply命令提交了要创建一个deployment资源请求；<br> 2、api-server收到创建资源的请求后，会对客户端操作进行身份认证，在客户端的~/.kube文件夹下，已经设置好了相关的用户认证信息，这样api-server会知道我是哪个用户，并对此用户进行鉴权，当api-server确定客户端的请求合法后，就会接受本次操作，并把相关的信息保存到etcd中，然后返回确认信息给客户端。<br> 3、apiserver开始反馈etcd中过程创建的对象的变化，其他组件使用watch机制跟踪apiserver上的变动。<br> 4、controller-manager组件会监听api-server的信息，controller-manager是有多个类型的，比如Deployment Controller, 它的作用就是负责监听Deployment，此时Deployment Controller发现有新的deployment要创建，那么它就会去创建一个ReplicaSet，一个ReplicaSet的产生，又被另一个叫做ReplicaSet Controller监听到了，紧接着它就会去分析ReplicaSet的语义，它了解到是要依照ReplicaSet的template去创建Pod, 它一看这个Pod并不存在，那么就新建此Pod，当Pod刚被创建时，它的nodeName属性值为空，代表着此Pod未被调度。<br> 5、调度器Scheduler组件开始介入工作，Scheduler也是通过watch机制跟踪apiserver上的变动，发现有未调度的Pod，则根据内部算法、节点资源情况，pod定义的亲和性反亲和性等等，调度器会综合的选出一批候选节点，在候选节点中选择一个最优的节点，然后将pod绑定该该节点，将信息反馈给api-server。<br> 6、kubelet组件布署于Node之上，它也是通过watch机制跟踪apiserver上的变动，监听到有一个Pod应该要被调度到自身所在Node上来，kubelet首先判断本地是否在此Pod，如果不存在，则会进入创建Pod流程，创建Pod有分为几种情况，第一种是容器不需要挂载外部存储，则相当于直接docker run把容器启动，但不会直接挂载docker网络，而是通过CNI调用网络插件配置容器网络，如果需要挂载外部存储，则还要调用CSI来挂载存储。kubelet创建完pod，将信息反馈给api-server，api-servier将pod信息写入etcd。<br> 7、Pod建立成功后，ReplicaSet Controller会对其持续进行关注，如果Pod因意外或被我们手动退出，ReplicaSet Controller会知道，并创建新的Pod，以保持replicas数量期望值。</p> \n <h2><a id=\"k8s_pod_443\"></a>k8s 创建一个pod的详细流程，涉及的组件怎么通信的？</h2> \n <p>答：</p> \n <p>1）客户端提交创建请求，可以通过 api-server 提供的 restful 接口，或者是通过 kubectl 命令行工具，支持的数据类型包括 JSON 和 YAML；</p> \n <p>2）api-server 处理用户请求，将 pod 信息存储至 etcd 中；</p> \n <p>3）kube-scheduler 通过 api-server 提供的接口监控到未绑定的 pod，尝试为 pod 分配 node 节点，主要分为两个阶段，预选阶段和优选阶段，其中预选阶段是遍历所有的 node 节点，根据策略筛选出候选节点，而优选阶段是在第一步的基础上，为每一个候选节点进行打分，分数最高者胜出；</p> \n <p>4）选择分数最高的节点，进行 pod binding 操作，并将结果存储至 etcd 中；</p> \n <p>5）随后目标节点的 kubelet 进程通过 api-server 提供的接口监测到 kube-scheduler 产生的 pod 绑定事件，然后从 etcd 获取 pod 清单，下载镜像并启动容器；</p> \n <h2><a id=\"pod_461\"></a>简单描述一下pod的终止过程</h2> \n <p>1、用户向apiserver发送删除pod对象的命令；<br> 2、apiserver中的pod对象信息会随着时间的推移而更新，在宽限期内（默认30s），pod被视为dead；<br> 3、将pod标记为terminating状态；<br> 4、kubectl在监控到pod对象为terminating状态了就会启动pod关闭过程；<br> 5、endpoint控制器监控到pod对象的关闭行为时将其从所有匹配到此endpoint的server资源endpoint列表中删除；<br> 6、如果当前pod对象定义了preStop钩子处理器，则在其被标记为terminating后会意同步的方式启动执行；<br> 7、pod对象中的容器进程收到停止信息；<br> 8、宽限期结束后，若pod中还存在运行的进程，那么pod对象会收到立即终止的信息；<br> 9、kubelet请求apiserver将此pod资源的宽限期设置为0从而完成删除操作，此时pod对用户已不可见。</p> \n <h2><a id=\"pod_473\"></a>pod的生命周期有哪几种？</h2> \n <p>pod生命周期有的5种状态（也称5种相位），如下：</p> \n <ul>\n  <li> <p>Pending（挂起）：API server已经创建pod，但是该pod还有一个或多个容器的镜像没有创建，包括正在下载镜像的过程；</p> </li>\n  <li> <p>Running（运行中）：Pod内所有的容器已经创建，且至少有一个容器处于运行状态、正在启动括正在重启状态；</p> </li>\n  <li> <p>Succeed（成功）：Pod内所有容器均已退出，且不会再重启；</p> </li>\n  <li> <p>Failed（失败）：Pod内所有容器均已退出，且至少有一个容器为退出失败状态</p> </li>\n  <li> <p>Unknown（未知）：某于某种原因apiserver无法获取该pod的状态，可能由于网络通行问题导致；</p> </li>\n </ul> \n <h2><a id=\"podpending_487\"></a>pod一致处于pending状态一般有哪些情况，怎么排查？（重点，持续更新）</h2> \n <p>（这个问题被问到的概率非常大）<br> 一个pod一开始创建的时候，它本身就是会处于pending状态，这时可能是正在拉取镜像，正在创建容器的过程。</p> \n <p>如果等了一会发现pod一直处于pending状态，</p> \n <p>那么我们可以使用kubectl describe命令查看一下pod的Events详细信息。一般可能会有这么几种情况导致pod一直处于pending状态：<br> 1、调度器调度失败。</p> \n <p>Scheduer调度器无法为pod分配一个合适的node节点。</p> \n <p>而这又会有很多种情况，比如，node节点处在cpu、内存压力，导致无节点可调度；pod定义了资源请求，没有node节点满足资源请求；node节点上有污点而pod没有定义容忍；pod中定义了亲和性或反亲和性而没有节点满足这些亲和性或反亲和性；以上是调度器调度失败的几种情况。<br> 2、pvc、pv无法动态创建。</p> \n <p>如果因为pvc或pv无法动态创建，那么pod也会一直处于pending状态，比如要使用StatefulSet 创建redis集群，因为粗心大意，定义的storageClassName名称写错了，那么会造成无法创建pvc，这种情况pod也会一直处于pending状态，或者，即使pvc是正常创建了，但是由于某些异常原因导致动态供应存储无法正常创建pv，那么这种情况pod也会一直处于pending状态。</p> \n <h2><a id=\"DaemonSet_506\"></a>DaemonSet资源对象的特性？</h2> \n <p>答：</p> \n <p>DaemonSet这种资源对象会在每个k8s集群中的节点上运行，并且每个节点只能运行一个pod，这是它和deployment资源对象的最大也是唯一的区别。</p> \n <p>所以，在其yaml文件中，不支持定义replicas，</p> \n <p>除此之外，与Deployment、RS等资源对象的写法相同,</p> \n <p>DaemonSet一般使用的场景有</p> \n <ul>\n  <li>在去做每个节点的日志收集工作；</li>\n  <li>监控每个节点的的运行状态;</li>\n </ul> \n <h2><a id=\"Pod_521\"></a>删除一个Pod会发生什么事情？</h2> \n <p>答：</p> \n <p>Kube-apiserver会接受到用户的删除指令，默认有30秒时间等待优雅退出，超过30秒会被标记为死亡状态，</p> \n <p>此时Pod的状态Terminating，kubelet看到pod标记为Terminating就开始了关闭Pod的工作;</p> \n <p>关闭流程如下：</p> \n <p>1）pod从service的endpoint列表中被移除；</p> \n <p>2)如果该pod定义了一个停止前的钩子，其会在pod内部被调用，停止钩子一般定义了如何优雅的结束进程；</p> \n <p>3)进程被发送TERM信号（kill -14）;</p> \n <p>4)当超过优雅退出的时间后，Pod中的所有进程都会被发送SIGKILL信号（kill -9）;</p> \n <h2><a id=\"pod_543\"></a>pod的共享资源？</h2> \n <p>​ 答：</p> \n <p>1）PID 命名空间：Pod 中的不同应用程序可以看到其他应用程序的进程 ID；</p> \n <p>2）网络命名空间：Pod 中的多个容器能够访问同一个IP和端口范围；</p> \n <p>3）IPC 命名空间：Pod 中的多个容器能够使用 SystemV IPC 或 POSIX 消息队列进行通信；</p> \n <p>4）UTS 命名空间：Pod 中的多个容器共享一个主机名；</p> \n <p>5）Volumes（共享存储卷）：Pod 中的各个容器可以访问在 Pod 级别定义的 Volumes；</p> \n <h2><a id=\"pod_561\"></a>pod的初始化容器是干什么的？</h2> \n <p>init container，初始化容器用于在启动应用容器之前完成应用容器所需要的前置条件，</p> \n <p>初始化容器本质上和应用容器是一样的，但是初始化容器是仅允许一次就结束的任务，初始化容器具有两大特征：</p> \n <p>1、初始化容器必须运行完成直至结束，若某初始化容器运行失败，那么kubernetes需要重启它直到成功完成；<br> 2、初始化容器必须按照定义的顺序执行，当且仅当前一个初始化容器成功之后，后面的一个初始化容器才能运行；</p> \n <h2><a id=\"pod_570\"></a>pod的资源请求、限制如何定义？</h2> \n <p>pod的资源请求、资源限制可以直接在pod中定义</p> \n <p>主要包括两块内容，</p> \n <ul>\n  <li>limits，限制pod能使用的最大cpu和内存，</li>\n  <li>requests，pod启动时申请的cpu和内存。</li>\n </ul> \n <pre><code class=\"prism language-bash\"> resources:					<span class=\"token comment\">#资源配额</span>\n      limits:					<span class=\"token comment\">#限制最大资源，上限</span>\n        cpu: <span class=\"token number\">2</span>					<span class=\"token comment\">#CPU限制，单位是code数</span>\n        memory: 2G				<span class=\"token comment\">#内存最大限制</span>\n      requests:					<span class=\"token comment\">#请求资源（最小，下限）</span>\n        cpu: <span class=\"token number\">1</span>					<span class=\"token comment\">#CPU请求，单位是code数</span>\n        memory: 500G			<span class=\"token comment\">#内存最小请求</span>\n\n</code></pre> \n <h2><a id=\"podcommandargsdockerentrypointc_592\"></a>pod的定义中有个command和args参数，这两个参数不会和docker镜像的entrypointc冲突吗？</h2> \n <p>不会。</p> \n <p>在pod中定义的command参数用于指定容器的启动命令列表，如果不指定，则默认使用Dockerfile打包时的启动命令，args参数用于容器的启动命令需要的参数列表；</p> \n <p>特别说明：</p> \n <p>kubernetes中的command、args其实是实现覆盖dockerfile中的ENTRYPOINT的功能的。</p> \n <pre><code class=\"prism language-bash\"><span class=\"token number\">1</span>、如果command和args均没有写，那么使用Dockerfile的配置；\n<span class=\"token number\">2</span>、如果command写了但args没写，那么Dockerfile默认的配置会被忽略，执行指定的command；\n<span class=\"token number\">3</span>、如果command没写但args写了，那么Dockerfile中的ENTRYPOINT的会被执行，使用当前args的参数；\n<span class=\"token number\">4</span>、如果command和args都写了，那么Dockerfile会被忽略，执行输入的command和args。\n\n\n</code></pre> \n <h2><a id=\"pause_615\"></a>pause容器作用是什么？</h2> \n <p>每个pod里运行着一个特殊的被称之为pause的容器，也称根容器，而其他容器则称为业务容器；</p> \n <p>创建pause容器主要是为了为业务容器提供 Linux命名空间，共享基础：包括 pid、icp、net 等，以及启动 init 进程，并收割僵尸进程；</p> \n <p>这些业务容器共享pause容器的网络命名空间和volume挂载卷，</p> \n <p>当pod被创建时，pod首先会创建pause容器，从而把其他业务容器加入pause容器，从而让所有业务容器都在同一个命名空间中，这样可以就可以实现网络共享。</p> \n <p>pod还可以共享存储，在pod级别引入数据卷volume，业务容器都可以挂载这个数据卷从而实现持久化存储。</p> \n <h2><a id=\"_629\"></a>标签及标签选择器是什么，如何使用？</h2> \n <p>标签是键值对类型，标签可以附加到任何资源对象上，主要用于管理对象，查询和筛选。</p> \n <p>标签常被用于标签选择器的匹配度检查，从而完成资源筛选；一个资源可以定义一个或多个标签在其上面。</p> \n <p>标签选择器，标签要与标签选择器结合在一起，标签选择器允许我们选择标记有特定标签的资源对象子集，如pod，并对这些特定标签的pod进行查询，删除等操作。</p> \n <p>标签和标签选择器最重要的使用之一在于，在deployment中，在pod模板中定义pod的标签，然后在deployment定义标签选择器，这样就通过标签选择器来选择哪些pod是受其控制的，service也是通过标签选择器来关联哪些pod最后其服务后端pod。</p> \n <h2><a id=\"servicepod_641\"></a>service是如何与pod关联的？</h2> \n <p>答案是通过标签选择器，每一个由deployment创建的pod都带有标签，这样，service就可以定义标签选择器来关联哪些pod是作为其后端了，就是这样，service就与pod管联在一起了。</p> \n <h2><a id=\"servicepod_647\"></a>service的域名解析格式、pod的域名解析格式</h2> \n <p>service的DNS域名表示格式为<code>&lt;servicename&gt;.&lt;namespace&gt;.svc.&lt;clusterdomain&gt;</code>，</p> \n <p>servicename是service的名称，namespace是service所处的命名空间，clusterdomain是k8s集群设置的域名后缀，一般默认为 cluster.local</p> \n <p>pod的DNS域名格式为：<code>&lt;pod-ip&gt;.&lt;namespace&gt;.pod.&lt;clusterdomain&gt;</code> ，</p> \n <p>其中，pod-ip需要使用-将ip直接的点替换掉，namespace为pod所在的命名空间，clusterdomain是k8s集群设置的域名后缀，一般默认为 cluster.local ，</p> \n <p>演示如下：<code>10-244-1-223.default.pod.cluster.local</code></p> \n <p>对于deployment、daemonsets等创建的pod，还还可以通过<code>&lt;pod-ip&gt;.&lt;deployment-name&gt;.&lt;namespace&gt;.svc.&lt;clusterdomain&gt;</code> 这样的域名访问。</p> \n <h2><a id=\"service_663\"></a>service的类型有哪几种</h2> \n <p>service的类型一般有4中，分别是：</p> \n <ul>\n  <li> <p>ClusterIP：表示service仅供集群内部使用，默认值就是ClusterIP类型</p> </li>\n  <li> <p>NodePort：表示service可以对外访问应用，会在每个节点上暴露一个端口，这样外部浏览器访问地址为：任意节点的IP：NodePort就能连上service了</p> </li>\n  <li> <p>LoadBalancer：表示service对外访问应用，这种类型的service是公有云环境下的service，此模式需要外部云厂商的支持，需要有一个公网IP地址</p> </li>\n  <li> <p>ExternalName：这种类型的service会把集群外部的服务引入集群内部，这样集群内直接访问service就可以间接的使用集群外部服务了</p> </li>\n </ul> \n <p>一般情况下，service都是ClusterIP类型的，通过ingress接入的外部流量。</p> \n <h2><a id=\"PodService_679\"></a>Pod到Service的通信？</h2> \n <p>​</p> \n <p>1）k8s在创建服务时为服务分配一个虚拟IP，客户端通过该IP访问服务，服务则负责将请求转发到后端Pod上；</p> \n <p>2）Service是通过kube-proxy服务进程实现，该进程在每个Node上均运行可以看作一个透明代理兼负载均衡器；</p> \n <p>3）对每个TCP类型Service，kube-proxy都会在本地Node上建立一个SocketServer来负责接受请求，然后均匀发送到后端Pod默认采用Round Robin负载均衡算法；</p> \n <p>4）Service的Cluster IP与NodePort等概念是kube-proxy通过Iptables的NAT转换实现，kube-proxy进程动态创建与Service相关的Iptables规则；</p> \n <p>5）kube-proxy通过查询和监听API Server中Service与Endpoints的变化来实现其主要功能，包括为新创建的Service打开一个本地代理对象，接收请求针对针对发生变化的Service列表，kube-proxy会逐个处理；</p> \n <h2><a id=\"podservicepodservice_697\"></a>一个应用pod是如何发现service的，或者说，pod里面的容器用于是如何连接service的？</h2> \n <p>答：有两种方式，一种是通过环境变量，另一种是通过service的dns域名方式。</p> \n <p>1、环境变量：</p> \n <p>当pod被创建之后，k8s系统会自动为容器注入集群内有效的service名称和端口号等信息为环境变量的形式，</p> \n <p>这样容器应用直接通过取环境变量值就能访问service了，</p> \n <p>如<code>curl http://${WEBAPP_SERVICE_HOST}:{WEBAPP_SERVICE_PORT}</code></p> \n <p>2、DNS方式：</p> \n <p>使用dns域名解析的前提是k8s集群内有DNS域名解析服务器，</p> \n <p>默认k8s中会有一个CoreDNS作为k8s集群的默认DNS服务器提供域名解析服务器；</p> \n <p>service的DNS域名表示格式为<code>&lt;servicename&gt;.&lt;namespace&gt;.svc.&lt;clusterdomain&gt;</code>，</p> \n <p>servicename是service的名称，namespace是service所处的命名空间，clusterdomain是k8s集群设置的域名后缀，一般默认为 cluster.local ，</p> \n <p>这样容器应用直接通过service域名就能访问service了，</p> \n <p>如<code>wget http://svc-deployment-nginx.default.svc.cluster.local:80</code>，</p> \n <p>另外，service的port端口如果定义了名称，那么port也可以通过DNS进行解析，</p> \n <p>格式为：<code>_&lt;portname&gt;._&lt;protocol&gt;.&lt;servicename&gt;.&lt;namespace&gt;.svc.&lt;clusterdomain&gt;</code></p> \n <h2><a id=\"servicek8s_729\"></a>如何创建一个service代理外部的服务，或者换句话来说，在k8s集群内的应用如何访问外部的服务，如数据库服务，缓存服务等?</h2> \n <p>答：可以通过创建一个没有标签选择器的service来代理集群外部的服务。</p> \n <p>1、创建service时不指定selector标签选择器，但需要指定service的port端口、端口的name、端口协议等，这样创建出来的service因为没有指定标签选择器就不会自动创建endpoint；</p> \n <p>2、手动创建一个与service同名的endpoint，endpoint中定义外部服务的IP和端口，endpoint的名称一定要与service的名称一样，端口协议也要一样，端口的name也要与service的端口的name一样，不然endpoint不能与service进行关联。</p> \n <p>完成以上两步，k8s会自动将service和同名的endpoint进行关联，</p> \n <p>这样，k8s集群内的应用服务直接访问这个service就可以相当于访问外部的服务了。</p> \n <h2><a id=\"serviceendpointkubeproxys_743\"></a>service、endpoint、kube-proxys三种的关系是什么？</h2> \n <p><strong>service</strong>：</p> \n <p>在kubernetes中，service是一种为一组功能相同的pod提供单一不变的接入点的资源。</p> \n <p>当service被建立时，service的IP和端口不会改变，这样外部的客户端（也可以是集群内部的客户端）通过service的IP和端口来建立链接，这些链接会被路由到提供该服务的任意一个pod上。</p> \n <p>通过这样的方式，客户端不需要知道每个单独提供服务的pod地址，这样pod就可以在集群中随时被创建或销毁。</p> \n <p><strong>endpoint</strong>：</p> \n <p>service维护一个叫endpoint的资源列表，endpoint资源对象保存着service关联的pod的ip和端口。</p> \n <p>从表面上看，当pod消失，service会在endpoint列表中剔除pod，当有新的pod加入，service就会将pod ip加入endpoint列表；</p> \n <p>但是正在底层的逻辑是，endpoint的这种自动剔除、添加、更新pod的地址其实底层是由<code>endpoint controller</code>控制的，<code>endpoint controller</code>负责监听service和对应的pod副本的变化，如果监听到service被删除，则删除和该service同名的endpoint对象，如果监听到新的service被创建或者修改，则根据该service信息获取得相关pod列表，然后创建或更新service对应的endpoint对象，如果监听到pod事件，则更新它所对应的service的endpoint对象。</p> \n <p><strong>kube-proxy</strong>：</p> \n <p>kube-proxy运行在node节点上，在Node节点上实现Pod网络代理，维护网络规则和四层负载均衡工作，</p> \n <p><code>kube-proxy</code>会监听<code>api-server</code>中从而获取service和endpoint的变化情况，创建并维护路由规则以提供服务IP和负载均衡功能。</p> \n <p>简单理解此进程是Service的透明代理兼负载均衡器，其核心功能是将到某个Service的访问请求转发到后端的多个Pod实例上。</p> \n <h2><a id=\"serviceserviceservice_769\"></a>无头service和普通的service有什么区别，无头service使用场景是什么？</h2> \n <p>答：</p> \n <p><strong>无头service</strong>没有cluster ip，在定义service时将 <code>service.spec.clusterIP：None</code>，就表示创建的是无头service。</p> \n <p><strong>普通的service</strong>是用于为一组后端pod提供请求连接的负载均衡，让客户端能通过固定的service ip地址来访问pod，这类的pod是没有状态的，同时service还具有负载均衡和服务发现的功能。普通service跟我们平时使用的nginx反向代理很相识。</p> \n <p>试想这样一种情况，有6个redis pod ,它们相互之间要通信并要组成一个redis集群，</p> \n <p>不需要所谓的service负载均衡，这时无头service就是派上用场了，</p> \n <p>无头service由于没有cluster ip，kube-proxy就不会处理它也就不会对它生成规则负载均衡，无头service直接绑定的是pod 的ip。无头service仍会有标签选择器，有标签选择器就会有endpoint资源。</p> \n <p><strong>无头service使用场景：</strong></p> \n <p>无头service一般用于有状态的应用场景，如Kaka集群、Redis集群等，这类pod之间需要相互通信相互组成集群，不在需要所谓的service负载均衡。</p> \n <h2><a id=\"deployment_789\"></a>deployment怎么扩容或缩容？</h2> \n <p>答：直接修改pod副本数即可，可以通过下面的方式来修改pod副本数：</p> \n <p>1、直接修改yaml文件的replicas字段数值，然后<code>kubectl apply -f xxx.yaml</code>来实现更新；</p> \n <p>2、使用<code>kubectl edit deployment xxx</code> 修改replicas来实现在线更新；</p> \n <p>3、使用<code>kubectl scale --replicas=5 deployment/deployment-nginx</code>命令来扩容缩容。</p> \n <h2><a id=\"deployment_799\"></a>deployment的更新升级策略有哪些？</h2> \n <p>答：deployment的升级策略主要有两种。</p> \n <p>1、Recreate 重建更新：这种更新策略会杀掉所有正在运行的pod，然后再重新创建的pod；</p> \n <p>2、rollingUpdate 滚动更新：这种更新策略，deployment会以滚动更新的方式来逐个更新pod，同时通过设置滚动更新的两个参数<code>maxUnavailable、maxSurge</code>来控制更新的过程。</p> \n <h2><a id=\"deployment_807\"></a>deployment的滚动更新策略有两个特别主要的参数，解释一下它们是什么意思？</h2> \n <p>答：deployment的滚动更新策略，rollingUpdate 策略，主要有两个参数，maxUnavailable、maxSurge。</p> \n <ul>\n  <li> <p>maxUnavailable：最大不可用数，maxUnavailable用于指定deployment在更新的过程中不可用状态的pod的最大数量，maxUnavailable的值可以是一个整数值，也可以是pod期望副本的百分比，如25%，计算时向下取整。</p> </li>\n  <li> <p>maxSurge：最大激增数，maxSurge指定deployment在更新的过程中pod的总数量最大能超过pod副本数多少个，maxUnavailable的值可以是一个整数值，也可以是pod期望副本的百分比，如25%，计算时向上取整。</p> </li>\n </ul> \n <h2><a id=\"deployment_815\"></a>deployment更新的命令有哪些？</h2> \n <p>答：可以通过三种方式来实现更新deployment。</p> \n <p>1、直接修改yaml文件的镜像版本，然后<code>kubectl apply -f xxx.yaml</code>来实现更新；</p> \n <p>2、使用<code>kubectl edit deployment xxx</code> 实现在线更新；</p> \n <p>3、使用<code>kubectl set image deployment/nginx busybox=busybox nginx=nginx:1.9.1</code> 命令来更新。</p> \n <h2><a id=\"deployment_827\"></a>简述一下deployment的更新过程?</h2> \n <p>deployment是通过控制replicaset来实现，由replicaset真正创建pod副本，每更新一次deployment，都会创建新的replicaset，下面来举例deployment的更新过程：</p> \n <p>假设要升级一个nginx-deployment的版本镜像为nginx:1.9，deployment的定义滚动更新参数如下：</p> \n <pre><code class=\"prism language-bash\">replicas: <span class=\"token number\">3</span>\ndeployment.spec.strategy.type: RollingUpdate\nmaxUnavailable：25%\nmaxSurge：25%\n\n</code></pre> \n <p>通过计算我们得出，3*25%=0.75，maxUnavailable是向下取整，则maxUnavailable=0，maxSurge是向上取整，则maxSurge=1，所以我们得出在整个deployment升级镜像过程中，不管旧的pod和新的pod是如何创建消亡的，pod总数最大不能超过3+maxSurge=4个，最大pod不可用数3-maxUnavailable=3个。</p> \n <p>现在具体讲一下deployment的更新升级过程：</p> \n <p>使用<code>kubectl set image deployment/nginx nginx=nginx:1.9 --record</code> 命令来更新；</p> \n <p>1、deployment创建一个新的replaceset，先新增1个新版本pod，此时pod总数为4个，不能再新增了，再新增就超过pod总数4个了；旧=3，新=1，总=4；</p> \n <p>2、减少一个旧版本的pod，此时pod总数为3个，这时不能再减少了，再减少就不满足最大pod不可用数3个了；旧=2，新=1，总=3；</p> \n <p>3、再新增一个新版本的pod，此时pod总数为4个，不能再新增了；旧=2，新=2，总=4；</p> \n <p>4、减少一个旧版本的pod，此时pod总数为3个，这时不能再减少了；旧=1，新=2，总=3；</p> \n <p>5、再新增一个新版本的pod，此时pod总数为4个，不能再新增了；旧=1，新=3，总=4；</p> \n <p>6、减少一个旧版本的pod，此时pod总数为3个，更新完成，pod都是新版本了；旧=0，新=3，总=3；</p> \n <h2><a id=\"deployment_859\"></a>deployment的回滚使用什么命令</h2> \n <p>在升级deployment时kubectl set image 命令加上 --record 参数可以记录具体的升级历史信息，</p> \n <p>使用<code>kubectl rollout history deployment/deployment-nginx</code> 命令来查看指定的deployment升级历史记录，</p> \n <p>如果需要回滚到某个指定的版本，可以使用<code>kubectl rollout undo deployment/deployment-nginx --to-revision=2</code> 命令来实现。</p> \n <h2><a id=\"_869\"></a>讲一下都有哪些存储卷，作用分别是什么?</h2> \n <table>\n  <thead>\n   <tr>\n    <th>卷</th>\n    <th>作用</th>\n    <th>常用场景</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>emptyDir</td>\n    <td>用于存储临时数据的简单空目录</td>\n    <td>一个pod中的多个容器需要共享彼此的数据 ，emptyDir的数据随着容器的消亡也会销毁</td>\n   </tr>\n   <tr>\n    <td>hostPath</td>\n    <td>用于将目录从工作节点的文件系统挂载到pod中</td>\n    <td>不常用，缺点是，pod的调度不是固定的，也就是当pod消失后deployment重新创建一个pod，而这pod如果不是被调度到之前pod的节点，那么该pod就不能访问之前的数据</td>\n   </tr>\n   <tr>\n    <td>configMap</td>\n    <td>用于将非敏感的数据保存到键值对中，使用时可以使用作为环境变量、命令行参数arg，存储卷被pods挂载使用</td>\n    <td>将应用程序的不敏感配置文件创建为configmap卷，在pod中挂载configmap卷，可是实现热更新</td>\n   </tr>\n   <tr>\n    <td>secret</td>\n    <td>主要用于存储和管理一些敏感数据，然后通过在 Pod 的容器里挂载 Volume 的方式或者环境变量的方式访问到这些 Secret 里保存的信息了，pod会自动解密Secret 的信息</td>\n    <td>将应用程序的账号密码等敏感信息通过secret卷的形式挂载到pod中使用</td>\n   </tr>\n   <tr>\n    <td>downwardApi</td>\n    <td>主要用于暴露pod元数据，如pod的名字</td>\n    <td>pod中的应用程序需要指定pod的name等元数据，就可以通过downwardApi 卷的形式挂载给pod使用</td>\n   </tr>\n   <tr>\n    <td>projected</td>\n    <td>这是一种特殊的卷，用于将上面这些卷一次性的挂载给pod使用</td>\n    <td>将上面这些卷一次性的挂载给pod使用</td>\n   </tr>\n   <tr>\n    <td>pvc</td>\n    <td>pvc是存储卷声明</td>\n    <td>通常会创建pvc表示对存储的申请，然后在pod中使用pvc</td>\n   </tr>\n   <tr>\n    <td>网络存储卷</td>\n    <td>pod挂载网络存储卷，这样就能将数据持久化到后端的存储里</td>\n    <td>常见的网络存储卷有nfs存储、glusterfs 卷、ceph rbd存储卷</td>\n   </tr>\n  </tbody>\n </table> \n <h2><a id=\"pv_884\"></a>pv的访问模式有哪几种</h2> \n <p>pv的访问模式有3种，如下：</p> \n <ul>\n  <li> <p>ReadWriteOnce，简写：RWO 表示，只仅允许单个节点以读写方式挂载；</p> </li>\n  <li> <p>ReadOnlyMany，简写：ROX 表示，可以被许多节点以只读方式挂载；</p> </li>\n  <li> <p>ReadWriteMany，简写：RWX 表示，可以被多个节点以读写方式挂载；</p> </li>\n </ul> \n <h2><a id=\"pv_894\"></a>pv的回收策略有哪几种</h2> \n <p>主要有3中回收策略：retain 保留、delete 删除、 Recycle回收。</p> \n <ul>\n  <li> <p>Retain：保留，该策略允许手动回收资源，当删除PVC时，PV仍然存在，PV被视为已释放，管理员可以手动回收卷。</p> </li>\n  <li> <p>Delete：删除，如果Volume插件支持，删除PVC时会同时删除PV，动态卷默认为Delete，目前支持Delete的存储后端包括AWS EBS，GCE PD，Azure Disk，OpenStack Cinder等。</p> </li>\n  <li> <p>Recycle：回收，如果Volume插件支持，Recycle策略会对卷执行rm -rf清理该PV，并使其可用于下一个新的PVC，但是本策略将来会被弃用，目前只有NFS和HostPath支持该策略。（这种策略已经被废弃，不用记）</p> </li>\n </ul> \n <h2><a id=\"pv_905\"></a>在pv的生命周期中，一般有几种状态</h2> \n <p>pv一共有4中状态，分别是：</p> \n <p>创建pv后，pv的的状态有以下4种：Available（可用）、Bound（已绑定）、Released（已释放）、Failed（失败）</p> \n <pre><code class=\"prism language-bash\">Available，表示pv已经创建正常，处于可用状态；\nBound，表示pv已经被某个pvc绑定，注意，一个pv一旦被某个pvc绑定，那么该pvc就独占该pv，其他pvc不能再与该pv绑定；\nReleased，表示pvc被删除了，pv状态就会变成已释放；\nFailed，表示pv的自动回收失败；\n\n</code></pre> \n <h2><a id=\"pv_921\"></a>pv存储空间不足怎么扩容?</h2> \n <p>一般的，我们会使用动态分配存储资源，</p> \n <p>在创建storageclass时指定参数 allowVolumeExpansion：true，表示允许用户通过修改pvc申请的存储空间自动完成pv的扩容，</p> \n <p>当增大pvc的存储空间时，不会重新创建一个pv，而是扩容其绑定的后端pv。</p> \n <p>这样就能完成扩容了。但是allowVolumeExpansion这个特性只支持扩容空间不支持减少空间。</p> \n <h2><a id=\"_933\"></a>存储类的资源回收策略:</h2> \n <p>主要有2中回收策略，delete 删除，默认就是delete策略、retain 保留。<br> Retain：保留，该策略允许手动回收资源，当删除PVC时，PV仍然存在，PV被视为已释放，管理员可以手动回收卷。<br> Delete：删除，如果Volume插件支持，删除PVC时会同时删除PV，动态卷默认为Delete，目前支持Delete的存储后端包括AWS EBS，GCE PD，Azure Disk，OpenStack Cinder等。</p> \n <p>注意：使用存储类动态创建的pv默认继承存储类的回收策略，当然当pv创建后你也可以手动修改pv的回收策略。</p> \n <h2><a id=\"node_943\"></a>怎么使一个node脱离集群调度，比如要停机维护单又不能影响业务应用</h2> \n <p>使用kubectl drain 命令</p> \n <h2><a id=\"k8s_951\"></a>k8s生产中遇到什么特别映像深刻的问题吗，问题排查解决思路是怎么样的？（重点）</h2> \n <p>（此问题被问到的概率高达90%，所以可以自己准备几个自己在生产环境中遇到的问题进行讲解）</p> \n <p>答：前端的lb负载均衡服务器上的keepalived出现过脑裂现象。</p> \n <p>1、当时问题现象是这样的，vip同时出现在主服务器和备服务器上，但业务上又没受到影响；<br> 2、这时首先去查看备服务器上的keepalived日志，发现有日志信息显示凌晨的时候备服务器出现了vrrp协议超时，所以才导致了备服务器接管了vip；查看主服务器上的keepalived日志，没有发现明显的报错信息，继续查看主服务器和备服务器上的keepalived进程状态，都是running状态的；查看主服务器上检测脚本所检测的进程，其进程也是正常的，也就是说主服务器根本没有成功执行检测脚本（成功执行检查脚本是会kill掉keepalived进程，脚本里面其实就是配置了检查nginx进程是否存活，如果检查到nginx不存活则kill掉keepalived，这样来实现备服务器接管vip）；<br> 3、排查服务器上的防火墙、selinux，防火墙状态和selinux状态都是关闭着的；<br> 4、使用tcpdump工具在备服务器上进行抓取数据包分析，分析发现，现在确实是备接管的vip，也确实是备服务器也在对外发送vrrp心跳包，所以现在外部流量应该都是流入备服务器上的vip；<br> 5、怀疑：主服务器上设置的vrrp心跳包时间间隔太长，以及检测脚本设置的检测时间设置不合理导致该问题；<br> 6、修改vrrp协议的心跳包时间间隔，由原来的2秒改成1秒就发送一次心跳包；检测脚本的检测时间也修改短一点，同时还修改检测脚本的检测失败的次数，比如连续检测2次失败才认定为检测失败；<br> 7、重启主备上的keepalived，现在keepalived是正常的，主服务器上有vip，备服务器上没有vip；<br> 8、持续观察：第二天又发现keepalived出现过脑裂现象，vip又同时出现在主服务器和备服务器上，又是凌晨的时候备服务器显示vrrp心跳包超时，所以才导致备服务器接管了vip；<br> 9、同样的时间，都是凌晨，vrrp协议超时；很奇怪，很有理由怀疑是网络问题，询问第三方厂家上层路由器是否禁止了vrrp协议，第三方厂家回复，没有禁止vrrp协议；<br> 10、百度、看官方文档求解；<br> 11、百度、看官网文档得知，keepalived有2种传播模式，一种是组播模式，一种是单播模式，keepalived默认在组播模式下工作，主服务器会往主播地址224.0.0.18发送心跳包，当局域网内有多个keepalived实例的时候，如果都用主播模式，会存在冲突干扰的情况，所以官方建议使用单播模式通信，单播模式就是点对点通行，即主向备服务器一对一的发送心跳包；</p> \n <p>12、将keepalived模式改为单播模式，继续观察，无再发生脑裂现象。问题得以解决。</p> \n <h2><a id=\"k8s_971\"></a>k8s生产中遇到什么特别映像深刻的问题吗，问题排查解决思路是怎么样的？（重点）</h2> \n <p>参考答案二：测试环境二进制搭建etcd集群，etcd集群出现2个leader的现象。<br> 1、问题现象就是：刚搭建的k8s集群，是测试环境的，搭建完成之后发现，使用kubectl get nodes 显示没有资源，kubectl get namespace 一会能正常显示全部的命名空间，一会又显示不了命名空间，这种奇怪情况。<br> 2、当时经验不是很足，第一点想到的是不是因为网络插件calico没装导致的，但是想想，即使没有安装网络插件，最多是node节点状态是notready，也不可能是没有资源发现呀；<br> 3、然后想到etcd数据库，k8s的资源都是存储在etcd数据库中的；<br> 4、查看etcd进程服务的启动状态，发现etcd服务状态是处于running状态，但是日志有大量的报错信息，日志大概报错信息就是集群节点的id不匹配，存在冲突等等报错信息；<br> 5、使用etcdctl命令查看etcd集群的健康状态，发现集群是health状态，但是居然显示有2个leader，这很奇怪（当初安装etcd的时候其实也只是简单看到了集群是健康状态，然后没注意到有2个leader，也没太关注etcd服务进程的日志报错信息，以为etcd集群状态是health状态就可以了）<br> 6、现在etcd出现了2个leader，肯定是存在问题的；<br> 7、全部检测一遍etcd的各个节点的配置文件，确认配置文件里面各个参数配置都没有问题，重启etcd集群，报错信息仍未解决，仍然存在2个leader；<br> 8、尝试把其中一个leader节点踢出集群，然后再重新添加它进入集群，仍然是报错，仍然显示有2个leader；<br> 9、尝试重新生成etcd的证书，重新颁发etcd的证书，问题仍然存在，仍然显示有2个leader；日志仍是报错集群节点的id不匹配，存在冲突；<br> 10、计算etcd命令的MD5值，确保各个节点的etcd命令是相同的，确保在scp传输的时候没有损耗等等，问题仍未解决；<br> 11、无解，请求同事，架构师介入帮忙排查问题，仍未解决；<br> 12、删除全部etcd相关的文件，重新部署etcd集群，etcd集群正常了，现在只有一个leader，使用命令kubectl get nodes 查看节点，也能正常显示了；<br> 13、最终问题的原因也没有定位出来，只能怀疑是环境问题了，由于是刚部署的k8s测试环境，etcd里面没有数据，所以可以删除重新创建etcd集群，如果是线上环境的etcd集群出现这种问题，就不能随便删除etcd集群了，必须要先进行数据备份才能进行其他方法的处理。</p> \n <h2><a id=\"etcd_990\"></a>etcd集群节点可以设置为偶数个吗，为什么要设置为基数个呢？</h2> \n <p>不能，也不建议这么设置。</p> \n <p>底层的原理，涉及到集群的脑裂 ，</p> \n <p>具体的答案，请参考 《尼恩java面试宝典 专题14》</p> \n <p><img src=\"https://img-blog.csdnimg.cn/e16f1bf77303495485b4df7e4584bdaa.png\" alt=\"在这里插入图片描述\"></p> \n <p><img src=\"https://img-blog.csdnimg.cn/f89139533bfa42a4a57447b276a19509.png\" alt=\"在这里插入图片描述\"></p> \n <h2><a id=\"etcd_1006\"></a>etcd集群节点之间是怎么同步数据的？</h2> \n <p>总体而言，是 通过Raft协议进行节点之间数据同步， 保证节点之间的数据一致性</p> \n <p>在正式开始介绍 Raft 协议之间，我们有必要简单介绍一下其相关概念。</p> \n <p>在现实的场景中，节点之间的一致性也就很难保证，这样就需要 Paxos、Raft 等一致性协议。</p> \n <p>一致性协议可以保证在集群中大部分节点可用的情况下，集群依然可以工作并给出一个正确的结果，从而保证依赖于该集群的其他服务不受影响。</p> \n <p>这里的“大部分节点可用”指的是集群中超过半数以上的节点可用，例如，集群中共有 5个节点，此时其中有 2 个节点出现故障宕机，剩余的可用节点数为 3，此时，集群中大多数节点处于可用的状态，从外部来看集群依然是可用的。</p> \n <p>常见的一致性算法有Paxos、Raft等，</p> \n <p>Paxos协议是Leslie Lamport于1990年提出的一种基于消息传递的、具有高度容错特性的一致性算法，Paxos 算法解决的主要问题是分布式系统内如何就某个值达成一致。在相当长的一段时间内，Paxos 算法几乎成为一致性算法的代名词，</p> \n <p>但是 Paxos 有两个明显的缺点：第一个也是最明显的缺点就是 Paxos 算法难以理解，Paxos 算法的论文本身就比较晦涩难懂，要完全理解 Paxos 协议需要付出较大的努力，很多经验丰富的开发者在看完 Paxos 论文之后，无法将其有效地应用到具体工程实践中，这明显增加了工程化的门槛，也正因如此，才出现了几次用更简单的术语来解释 Paxos 的尝试。</p> \n <p>Paxos算法的第二个缺点就是它没有提供构建现实系统的良好基础，也有很多工程化 Paxos 算法的尝试，但是它们对 Paxos 算法本身做了比较大的改动，彼此之间的实现差距都比较大，实现的功能和目的都有所不同，同时与Paxos算法的描述有很多出入。例如，著名Chubby，它实现了一个类Paxos的算法，但其中很多细节并未被明确。本章并不打算详细介绍 Paxos 协议的相关内容，如果读者对Paxos感兴趣，则可以参考Lamport发表的三篇论文：《The Part-Time Parliament》、《Paxos made simple》、《Fast Paxos》。</p> \n <p>Raft算法是一种用于管理复制日志的一致性算法，其功能与Paxos算法相同类似，但其算法结构和Paxos算法不同，在设计Raft算法时设计者就将易于理解作为其目标之一，这使得Raft算法更易于构建实际的系统，大幅度减少了工程化的工作量，也方便开发者此基础上进行扩展。</p> \n <p>Raft协议中，核心就是用于：</p> \n <ul>\n  <li>Leader选举</li>\n  <li>日志复制。</li>\n </ul> \n <h3><a id=\"Leader_1035\"></a>Leader选举</h3> \n <p>Raft 协议的工作模式是一个 Leader 节点和多个 Follower 节点的模式，也就是常说的Leader-Follower 模式。</p> \n <p>在 Raft 协议中，每个节点都维护了一个状态机，该状态机有三种状态，分别是Leader状态、Follower状态和Candidate状态，在任意时刻，集群中的任意一个节点都处于这三个状态之一。</p> \n <p>各个状态和转换条件如图所示。<br> <img src=\"https://img-blog.csdnimg.cn/85663942ddfb437a8eeee92f79a531f4.png\" alt=\"在这里插入图片描述\"></p> \n <p>在多数情况下，集群中有一个Leader节点，其他节点都处于Follower状态，下面简单介绍一下每个状态的节点负责的主要工作。</p> \n <ul>\n  <li> <p>Leader节点负责处理所有客户端的请求，当接收到客户端的写入请求时，Leader节点会在本地追加一条相应的日志，然后将其封装成消息发送到集群中其他的Follower节点。当Follower节点收到该消息时会对其进行响应。如果集群中多数（超过半数）节点都已收到该请求对应的日志记录时，则 Leader 节点认为该条日志记录已提交（committed），可以向客户端返回响应。Leader 还会处理客户端的只读请求，其中涉及一个简单的优化，后面介绍具体实现时，再进行详细介绍。Leader节点的另一项工作是定期向集群中的 Follower 节点发送心跳消息，这主要是为了防止集群中的其他Follower节点的选举计时器超时而触发新一轮选举。</p> </li>\n  <li> <p>Follower节点不会发送任何请求，它们只是简单地响应来自Leader或者Candidate 的请求；Follower节点也不处理Client的请求，而是将请求重定向给集群的Leader节点进行处理。</p> </li>\n  <li> <p>Candidate节点是由Follower节点转换而来的，当Follower节点长时间没有收到Leader节点发送的心跳消息时，则该节点的选举计时器就会过期，同时会将自身状态转换成Candidate，发起新一轮选举。选举的具体过程在下面详细描述。</p> </li>\n </ul> \n <p>了解了Raft协议中节点的三种状态及各个状态下节点的主要行为之后，我们通过一个示例介绍Raft协议中Leader选举的大致流程。为了方便描述，我们假设当前集群中有三个节点（A、B、C），如图所示。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/cd86035aff7640949ebe64082b63aa3c.png\" alt=\"在这里插入图片描述\"></p> \n <p>在Raft协议中有两个时间控制Leader选举发生，其中一个是选举超时时间（election timeout），每个Follower节点在接收不到Leader节点的心跳消息之后，并不会立即发起新一轮选举，而是需要等待一段时间之后才切换成Candidate状态发起新一轮选举。这段等待时长就是这里所说的election timeout（后面介绍etcd的具体实现时会提到，Follower节点等待的时长并不完全等于该配置）。之所以这样设计，主要是 Leader 节点发送的心跳消息可能因为瞬间的网络延迟或程序瞬间的卡顿而迟到（或是丢失），因此就触发新一轮选举是没有必要的。election timeout一般设置为150ms～300ms之间的随机数。另一个超时时间是心跳超时时间（heartbeat timeout），也就是Leader节点向集群中其他Follower节点发送心跳消息的时间间隔。</p> \n <p>当集群初始化时，所有节点都处于 Follower 的状态，此时的集群中没有 Leader 节点。当Follower 节点一段时间（选举计时器超时）内收不到 Leader 节点的心跳消息，则认为 Leader节点出现故障导致其任期（Term）过期，Follower节点会转换成Candidate状态，发起新一轮的选举。所谓 “任期（Term）”，实际上就是一个全局的、连续递增的整数，在 Raft 协议中每进行一次选举，任期（Term）加一，在每个节点中都会记录当前的任期值（currentTerm）。每一个任期都是从一次选举开始的，在选举时，会出现一个或者多个 Candidate 节点尝试成为 Leader节点，如果其中一个Candidate节点赢得选举，则该节点就会切换为Leader状态并成为该任期的Leader节点，直到该任期结束。</p> \n <p>回到前面的示例中，此时节点 A 由于长时间未收到 Leader 的心跳消息，就会切换成为Candidate状态并发起选举（节点A的选举计时器（election timer）已被重置）。</p> \n <p>在选举过程中，节点A首先会将自己的选票投给自己，并会向集群中其他节点发送选举请求（Request Vote）以获取其选票，如图2-3（1）所示；此时的节点B和节点C还都是处于Term=0的任期之中，且都是Follower状态，均未投出Term=1任期中的选票，所以节点B和节点C在接收到节点A的选举请求后会将选票投给节点A，另外，节点B、C在收到节点A的选举请求的同时会将选举定时器重置，这是为了防止一个任期中同时出现多个Candidate节点，导致选举失败，如图2-3 （2）所示。</p> \n <p>注意，节点B和节点C也会递增自身记录的Term值。<br> <img src=\"https://img-blog.csdnimg.cn/dc406fa0f9a2460fb765e48ff1c372e0.png\" alt=\"在这里插入图片描述\"></p> \n <p>在节点 A 收到节点 B、C 的投票之后，其收到了集群中超过半数的选票，所以在 Term=1这个任期中，该集群的Leader节点就是节点A，其他节点将切换成Follower状态，如图2-4所示。</p> \n <p>另外需要读者了解的是，集群中的节点除了记录当期任期号（currentTerm），还会记录在该任期中当前节点的投票结果（VoteFor）。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/4ea4fde0b7f44bf38f1b159ae26aa0ef.png\" alt=\"在这里插入图片描述\"></p> \n <p>继续前面的示例，成为Term=1任期的Leader节点之后，节点A会定期向集群中的其他节点发送心跳消息，如图2-5（1）所示，</p> \n <p>这样就可以防止节点B和节点C中的选举计时器（election timer）超时而触发新一轮的选举；当节点B和节点C（Follower）收到节点A的心跳消息之后会重置选举计时器，如图2-5（2）所示，由此可见，心跳超时时间（heartbeat timeout）需要远远小于选举超时时间（election timeout）</p> \n <p><img src=\"https://img-blog.csdnimg.cn/d221517b5e794b6fac6f705a75225d27.png\" alt=\"在这里插入图片描述\"></p> \n <p>到这里读者可能会问，如果有两个或两个以上节点的选举计时器同时过期，则这些节点会同时由 Follower 状态切换成 Candidate 状态，然后同时触发新一轮选举，在该轮选举中，每个Candidate节点获取的选票都不到半数，无法选举出Leader节点，那么Raft协议会如何处理呢？这种情况确实存在，假设集群中有4个节点，其中节点A和节点B的选举计时器同时到期，切换到Candidate状态并向集群中其他节点发出选举请求，如图2-6（1）所示。</p> \n <p>这里假设节点A发出的选举请求先抵达节点C，节点B发出的选举请求先抵达节点D，如图2-6（2）所示，节点A和节点B除了得到自身的选票之外，还分别得到了节点C和节点D投出的选票，得票数都是2，都没有超过半数。在这种情况下，Term=4这个任期会以选举失败结束，随着时间的流逝，当任意节点的选举计时器到期之后，会再次发起新一轮的选举。前面提到过election timeout是在一个时间区间内取的随机数，所以在配置合理的时候，像上述情况多次出现的概率并不大。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/e21e573adf37422096f4b7a7f26c66fe.png\" alt=\"在这里插入图片描述\"></p> \n <p>继续上面的示例，这里假设节点A的选举计时器再次到期（此次节点B、C、D 的选举计时器并未到期），它会切换成Candidate状态并发起新一轮选举（Term=5），如图2-7（1）所示，其中节点B虽然处于Candidate状态，但是接收到Term值比自身记录的Term值大的请求时，节点会切换成Follower状态并更新自身记录的Term值，所以该示例中的节点B也会将选票投给节点A，如图2-7（2）所示。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/5bfb92202e9d45a8b9d97a4830903d0b.png\" alt=\"在这里插入图片描述\"></p> \n <p>在获取集群中半数以上的选票并成为新任期（Term=5）的 Leader 之后，节点 A 会定期向集群中其他节点发送心跳消息；当集群中其他节点收到Leader节点的心跳消息的时候，会重置选举定时器，如图2-8所示。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/050a9d1dc9cf4a5ea410bfec89d505ef.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeXpubO-8gQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>介绍完集群启动时的Leader选举流程之后，下面分析Leader节点宕机之后重新选举的场景。继续上述4节点集群的示例，在系统运行一段时间后，集群当前的Leader节点（A）因为故障而宕机，此时将不再有心跳消息发送到集群的其他Follower节点（节点B、C、D），一段时间后，会有一个Follower节点的选举计时器最先超时，这里假设节点D的选举计时器最先超时，然后它将切换为Candidate状态并发起新一轮选举，如图2-9（1）所示。<br> <img src=\"https://img-blog.csdnimg.cn/39965656ea004da48e9a12a4536e9175.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeXpubO-8gQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>当节点B和节点C收到节点D的选举请求后，会将其选票投给节点D，由于节点A已经宕机，没有参加此次选举，也就无法进行投票，但是在此轮选举中，节点D依然获得了半数以上的选票，故成为新任期（Term=6）的Leader节点，并开始向其他Follower节点发送心跳消息，如图2-10所示。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/5fbb4bc3734148e5a8c27124040c2b00.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeXpubO-8gQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>当节点A恢复之后，会收到节点D发来的心跳消息，该消息中携带的任期号（Term=6）大于节点A当前记录的任期号（Term=5），所以节点A会切换成Follower状态。在Raft协议中，当某个节点接收到的消息所携带的任期号大于当前节点本身记录的任期号，那么该节点会更新自身记录的任期号，同时会切换为Follower状态并重置选举计时器，这是Raft算法中所有节点最后请读者考虑一个场景：如果集群中选出的Leader节点频繁崩溃或是其他原因导致选举频繁发生，这会使整个集群中没有一个稳定的Leader节点，这样客户端无法与集群中的Leader节点正常交互，也就会导致整个集群无法正常工作。</p> \n <p>Leader选举是Raft算法中对时间要求较为严格的一个点，一般要求整个集群中的时间满足如下不等式：<br> 广播时间 ＜＜ 选举超时时间 ＜＜ 平均故障间隔时间</p> \n <p>在上述不等式中，广播时间指的是从一个节点发送心跳消息到集群中的其他节点并接收响应的平均时间；平均故障间隔时间就是对于一个节点而言，两次故障之间的平均时间。为了保证整个Raft集群可用，广播时间必须比选举超时时间小一个数量级，这样Leader节点才能够发送稳定的心跳消息来重置其他 Follower 节点的选举计时器，从而防止它们切换成 Candidate 状态，触发新一轮选举。在前面的描述中也提到过，选举超时时间是一个随机数，通过这种随机的方式，会使得多个Candidate节点瓜分选票的情况明显减少，也就减少了选举耗时。</p> \n <p>另外，选举超时时间应该比平均故障间隔时间小几个数量级，这样Leader节点才能稳定存在，整个集群才能稳定运行。当Leader节点崩溃之后，整个集群会有大约相当于选举超时的时间不可用，这种情况占比整个集群稳定运行的时间还是非常小的。</p> \n <p>广播时间和平均故障间隔时间是由网络和服务器本身决定的，但是选举超时时间是可以由我们自己调节的。</p> \n <p>一般情况下，广播时间可以做到0.5ms～50ms，选举超时时间设置为200ms～1s之间，而大多数服务器的平均故障间隔时间都在几个月甚至更长，很容易满足上述不等式的时间需求。</p> \n <h3><a id=\"_1145\"></a>日志复制</h3> \n <p>通过上一节介绍的Leader选举过程，集群中最终会选举出一个Leader节点，而集群中剩余的其他节点将会成为Follower节点。</p> \n <p>Leader节点除了向Follower节点发送心跳消息，<strong>还会处理客户端的请求</strong>，并将客户端的更新操作以消息（Append Entries消息）的形式发送到集群中所有的Follower节点。</p> \n <p>当Follower节点记录收到的这些消息之后，会向Leader节点返回相应的响应消息。当Leader节点在收到半数以上的Follower节点的响应消息之后，会对客户端的请求进行应答。</p> \n <p>最后，Leader会提交客户端的更新操作，该过程会发送Append Entries消息到Follower节点，通知Follower节点该操作已经提交，同时Leader节点和Follower节点也就可以将该操作应用到自己的状态机中。</p> \n <p>上面这段描述仅仅是Raft协议中日志复制部分的大致流程，下面我们依然通过一个示例描述该过程，为了方便描述，我们依然假设当前集群中有三个节点（A、B、C），其中A是Leader节点，B、C是Follower 节点，此时有一个客户端发送了一个更新操作到集群，如图 2-11（1）所示。前面提到过，集群中只有Leader节点才能处理客户端的更新操作，这里假设客户端直接将请求发给了节点A。当收到客户端的请求时，节点A会将该更新操作记录到本地的Log中，如图2-11（2）所示。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/45356dc22a224dd1b40e915b8de5c296.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeXpubO-8gQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>之后，节点A会向其他节点发送Append Entries消息，其中记录了Leader节点最近接收到的请求日志，如图2-12（1）所示。集群中其他Follower节点收到该Append Entries消息之后，会将该操作记录到本地的Log中，并返回相应的响应消息，如图2-12（2）所示。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/bca50412245c4e6abdfd64b55d52044a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeXpubO-8gQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>当Leader节点收到半数以上的响应消息之后，会认为集群中有半数以上的节点已经记录了该更新操作，Leader 节点会将该更新操作对应的日志记录设置为已提交（committed），并应用到自身的状态机中。同时 Leader 节点还会对客户端的请求做出响应，如图 2-13（1）所示。同时，Leader节点也会向集群中的其他Follower节点发送消息，通知它们该更新操作已经被提交，Follower节点收到该消息之后，才会将该更新操作应用到自己的状态机中，如图2-13（2）所示。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/584db40228b3480fadb714be447c8c9f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeXpubO-8gQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>在上述示例的描述中我们可以看到，集群中各个节点都会维护一个本地Log用于记录更新操作，除此之外，每个节点还会维护commitIndex和lastApplied两个值，它们是本地Log的索引值，其中commitIndex表示的是当前节点已知的、最大的、已提交的日志索引值，lastApplied表示的是当前节点最后一条被应用到状态机中的日志索引值。当节点中的 commitIndex 值大于lastApplied值时，会将lastApplied 加1，并将lastApplied对应的日志应用到其状态机中。</p> \n <p>在Leader节点中不仅需要知道自己的上述信息，还需要了解集群中其他Follower节点的这些信息，例如，Leader节点需要了解每个Follower节点的日志复制到哪个位置，从而决定下次发送 Append Entries 消息中包含哪些日志记录。为此，Leader 节点会维护 nextIndex[]和matchIndex[]两个数组，这两个数组中记录的都是日志索引值，其中nextIndex[]数组记录了需要发送给每个 Follower 节点的下一条日志的索引值，matchIndex[]表示记录了已经复制给每个Follower节点的最大的日志索引值。</p> \n <p>这里简单看一下 Leader 节点与某一个 Follower 节点复制日志时，对应 nextIndex 和matchIndex值的变化：Follower节点中最后一条日志的索引值大于等于该Follower节点对应的nextIndex 值，那么通过 Append Entries 消息发送从 nextIndex 开始的所有日志。之后，Leader节点会检测该 Follower 节点返回的相应响应，如果成功则更新相应该 Follower 节点对应的nextIndex值和matchIndex值；如果因为日志不一致而失败，则减少nextIndex值重试。</p> \n <p>下面我们依然通过一个示例来说明nextIndex[]和matchIndex[]在日志复制过程中的作用，假设集群现在有三个节点，其中节点A是Leader节点（Term=1），而Follower节点C因为宕机导致有一段时间未与Leader节点同步日志。此时，节点C的Log中并不包含全部的已提交日志，而只是节点A的Log的子集，节点C故障排除后重新启动，当前集群的状态如图2-14所示（这里只关心Log、nextIndex[]、matchIndex[]，其他的细节省略，另外需要注意的是，图中的Term=1表示的是日志发送时的任期号，而非当前的任期号）。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/a74a2bb5e0b34dd4a297d97a5584aa12.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeXpubO-8gQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>A作为Leader节点，记录了nextIndex[]和matchIndex[]，所以知道应该向节点C发送哪些日志，在本例中，Leader节点在下次发送Append Entries消息时会携带Index=2的消息（这里为了描述简单，每条消息只携带单条日志，Raft协议采用批量发送的方式，这样效率更高），如图2-15（1）所示。当节点C收到Append Entries消息后，会将日志记录到本地Log中，然后向Leader 节点返回追加日志成功的响应，当 Leader 节点收到响应之后，会递增节点 C 对应的nextIndex和matchIndex，这样Leader节点就知道下次发送日志的位置了，该过程如图2-15（2）所示。</p> \n <p>在上例中，当Leader节点并未发生过切换，所以Leader节点始终准确地知道节点C对应nextIndex值和matchIndex值。</p> \n <p>如果在上述示例中，在节点C故障恢复后，节点A宕机后重启，并且导致节点B成为新任期（Term=2）的 Leader 节点，则此时节点 B 并不知道旧 Leader 节点中记录的 nextIndex[]和matchIndex[]信息，所以新Leader节点会重置nextIndex[]和matchIndex[]，其中会将nextIndex[]全部重置为其自身Log的最后一条已提交日志的Index值，而matchIndex[]全部重置为0，如图2-16所示。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/67ef8d17747c49f08c2c890800d6cb1e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeXpubO-8gQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p><img src=\"https://img-blog.csdnimg.cn/27d53d3f03a34f7f9b6bf435ded2da51.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeXpubO-8gQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>随后，新任期中的Leader节点会向其他节点发送Append Entries消息，如图2-17（1）所示，节点A已经拥有了当前Leader的全部日志记录，所以会返回追加成功的响应并等待后续的日志，而节点C并没有Index=2和Index=3两条日志，所以返回追加日志失败的响应，在收到该响应后，Leader节点会将nextIndex前移，如图2-17（2）所示。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/77ed46f5a5d94a648e70b2c8401ff739.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeXpubO-8gQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>然后新 Leader 节点会再次尝试发送 Append Entries 消息，循环往复，不断减小 nextIndex值，直至节点C返回追加成功的响应，之后就进入了正常追加消息记录的流程，不再赘述。</p> \n <p>了解了 Log 日志及节点中基本的数据结构之后，请读者回顾前面描述的选举过程，</p> \n <p>其中Follower节点的投票过程并不像前面描述的那样简单（先收到哪个Candidate节点的选举请求，就将选票投给哪个Candidate节点），Follower节点还需要比较该Candidate节点的日志记录与自身的日志记录，拒绝那些日志没有自己新的Candidate节点发来的投票请求，确保将选票投给包含了全部已提交（committed）日志记录的 Candidate 节点。</p> \n <p>这也就保证了已提交的日志记录不会丢失：Candidate节点为了成为Leader节点，必然会在选举过程中向集群中半数以上的节点发送选举请求，因为已提交的日志记录必须存在集群中半数以上的节点中，这也就意味着每一条已提交的日志记录肯定在这些接收到节点中的至少存在一份。也就是说，记录全部已提交日志的节点和接收到Candidate节点的选举请求的节点必然存在交集，如图2-18所示。<br> <img src=\"https://img-blog.csdnimg.cn/972aece1557b4251aafbf9f3a39ea44d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeXpubO-8gQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>如果Candidate节点上的日志记录与集群中大多数节点上的日志记录一样新，那么其日志一定包含所有已经提交的日志记录，也就可以获得这些节点的投票并成为Leader。</p> \n <p>在比较两个节点的日志新旧时，Raft 协议通过比较两节点日志中的最后一条日志记录的索引值和任期号，以决定谁的日志比较新：首先会比较最后一条日志记录的任期号，如果最后的日志记录的任期号不同，那么任期号大的日志记录比较新；如果最后一条日志记录的任期号相同，那么日志索引较大的 比较新。</p> \n <p>这里只是大概介绍一下 Raft 协议的流程和节点使用的各种数据结构，读者需要了解的是Raft 协议的工作原理，如果对上述数据结构描述感到困惑，在后面介绍etcd-raft 模块时，还会再次涉及这些数据结构，到时候读者可以结合代码及这里的描述进一步进行分析。</p> \n <h2><a id=\"kubeproxy_1236\"></a>请详述kube-proxy原理?</h2> \n <p>​ 答：集群中每个Node上都会运行一个kube-proxy服务进程，他是Service的透明代理兼均衡负载器，其核心功能是将某个Service的访问转发到后端的多个Pod上。</p> \n <p>kube-proxy通过监听集群状态变更，并对本机iptables做修改，从而实现网络路由。</p> \n <p>而其中的负载均衡，也是通过iptables的特性实现的。</p> \n <p>从V1.8版本开始，用IPVS（IP Virtual Server）模式，用于路由规则的配置，主要优势是：</p> \n <p>1）为大型集群提供了更好的扩展性和性能。采用哈希表的数据结构，更高效；</p> \n <p>2）支持更复杂的负载均衡算法；</p> \n <p>3）支持服务器健康检查和连接重试；</p> \n <p>4）可以动态修改ipset的集合；</p> \n <h2><a id=\"flannel__ovs__1256\"></a>flannel 和 ovs 网络的区别？</h2> \n <p>​ 答：</p> \n <p>1）配置是否自动化：OpenvSwitch（ovs）作为开源的交换机软件，相对比较成熟和稳定，支持各种网络隧道和协议，经历了大型项目 OpenStack 的考验，而 flannel 除了支持建立覆盖网络来实现 Pod 到 Pod 之间的无缝通信之外，还跟 docker、k8s 的架构体系紧密结合，flannel 能感知 k8s 中的 service 对象，然后动态维护自己的路由表，并通过 etcd 来协助 docker 对整个 k8s 集群的 docker0 网段进行规范，而 ovs ，这些操作则需要手动完成，假如集群中有 N 个节点，则需要建立 N(N-1)/2 个 Vxlan 或者 gre 连接，这取决于集群的规模，如果集群的规模很大，则必须通过自动化脚本来初始化，避免出错。</p> \n <p>2）是否支持隔离：flannel 虽然很方便实现 Pod 到 Pod 之间的通信，但不能实现多租户隔离，也不能很好地限制 Pod 的网络流量，而 ovs 网络有两种模式：单租户模式和多租户模式，单租户模式直接使用 openvswitch + vxlan 将 k8s 的 pod 网络组成一个大二层，所有的 pod 可以互相通信访问，多租户模式以 Namespace 为维度分配虚拟网络，从而形成一个网络独立用户，一个 Namespace 中的 pod 无法访问其他 Namespace 中的 pod 和 svc 对象；</p> \n <h2><a id=\"k8sPod_1266\"></a>k8s集群外流量怎么访问Pod？</h2> \n <p>答：</p> \n <p>可以通过Service的NodePort方式访问，会在所有节点监听同一个端口，比如：30000，访问节点的流量会被重定向到对应的Service上面；</p> \n <h2><a id=\"K8S__QoS_1274\"></a>K8S 资源限制 QoS？</h2> \n <p>​ 答：Quality of Service（Qos）</p> \n <p>主要有三种类别：</p> \n <p>1）BestEffort：什么都不设置（CPU or Memory），佛系申请资源；</p> \n <p>2）Burstable：Pod 中的容器至少一个设置了CPU 或者 Memory 的请求；</p> \n <p>3）Guaranteed：Pod 中的所有容器必须设置 CPU 和 Memory，并且 request 和 limit 值相等；</p> \n <h2><a id=\"k8s_1288\"></a>k8s数据持久化的方式有哪些？</h2> \n <p>​ 答：</p> \n <p>1)EmptyDir（空目录）：没有指定要挂载宿主机上的某个目录，直接由Pod内保部映射到宿主机上。类似于docker中的manager volume；场景有：a.只需要临时将数据保存在磁盘上，比如在合并/排序算法中；b.作为两个容器的共享存储，使得第一个内容管理的容器可以将生成的数据存入其中，同时由同一个webserver容器对外提供这些页面;emptyDir的特性：同个pod里面的不同容器，共享同一个持久化目录，当pod节点删除时，volume的数据也会被删除。如果仅仅是容器被销毁，pod还在，则不会影响volume中的数据。总结来说：emptyDir的数据持久化的生命周期和使用的pod一致。一般是作为临时存储使用。</p> \n <p>2）Hostpath：将宿主机上已存在的目录或文件挂载到容器内部。类似于docker中的bind mount挂载方式；</p> \n <p>3）PersistentVolume（简称PV）：基于NFS服务的PV，也可以基于GFS的PV。它的作用是统一数据持久化目录，方便管理，PVC是向PV申请应用所需的容量大小，K8s集群中可能会有多个PV，PVC和PV若要关联，其定义的访问模式必须一致。定义的storageClassName也必须一致，若群集中存在相同的（名字、访问模式都一致）两个PV，那么PVC会选择向它所需容量接近的PV去申请，或者随机申请；</p> \n <h2><a id=\"K8S_1300\"></a>K8S的基本组成部分？</h2> \n <p>答：</p> \n <p>Master节点主要有五个组件，分别是kubectl、api-server、controller-manager、kube-scheduler 和 etcd；</p> \n <p>node节点主要有三个组件，分别是 kubelet、kube-proxy 和 容器运行时 docker 或者 rkt；</p> \n <p>kubectl：客户端命令行工具，作为整个系统的操作入口。<br> apiserver：以REST API服务形式提供接口，作为整个系统的控制入口。<br> controller-manager：执行整个系统的后台任务，包括节点状态状况、Pod个数、Pods和Service的关联等。<br> kube-scheduler：负责节点资源管理，接收来自kube-apiserver创建Pods任务，并分配到某个节点。<br> etcd：负责节点间的服务发现和配置共享。<br> kube-proxy：运行在每个计算节点上，负责Pod网络代理。定时从etcd获取到service信息来做相应的策略。<br> kubelet：运行在每个计算节点上，作为agent，接收分配该节点的Pods任务及管理容器，周期性获取容器状态，反馈给kube-apiserver。<br> DNS：一个可选的DNS服务，用于为每个Service对象创建DNS记录，这样所有的Pod就可以通过DNS访问服务了。</p> \n <h2><a id=\"K8s_1321\"></a>K8s中镜像的下载策略是什么？</h2> \n <p>​ 答：可通过命令“kubectl explain pod.spec.containers”来查看imagePullPolicy这行的解释，</p> \n <p>K8s的镜像下载策略有三种：</p> \n <p>Always：镜像标签为latest时，总是从指定的仓库中获取镜像；</p> \n <p>Never：禁止从仓库中下载镜像，也就是说只能使用本地镜像；</p> \n <p>IfNotPresent：仅当本地没有对应镜像时，才从目标仓库中下载；</p> \n <h2><a id=\"_1333\"></a>标签与标签选择器的作用是什么？</h2> \n <p>​ 答：标签：是当相同类型的资源对象越来越多的时候，为了更好的管理，可以按照标签将其分为一个组，为的是提升资源对象的管理效率；标签选择器：就是标签的查询过滤条件。</p> \n <h2><a id=\"K8s_1337\"></a>K8s的负载均衡器？</h2> \n <p>​ 答：负载均衡器是暴露服务的最常见和标准方式之一。</p> \n <p>根据工作环境使用两种类型的负载均衡器，即内部负载均衡器或外部负载均衡器。内部负载均衡器自动平衡负载并使用所需配置分配容器，而外部负载均衡器将流量从外部负载引导至后端容器；</p> \n <h2><a id=\"kubelet__Node__1343\"></a>kubelet 监控 Node 节点资源使用是通过什么组件来实现的？</h2> \n <p>​ 答：用Metrics Server提供核心指标，包括Node、Pod的CPU和内存的使用。而Metrics Server需要采集node上的cAdvisor提供的数据资源，</p> \n <p>当 kubelet 服务启动时，它会自动启动 cAdvisor 服务，然后 cAdvisor 会实时采集所在节点的性能指标及在节点上运行的容器的性能指标。</p> \n <p>kubelet 的启动参数 --cadvisor-port 可自定义 cAdvisor 对外提供服务的端口号，默认是 4194；</p> \n <h2><a id=\"Pod_1353\"></a>Pod的状态？</h2> \n <p>​ 答：</p> \n <p>1）Pending：已经创建了Pod，但是其内部还有容器没有创建；</p> \n <p>2）Running：Pod内部的所有容器都已经创建，只有由一个容器还处于运行状态或者重启状态；</p> \n <p>3）Succeeed：Pod内所有容器均已经成功执行并且退出，不会再重启；</p> \n <p>4）Failed：Pod内所有容器都退出，但至少有一个为退出失败状态；</p> \n <p>5）Unknown：由于某种原因不能获取该Pod的状态，可能是网络问题；</p> \n <h2><a id=\"deploymentrs_1369\"></a>deployment/rs的区别？</h2> \n <p>​ 答：deployment是rs的超集，提供更多的部署功能，如：回滚、暂停和重启、 版本记录、事件和状态查看、滚动升级和替换升级。</p> \n <p>如果能使用deployment，则不应再使用rc和rs；</p> \n <h2><a id=\"rcrs_1379\"></a>rc/rs实现原理？</h2> \n <p>答：</p> \n <p>Replication Controller 可以保证Pod始终处于规定的副本数，</p> \n <p>而当前推荐的做法是使用Deployment+ReplicaSet，</p> \n <p>ReplicaSet 号称下一代的 Replication Controller，当前唯一区别是RS支持set-based selector，</p> \n <p>RC是通过ReplicationManager监控RC和RC内Pod的状态，从而增删Pod，以实现维持特定副本数的功能，RS也是大致相同；</p> \n <h2><a id=\"kubernetes_1393\"></a>kubernetes服务发现？</h2> \n <p>答：</p> \n <p>1）环境变量： 当你创建一个Pod的时候，kubelet会在该Pod中注入集群内所有Service的相关环境变量。<strong>需要注意:</strong> 要想一个Pod中注入某个Service的环境变量，则必须Service要先比该Pod创建；</p> \n <p>2）DNS：可以通过cluster add-on方式轻松的创建KubeDNS来对集群内的Service进行服务发现；</p> \n <h2><a id=\"k8sservcie_1401\"></a>k8s发布(暴露)服务，servcie的类型有那些？</h2> \n <p>答：</p> \n <p>kubernetes原生的，一个Service的ServiceType决定了其发布服务的方式。</p> \n <p>1） ClusterIP：这是k8s默认的ServiceType。通过集群内的ClusterIP在内部发布服务。</p> \n <p>2）NodePort：这种方式是常用的，用来对集群外暴露Service，你可以通过访问集群内的每个NodeIP:NodePort的方式，访问到对应Service后端的Endpoint。</p> \n <p>3）LoadBalancer: 这也是用来对集群外暴露服务的，不同的是这需要Cloud Provider的支持，比如AWS等。</p> \n <p>4）ExternalName：这个也是在集群内发布服务用的，需要借助KubeDNS(version &gt;= 1.7)的支持，就是用KubeDNS将该service和ExternalName做一个Map，KubeDNS返回一个CNAME记录；</p> \n <h2><a id=\"ETCD_1417\"></a>简述ETCD及其特点?</h2> \n <p>答：etcd是一个分布式的、高可用的、一致的key-value存储数据库，基于Go语言实现，主要用于共享配置和服务发现。特点：</p> \n <p>1）完全复制：集群中的每个节点都可以使用完整的存档；</p> \n <p>2）高可用性：Etcd可用于避免硬件的单点故障或网络问题；</p> \n <p>3）一致性：每次读取都会返回跨多主机的最新写入；</p> \n <p>4）简单：包括一个定义良好、面向用户的API（gRPC）；</p> \n <p>5）安全：实现了带有可选的客户端证书身份验证的自动化TLS；</p> \n <p>6）快速：每秒10000次写入的基准速度；</p> \n <p>7）可靠：使用Raft算法实现了强一致、高可用的服务存储目录；</p> \n <h2><a id=\"ETCD_1437\"></a>简述ETCD适应的场景?</h2> \n <p>​ 答：</p> \n <p>1）服务发现：服务发现要解决的也是分布式系统中最常见的问题之一，即在同一个分布式集群中的进程或服务，要如何才能找到对方并建立连接。本质上来说，服务发现就是想要了解集群中是否有进程在监听udp或tcp端口，并且通过名字就可以查找和连接。</p> \n <p>2）消息发布与订阅：在分布式系统中，最实用对的一种组件间的通信方式：消息发布与订阅。构建一个配置共享中心，数据提供者在这个配置中心发布消息，而消息使用者订阅他们关心的主题，一旦主题有消息发布，就会实时通知订阅者。达成集中式管理与动态更新。应用中用到的一些配置信息放到etcd上进行集中管理。</p> \n <p>3）负载均衡：分布式系统中，为了保证服务的高可用以及数据的一致性，通常都会把数据和服务部署多份，以此达到对等服务，即使其中的某一个服务失效了，也不影响使用。etcd本身分布式架构存储的信息访问支持负载均衡。</p> \n <p>4）分布式通知与协调：通过注册与异步通知机制，实现分布式环境下不同系统之间的通知与协调，从而对数据变更做到实时处理。</p> \n <p>5）分布式锁：因为etcd使用Raft算法保持了数据的强一致性，某次操作存储到集群中的值必然是全局一致的，所以很容易实现分布式锁。锁服务有两种使用方式，一是保持独占，二是控制时序。</p> \n <p>6）分布式队列：分布式队列的常规用法与场景五中所描述的分布式锁的控制时序用法类似，即创建一个先进先出的队列，保证顺序。</p> \n <p>7）集群监控与Leader精选：通过etcd来进行监控实现起来非常简单并且实时性强；</p> \n <h2><a id=\"Kubernetes_RC_1459\"></a>简述Kubernetes RC的机制?</h2> \n <p>​ 答：Replication Controller用来管理Pod的副本，保证集群中存在指定数量的Pod副本。当定义了RC并提交至Kubernetes集群中之后，Master节点上的Controller Manager组件获悉，并同时巡检系统中当前存活的目标Pod，并确保目标Pod实例的数量刚好等于此RC的期望值，若存在过多的Pod副本在运行，系统会停止一些Pod，反之则自动创建一些Pod；</p> \n <h2><a id=\"kubeproxy_1465\"></a>简述kube-proxy作用?</h2> \n <p>答：kube-proxy 运行在所有节点上，它监听 apiserver 中 service 和 endpoint 的变化情况，创建路由规则以提供服务 IP 和负载均衡功能。</p> \n <p>简单理解此进程是Service的透明代理兼负载均衡器，其核心功能是将到某个Service的访问请求转发到后端的多个Pod实例上；</p> \n <h2><a id=\"kubeproxy_iptables_1475\"></a>简述kube-proxy iptables原理?</h2> \n <p>​ 答：Kubernetes从1.2版本开始，将iptables作为kube-proxy的默认模式。iptables模式下的kube-proxy不再起到Proxy的作用，其核心功能：通过API Server的Watch接口实时跟踪Service与Endpoint的变更信息，并更新对应的iptables规则，Client的请求流量则通过iptables的NAT机制“直接路由”到目标Pod；</p> \n <h2><a id=\"kubeproxy_ipvs_1479\"></a>简述kube-proxy ipvs原理?</h2> \n <p>答：IPVS在Kubernetes1.11中升级为GA稳定版。</p> \n <p>IPVS则专门用于高性能负载均衡，并使用更高效的数据结构（Hash表），允许几乎无限的规模扩张，因此被kube-proxy采纳为最新模式；</p> \n <p>在IPVS模式下，使用iptables的扩展ipset，而不是直接调用iptables来生成规则链。</p> \n <p>iptables规则链是一个线性的数据结构，ipset则引入了带索引的数据结构，因此当规则很多时，也可以很高效地查找和匹配；</p> \n <p>可以将ipset简单理解为一个IP（段）的集合，这个集合的内容可以是IP地址、IP网段、端口等，iptables可以直接添加规则对这个“可变的集合”进行操作，这样做的好处在于可以大大减少iptables规则的数量，从而减少性能损耗；</p> \n <h2><a id=\"kubeproxy_ipvsiptables_1491\"></a>简述kube-proxy ipvs和iptables的异同?</h2> \n <p>答：iptables与IPVS都是基于Netfilter实现的，但因为定位不同，二者有着本质的差别：</p> \n <p>iptables是为防火墙而设计的；IPVS则专门用于高性能负载均衡，并使用更高效的数据结构（Hash表），允许几乎无限的规模扩张。</p> \n <p>与iptables相比，IPVS拥有以下明显优势：为大型集群提供了更好的可扩展性和性能；支持比iptables更复杂的复制均衡算法（最小负载、最少连接、加权等）；支持服务器健康检查和连接重试等功能；可以动态修改ipset的集合，即使iptables的规则正在使用这个集合；</p> \n <h2><a id=\"KubernetesPod_1501\"></a>简述Kubernetes中什么是静态Pod?</h2> \n <p>答：静态pod是由kubelet进行管理的仅存在于特定Node的Pod上，他们不能通过API Server进行管理，无法与ReplicationController、Deployment或者DaemonSet进行关联，并且kubelet无法对他们进行健康检查。</p> \n <p>静态Pod总是由kubelet进行创建，并且总是在kubelet所在的Node上运行；</p> \n <h2><a id=\"Kubernetes_Pod_1511\"></a>简述Kubernetes Pod的常见调度方式?</h2> \n <p>答：</p> \n <p>1）Deployment或RC：该调度策略主要功能就是自动部署一个容器应用的多份副本，以及持续监控副本的数量，在集群内始终维持用户指定的副本数量；</p> \n <p>2）NodeSelector：定向调度，当需要手动指定将Pod调度到特定Node上，可以通过Node的标签（Label）和Pod的nodeSelector属性相匹配；</p> \n <p>3）NodeAffinity亲和性调度：亲和性调度机制极大的扩展了Pod的调度能力，目前有两种节点亲和力表达：硬规则，必须满足指定的规则，调度器才可以调度Pod至Node上（类似nodeSelector，语法不同）；软规则，优先调度至满足的Node的节点，但不强求，多个优先级规则还可以设置权重值；</p> \n <p>4）Taints和Tolerations（污点和容忍）：Taint：使Node拒绝特定Pod运行；Toleration：为Pod的属性，表示Pod能容忍（运行）标注了Taint的Node；</p> \n <h2><a id=\"Kubernetesinit_container_1527\"></a>简述Kubernetes初始化容器（init container）?</h2> \n <p>答：init container的运行方式与应用容器不同，它们必须先于应用容器执行完成，当设置了多个init container时，将按顺序逐个运行，并且只有前一个init container运行成功后才能运行后一个init container。</p> \n <p>当所有init container都成功运行后，Kubernetes才会初始化Pod的各种信息，并开始创建和运行应用容器；</p> \n <h2><a id=\"Kubernetes_deployment_1537\"></a>简述Kubernetes deployment升级过程?</h2> \n <p>答：</p> \n <p>初始创建Deployment时，系统创建了一个ReplicaSet，并按用户的需求创建了对应数量的Pod副本；</p> \n <p>当更新Deployment时，系统创建了一个新的ReplicaSet，并将其副本数量扩展到1，然后将旧ReplicaSet缩减为2；</p> \n <p>之后，系统继续按照相同的更新策略对新旧两个ReplicaSet进行逐个调整；</p> \n <p>最后，新的ReplicaSet运行了对应个新版本Pod副本，旧的ReplicaSet副本数量则缩减为0；</p> \n <h2><a id=\"Kubernetes_deployment_1553\"></a>简述Kubernetes deployment升级策略?</h2> \n <p>答：</p> \n <p>在Deployment的定义中，可以通过spec.strategy指定Pod更新的策略，</p> \n <p>目前支持两种策略：Recreate（重建）和RollingUpdate（滚动更新），</p> \n <p>默认值为RollingUpdate；</p> \n <p>Recreate：设置spec.strategy.type=Recreate，表示Deployment在更新Pod时，会先杀掉所有正在运行的Pod，然后创建新的Pod；</p> \n <p>RollingUpdate：设置spec.strategy.type=RollingUpdate，表示Deployment会以滚动更新的方式来逐个更新Pod。同时，可以通过设置spec.strategy.rollingUpdate下的两个参数（maxUnavailable和maxSurge）来控制滚动更新的过程；</p> \n <h2><a id=\"Kubernetes_DaemonSet_1569\"></a>简述Kubernetes DaemonSet类型的资源特性?</h2> \n <p>答：</p> \n <p>DaemonSet资源对象会在每个Kubernetes集群中的节点上运行，并且每个节点只能运行一个pod，这是它和deployment资源对象的最大也是唯一的区别。</p> \n <p>因此，在定义yaml文件中，不支持定义replicas。</p> \n <p>它的一般使用场景如下：在去做每个节点的日志收集工作。监控每个节点的的运行状态。</p> \n <h2><a id=\"Kubernetes_1581\"></a>简述Kubernetes自动扩容机制?</h2> \n <p>答：</p> \n <p>Kubernetes使用Horizontal Pod Autoscaler（HPA）的控制器实现基于CPU使用率进行自动Pod扩缩容的功能。</p> \n <p>HPA控制器周期性地监测目标Pod的资源性能指标，并与HPA资源对象中的扩缩容条件进行对比，在满足条件时对Pod副本数量进行调整；</p> \n <h2><a id=\"Kubernetes_Service_1593\"></a>简述Kubernetes Service分发后端的策略?</h2> \n <p>答：</p> \n <p>1）RoundRobin：默认为轮询模式，即轮询将请求转发到后端的各个Pod上；</p> \n <p>2）SessionAffinity：基于客户端IP地址进行会话保持的模式，即第1次将某个客户端发起的请求转发到后端的某个Pod上，之后从相同的客户端发起的请求都将被转发到后端相同的Pod上；</p> \n <h2><a id=\"Kubernetes_Headless_Service_1605\"></a>简述Kubernetes Headless Service?</h2> \n <p>答：在某些应用场景中，若需要人为指定负载均衡器，不使用Service提供的默认负载均衡的功能，或者应用程序希望知道属于同组服务的其他实例。</p> \n <p>Kubernetes提供了Headless Service来实现这种功能，即不为Service设置ClusterIP（入口IP地址），仅通过Label Selector将后端的Pod列表返回给调用的客户端；</p> \n <h2><a id=\"Kubernetes_1615\"></a>简述Kubernetes外部如何访问集群内的服务?</h2> \n <p>答：</p> \n <p>映射Pod到物理机：将Pod端口号映射到宿主机，即在Pod中采用hostPort方式，以使客户端应用能够通过物理机访问容器应用；</p> \n <p>映射Service到物理机：将Service端口号映射到宿主机，即在Service中采用nodePort方式，以使客户端应用能够通过物理机访问容器应用；</p> \n <p>映射Service到LoadBalancer：通过设置LoadBalancer映射到云服务商提供的LoadBalancer地址。这种用法仅用于在公有云服务提供商的云平台上设置Service的场景；</p> \n <h2><a id=\"Kubernetes_ingress_1629\"></a>简述Kubernetes ingress?</h2> \n <p>​ 答：</p> \n <p>K8s的Ingress资源对象，用于将不同URL的访问请求转发到后端不同的Service，以实现HTTP层的业务路由机制。</p> \n <p>K8s使用了Ingress策略和Ingress Controller，两者结合并实现了一个完整的Ingress负载均衡器。</p> \n <p>使用Ingress进行负载分发时，Ingress Controller基于Ingress规则将客户端请求直接转发到Service对应的后端Endpoint（Pod）上，从而跳过kube-proxy的转发功能，kube-proxy不再起作用，</p> \n <p>全过程为：ingress controller + ingress 规则 ----&gt; services；</p> \n <h2><a id=\"Kubernetes_1643\"></a>简述Kubernetes镜像的下载策略?</h2> \n <p>​ 答：</p> \n <p>1）Always：镜像标签为latest时，总是从指定的仓库中获取镜像；</p> \n <p>2）Never：禁止从仓库中下载镜像，也就是说只能使用本地镜像；</p> \n <p>3）IfNotPresent：仅当本地没有对应镜像时，才从目标仓库中下载；默认的镜像下载策略是：当镜像标签是latest时，默认策略是Always；当镜像标签是自定义时（也就是标签不是latest），那么默认策略是IfNotPresent；</p> \n <h2><a id=\"Kubernetes_1655\"></a>简述Kubernetes的负载均衡器?</h2> \n <p>​ 答：</p> \n <p>根据工作环境使用两种类型的负载均衡器，即内部负载均衡器或外部负载均衡器。</p> \n <p>内部负载均衡器自动平衡负载并使用所需配置分配容器，而外部负载均衡器将流量从外部负载引导至后端容器；</p> \n <h2><a id=\"KubernetesAPI_Server_1665\"></a>简述Kubernetes各模块如何与API Server通信?</h2> \n <p>答：K8s API Server作为集群的核心，负责集群各功能模块之间的通信。</p> \n <p>集群内的各个功能模块通过API Server将信息存入etcd，当需要获取和操作这些数据时，则通过API Server提供的REST接口（用GET、LIST或WATCH方法）来实现，从而实现各模块之间的信息交互。</p> \n <p>1）kubelet进程与API Server的交互：每个Node上的kubelet每隔一个时间周期，就会调用一次API Server的REST接口报告自身状态，API Server在接收到这些信息后，会将节点状态信息更新到etcd中；</p> \n <p>2）kube-controller-manager进程与API Server的交互：kube-controller-manager中的Node Controller模块通过API Server提供的Watch接口实时监控Node的信息，并做相应处理</p> \n <p>；3）kube-scheduler进程与API Server的交互：Scheduler通过API Server的Watch接口监听到新建Pod副本的信息后，会检索所有符合该Pod要求的Node列表，开始执行Pod调度逻辑，在调度成功后将Pod绑定到目标节点上；</p> \n <h2><a id=\"Kubernetes_Scheduler_1681\"></a>简述Kubernetes Scheduler作用及实现原理?</h2> \n <p>​ 答：</p> \n <p>Scheduler是负责Pod调度的重要功能模块，负责接收Controller Manager创建的新Pod，为其调度至目标Node，调度完成后，目标Node上的kubelet服务进程接管后继工作，负责Pod接下来生命周期；</p> \n <p>Scheduler的作用是将待调度的Pod，按照特定的调度算法和调度策略绑定（Binding）到集群中某个合适的Node上，并将绑定信息写入etcd中；</p> \n <p>Scheduler通过调度算法调度为待调度Pod列表中的每个Pod从Node列表中选择一个最适合的Node来实现Pod的调度。随后，目标节点上的kubelet通过API Server监听到Kubernetes Scheduler产生的Pod绑定事件，然后获取对应的Pod清单，下载Image镜像并启动容器；</p> \n <h2><a id=\"Kubernetes_SchedulerPodworker_1693\"></a>简述Kubernetes Scheduler使用哪两种算法将Pod绑定到worker节点?</h2> \n <p>​ 答：</p> \n <p>1）预选（Predicates）：输入是所有节点，输出是满足预选条件的节点。kube-scheduler根据预选策略过滤掉不满足策略的Nodes。如果某节点的资源不足或者不满足预选策略的条件则无法通过预选；</p> \n <p>2）优选（Priorities）：输入是预选阶段筛选出的节点，优选会根据优先策略为通过预选的Nodes进行打分排名，选择得分最高的Node。例如，资源越富裕、负载越小的Node可能具有越高的排名；</p> \n <h2><a id=\"Kubernetes_kubelet_1703\"></a>简述Kubernetes kubelet的作用?</h2> \n <p>​ 答：</p> \n <p>在Kubernetes集群中，在每个Node（又称Worker）上都会启动一个kubelet服务进程。</p> \n <p>该进程用于处理Master下发到本节点的任务，管理Pod及Pod中的容器。</p> \n <p>每个kubelet进程都会在API Server上注册节点自身的信息，定期向Master汇报节点资源的使用情况，并通过cAdvisor监控容器和节点资源；</p> \n <h2><a id=\"Kubernetes_kubeletWorker_1715\"></a>简述Kubernetes kubelet监控Worker节点资源是使用什么组件来实现的?</h2> \n <p>​ 答:</p> \n <p>kubelet使用cAdvisor对worker节点资源进行监控。</p> \n <p>在 Kubernetes 系统中，cAdvisor 已被默认集成到 kubelet 组件内，当 kubelet 服务启动时，它会自动启动 cAdvisor 服务，然后 cAdvisor 会实时采集所在节点的性能指标及在节点上运行的容器的性能指标；</p> \n <h2><a id=\"Kubernetes_1725\"></a>简述Kubernetes如何保证集群的安全性?</h2> \n <p>​ 答：</p> \n <p>1）基础设施方面：保证容器与其所在宿主机的隔离；</p> \n <p>2）用户权限：划分普通用户和管理员的角色；</p> \n <p>3）API Server的认证授权：Kubernetes集群中所有资源的访问和变更都是通过Kubernetes API Server来实现的，因此需要建议采用更安全的HTTPS或Token来识别和认证客户端身份（Authentication），以及随后访问权限的授权（Authorization）环节；</p> \n <p>4）API Server的授权管理：通过授权策略来决定一个API调用是否合法。对合法用户进行授权并且随后在用户访问时进行鉴权，建议采用更安全的RBAC方式来提升集群安全授权；</p> \n <p>5）AdmissionControl（准入机制）：对kubernetes api的请求过程中，顺序为：先经过认证 &amp; 授权，然后执行准入操作，最后对目标对象进行操作；</p> \n <h2><a id=\"Kubernetes_1741\"></a>简述Kubernetes准入机制?</h2> \n <p>答：</p> \n <p>在对集群进行请求时，每个准入控制代码都按照一定顺序执行。</p> \n <p>如果有一个准入控制拒绝了此次请求，那么整个请求的结果将会立即返回，并提示用户相应的error信息，准入控制（AdmissionControl）准入控制本质上为一段准入代码，在对kubernetes api的请求过程中，顺序为：先经过认证 &amp; 授权，然后执行准入操作，最后对目标对象进行操作。</p> \n <p>常用组件（控制代码）如下：</p> \n <p>AlwaysAdmit：允许所有请求；</p> \n <p>AlwaysDeny：禁止所有请求，多用于测试环境；</p> \n <p>ServiceAccount：它将serviceAccounts实现了自动化，它会辅助serviceAccount做一些事情，比如如果pod没有serviceAccount属性，它会自动添加一个default，并确保pod的serviceAccount始终存在；</p> \n <p>LimitRanger：观察所有的请求，确保没有违反已经定义好的约束条件，这些条件定义在namespace中LimitRange对象中；</p> \n <p>NamespaceExists：观察所有的请求，如果请求尝试创建一个不存在的namespace，则这个请求被拒绝；</p> \n <h2><a id=\"Kubernetes_RBAC_1763\"></a>简述Kubernetes RBAC及其特点（优势）?</h2> \n <p>​ 答：</p> \n <p>RBAC是基于角色的访问控制，是一种基于个人用户的角色来管理对计算机或网络资源的访问的方法，</p> \n <p>优势：</p> \n <p>1）对集群中的资源和非资源权限均有完整的覆盖；</p> \n <p>2）整个RBAC完全由几个API对象完成， 同其他API对象一样， 可以用kubectl或API进行操作；</p> \n <p>3）可以在运行时进行调整，无须重新启动API Server；</p> \n <h2><a id=\"Kubernetes_Secret_1779\"></a>简述Kubernetes Secret作用?</h2> \n <p>​ 答：</p> \n <p>Secret对象，主要作用是保管私密数据，比如密码、OAuth Tokens、SSH Keys等信息。</p> \n <p>将这些私密信息放在Secret对象中比直接放在Pod或Docker Image中更安全，也更便于使用和分发；</p> \n <h2><a id=\"Kubernetes_Secret_1789\"></a>简述Kubernetes Secret有哪些使用方式?</h2> \n <p>​ 答：</p> \n <p>1）在创建Pod时，通过为Pod指定Service Account来自动使用该Secret；</p> \n <p>2）通过挂载该Secret到Pod来使用它；</p> \n <p>3）在Docker镜像下载时使用，通过指定Pod的spc.ImagePullSecrets来引用它；</p> \n <h2><a id=\"Kubernetes_PodSecurityPolicy_1801\"></a>简述Kubernetes PodSecurityPolicy机制?</h2> \n <p>​ 答：</p> \n <p>Kubernetes PodSecurityPolicy是为了更精细地控制Pod对资源的使用方式以及提升安全策略。</p> \n <p>在开启PodSecurityPolicy准入控制器后，Kubernetes默认不允许创建任何Pod，需要创建PodSecurityPolicy策略和相应的RBAC授权策略（Authorizing Policies），Pod才能创建成功；</p> \n <h2><a id=\"Kubernetes_PodSecurityPolicy_1811\"></a>简述Kubernetes PodSecurityPolicy机制能实现哪些安全策略?</h2> \n <p>1）特权模式：privileged是否允许Pod以特权模式运行；</p> \n <p>2）宿主机资源：控制Pod对宿主机资源的控制，如hostPID：是否允许Pod共享宿主机的进程空间；</p> \n <p>3）用户和组：设置运行容器的用户ID（范围）或组（范围）；</p> \n <p>4）提升权限：AllowPrivilegeEscalation：设置容器内的子进程是否可以提升权限，通常在设置非root用户（MustRunAsNonRoot）时进行设置；</p> \n <p>5）SELinux：进行SELinux的相关配置；</p> \n <h2><a id=\"Kubernetes_1827\"></a>简述Kubernetes网络模型?</h2> \n <p>答：Kubernetes网络模型中每个Pod都拥有一个独立的IP地址，不管它们是否运行在同一个Node（宿主机）中，都要求它们可以直接通过对方的IP进行访问；</p> \n <p>同时为每个Pod都设置一个IP地址的模型使得同一个Pod内的不同容器会共享同一个网络命名空间，也就是同一个Linux网络协议栈。</p> \n <p>这就意味着同一个Pod内的容器可以通过localhost来连接对方的端口；在Kubernetes的集群里，IP是以Pod为单位进行分配的。一个Pod内部的所有容器共享一个网络堆栈；</p> \n <h2><a id=\"Kubernetes_CNI_1839\"></a>简述Kubernetes CNI模型?</h2> \n <p>答：</p> \n <p>Kubernetes CNI模型是对容器网络进行操作和配置的规范，通过插件的形式对CNI接口进行实现。</p> \n <p>CNI仅关注在创建容器时分配网络资源，和在销毁容器时删除网络资源。</p> \n <p>容器（Container）：是拥有独立Linux网络命名空间的环境，例如使用Docker或rkt创建的容器。容器需要拥有自己的Linux网络命名空间，这是加入网络的必要条件；</p> \n <p>网络（Network）：表示可以互连的一组实体，这些实体拥有各自独立、唯一的IP地址，可以是容器、物理机或者其他网络设备（比如路由器）等；</p> \n <h2><a id=\"Kubernetes_1855\"></a>简述Kubernetes网络策略?</h2> \n <p>​ 答：</p> \n <p>为实现细粒度的容器间网络访问隔离策略，K8s引入Network Policy主要功能是对Pod间的网络通信进行限制和准入控制，设置允许访问或禁止访问的客户端Pod列表。</p> \n <p>Network Policy定义网络策略，配合策略控制器（Policy Controller）进行策略的实现；</p> \n <h2><a id=\"Kubernetes_1865\"></a>简述Kubernetes网络策略原理?</h2> \n <p>​ 答：</p> \n <p>Network Policy的工作原理主要为：policy controller需要实现一个API Listener，监听用户设置的Network Policy定义，并将网络访问规则通过各Node的Agent进行实际设置（Agent则需要通过CNI网络插件实现）；</p> \n <h2><a id=\"Kubernetesflannel_1873\"></a>简述Kubernetes中flannel的作用?</h2> \n <p>​ 答：</p> \n <p>1）它能协助Kubernetes，给每一个Node上的Docker容器都分配互相不冲突的IP地址；</p> \n <p>2）它能在这些IP地址之间建立一个覆盖网络（Overlay Network），通过这个覆盖网络，将数据包原封不动地传递到目标容器内；</p> \n <h2><a id=\"Kubernetes_Calico_1883\"></a>简述Kubernetes Calico网络组件实现原理?</h2> \n <p>​ 答：</p> \n <p>Calico是一个基于BGP的纯三层的网络方案，与OpenStack、Kubernetes、AWS、GCE等云平台都能够良好地集成，Calico在每个计算节点都利用Linux Kernel实现了一个高效的vRouter来负责数据转发。每个vRouter都通过BGP协议把在本节点上运行的容器的路由信息向整个Calico网络广播，并自动设置到达其他节点的路由转发规则；Calico保证所有容器之间的数据流量都是通过IP路由的方式完成互联互通的。</p> \n <p>Calico节点组网时可以直接利用数据中心的网络结构（L2或者L3），不需要额外的NAT、隧道或者Overlay Network，没有额外的封包解包，能够节约CPU运算，提高网络效率；</p> \n <h2><a id=\"Kubernetes_1893\"></a>简述Kubernetes共享存储的作用?</h2> \n <p>​ 答：</p> \n <p>Kubernetes对于有状态的容器应用或者对数据需要持久化的应用，因此需要更加可靠的存储来保存应用产生的重要数据，以便容器应用在重建之后仍然可以使用之前的数据。因此需要使用共享存储；</p> \n <h2><a id=\"Kubernetes_PVPVC_1901\"></a>简述Kubernetes PV和PVC?</h2> \n <p>答：</p> \n <p>PV是对底层网络共享存储的抽象，将共享存储定义为一种“资源”；</p> \n <p>PVC则是用户对存储资源的一个“申请”；</p> \n <h2><a id=\"Kubernetes_PV_1911\"></a>简述Kubernetes PV生命周期内的阶段?</h2> \n <p>答：</p> \n <p>1）Available：可用状态，还未与某个PVC绑定；</p> \n <p>2）Bound：已与某个PVC绑定；</p> \n <p>3）Released：绑定的PVC已经删除，资源已释放，但没有被集群回收；</p> \n <p>4）Failed：自动资源回收失败；</p> \n <h2><a id=\"Kubernetes_CSI_1923\"></a>简述Kubernetes CSI模型?</h2> \n <p>答：</p> \n <p>CSI是Kubernetes推出与容器对接的存储接口标准，存储提供方只需要基于标准接口进行存储插件的实现，就能使用Kubernetes的原生存储机制为容器提供存储服务，CSI使得存储提供方的代码能和Kubernetes代码彻底解耦，部署也与Kubernetes核心组件分离；</p> \n <p>CSI包括CSI Controller：的主要功能是提供存储服务视角对存储资源和存储卷进行管理和操作；Node的主要功能是对主机（Node）上的Volume进行管理和操作；</p> \n <h2><a id=\"Kubernetes_Worker_1931\"></a>简述Kubernetes Worker节点加入集群的过程?</h2> \n <p>​ 答：在该Node上安装Docker、kubelet和kube-proxy服务； 然后配置kubelet和kubeproxy的启动参数，将Master URL指定为当前Kubernetes集群Master的地址，最后启动这些服务； 通过kubelet默认的自动注册机制，新的Worker将会自动加入现有的Kubernetes集群中； Kubernetes Master在接受了新Worker的注册之后，会自动将其纳入当前集群的调度范围；</p> \n <h2><a id=\"Kubernetes_Pod_1935\"></a>简述Kubernetes Pod如何实现对节点的资源控制?</h2> \n <p>​ 答：</p> \n <p>Kubernetes集群里的节点提供的资源主要是计算资源，计算资源是可计量的能被申请、分配和使用的基础资源。当前Kubernetes集群中的计算资源主要包括CPU、GPU及Memory。</p> \n <p>CPU与Memory是被Pod使用的，因此在配置Pod时可以通过参数CPU Request及Memory Request为其中的每个容器指定所需使用的CPU与Memory量，Kubernetes会根据Request的值去查找有足够资源的Node来调度此Pod；</p> \n <h2><a id=\"Kubernetes_RequestsLimitsPod_1945\"></a>简述Kubernetes Requests和Limits如何影响Pod的调度?</h2> \n <p>​ 答：</p> \n <p>当一个Pod创建成功时，Kubernetes调度器（Scheduler）会为该Pod选择一个节点来执行。对于每种计算资源（CPU和Memory）而言，每个节点都有一个能用于运行Pod的最大容量值。调度器在调度时，首先要确保调度后该节点上所有Pod的CPU和内存的Requests总和，不超过该节点能提供给Pod使用的CPU和Memory的最大容量值；</p> \n <h2><a id=\"Kubernetes_Metric_Service_1953\"></a>简述Kubernetes Metric Service?</h2> \n <p>答：在Kubernetes从1.10版本后采用Metrics Server作为默认的性能数据采集和监控，主要用于提供核心指标（Core Metrics），包括Node、Pod的CPU和内存使用指标。</p> \n <p>对其他自定义指标（Custom Metrics）的监控则由Prometheus等组件来完成；</p> \n <h2><a id=\"KubernetesEFK_1963\"></a>简述Kubernetes中，如何使用EFK实现日志的统一管理？</h2> \n <p>答：</p> \n <p>在Kubernetes集群环境中，通常一个完整的应用或服务涉及组件过多，建议对日志系统进行集中化管理，EFK是 Elasticsearch、Fluentd 和 Kibana 的组合，</p> \n <p>Elasticsearch：是一个搜索引擎，负责存储日志并提供查询接口；</p> \n <p>Fluentd：负责从 Kubernetes 搜集日志，每个node节点上面的fluentd监控并收集该节点上面的系统日志，并将处理过后的日志信息发送给Elasticsearch；</p> \n <p>Kibana：提供了一个 Web GUI，用户可以浏览和搜索存储在 Elasticsearch 中的日志；</p> \n <h2><a id=\"Kubernetes_1979\"></a>简述Kubernetes如何进行优雅的节点关机维护?</h2> \n <p>​ 答：由于Kubernetes节点运行大量Pod，因此在进行关机维护之前，建议先使用kubectl drain将该节点的Pod进行驱逐，然后进行关机维护；</p> \n <h2><a id=\"Kubernetes_1985\"></a>简述Kubernetes集群联邦?</h2> \n <p>​ 答：Kubernetes集群联邦可以将多个Kubernetes集群作为一个集群进行管理。因此，可以在一个数据中心/云中创建多个Kubernetes集群，并使用集群联邦在一个地方控制/管理所有集群；</p> \n <h2><a id=\"Helm_1991\"></a>简述Helm及其优势?</h2> \n <p>​ 答：Helm 是 Kubernetes 的软件包管理工具，Helm能够将一组K8S资源打包统一管理, 是查找、共享和使用为Kubernetes构建的软件的最佳方式。 Helm中通常每个包称为一个Chart，一个Chart是一个目录，优势：1）统一管理、配置和更新这些分散的 k8s 的应用资源文件；2）分发和复用一套应用模板；3）将应用的一系列资源当做一个软件包管理；4）对于应用发布者而言，可以通过 Helm 打包应用、管理应用依赖关系、管理应用版本并发布应用到软件仓库；5）对于使用者而言，使用 Helm 后不用需要编写复杂的应用部署文件，可以以简单的方式在 Kubernetes 上查找、安装、升级、回滚、卸载应用程序；</p> \n <h2><a id=\"_1997\"></a>标签与标签选择器的作用是什么?</h2> \n <p>​ 答：</p> \n <p>1）标签可以附加在kubernetes任何资源对象之上的键值型数据，常用于标签选择器的匹配度检查，从而完成资源筛选；</p> \n <p>2）标签选择器用于表达标签的查询条件或选择标准，Kubernetes API目前支持两个选择器：基于等值关系（equality-based）的标签选项器以及基于集合关系（set-based）的标签选择器；</p> \n <h2><a id=\"Google_2007\"></a>什么是Google容器引擎?</h2> \n <p>​ 答：Google Container Engine（GKE）是Docker容器和集群的开源管理平台。这个基于 Kubernetes的引擎仅支持在Google的公共云服务中运行的群集；</p> \n <h2><a id=\"image_2017\"></a>image的状态有那些？</h2> \n <p>​ 答：</p> \n <p>1）Running：Pod所需的容器已经被成功调度到某个节点，且已经成功运行；</p> \n <p>2）Pending：APIserver创建了pod资源对象，并且已经存入etcd中，但它尚未被调度完成或者仍然处于仓库中下载镜像的过程；</p> \n <p>3）Unknown：APIserver无法正常获取到pod对象的状态，通常是其无法与所在工作节点的kubelet通信所致；</p> \n <h2><a id=\"Service_2029\"></a>Service这种资源对象的作用是什么?</h2> \n <p>​ 答：</p> \n <p>service就是将多个POD划分到同一个逻辑组中，并统一向外提供服务，POD是通过Label Selector加入到指定的service中。</p> \n <p>Service相当于是一个负载均衡器，用户请求会先到达service，再由service转发到它内部的某个POD上，通过 services.spec.type 字段来指定：</p> \n <p>1）ClusterIP：用于集群内部访问。该类型会为service分配一个IP，集群内部请求先到达service，再由service转发到其内部的某个POD上；</p> \n <p>2）NodePort：用于集群外部访问。该类型会将Service的Port映射到集群的每个Node节点上，然后在集群之外，就能通过Node节点上的映射端口访问到这个Service；</p> \n <p>3）LoadBalancer：用于集群外部访问。该类型是在所有Node节点前又挂了一个负载均衡器，作为集群外部访问的统一入口，外部流量会先到达LoadBalancer，再由它转发到集群的node节点上，通过nodePort再转发给对应的service，最后由service转发到后端Pod中；</p> \n <p>4）ExternalName：创建一个DNS别名（即CNAME）并指向到某个Service Name上，也就是为某个Service Name添加一条CNAME记录，当有请求访问这个CNAME时会自动解析到这个Service Name上；</p> \n <h2><a id=\"_2047\"></a>常用的标签分类有哪些?</h2> \n <p>​ 答：release（版本）：stable（稳定版）、canary（金丝雀版本）、beta（测试版本）、environment（环境变量）：dev（开发）、qa（测试）、production（生产）、application（应用）：ui、as（application software应用软件）、pc、sc、tier（架构层级）：frontend（前端）、backend（后端）、cache（缓存）、partition（分区）：customerA（客户A）、customerB（客户B）、track（品控级别）：daily（每天）、weekly（每周）；</p> \n <h2><a id=\"Job_2053\"></a>说说你对Job这种资源对象的了解?</h2> \n <p>​ 答：</p> \n <p>Job控制一组Pod容器，可以通过Job这种资源对象定义并启动一个批处理任务的Job，其中Job所控制的Pod副本是短暂运行的，可以将其视为一组Docker容器，每个Docker容器都仅仅运行一次，当Job控制的所有Pod的副本都运行结束时，对应的Job也就结来。</p> \n <p>Job生成的副本是不能自动重启的，对应的Pod副本的RestartPolicy都被设置为Never。</p> \n <p>Job所控制的Pod副本的工作模式能够多实例并行计算。</p> \n <h2><a id=\"k8s_2065\"></a>k8s是怎么进行服务注册的?</h2> \n <p>​ 答：</p> \n <p>1）Service创建的时候会向 API Server 用 POST 方式提交一个新的 Service 定义，这个请求需要经过认证、鉴权以及其它的准入策略检查过程之后才会放行；</p> \n <p>2）CoreDns 会为Service创建一个dns记录，Service 得到一个 ClusterIP（虚拟 IP 地址），并保存到集群数据仓库；</p> \n <p>3）在集群范围内传播 Service 配置；</p> \n <h2><a id=\"KubernetesDocker_Swarm_2077\"></a>Kubernetes与Docker Swarm的区别如何?</h2> \n <p>​ 答：</p> \n <p>1）安装和部署：k8s安装很复杂;但是一旦安装完毕，集群就非常强大，Docker Swarm安装非常简单;但是集群不是很强大;2)图形用户界面：k8s有，Docker Swarm无；</p> \n <p>3）可伸缩性：k8s支持，Docker Swarm比k8s快5倍；</p> \n <p>4）自动伸缩：k8s有，Docker Swarm无；</p> \n <p>5）负载均衡：k8s在不同的Pods中的不同容器之间平衡负载流量，需要手动干预，Docker Swarm可以自动平衡集群中容器之间的流量；</p> \n <p>6）滚动更新回滚：k8s支持，Docker Swarm可以部署滚动更新，但不能自动回滚；</p> \n <p>7）数据量：k8s可以共享存储卷。只能与其他集装箱在同一Pod，Docker Swarm可以与任何其他容器共享存储卷；</p> \n <p>8）日志记录和监控：k8s内置的日志和监控工具，Docker Swarm要用第三方工具进行日志记录和监控；</p> \n <h2><a id=\"Container_Orchestration_2097\"></a>什么是Container Orchestration?</h2> \n <p>答：</p> \n <p>1）资源编排 - 负责资源的分配，如限制 namespace 的可用资源，scheduler 针对资源的不同调度策略；</p> \n <p>2）工作负载编排 - 负责在资源之间共享工作负载，如 Kubernetes 通过不同的 controller 将 Pod 调度到合适的 node 上，并且负责管理它们的生命周期；</p> \n <p>3）服务编排 - 负责服务发现和高可用等，如 Kubernetes 中可用通过 Service 来对内暴露服务，通过 Ingress 来对外暴露服务；容器编排常用的控制器有：Deployment 经常被作为无状态实例控制器使用; StatefulSet 是一个有状态实例控制器; DaemonSet 可以指定在选定的 Node 上跑，每个 Node 上会跑一个副本，它有一个特点是它的 Pod 的调度不经过调度器，在 Pod 创建的时候就直接绑定 NodeName；最后一个是定时任务，它是一个上级控制器，和 Deployment 有些类似，当一个定时任务触发的时候，它会去创建一个 Job ，具体的任务实际上是由 Job 来负责执行的；</p> \n <h2><a id=\"Heapster_2111\"></a>什么是Heapster?</h2> \n <p>​ 答：</p> \n <p>Heapster 是 K8s 原生的集群监控方案。</p> \n <p>Heapster 以 Pod 的形式运行，它会自动发现集群节点、从节点上的 Kubelet 获取监控数据。Kubelet 则是从节点上的 cAdvisor 收集数据；</p> \n <h2><a id=\"k8s_Architecture_2121\"></a>k8s Architecture的不同组件有哪些?</h2> \n <p>​ 答：</p> \n <p>主要有两个组件 – 主节点和工作节点。</p> \n <p>主节点具有kube-controller-manager，kube-apiserver，kube-scheduler等组件。</p> \n <p>而工作节点具有kubelet和kube-proxy等组件；</p> \n <h2><a id=\"Kubernetes_2133\"></a>能否介绍一下Kubernetes中主节点的工作情况?</h2> \n <p>​ 答：</p> \n <p>主节点是集群控制节点，负责集群管理和控制，包含：</p> \n <p>1）apiserver: rest接口，资源增删改查入口；</p> \n <p>2）controller-manager:所有资源对象的控制中心；</p> \n <p>3）scheduler:负责资源调度，例如pod调度；</p> \n <p>4）etcd: 保存资源对象数据；</p> \n <h2><a id=\"kubeapiserverkubescheduler_2149\"></a>kube-apiserver和kube-scheduler的作用是什么？</h2> \n <p>​ 答：</p> \n <p>kube-apiserver: rest接口，增删改查接口，集群内模块通信；</p> \n <p>kube-scheduler: 将待调度的pod按照调度算法绑定到合适的pod，并将绑定信息写入etcd；</p> \n <h2><a id=\"Kubernetes_2157\"></a>你能简要介绍一下Kubernetes控制管理器吗？</h2> \n <p>Kubernetes控制管理器是集群内部的控制中心，负责node,pod,namespace等管理，</p> \n <p>控制管理器负责管理各种控制器，每个控制器通过api server监控资源对象状态，将现有状态修正到期望状态；</p> \n <h2><a id=\"Kubernetes_2167\"></a>Kubernetes有哪些不同类型的服务？</h2> \n <ul>\n  <li>ClusterIP、</li>\n  <li>NodePort、</li>\n  <li>LoadBalancer、</li>\n  <li>ExternalName；</li>\n </ul> \n <h2><a id=\"Kubernetes_2178\"></a>你对Kubernetes的负载均衡器有什么了解？</h2> \n <p>答：</p> \n <p>1）内部负载均衡器: 自动平衡负载并使用所需配置分配容器；</p> \n <p>2）外部负载均衡器: 将流量从外部负载引导至后端容器；</p> \n <h2><a id=\"Kubernetes_2188\"></a>使用Kubernetes时可以采取哪些最佳安全措施?</h2> \n <p>​</p> \n <p>1）确保容器本身安全；</p> \n <p>2）锁定容器的Linux内核；</p> \n <p>3）使用基于角色的访问控制（RBAC）；</p> \n <p>4）保守秘密的辛勤工作；5）保持网络安全；</p> \n <p>​</p> \n <h2><a id=\"_2206\"></a>参考文献：</h2> \n <p>https://blog.csdn.net/qq_21222149/article/details/89201744</p> \n <p>https://blog.csdn.net/warrior_0319/article/details/80073720<br> http://www.sel.zju.edu.cn/?p=840<br> http://alexander.holbreich.org/docker-components-explained/<br> https://www.cnblogs.com/sparkdev/p/9129334.htmls</p> \n <h2><a id=\"_2217\"></a>推荐阅读：</h2> \n <ul>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128670335\">Docker面试题（史上最全 + 持续更新）</a>》</p> </li>\n  <li> <p>《 <a href=\"https://blog.csdn.net/crazymakercircle/article/details/128533821\">场景题：假设10W人突访，你的系统如何做到不 雪崩？</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124790425\">尼恩Java面试宝典</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057567\">Springcloud gateway 底层原理、核心实战 (史上最全)</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124120506\">Flux、Mono、Reactor 实战（史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125059491\">sentinel （史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057545\">Nacos (史上最全)</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/123420859\">分库分表 Sharding-JDBC 底层原理、核心实战（史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/114527369\">TCP协议详解 (史上最全)</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126992542\">clickhouse 超底层原理 + 高可用实操 （史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120702536\">nacos高可用（图解+秒懂+史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264803\">队列之王： Disruptor 原理、架构、源码 一文穿透</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264508\">环形队列、 条带环形队列 Striped-RingBuffer （史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125135726\">一文搞定：SpringBoot、SLF4j、Log4j、Logback、Netty之间混乱关系（史上最全）</a></p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128265067\">单例模式（史上最全）</a></p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125017316\">红黑树（ 图解 + 秒懂 + 史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/109459593\">分布式事务 （秒懂）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128123114\">缓存之王：Caffeine 源码、架构、原理（史上最全，10W字 超级长文）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/113751575\">缓存之王：Caffeine 的使用（史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126579528\">Java Agent 探针、字节码增强 ByteBuddy（史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120747767\">Docker原理（图解+秒懂+史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/116425814\">Redis分布式锁（图解 - 秒懂 - 史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85956246\">Zookeeper 分布式锁 - 图解 - 秒懂</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85922561\">Zookeeper Curator 事件监听 - 10分钟看懂</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83957259\">Netty 粘包 拆包 | 史上最全解读</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83758107\">Netty 100万级高并发服务器配置</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/102557988\">Springcloud 高并发 配置 （一文全懂）</a>》</p> </li>\n </ul> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 3299);
INSERT INTO `crawlerblog` VALUES (123124014, '操作系统面试题（史上最全、持续更新）', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <h2><a id=\"40_0\"></a>尼恩面试宝典专题40：操作系统面试题（史上最全、持续更新）</h2> \n <h4><a id=\"V28_1\"></a>本文版本说明：V28</h4> \n <h2><a id=\"_3\"></a>《尼恩面试宝典》升级规划为：</h2> \n <p>后续基本上，<strong>每一个月，都会发布一次</strong>，最新版本，可以联系构师尼恩获取， 发送 “领取电子书” 获取。</p> \n <hr> \n <h2><a id=\"_9\"></a>操作系统基础篇</h2> \n <p>在信息化时代，软件被称为计算机系统的灵魂。而作为软件核心的操作系统，已经与现代计算机系统密不可分、融为一体。计算机系统自下而上可粗分为四个部分：<code>硬件</code>、<code>操作系统</code>、<code>应用程序</code>和<code>用户</code>。操作系统管理各种计算机硬件，为应用程序提供基础，并充当计算机硬件和用户的中介。</p> \n <p>硬件，如中央处理器、内存、输入输出设备等，提供了基本的计算资源。应用程序，如字处理程序、电子制表软件、编译器、网络浏览器等，规定了按何种方式使用这些资源来解决用户的计算问题。操作系统控制和协调各用户的应用程序对硬件的使用。</p> \n <p>综上所述，操作系统是指控制和管理整个计算机系统的硬件和软件资源，并合理的组织调度计算机的工作和资源的分配，以提供给用户和其他软件方便的接口和环境集合。计算机操作系统是随着计算机研究和应用的发展逐步形成并发展起来的，它是计算机系统中最基本的系统软件。</p> \n <h3><a id=\"_17\"></a>操作系统的特征</h3> \n <p>操作系统是一种系统软件，但与其他的系统软件和应用软件有很大的不同，他有自己的特殊性即基本特征，操作系统的基本特征包括<code>并发</code>、<code>共享</code>、<code>虚拟</code>和<code>异步</code>。这些概念对理解和掌握操作系统的核心至关重要。</p> \n <h4><a id=\"_21\"></a>并发</h4> \n <p>并发是指两个或多个事件在同一时间间隔内发生，在多道程序环境下，一段时间内宏观上有多个程序在同时执行，而在同一时刻，单处理器环境下实际上只有一个程序在执行，故微观上这些程序还是在分时的交替进行。操作系统的并发是通过分时得以实现的。操作系统的并发性是指计算机系统中同时存在多个运行着的程序，因此它具有处理和调度多个程序同时执行的能力。在操作系统中，引入进程的目的实施程序能并发执行。</p> \n <h4><a id=\"_25\"></a>共享</h4> \n <p>资源共享即共享，是指系统中的资源可供内存中多个并发执行的进程共同使用。共享可以分为以下两种资源共享方式。</p> \n <h5><a id=\"_29\"></a>互斥共享方式</h5> \n <p>系统中的某些资源，，如打印机、磁带机，虽然他们可以提供给多个进程使用，但为使所打印的内容不致造成混淆，应规定在同一段时间内只允许一个进程方位该资源。</p> \n <p>为此，当进程a访问某资源时，必须先提出请求，如果此时该资源空闲，系统便可将之分配给进程a使用，伺候若再有其他进程也要访问该资源（只要a未用完）则必须等待。仅当进程a访问完并释放该资源后，才允许另一进城对该资源进行访问。计算机系统中的大所属物理设备，以及某些软件中所用的栈、变量和表格，都属于临界资源，他们都要求被互斥的共享。</p> \n <h5><a id=\"_35\"></a>同时访问方式</h5> \n <p>系统中还有一种资源，允许在一段时间内由多个进程“同时”对它进行访问。这里所谓的“同时”往往是宏观上的，而在微观上，这些进程可能是交替的对该资源进行访问即“分时共享”。典型的可供多个进程同时访问的资源是磁盘设备，一些用重入码编写的文件也可以被 “同时” 共享，即若干个用户同时访问该文件。</p> \n <p>并发和共享是操作系统两个最基本的特征，这两者之间又是互为存在条件的：1资源共享是以程序的并发为条件的，若系统不允许程序并发执行，则自然不存在资源共享的问题；2若系统不能对资源共享实施有效地管理，也必将影响到程序的并发执行，甚至根本无法并发执行。</p> \n <h4><a id=\"_41\"></a>虚拟</h4> \n <p>虚拟是指把一个物理上的实体变为若干个逻辑上的对应物。物理实体是实的，即实际存在的；而后者是虚的，是用户感觉上的事物。相应的，用于实现虚拟的技术，成为虚拟技术。在操作系统中利用了多种虚拟技术，分别用来实现虚拟处理器、虚拟内存和虚拟外部设备。</p> \n <p>在虚拟处理器技术中，是通过多道程序设计技术，让多道程序并发执行的方法，来分时使用一台处理器的。此时，虽然只有一台处理器，但他能同时为多个用户服务，是每个终端用户都认为是有一个中央处理器在为他服务。利用多道程序设计技术，把一台物理上的 CPU 虚拟为多台逻辑上的 CPU，称为虚拟处理器。</p> \n <p>类似的，可以通过虚拟存储器技术，将一台机器的物理存储器变为虚拟存储器，一边从逻辑上来扩充存储器的容量。当然， 这是用户所感觉到的内存容量是虚的，我们把用户所发哦绝倒的存储器程序虚拟存储器。</p> \n <p>还可以通过虚拟设备技术，将一台物理IO设备虚拟为多台逻辑上的IO设备，并允许每个用户占用一台逻辑上的 IO 设备，这样便可使原来仅允许在一段时间内有一个用户访问的设备，变为在一段时间内允许多个用户同时访问的共享设备。</p> \n <p>因此操作系统的虚拟技术可归纳为：<code>时分复用技术</code>和<code>空分复用技术</code>。</p> \n <h4><a id=\"_53\"></a>异步</h4> \n <p>在多道程序环境下，允许多个程序并发执行，但由于资源有限，进程的执行不是一贯到底，而是走走停停，以不可预知的速度向前推进，这就是进程的异步性。</p> \n <p>异步性使得操作系统运行在一种随机的环境下，可能导致进程产生于时间有关的错误。但是只要运行环境相同，操作系统必须保证多次运行进程，都获得相同的结果。</p> \n <h3><a id=\"_61\"></a>操作系统五大功能</h3> \n <p>一般来说，操作系统可以分为五大管理功能部分：</p> \n <ol>\n  <li><code>设备管理</code>：主要是负责内核与外围设备的数据交互，实质是对硬件设备的管理，包括对输入输出设备的分配，初始化，维护与回收等。例如管理音频输入输出。</li>\n  <li><code>作业管理</code>：这部分功能主要是负责人机交互，图形界面或者系统任务的管理。</li>\n  <li><code>文件管理</code>：这部分功能涉及文件的逻辑组织和物理组织，目录结构和管理等。从操作系统的角度来看，文件系统是系统对文件存储器的存储空间进行分配，维护和回收，同时负责文件的索引，共享和权限保护。而从用户的角度来说，文件系统是按照文件目录和文件名来进行存取的。</li>\n  <li><code>进程管理</code>：说明一个进程存在的唯一标志是 pcb（进程控制块），负责维护进程的信息和状态。进程管理实质上是系统采取某些进程调度算法来使处理合理的分配给每个任务使用。</li>\n  <li><code>存储管理</code>：数据的存储方式和组织结构。</li>\n </ol> \n <h3><a id=\"_71\"></a>操作系统分类</h3> \n <p>操作系统的类型也可以分为几种：批处理系统，分时操作系统，实时操作系统，网络操作系统等。下面将简单的介绍他们各自的特点：</p> \n <ol>\n  <li><code>批处理系统</code>：首先，用户提交完作业后并在获得结果之前不会再与操作系统进行数据交互，用户提交的作业由系统外存储存为后备作业；数据是成批处理的，有操作系统负责作业的自动完成；支持多道程序运行。</li>\n  <li><code>分时操作系统</code>：首先交互性方面，用户可以对程序动态运行时对其加以控制；支持多个用户登录终端，并且每个用户共享CPU和其他系统资源。</li>\n  <li><code>实时操作系统</code>：会有时钟管理，包括定时处理和延迟处理。实时性要求比较高，某些任务必须优先处理，而有些任务则会被延迟调度完成。</li>\n  <li><code>网络操作系统</code>：网络操作系统主要有几种基本功能 \n   <ol>\n    <li>网络通信：负责在源主机与目标主机之间的数据的可靠通信，这是最基本的功能。</li>\n    <li>网络服务：系统支持一些电子邮件服务，文件传输，数据共享，设备共享等。</li>\n    <li>资源管理：对网络中共享的资源进行管理，例如设置权限以保证数据源的安全性。</li>\n    <li>网络管理：主要任务是实现安全管理，例如通过“存取控制”来确保数据的存取安全性，通过“容错性”来保障服务器故障时数据的安全性。</li>\n    <li>支持交互操作：在客户/服务器模型的LAN环境下，多种客户机和主机不仅能与服务器进行数据连接通信，并且可以访问服务器的文件系统。</li>\n   </ol> </li>\n </ol> \n <h3><a id=\"_87\"></a>聊聊：什么是操作系统</h3> \n <p><strong>操作系统是管理硬件和软件的一种应用程序</strong>。操作系统是运行在计算机上最重要的一种<code>软件</code>，它管理计算机的资源和进程以及所有的硬件和软件。它为计算机硬件和软件提供了一种中间层，使应用软件和硬件进行分离，让我们无需关注硬件的实现，把关注点更多放在软件应用上。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/e04c7b7a7547b3f8ddf6044a99aacf10.png\" alt=\"\"></p> \n <p>通常情况下，计算机上会运行着许多应用程序，它们都需要对内存和 CPU 进行交互，操作系统的目的就是为了保证这些访问和交互能够准确无误的进行。</p> \n <h3><a id=\"_95\"></a>聊聊：操作系统的主要功能</h3> \n <p>一般来说，现代操作系统主要提供下面几种功能</p> \n <ul>\n  <li><code>进程管理</code>: 进程管理的主要作用就是任务调度，在单核处理器下，操作系统会为每个进程分配一个任务，进程管理的工作十分简单；而在多核处理器下，操作系统除了要为进程分配任务外，还要解决处理器的调度、分配和回收等问题</li>\n  <li><code>内存管理</code>：内存管理主要是操作系统负责管理内存的分配、回收，在进程需要时分配内存以及在进程完成时回收内存，协调内存资源，通过合理的页面置换算法进行页面的换入换出</li>\n  <li><code>设备管理</code>：根据确定的设备分配原则对设备进行分配，使设备与主机能够并行工作，为用户提供良好的设备使用界面。</li>\n  <li><code>文件管理</code>：有效地管理文件的存储空间，合理地组织和管理文件系统，为文件访问和文件保护提供更有效的方法及手段。</li>\n  <li><code>提供用户接口</code>：操作系统提供了访问应用程序和硬件的接口，使用户能够通过应用程序发起系统调用从而操纵硬件，实现想要的功能。</li>\n </ul> \n <h3><a id=\"_105\"></a>聊聊：软件访问硬件的几种方式</h3> \n <p>软件访问硬件其实就是一种 IO 操作，软件访问硬件的方式，也就是 I/O 操作的方式有哪些。</p> \n <p>硬件在 I/O 上大致分为<strong>并行和串行</strong>，同时也对应串行接口和并行接口。</p> \n <p>随着计算机技术的发展，I/O 控制方式也在不断发展。选择和衡量 I/O 控制方式有如下三条原则</p> \n <blockquote> \n  <p>（1） 数据传送速度足够快，能满足用户的需求但又不丢失数据；</p> \n  <p>（2） 系统开销小，所需的处理控制程序少；</p> \n  <p>（3） 能充分发挥硬件资源的能力，使 I/O 设备尽可能忙，而 CPU 等待时间尽可能少。</p> \n </blockquote> \n <p>根据以上控制原则，I/O 操作可以分为四类</p> \n <ul>\n  <li><code>直接访问</code>：直接访问由用户进程直接控制主存或 CPU 和外围设备之间的信息传送。直接程序控制方式又称为忙/等待方式。</li>\n  <li><code>中断驱动</code>：为了减少程序直接控制方式下 CPU 的等待时间以及提高系统的并行程度，系统引入了中断机制。中断机制引入后，外围设备仅当操作正常结束或异常结束时才向 CPU 发出中断请求。在 I/O 设备输入每个数据的过程中，由于无需 CPU 的干预，一定程度上实现了 CPU 与 I/O 设备的并行工作。</li>\n </ul> \n <p>上述两种方法的特点都是以 <code>CPU</code> 为中心，数据传送通过一段程序来实现，软件的传送手段限制了数据传送的速度。接下来介绍的这两种 I/O 控制方式采用硬件的方法来显示 I/O 的控制</p> \n <ul>\n  <li><code>DMA 直接内存访问</code>：为了进一步减少 CPU 对 I/O 操作的干预，防止因并行操作设备过多使 CPU 来不及处理或因速度不匹配而造成的数据丢失现象，引入了 DMA 控制方式。</li>\n  <li><code>通道控制方式</code>：通道，独立于 CPU 的专门负责输入输出控制的处理机，它控制设备与内存直接进行数据交换。有自己的通道指令，这些指令由 CPU 启动，并在操作结束时向 CPU 发出中断信号。</li>\n </ul> \n <h3><a id=\"_129\"></a>聊聊：操作系统的主要目的是什么</h3> \n <p>操作系统是一种软件，它的主要目的有三种</p> \n <ul>\n  <li>管理计算机资源，这些资源包括 CPU、内存、磁盘驱动器、打印机等。</li>\n  <li>提供一种图形界面，就像我们前面描述的那样，它提供了用户和计算机之间的桥梁。</li>\n  <li>为其他软件提供服务，操作系统与软件进行交互，以便为其分配运行所需的任何必要资源。</li>\n </ul> \n <h3><a id=\"_137\"></a>聊聊：操作系统的种类有哪些</h3> \n <p>操作系统通常预装在你购买计算机之前。大部分用户都会使用默认的操作系统，但是你也可以升级甚至更改操作系统。但是一般常见的操作系统只有三种：<strong>Windows、macOS 和 Linux</strong>。</p> \n <h3><a id=\"_Linux__Windows__141\"></a>聊聊：为什么 Linux 系统下的应用程序不能直接在 Windows 下运行</h3> \n <p>这是一个老生常谈的问题了，在这里给出具体的回答。</p> \n <p>其中一点是因为 Linux 系统和 Windows 系统的格式不同，<strong>格式就是协议</strong>，就是在固定位置有意义的数据。Linux 下的可执行程序文件格式是 <code>elf</code>，可以使用 <code>readelf</code> 命令查看 elf 文件头。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/ad82150828eea21e25d99c9e6416784b.png\" alt=\"\"></p> \n <p>而 Windows 下的可执行程序是 <code>PE</code> 格式，它是一种可移植的可执行文件。</p> \n <p>还有一点是因为 Linux 系统和 Windows 系统的 <code>API</code> 不同，这个 API 指的就是操作系统的 API，Linux 中的 API 被称为<code>系统调用</code>，是通过 <code>int 0x80</code> 这个软中断实现的。而 Windows 中的 API 是放在动态链接库文件中的，也就是 Windows 开发人员所说的 <code>DLL</code> ，这是一个库，里面包含代码和数据。Linux 中的可执行程序获得系统资源的方法和 Windows 不一样，所以显然是不能在 Windows 中运行的。</p> \n <h3><a id=\"_153\"></a>聊聊：操作系统结构</h3> \n <h5><a id=\"_155\"></a>单体系统</h5> \n <p>在大多数系统中，整个系统在内核态以单一程序的方式运行。整个操作系统是以程序集合来编写的，链接在一块形成一个大的二进制可执行程序，这种系统称为单体系统。</p> \n <p>在单体系统中构造实际目标程序时，会首先编译所有单个过程（或包含这些过程的文件），然后使用系统链接器将它们全部绑定到一个可执行文件中</p> \n <p>在单体系统中，对于每个系统调用都会有一个服务程序来保障和运行。需要一组实用程序来弥补服务程序需要的功能，例如从用户程序中获取数据。可将各种过程划分为一个三层模型</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/4fd6e807f5d1f2ef056ffae80798d8c4.png\" alt=\"\"></p> \n <p>除了在计算机初启动时所装载的核心操作系统外，许多操作系统还支持额外的扩展。比如 I/O 设备驱动和文件系统。这些部件可以按需装载。在 UNIX 中把它们叫做 <code>共享库(shared library)</code>，在 Windows 中则被称为 <code>动态链接库(Dynamic Link Library,DLL)</code>。他们的扩展名为 <code>.dll</code>，在 <code>C:\\Windows\\system32</code> 目录下存在 1000 多个 DLL 文件，所以不要轻易删除 C 盘文件，否则可能就炸了哦。</p> \n <h5><a id=\"_167\"></a>分层系统</h5> \n <p>分层系统使用层来分隔不同的功能单元。每一层只与该层的上层和下层通信。每一层都使用下面的层来执行其功能。层之间的通信通过预定义的固定接口通信。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/7434d7668d8bbc134f478d18de8ed472.png\" alt=\"\"></p> \n <h5><a id=\"_173\"></a>微内核</h5> \n <p>为了实现高可靠性，将操作系统划分成小的、层级之间能够更好定义的模块是很有必要的，只有一个模块 — 微内核 — 运行在内核态，其余模块可以作为普通用户进程运行。由于把每个设备驱动和文件系统分别作为普通用户进程，这些模块中的错误虽然会使这些模块崩溃，但是不会使整个系统死机。</p> \n <p><code>MINIX 3</code> 是微内核的代表作，它的具体结构如下</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/3ada7ebd262fc66297797496f86e17d8.png\" alt=\"\"></p> \n <p>在内核的外部，系统的构造有三层，它们都在用户态下运行，最底层是设备驱动器。由于它们都在用户态下运行，所以不能物理的访问 I/O 端口空间，也不能直接发出 I/O 命令。相反，为了能够对 I/O 设备编程，驱动器构建一个结构，指明哪个参数值写到哪个 I/O 端口，并声称一个内核调用，这样就完成了一次调用过程。</p> \n <h5><a id=\"_183\"></a>客户-服务器模式</h5> \n <p>微内核思想的策略是把进程划分为两类：<code>服务器</code>，每个服务器用来提供服务；<code>客户端</code>，使用这些服务。这个模式就是所谓的 <code>客户-服务器</code>模式。</p> \n <p>客户-服务器模式会有两种载体，一种情况是一台计算机既是客户又是服务器，在这种方式下，操作系统会有某种优化；但是普遍情况下是客户端和服务器在不同的机器上，它们通过局域网或广域网连接。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/c310ab2ed83826be6b93a0c9993beb86.png\" alt=\"\"></p> \n <p>客户通过发送消息与服务器通信，客户端并不需要知道这些消息是在本地机器上处理，还是通过网络被送到远程机器上处理。对于客户端而言，这两种情形是一样的：都是发送请求并得到回应。</p> \n <h3><a id=\"_193\"></a>聊聊：为什么称为陷入内核</h3> \n <p>如果把软件结构进行分层说明的话，应该是这个样子的，最外层是应用程序，里面是操作系统内核。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/2ce2429639ed564a5b72ae47539c3423.png\" alt=\"\"></p> \n <p>应用程序处于特权级 3，操作系统内核处于特权级 0 。如果用户程序想要访问操作系统资源时，会发起系统调用，陷入内核，这样 CPU 就进入了内核态，执行内核代码。至于为什么是陷入，我们看图，内核是一个凹陷的构造，有陷下去的感觉，所以称为陷入。</p> \n <h3><a id=\"_201\"></a>聊聊：什么是用户态和内核态</h3> \n <p>用户态和内核态是操作系统的两种运行状态。</p> \n <ul>\n  <li><code>内核态</code>：处于内核态的 CPU 可以访问任意的数据，包括外围设备，比如网卡、硬盘等，处于内核态的 CPU 可以从一个程序切换到另外一个程序，并且占用 CPU 不会发生抢占情况，一般处于特权级 0 的状态我们称之为内核态。</li>\n  <li><code>用户态</code>：处于用户态的 CPU 只能受限的访问内存，并且不允许访问外围设备，用户态下的 CPU 不允许独占，也就是说 CPU 能够被其他程序获取。</li>\n </ul> \n <blockquote> \n  <p>那么为什么要有用户态和内核态呢？</p> \n </blockquote> \n <p>这个主要是访问能力的限制的考量，计算机中有一些比较危险的操作，比如设置时钟、内存清理，这些都需要在内核态下完成，如果随意进行这些操作，那你的系统得崩溃多少次。</p> \n <h3><a id=\"_212\"></a>聊聊：用户态和内核态是如何切换的？</h3> \n <p>所有的用户进程都是运行在用户态的，但是我们上面也说了，用户程序的访问能力有限，一些比较重要的比如从硬盘读取数据，从键盘获取数据的操作则是内核态才能做的事情，而这些数据却又对用户程序来说非常重要。所以就涉及到两种模式下的转换，即<strong>用户态 -&gt; 内核态 -&gt; 用户态</strong>，而唯一能够做这些操作的只有 <code>系统调用</code>，而能够执行系统调用的就只有 <code>操作系统</code>。</p> \n <p>一般用户态 -&gt; 内核态的转换我们都称之为 trap 进内核，也被称之为 <code>陷阱指令(trap instruction)</code>。</p> \n <p>他们的工作流程如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/32647dab68cbcc50b9703a967f836096.png\" alt=\"\"></p> \n <ul>\n  <li>首先用户程序会调用 <code>glibc</code> 库，glibc 是一个标准库，同时也是一套核心库，库中定义了很多关键 API。</li>\n  <li>glibc 库知道针对不同体系结构调用<code>系统调用</code>的正确方法，它会根据体系结构应用程序的二进制接口设置用户进程传递的参数，来准备系统调用。</li>\n  <li>然后，glibc 库调用<code>软件中断指令(SWI)</code> ，这个指令通过更新 <code>CPSR</code> 寄存器将模式改为超级用户模式，然后跳转到地址 <code>0x08</code> 处。</li>\n  <li>到目前为止，整个过程仍处于用户态下，在执行 SWI 指令后，允许进程执行内核代码，MMU 现在允许内核虚拟内存访问</li>\n  <li>从地址 0x08 开始，进程执行加载并跳转到中断处理程序，这个程序就是 ARM 中的 <code>vector_swi()</code>。</li>\n  <li>在 vector_swi() 处，从 SWI 指令中提取系统调用号 SCNO，然后使用 SCNO 作为系统调用表 <code>sys_call_table</code> 的索引，调转到系统调用函数。</li>\n  <li>执行系统调用完成后，将还原用户模式寄存器，然后再以用户模式执行。</li>\n </ul> \n <h3><a id=\"_230\"></a>聊聊：什么是内核</h3> \n <p><strong>在计算机中，内核是一个计算机程序，它是操作系统的核心，可以控制操作系统中所有的内容</strong>。内核通常是在 boot loader 装载程序之前加载的第一个程序。</p> \n <p>这里还需要了解一下什么是 <code>boot loader</code>。</p> \n <blockquote> \n  <p>boot loader 又被称为引导加载程序，能够将计算机的操作系统放入内存中。在电源通电或者计算机重启时，BIOS 会执行一些初始测试，然后将控制权转移到引导加载程序所在的<code>主引导记录(MBR)</code> 。</p> \n </blockquote> \n <h3><a id=\"_238\"></a>聊聊：什么是实时系统</h3> \n <p>实时操作系统对时间做出了严格的要求，实时操作系统分为两种：<strong>硬实时和软实时</strong></p> \n <p><code>硬实时操作系统</code>规定某个动作必须在规定的时刻内完成或发生，比如汽车生产车间，焊接机器必须在某一时刻内完成焊接，焊接的太早或者太晚都会对汽车造成永久性伤害。</p> \n <p><code>软实时操作系统</code>虽然不希望偶尔违反最终的时限要求，但是仍然可以接受。并且不会引起任何永久性伤害。比如数字音频、多媒体、手机都是属于软实时操作系统。</p> \n <p>你可以简单理解硬实时和软实时的两个指标：<strong>是否在时刻内必须完成以及是否造成严重损害</strong>。</p> \n <h3><a id=\"Linux__248\"></a>聊聊：Linux 操作系统的启动过程</h3> \n <p>当计算机电源通电后，<code>BIOS</code>会进行<code>开机自检(Power-On-Self-Test, POST)</code>，对硬件进行检测和初始化。因为操作系统的启动会使用到磁盘、屏幕、键盘、鼠标等设备。</p> \n <p>下一步，磁盘中的第一个分区，也被称为 <code>MBR(Master Boot Record)</code> 主引导记录，被读入到一个固定的内存区域并执行。这个分区中有一个非常小的，只有 512 字节的程序。程序从磁盘中调入 boot 独立程序，boot 程序将自身复制到高位地址的内存从而为操作系统释放低位地址的内存。</p> \n <p>复制完成后，boot 程序读取启动设备的根目录。boot 程序要理解文件系统和目录格式。然后 boot 程序被调入内核，把控制权移交给内核。直到这里，boot 完成了它的工作。系统内核开始运行。</p> \n <p>内核启动代码是使用<code>汇编语言</code>完成的，主要包括创建内核堆栈、识别 CPU 类型、计算内存、禁用中断、启动内存管理单元等，然后调用 C 语言的 main 函数执行操作系统部分。</p> \n <p>这部分也会做很多事情，首先会分配一个消息缓冲区来存放调试出现的问题，调试信息会写入缓冲区。如果调试出现错误，这些信息可以通过诊断程序调出来。</p> \n <p>然后操作系统会进行自动配置，检测设备，加载配置文件，被检测设备如果做出响应，就会被添加到已链接的设备表中，如果没有相应，就归为未连接直接忽略。</p> \n <p>配置完所有硬件后，接下来要做的就是仔细手工处理进程0，设置其堆栈，然后运行它，执行初始化、配置时钟、挂载文件系统。创建 <code>init 进程(进程 1 )</code> 和 <code>守护进程(进程 2)</code>。</p> \n <p>init 进程会检测它的标志以确定它是否为单用户还是多用户服务。在前一种情况中，它会调用 fork 函数创建一个 shell 进程，并且等待这个进程结束。后一种情况调用 fork 函数创建一个运行系统初始化的 shell 脚本（即 <code>/etc/rc</code>）的进程，这个进程可以进行文件系统一致性检测、挂载文件系统、开启守护进程等。</p> \n <p>然后 <code>/etc/rc</code> 这个进程会从 <code>/etc/ttys</code> 中读取数据，<code>/etc/ttys</code> 列出了所有的终端和属性。对于每一个启用的终端，这个进程调用 fork 函数创建一个自身的副本，进行内部处理并运行一个名为 <code>getty</code> 的程序。</p> \n <p>getty 程序会在终端上输入</p> \n <pre><code class=\"prism language-shell\">login:\n</code></pre> \n <p>等待用户输入用户名，在输入用户名后，getty 程序结束，登陆程序 <code>/bin/login</code> 开始运行。login 程序需要输入密码，并与保存在 <code>/etc/passwd</code> 中的密码进行对比，如果输入正确，login 程序以用户 shell 程序替换自身，等待第一个命令。如果不正确，login 程序要求输入另一个用户名。</p> \n <p>整个系统启动过程如下</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/09d0338dadd784d3874dee385e831f10.png\" alt=\"\"></p> \n <h2><a id=\"_282\"></a>进程线程协程篇</h2> \n <h3><a id=\"_284\"></a>系统调度</h3> \n <p>在未配置 OS 的系统中，程序的执行方式是顺序执行，即必须在一个程序执行完后，才允许另一个程序执行；在多道程序环境下，则允许多个程序并发执行。程序的这两种执行方式间有着显著的不同。也正是程序并发执行时的这种特征，才导致了在操作系统中引入进程的概念。进程是资源分配的基本单位，线程是资源调度的基本单位。</p> \n <p>应用启动体现的就是静态指令加载进内存，进而进入 CPU 运算，操作系统在内存开辟了一段栈内存用来存放指令和变量值，从而形成了进程。早期的操作系统基于进程来调度 CPU，不同进程间是不共享内存空间的，所以进程要做任务切换就要切换内存映射地址。由于进程的上下文关联的变量，引用，计数器等现场数据占用了打段的内存空间，所以频繁切换进程需要整理一大段内存空间来保存未执行完的进程现场，等下次轮到 CPU 时间片再恢复现场进行运算。</p> \n <p>这样既耗费时间又浪费空间，所以我们才要研究多线程。一个进程创建的所有线程，都是共享一个内存空间的，所以线程做任务切换成本就很低了。现代的操作系统都基于更轻量的线程来调度，现在我们提到的 “任务切换” 都是指 “线程切换”。</p> \n <h3><a id=\"_292\"></a>进程详解</h3> \n <p>进程是操作系统对一个正在运行的程序的一种抽象，在一个系统上可以同时运行多个进程，而每个进程都好像在独占地使用硬件。所谓的并发运行，则是说一个进程的指令和另一个进程的指令是交错执行的。无论是在单核还是多核系统中，可以通过处理器在进程间切换，来实现单个 CPU 看上去像是在并发地执行多个进程。操作系统实现这种交错执行的机制称为上下文切换。</p> \n <p>操作系统保持跟踪进程运行所需的所有状态信息。这种状态，也就是上下文，它包括许多信息，例如 PC 和寄存器文件的当前值，以及主存的内容。在任何一个时刻，单处理器系统都只能执行一个进程的代码。当操作系统决定要把控制权从当前进程转移到某个新进程时，就会进行上下文切换，即保存当前进程的上下文、恢复新进程的上下文，然后将控制权传递到新进程。新进程就会从上次停止的地方开始。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/f4724ef595d94a078c932582d1b86161.png\" alt=\"\"></p> \n <p>操作系统为每个进程提供了一个假象，即每个进程都在独占地使用主存。每个进程看到的是一致的存储器，称为虚拟地址空间。其虚拟地址空间最上面的区域是为操作系统中的代码和数据保留的，这对所有进程来说都是一样的；地址空间的底部区域存放用户进程定义的代码和数据。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/8183705a922a48119c9ac1e89153156c.png\" alt=\"\"></p> \n <p>程序代码和数据：对于所有的进程来说，代码是从同一固定地址开始，直接按照可执行目标文件的内容初始化。</p> \n <p><code>堆</code>：代码和数据区后紧随着的是运行时堆。代码和数据区是在进程一开始运行时就被规定了大小，与此不同，当调用如 malloc 和 free 这样的 C 语言 标准库函数时，堆可以在运行时动态地扩展和收缩。</p> \n <p><code>共享库</code>：大约在地址空间的中间部分是一块用来存放像 C 标准库和数学库这样共享库的代码和数据的区域。</p> \n <p><code>栈</code>：位于用户虚拟地址空间顶部的是用户栈，编译器用它来实现函数调用。和堆一样，用户栈在程序执行期间可以动态地扩展和收缩。</p> \n <p><code>内核虚拟存储器</code>：内核总是驻留在内存中，是操作系统的一部分。地址空间顶部的区域是为内核保留的，不允许应用程序读写这个区域的内容或者直接调用内核代码定义的函数。</p> \n <h3><a id=\"_314\"></a>线程详解</h3> \n <p>在现代系统中，一个进程实际上可以由多个称为线程的执行单元组成，每个线程都运行在进程的上下文中，并共享同样的代码和全局数据。进程的个体间是完全独立的，而线程间是彼此依存的。多进程环境中，任何一个进程的终止，不会影响到其他进程。而多线程环境中，父线程终止，全部子线程被迫终止(没有了资源)。</p> \n <p>而任何一个子线程终止一般不会影响其他线程，除非子线程执行了 exit() 系统调用。任何一个子线程执行 exit()，全部线程同时灭亡。多线程程序中至少有一个主线程，而这个主线程其实就是有 main 函数的进程。它是整个程序的进程，所有线程都是它的子线程；我们通常把具有多线程的主进程称之为主线程。</p> \n <p>线程共享的环境包括：进程代码段、进程的公有数据、进程打开的文件描述符、信号的处理器、进程的当前目录、进程用户 ID 与进程组 ID 等，利用这些共享的数据，线程很容易的实现相互之间的通讯。线程拥有这许多共性的同时，还拥有自己的个性，并以此实现并发性：</p> \n <p>线程 ID：每个线程都有自己的线程 ID，这个 ID 在本进程中是唯一的。进程用此来标识线程。</p> \n <p>寄存器组的值：由于线程间是并发运行的，每个线程有自己不同的运行线索，当从一个线程切换到另一个线程上时，必须将原有的线程的寄存器集合的状态保存，以便 将来该线程在被重新切换到时能得以恢复。</p> \n <p>线程的堆栈：堆栈是保证线程独立运行所必须的。线程函数可以调用函数，而被调用函数中又是可以层层嵌套的，所以线程必须拥有自己的函数堆栈， 使得函数调用可以正常执行，不受其他线程的影响。</p> \n <p>错误返回码：由于同一个进程中有很多个线程在同时运行，可能某个线程进行系统调用后设置了 errno 值，而在该 线程还没有处理这个错误，另外一个线程就在此时 被调度器投入运行，这样错误值就有可能被修改。 所以，不同的线程应该拥有自己的错误返回码变量。</p> \n <p>线程的信号屏蔽码：由于每个线程所感兴趣的信号不同，所以线程的信号屏蔽码应该由线程自己管理。但所有的线程都共享同样的信号处理器。</p> \n <p>线程的优先级：由于线程需要像进程那样能够被调度，那么就必须要有可供调度使用的参数，这个参数就是线程的优先级。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/53e0475c131145f69fb4f3fbe81fb3eb.png\" alt=\"\"></p> \n <h3><a id=\"_336\"></a>线程模型</h3> \n <h4><a id=\"_338\"></a>线程实现在用户空间下</h4> \n <p>当线程在用户空间下实现时，操作系统对线程的存在一无所知，操作系统只能看到进程，而不能看到线程。所有的线程都是在用户空间实现。在操作系统看来，每一个进程只有一个线程。过去的操作系统大部分是这种实现方式，这种方式的好处之一就是即使操作系统不支持线程，也可以通过库函数来支持线程。</p> \n <p>在这在模型下，程序员需要自己实现线程的数据结构、创建销毁和调度维护。也就相当于需要实现一个自己的线程调度内核，而同时这些线程运行在操作系统的一个进程内，最后操作系统直接对进程进行调度。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/7605808112bf480db07bb6410bb8e67c.png\" alt=\"\"></p> \n <p>这样做有一些优点，首先就是确实在操作系统中实现了真实的多线程，其次就是线程的调度只是在用户态，减少了操作系统从内核态到用户态的切换开销。这种模式最致命的缺点也是由于操作系统不知道线程的存在，因此当一个进程中的某一个线程进行系统调用时，比如缺页中断而导致线程阻塞，此时操作系统会阻塞整个进程，即使这个进程中其它线程还在工作。还有一个问题是假如进程中一个线程长时间不释放 CPU，因为用户空间并没有时钟中断机制，会导致此进程中的其它线程得不到 CPU 而持续等待。</p> \n <h4><a id=\"_348\"></a>线程实现在操作系统内核中</h4> \n <p>内核线程就是直接由操作系统内核（Kernel）支持的线程，这种线程由内核来完成线程切换，内核通过操纵调度器（Scheduler）对线程进行调度，并负责将线程的任务映射到各个处理器上。每个内核线程可以视为内核的一个分身，这样操作系统就有能力同时处理多件事情，支持多线程的内核就叫做多线程内核（Multi-Threads Kernel）。</p> \n <p>程序员直接使用操作系统中已经实现的线程，而线程的创建、销毁、调度和维护，都是靠操作系统（准确的说是内核）来实现，程序员只需要使用系统调用，而不需要自己设计线程的调度算法和线程对 CPU 资源的抢占使用。</p> \n <h4><a id=\"_354\"></a>使用用户线程加轻量级进程混合实现</h4> \n <p>在这种混合实现下，即存在用户线程，也存在轻量级进程。用户线程还是完全建立在用户空间中，因此用户线程的创建、切换、析构等操作依然廉价，并且可以支持大规模的用户线程并发。而操作系统提供支持的轻量级进程则作为用户线程和内核线程之间的桥梁，这样可以使用内核提供的线程调度功能及处理器映射，并且用户线程的系统调用要通过轻量级进程来完成，大大降低了整个进程被完全阻塞的风险。在这种混合模式中，用户线程与轻量级进程的数量比是不定的，即为 N:M 的关系：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/c9c7ee368d7045a288a7281b18ca329a.png\" alt=\"\"></p> \n <p>Golang 的协程就是使用了这种模型，在用户态，协程能快速的切换，避免了线程调度的 CPU 开销问题，协程相当于线程的线程。</p> \n <h3><a id=\"Linux_362\"></a>Linux中的线程</h3> \n <p>在 Linux 2.4 版以前，线程的实现和管理方式就是完全按照进程方式实现的；在 Linux 2.6 之前，内核并不支持线程的概念，仅通过轻量级进程（Lightweight Process）模拟线程；轻量级进程是建立在内核之上并由内核支持的用户线程，它是内核线程的高度抽象，每一个轻量级进程都与一个特定的内核线程关联。内核线程只能由内核管理并像普通进程一样被调度。这种模型最大的特点是线程调度由内核完成了，而其他线程操作（同步、取消）等都是核外的线程库（Linux Thread）函数完成的。</p> \n <p>为了完全兼容 Posix 标准，Linux 2.6 首先对内核进行了改进，引入了线程组的概念（仍然用轻量级进程表示线程），有了这个概念就可以将一组线程组织称为一个进程，不过内核并没有准备特别的调度算法或是定义特别的数据结构来表征线程；相反，线程仅仅被视为一个与其他进程（概念上应该是线程）共享某些资源的进程（概念上应该是线程）。在实现上主要的改变就是在 task_struct 中加入 tgid 字段，这个字段就是用于表示线程组 id 的字段。在用户线程库方面，也使用 NPTL 代替 Linux Thread，不同调度模型上仍然采用 1 对 1 模型。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/a5c44bba64754c82ac5cf112bf7ff712.png\" alt=\"\"></p> \n <p>进程的实现是调用 fork 系统调用：pid_t fork(void);，线程的实现是调用 clone 系统调用：<code>int clone(int (*fn)(void *), void *child_stack, int flags, void *arg, ...)</code>。与标准 fork() 相比，线程带来的开销非常小，内核无需单独复制进程的内存空间或文件描写叙述符等等。这就节省了大量的 CPU 时间，使得线程创建比新进程创建快上十到一百倍，能够大量使用线程而无需太过于操心带来的 CPU 或内存不足。无论是 fork、vfork、kthread_create 最后都是要调用 do_fork，而 do_fork 就是根据不同的函数参数，对一个进程所需的资源进行分配。</p> \n <h3><a id=\"_372\"></a>内核线程</h3> \n <p>内核线程是由内核自己创建的线程，也叫做守护线程（Deamon），在终端上用命令 ps -Al 列出的所有进程中，名字以 k 开关以 d 结尾的往往都是内核线程，比如 kthreadd、kswapd 等。与用户线程相比，它们都由 do_fork() 创建，每个线程都有独立的 task_struct 和内核栈；也都参与调度，内核线程也有优先级，会被调度器平等地换入换出。二者的不同之处在于，内核线程只工作在内核态中；而用户线程则既可以运行在内核态（执行系统调用时），也可以运行在用户态；内核线程没有用户空间，所以对于一个内核线程来说，它的 0~3G 的内存空间是空白的，它的 current-&gt;mm 是空的，与内核使用同一张页表；而用户线程则可以看到完整的 0~4G 内存空间。</p> \n <p>在 Linux 内核启动的最后阶段，系统会创建两个内核线程，一个是 init，一个是 kthreadd。其中 init 线程的作用是运行文件系统上的一系列”init”脚本，并启动 shell 进程，所以 init 线程称得上是系统中所有用户进程的祖先，它的 pid 是 1。kthreadd 线程是内核的守护线程，在内核正常工作时，它永远不退出，是一个死循环，它的 pid 是 2。</p> \n <h3><a id=\"_378\"></a>协程</h3> \n <p>协程是用户模式下的轻量级线程，最准确的名字应该叫用户空间线程（User Space Thread），在不同的领域中也有不同的叫法，譬如纤程(Fiber)、绿色线程(Green Thread)等等。操作系统内核对协程一无所知，协程的调度完全有应用程序来控制，操作系统不管这部分的调度；一个线程可以包含一个或多个协程，协程拥有自己的寄存器上下文和栈，协程调度切换时，将寄存器上细纹和栈保存起来，在切换回来时恢复先前保运的寄存上下文和栈。</p> \n <p>协程的优势如下：</p> \n <ul>\n  <li>节省内存，每个线程需要分配一段栈内存，以及内核里的一些资源</li>\n  <li>节省分配线程的开销（创建和销毁线程要各做一次 syscall）</li>\n  <li>节省大量线程切换带来的开销</li>\n  <li>与 NIO 配合实现非阻塞的编程，提高系统的吞吐</li>\n </ul> \n <p>比如 Golang 里的 go 关键字其实就是负责开启一个 Fiber，让 func 逻辑跑在上面。而这一切都是发生的用户态上，没有发生在内核态上，也就是说没有 ContextSwitch 上的开销。</p> \n <h3><a id=\"Go_391\"></a>Go协程模型</h3> \n <p>Go 线程模型属于多对多线程模型，在操作系统提供的内核线程之上，Go 搭建了一个特有的两级线程模型。Go 中使用使用 Go 语句创建的 Goroutine 可以认为是轻量级的用户线程，Go 线程模型包含三个概念：</p> \n <p>G: 表示 Goroutine，每个 Goroutine 对应一个 G 结构体，G 存储 Goroutine 的运行堆栈、状态以及任务函数，可重用。G 并非执行体，每个 G 需要绑定到 P 才能被调度执行。</p> \n <p>P: Processor，表示逻辑处理器，对 G 来说，P 相当于 CPU 核，G 只有绑定到 P(在 P 的 local runq 中)才能被调度。对 M 来说，P 提供了相关的执行环境（Context），如内存分配状态（mcache），任务队列（G）等，P 的数量决定了系统内最大可并行的 G 的数量（物理 CPU 核数 &gt;= P 的数量），P 的数量由用户设置的 GOMAXPROCS 决定，但是不论 GOMAXPROCS 设置为多大，P 的数量最大为 256。</p> \n <p>M: Machine，OS 线程抽象，代表着真正执行计算的资源，在绑定有效的 P 后，进入 schedule 循环；M 的数量是不定的，由 Go Runtime 调整，为了防止创建过多 OS 线程导致系统调度不过来，目前默认最大限制为 10000 个。</p> \n <p>在 Go 中每个逻辑处理器§会绑定到某一个内核线程上，每个逻辑处理器（P）内有一个本地队列，用来存放 Go 运行时分配的 goroutine。多对多线程模型中是操作系统调度线程在物理 CPU 上运行，在 Go 中则是 Go 的运行时调度 Goroutine 在逻辑处理器（P）上运行。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/ba0502c3127d440db21949cb31078377.png\" alt=\"\"></p> \n <p>Go 的栈是动态分配大小的，随着存储数据的数量而增长和收缩。每个新建的 Goroutine 只有大约 4KB 的栈。每个栈只有 4KB，那么在一个 1GB 的 RAM 上，我们就可以有 256 万个 Goroutine 了，相对于 Java 中每个线程的 1MB，这是巨大的提升。Golang 实现了自己的调度器，允许众多的 Goroutines 运行在相同的 OS 线程上。就算 Go 会运行与内核相同的上下文切换，但是它能够避免切换至 ring-0 以运行内核，然后再切换回来，这样就会节省大量的时间。</p> \n <p>在 Go 中存在两级调度:</p> \n <ul>\n  <li>一级是操作系统的调度系统，该调度系统调度逻辑处理器占用 cpu 时间片运行；</li>\n  <li>一级是 Go 的运行时调度系统，该调度系统调度某个 Goroutine 在逻辑处理上运行。</li>\n </ul> \n <p>使用 Go 语句创建一个 Goroutine 后，创建的 Goroutine 会被放入 Go 运行时调度器的全局运行队列中，然后 Go 运行时调度器会把全局队列中的 Goroutine 分配给不同的逻辑处理器（P），分配的 Goroutine 会被放到逻辑处理器（P)的本地队列中，当本地队列中某个 Goroutine 就绪后待分配到时间片后就可以在逻辑处理器上运行了。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/47660db256eb44468692b3148e6f396d.png\" alt=\"\"></p> \n <h3><a id=\"_416\"></a>进程线程协程详解总结</h3> \n <p>进程是操作系统对一个正在运行的程序的一种抽象，在一个系统上可以同时运行多个进程，而每个进程都好像在独占地使用硬件。</p> \n <p>在现代系统中，一个进程实际上可以由多个称为线程的执行单元组成，每个线程都运行在进程的上下文中，并共享同样的代码和全局数据。</p> \n <p>协程是用户模式下的轻量级线程，最准确的名字应该叫用户空间线程（User Space Thread）。</p> \n <h2><a id=\"_426\"></a>进程线程协程区别</h2> \n <h3><a id=\"_428\"></a>进程协程进程对比</h3> \n <h4><a id=\"_430\"></a>进程概念</h4> \n <p>进程是系统资源分配的最小单位, 系统由一个个进程(程序)组成 一般情况下，包括文本区域（text region）、数据区域（data region）和堆栈（stack region）。</p> \n <p>文本区域存储处理器执行的代码，数据区域存储变量和进程执行期间使用的动态分配的内存，堆栈区域存储着活动过程调用的指令和本地变量。</p> \n <p>因此进程的创建和销毁都是相对于系统资源,所以是一种比较昂贵的操作。 进程有三个状态:</p> \n <table>\n  <thead>\n   <tr>\n    <th>状态</th>\n    <th>描述</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>等待态</td>\n    <td>等待某个事件的完成</td>\n   </tr>\n   <tr>\n    <td>就绪态</td>\n    <td>等待系统分配处理器以便运行</td>\n   </tr>\n   <tr>\n    <td>运行态</td>\n    <td>占有处理器正在运行</td>\n   </tr>\n  </tbody>\n </table> \n <p>进程是抢占式的争夺 CPU 运行自身,而 CPU 单核的情况下同一时间只能执行一个进程的代码，但是多进程的实现则是通过 CPU 飞快的切换不同进程，因此使得看上去就像是多个进程在同时进行。</p> \n <p>通信问题:由于进程间是隔离的，各自拥有自己的内存内存资源, 因此相对于线程比较安全, 所以不同进程之间的数据只能通过 IPC(Inter-Process Communication) 进行通信共享。</p> \n <h4><a id=\"_448\"></a>线程概念</h4> \n <p>线程属于进程，线程共享进程的内存地址空间并且线程几乎不占有系统资源。</p> \n <p>通信问题: 进程相当于一个容器，而线程而是运行在容器里面的，因此对于容器内的东西，线程是共同享有的，因此线程间的通信可以直接通过全局变量进行通信。但是由此带来的例如多个线程读写同一个地址变量的时候则将带来不可预期的后果，因此这时候引入了各种锁的作用，例如互斥锁等。</p> \n <p>同时多线程是不安全的，当一个线程崩溃了，会导致整个进程也崩溃了，即其他线程也挂了, 但多进程而不会，一个进程挂了，另一个进程依然照样运行。</p> \n <p>进程是系统分配资源的最小单位，线程是 CPU 调度的最小单位。由于默认进程内只有一个线程，所以多核 CPU 处理多进程就像是一个进程一个核心。</p> \n <h4><a id=\"_458\"></a>协程概念</h4> \n <p>协程是属于线程的。协程程序是在线程里面跑的，因此协程又称微线程和纤程等，协没有线程的上下文切换消耗。协程的调度切换是用户(程序员)手动切换的，因此更加灵活，因此又叫用户空间线程。</p> \n <p>原子操作性。由于协程是用户调度的，所以不会出现执行一半的代码片段被强制中断了，因此无需原子操作锁。</p> \n <h3><a id=\"_466\"></a>进程线程协程详解</h3> \n <h4><a id=\"_468\"></a>进程</h4> \n <p>进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动,进程是系统进行资源分配和调度的一个独立单位。每个进程都有自己的独立内存空间，不同进程通过进程间通信来通信。由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大，但相对比较稳定安全。</p> \n <h4><a id=\"_472\"></a>线程</h4> \n <p>线程是进程的一个实体,是 CPU 调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。</p> \n <h4><a id=\"_476\"></a>协程</h4> \n <p>协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。</p> \n <h4><a id=\"_480\"></a>图解</h4> \n <p>线程图解如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/079bf3d5a92b46efa450459a194203ab.png\" alt=\"\"></p> \n <p>协程图解如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/f8f1a1a1c2fc439790c6488dde517d29.png\" alt=\"\"></p> \n <h3><a id=\"_492\"></a>进程与线程比较</h3> \n <ol>\n  <li>地址空间:线程是进程内的一个执行单元，进程内至少有一个线程，它们共享进程的地址空间，而进程有自己独立的地址空间。</li>\n  <li>资源拥有: 进程是资源分配和拥有的单位，同一个进程内的线程共享进程的资源。</li>\n  <li>线程是处理器调度的基本单位，但进程不是。</li>\n  <li>二者均可并发执行。</li>\n  <li>每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口，但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。</li>\n </ol> \n <h3><a id=\"_500\"></a>协程与线程进行比较</h3> \n <ol>\n  <li>一个线程可以多个协程，一个进程也可以单独拥有多个协程。</li>\n  <li>线程进程都是同步机制，而协程则是异步。</li>\n  <li>协程能保留上一次调用时的状态，每次过程重入时，就相当于进入上一次调用的状态。</li>\n </ol> \n <h3><a id=\"_506\"></a>进程线程协程区别总结</h3> \n <p>进程是系统资源分配的最小单位, 系统由一个个进程(程序)组成 一般情况下，包括文本区域（text region）、数据区域（data region）和堆栈（stack region）。</p> \n <p>线程属于进程，线程共享进程的内存地址空间并且线程几乎不占有系统资源。</p> \n <p>协程是属于线程的。协程程序是在线程里面跑的，因此协程又称微线程和纤程等，协没有线程的上下文切换消耗。协程的调度切换是用户(程序员)手动切换的，因此更加灵活，因此又叫用户空间线程。</p> \n <h3><a id=\"_516\"></a>孤儿进程</h3> \n <h4><a id=\"_518\"></a>孤儿进程教程</h4> \n <p>如果父进程先退出，子进程还没退出那么子进程将被托孤给 init 进程，这时子进程的父进程就是 init 进程（1 号进程）。</p> \n <h4><a id=\"_522\"></a>案例</h4> \n <h5><a id=\"_524\"></a>创建孤儿进程</h5> \n <p>我们在 Linux 下使用 vim 新建一个 childprocess.c 的文件，编写如下 C 语言 代码如下：</p> \n <pre><code class=\"prism language-c\"><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;sys/types.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;unistd.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;stdlib.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;stdio.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;string.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;signal.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;errno.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;signal.h&gt;</span></span>\n<span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">void</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token class-name\">pid_t</span> pid <span class=\"token punctuation\">;</span>\n        <span class=\"token function\">signal</span><span class=\"token punctuation\">(</span>SIGCHLD<span class=\"token punctuation\">,</span>SIG_IGN<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"before fork pid:%d\\n\"</span><span class=\"token punctuation\">,</span><span class=\"token function\">getpid</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> abc <span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">;</span>\n        pid <span class=\"token operator\">=</span> <span class=\"token function\">fork</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>pid <span class=\"token operator\">==</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">{\n    <!-- --></span>\n                <span class=\"token function\">perror</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"tile\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token keyword\">return</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>pid <span class=\"token operator\">&gt;</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span>           <span class=\"token comment\">//父进程先退出</span>\n        <span class=\"token punctuation\">{\n    <!-- --></span>\n                abc<span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n                <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"parent:pid:%d \\n\"</span><span class=\"token punctuation\">,</span><span class=\"token function\">getpid</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"abc:%d \\n\"</span><span class=\"token punctuation\">,</span>abc<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token function\">sleep</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">else</span> <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>pid <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span>    <span class=\"token comment\">//值进程后退出,被托付给init进程</span>\n        <span class=\"token punctuation\">{\n    <!-- --></span>  \n                abc<span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n                <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"child:%d,parent: %d\\n\"</span><span class=\"token punctuation\">,</span><span class=\"token function\">getpid</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token function\">getppid</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"abc:%d\"</span><span class=\"token punctuation\">,</span>abc<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token function\">sleep</span><span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"fork after...\\n\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>我们使用 gcc 编译上述程序，具体命令如下：</p> \n <pre><code class=\"prism language-bash\">gcc childprocess.c <span class=\"token parameter variable\">-ochildprocess</span>\n</code></pre> \n <p>编译完成后，会在当前目录生成一个 childprocess 的二进制可执行文件，我们使用 ls 命令，查看，如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/05aa810adec24bf5b82287712f14fb4d.png\" alt=\"\"></p> \n <p>此时，我们直接运行该二进制文件，输入以下命令：</p> \n <pre><code class=\"prism language-bash\">./childprocess\n</code></pre> \n <p>运行成功后，控制台输出如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/5c7d453633f9477897d58723fcf3f0a6.png\" alt=\"\"></p> \n <p>此时，我们在另一终端，使用 ps 命令，查看当前进程的状态，具体命令如下：</p> \n <pre><code>ps -elf | grep childprocess\n</code></pre> \n <p>此时，运行后，控制台输出如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/2ad5bbd8f0da410d81e11cad7a508f17.png\" alt=\"\"></p> \n <p>此时，我们可以看到，有两个 childprocess 进程在运行，稍等一会，我们再次使用 ps 命令查看当前进程状态，此时，运行后，控制台输出如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/b75792ec32e44767ba7f17146eaedc5d.png\" alt=\"\"></p> \n <p>此时，我们可以看到，只有一个 childprocess 进程在运行了，而且此时的 childprocess 进程的父进程变成了 1，也就是我们说的 init 进程。</p> \n <h3><a id=\"_605\"></a>僵尸进程</h3> \n <h4><a id=\"_607\"></a>僵尸进程教程</h4> \n <p>如果我们了解过 Linux 进程状态及转换关系，我们应该知道进程这么多状态中有一种状态是僵死状态，就是进程终止后进入僵死状态（zombie）等待告知父进程自己终止后才能完全消失。</p> \n <p>但是如果一个进程已经终止了，但是其父进程还没有获取其状态，那么这个进程就称之为僵尸进程。</p> \n <p>僵尸进程还会消耗一定的系统资源，并且还保留一些概要信息供父进程查询子进程的状态可以提供父进程想要的信息，一旦父进程得到想要的信息，僵尸进程就会结束。</p> \n <h4><a id=\"_615\"></a>案例</h4> \n <h5><a id=\"_617\"></a>创建僵尸进程</h5> \n <p>我们在 Linux 下使用 vim 新建一个 zombie.c 的文件，编写如下 C 语言 代码如下：</p> \n <pre><code class=\"prism language-c\"><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;sys/types.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;unistd.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;stdlib.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;stdio.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;string.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;signal.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;errno.h&gt;</span></span>\n<span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">void</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token class-name\">pid_t</span> pid <span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">//signal(SIGCHLD,SIG_IGN);</span>\n        <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"before fork pid:%d\\n\"</span><span class=\"token punctuation\">,</span><span class=\"token function\">getpid</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> abc <span class=\"token operator\">=</span> <span class=\"token number\">10</span><span class=\"token punctuation\">;</span>\n        pid <span class=\"token operator\">=</span> <span class=\"token function\">fork</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>pid <span class=\"token operator\">==</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">{\n    <!-- --></span>\n                <span class=\"token function\">perror</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"tile\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token keyword\">return</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>pid <span class=\"token operator\">&gt;</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">{\n    <!-- --></span>\n                abc<span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n                <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"parent:pid:%d \\n\"</span><span class=\"token punctuation\">,</span><span class=\"token function\">getpid</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"abc:%d \\n\"</span><span class=\"token punctuation\">,</span>abc<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token function\">sleep</span><span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">else</span> <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>pid <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">{\n    <!-- --></span>\n                abc<span class=\"token operator\">++</span><span class=\"token punctuation\">;</span>\n                <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"child:%d,parent: %d\\n\"</span><span class=\"token punctuation\">,</span><span class=\"token function\">getpid</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token function\">getppid</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"abc:%d\"</span><span class=\"token punctuation\">,</span>abc<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token function\">exit</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"fork after...\\n\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>我们使用 gcc 编译上述程序，具体命令如下：</p> \n <pre><code class=\"prism language-bash\">gcc zombie.c <span class=\"token parameter variable\">-ozombie</span>\n</code></pre> \n <p>编译完成后，会在当前目录生成一个 zombie 的二进制可执行文件，我们使用 ls 命令，查看，如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/a2c8c2d3e00d465e9278624d89135b69.png\" alt=\"\"></p> \n <p>此时，我们直接运行该二进制文件，输入以下命令：</p> \n <pre><code class=\"prism language-bash\">./zombie\n</code></pre> \n <p>运行成功后，控制台输出如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/a6f75eccffb840738eeb66f5b317c00e.png\" alt=\"\"></p> \n <p>此时，我们在另一终端，使用 ps 命令，查看当前进程的状态，具体命令如下：</p> \n <pre><code class=\"prism language-bash\"><span class=\"token function\">ps</span> <span class=\"token parameter variable\">-elf</span> <span class=\"token operator\">|</span> <span class=\"token function\">grep</span> zombie\n</code></pre> \n <p>此时，运行后，控制台输出如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/651b7aa656c744e4a3877b1c8d4cda28.png\" alt=\"\"></p> \n <p>此时，我们可以看到，zombie 进程后面的状态为 defunct，即此时的 zombie 进程即为僵尸进程。</p> \n <h3><a id=\"_691\"></a>怎么避免僵尸进程</h3> \n <p>看程序被注释的那句 signal(SIGCHLD,SIG_IGN)，加上就不会出现僵尸进程了。</p> \n <p>这是 signal() 函数 的声明 sighandler_t signal(int signum, sighandler_t handler)，我们可以得出 signal 函数的第一个函数是 Linux 支持的信号，第二个参数是对信号的操作 ，是系统默认还是忽略或捕获。</p> \n <p>我们这是就可以知道 signal(SIGCHLD,SIG_IGN) 是选择对子程序终止信号选择忽略，这是僵尸进程就是交个内核自己处理，并不会产生僵尸进程。</p> \n <h3><a id=\"_701\"></a>守护进程</h3> \n <h4><a id=\"_703\"></a>守护进程教程</h4> \n <p>守护进程就是在后台运行，不与任何终端关联的进程。</p> \n <p>通常情况下守护进程在系统启动时就在运行，它们以 root 用户或者其他特殊用户（apache 和 postfix）运行，并能处理一些系统级的任务。习惯上守护进程的名字通常以 d 结尾（sshd），但这些不是必须的。</p> \n <h4><a id=\"_709\"></a>创建守护进程的步骤</h4> \n <ul>\n  <li>调用 fork()，创建新进程，它会是将来的守护进程。</li>\n  <li>在父进程中调用 exit，保证子进程不是进程组长。</li>\n  <li>调用 setsid() 创建新的会话区。</li>\n  <li>将当前目录改成跟目录（如果把当前目录作为守护进程的目录，当前目录不能被卸载他作为守护进程的工作目录）。</li>\n  <li>将标准输入，标注输出，标准错误重定向到 /dev/null。</li>\n </ul> \n <h4><a id=\"_717\"></a>案例</h4> \n <h5><a id=\"_719\"></a>创建守护进程</h5> \n <p>我们在 Linux 下使用 vim 新建一个 daemon.c 的文件，编写如下 C 语言 代码如下：</p> \n <pre><code class=\"prism language-c\"><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;sys/types.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;sys/stat.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;unistd.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;stdlib.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;stdio.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;string.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;signal.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;errno.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;signal.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;fcntl.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;unistd.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;linux/fs.h&gt;</span></span>\n<span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">void</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token class-name\">pid_t</span> pid<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">int</span> i<span class=\"token punctuation\">;</span>\n    pid <span class=\"token operator\">=</span> <span class=\"token function\">fork</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>    <span class=\"token comment\">//创建一个新进程,将来会是守护进程</span>\n    <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>pid <span class=\"token operator\">==</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token keyword\">return</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token keyword\">else</span> <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>pid <span class=\"token operator\">!=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">{\n    <!-- --></span> \n    	<span class=\"token comment\">//父进程调用exit,保证子进程不是进程组长</span>\n        <span class=\"token function\">exit</span><span class=\"token punctuation\">(</span>EXIT_SUCCESS<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span><span class=\"token function\">setsid</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">//创建新的会话区</span>\n    <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token keyword\">return</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">;</span>        \n    <span class=\"token punctuation\">}</span>\n    <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span><span class=\"token function\">chdir</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"/\"</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\">//将当前目录改成根目录</span>\n    <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token keyword\">return</span>  <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token keyword\">for</span><span class=\"token punctuation\">(</span>i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>i <span class=\"token operator\">&lt;</span> <span class=\"token number\">1024</span><span class=\"token punctuation\">;</span>i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token function\">close</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token function\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"/dev/null\"</span><span class=\"token punctuation\">,</span>O_RDWR<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  <span class=\"token comment\">//重定向</span>\n    <span class=\"token function\">dup</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token function\">dup</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">return</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>我们使用 gcc 编译上述程序，具体命令如下：</p> \n <pre><code class=\"prism language-bash\">gcc daemon.c <span class=\"token parameter variable\">-odaemon</span>\n</code></pre> \n <p>编译完成后，会在当前目录生成一个 daemon 的二进制可执行文件，我们使用 ls 命令，查看，如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/757e6cfe779e4dc592103589e2b2745a.png\" alt=\"\"></p> \n <p>此时，我们直接运行该二进制文件，输入以下命令：</p> \n <pre><code class=\"prism language-bash\">./daemon\n</code></pre> \n <p>运行成功后，控制台输出如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/01a057cc1a7d4ea78754b0a1628238b0.png\" alt=\"\"></p> \n <p>此时，我们的程序就是守护进程了。</p> \n <h3><a id=\"_793\"></a>上下文切换</h3> \n <h4><a id=\"_795\"></a>进程切换</h4> \n <ol>\n  <li>切换页目录以使用新的地址空间</li>\n  <li>切换内核栈</li>\n  <li>切换硬件上下文</li>\n </ol> \n <h4><a id=\"_801\"></a>线程切换</h4> \n <ol>\n  <li>切换内核栈</li>\n  <li>切换硬件上下文</li>\n </ol> \n <h3><a id=\"_808\"></a>进程间通信方式</h3> \n <h4><a id=\"_810\"></a>概述</h4> \n <p>进程通信(Interprocess Communication，IPC)是一个进程与另一个进程间共享消息的一种通信方式。消息(message)是发送进程形成的一个消息块，将消息内容传送给接收进程。</p> \n <p>IPC 机制是消息从一个进程的地址空间拷贝到另一个进程的地址空间。</p> \n <h4><a id=\"_816\"></a>进程通信的目的</h4> \n <p><strong>数据传输：</strong> 一个进程需要将其数据发送给另一进程，发送的数据量在一个字节到几 M 字节之间。</p> \n <p><strong>共享数据：</strong> 多个进程操作共享数据。</p> \n <p><strong>事件通知：</strong> 一个进程需要向另一个或一组进程发送消息，通知它（它们）发生了某种事件（如进程终止时要通知父进程）。</p> \n <p><strong>资源共享：</strong> 多个进程之间共享同样的资源。为了作到这一点，需要内核提供锁和同步机制。</p> \n <p><strong>进程控制：</strong> 有些进程希望完全控制另一个进程的执行（如 Debug 进程），此时控制进程希望能够拦截另一个进程的所有陷入和异常，并能够及时知道它的状态改变。</p> \n <h4><a id=\"LinuxIPC_828\"></a>Linux进程间通信（IPC）的发展</h4> \n <p>Linux 下的进程通信手段基本上是从 Unix 平台上的进程通信手段继承而来的。而对 Unix 发展做出重大贡献的两大主力 AT&amp;T 的贝尔实验室及 BSD（加州大学伯克利分校的伯克利软件发布中心）在进程间通信方面的侧重点有所不同。</p> \n <p>前者对 Unix 早期的进程间通信手段进行了系统的改进和扩充，形成了 “system V IPC”，通信进程局限在单个计算机内；后者则跳过了该限制，形成了基于套接口（socket）的进程间通信机制。Linux 则把两者继承了下来。</p> \n <ul>\n  <li>早期 UNIX 进程间通信</li>\n  <li>基于 System V 进程间通信</li>\n  <li>基于 Socket 进程间通信</li>\n  <li>POSIX 进程间通信</li>\n </ul> \n <p>UNIX 进程间通信方式包括：管道、FIFO、信号。</p> \n <p>System V 进程间通信方式包括：System V 消息队列、System V 信号灯、System V 共享内存</p> \n <p>POSIX 进程间通信包括：posix 消息队列、posix 信号灯、posix 共享内存。</p> \n <p>由于 Unix 版本的多样性，电子电气工程协会（IEEE）开发了一个独立的 Unix 标准，这个新的 ANSI Unix 标准被称为计算机环境的可移植性操作系统界面（PSOIX）。现有大部分 Unix 和流行版本都是遵循 POSIX 标准的，而 Linux 从一开始就遵循 POSIX 标准。</p> \n <p>BSD 并不是没有涉足单机内的进程间通信（socket 本身就可以用于单机内的进程间通信）。事实上，很多 Unix 版本的单机 IPC 留有 BSD 的痕迹，如 4.4BSD 支持的匿名内存映射、4.3+BSD 对可靠信号语义的实现等等。</p> \n <h3><a id=\"Linux_849\"></a>Linux使用的进程间通信方式</h3> \n <ol>\n  <li>管道（pipe）,流管道(s_pipe)和有名管道（FIFO）</li>\n  <li>信号（signal）</li>\n  <li>消息队列</li>\n  <li>共享内存</li>\n  <li>信号量</li>\n  <li>套接字（socket)</li>\n </ol> \n <h4><a id=\"_pipe__858\"></a>管道( pipe )</h4> \n <p>管道这种通讯方式有两种限制，一是半双工的通信，数据只能单向流动，二是只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。</p> \n <p>流管道 s_pipe: 去除了第一种限制,可以双向传输。</p> \n <p>管道可用于具有亲缘关系进程间的通信，命名管道：name_pipe 克服了管道没有名字的限制，因此，除具有管道所具有的功能外，它还允许无亲缘关系进程间的通信。</p> \n <h4><a id=\"_semophore__866\"></a>信号量( semophore )</h4> \n <p>信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。</p> \n <p>信号是比较复杂的通信方式，用于通知接受进程有某种事件发生，除了用于进程间通信外，进程还可以发送信号给进程本身；linux 除了支持 Unix 早期信号语义函数 signal 外，还支持语义符合 Posix.1 标准的信号函数 sigaction（实际上，该函数是基于 BSD 的，BSD 为了实现可靠信号机制，又能够统一对外接口，用 sigaction 函数重新实现了 signal 函数）；</p> \n <h4><a id=\"_message_queue__872\"></a>消息队列( message queue )</h4> \n <p>消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。</p> \n <p>消息队列是消息的链接表，包括 Posix 消息队列 system V 消息队列。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。</p> \n <h4><a id=\"__singal__878\"></a>信号 ( singal )</h4> \n <p>信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。</p> \n <p>主要作为进程间以及同一进程不同线程之间的同步手段。</p> \n <h4><a id=\"_shared_memory__884\"></a>共享内存( shared memory )</h4> \n <p>共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。</p> \n <p>使得多个进程可以访问同一块内存空间，是最快的可用 IPC 形式。是针对其他通信机制运行效率较低而设计的。往往与其它通信机制，如信号量结合使用，来达到进程间的同步及互斥。</p> \n <h4><a id=\"_socket__890\"></a>套接字( socket )</h4> \n <p>套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信</p> \n <p>更为一般的进程间通信机制，可用于不同机器之间的进程间通信。起初是由 Unix 系统的 BSD 分支开发出来的，但现在一般可以移植到其它类 Unix 系统上：Linux 和 System V 的变种都支持套接字。</p> \n <h3><a id=\"_896\"></a>进程间通信各种方式效率比较</h3> \n <table>\n  <thead>\n   <tr>\n    <th>类型</th>\n    <th>无连接</th>\n    <th>可靠</th>\n    <th>流控制</th>\n    <th>优先级</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>普通PIPE</td>\n    <td>N</td>\n    <td>Y</td>\n    <td>Y</td>\n    <td>N</td>\n   </tr>\n   <tr>\n    <td>流PIPE</td>\n    <td>N</td>\n    <td>Y</td>\n    <td>Y</td>\n    <td>N</td>\n   </tr>\n   <tr>\n    <td>命名PIPE(FIFO)</td>\n    <td>N</td>\n    <td>Y</td>\n    <td>Y</td>\n    <td>N</td>\n   </tr>\n   <tr>\n    <td>消息队列</td>\n    <td>N</td>\n    <td>Y</td>\n    <td>Y</td>\n    <td>Y</td>\n   </tr>\n   <tr>\n    <td>信号量</td>\n    <td>N</td>\n    <td>Y</td>\n    <td>Y</td>\n    <td>Y</td>\n   </tr>\n   <tr>\n    <td>共享存储</td>\n    <td>N</td>\n    <td>Y</td>\n    <td>Y</td>\n    <td>Y</td>\n   </tr>\n   <tr>\n    <td>UNIX流SOCKET</td>\n    <td>N</td>\n    <td>Y</td>\n    <td>Y</td>\n    <td>N</td>\n   </tr>\n   <tr>\n    <td>UNIX数据包SOCKET</td>\n    <td>Y</td>\n    <td>Y</td>\n    <td>N</td>\n    <td>N</td>\n   </tr>\n  </tbody>\n </table> \n <p>注:无连接: 指无需调用某种形式的OPEN,就有发送消息的能力流控制，如果系统资源短缺或者不能接收更多消息,则发送进程能进行流量控制。</p> \n <h3><a id=\"_911\"></a>通信方式的比较和优缺点</h3> \n <ol>\n  <li>管道：速度慢，容量有限，只有父子进程能通讯</li>\n  <li>FIFO：任何进程间都能通讯，但速度慢</li>\n  <li>消息队列：容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题</li>\n  <li>信号量：不能传递复杂消息，只能用来同步</li>\n  <li>共享内存区：能够很容易控制容量，速度快，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全，当然，共享内存区同样可以用作线程间通讯，不过没这个必要，线程间本来就已经共享了同一进程内的一块内存</li>\n </ol> \n <p>如果用户传递的信息较少或是需要通过信号来触发某些行为，前文提到的软中断信号机制不失为一种简捷有效的进程间通信方式。</p> \n <p>但若是进程间要求传递的信息量比较大或者进程间存在交换数据的要求，那就需要考虑别的通信方式了。</p> \n <p>无名管道简单方便．但局限于单向通信的工作方式．并且只能在创建它的进程及其子孙进程之间实现管道的共享。</p> \n <p>有名管道虽然可以提供给任意关系的进程使用，但是由于其长期存在于系统之中，使用不当容易出错，所以普通用户一般不建议使用。</p> \n <p>消息缓冲可以不再局限于父子进程，而允许任意进程通过共享消息队列来实现进程间通信，并由系统调用函数来实现消息发送和接收之间的同步，从而使得用户在使用消息缓冲进行通信时不再需要考虑同步问题，使用方便，但是信息的复制需要额外消耗 CPU 的时间，不适宜于信息量大或操作频繁的场合。</p> \n <p>共享内存针对消息缓冲的缺点改而利用内存缓冲区直接交换信息，无须复制，快捷、信息量大是其优点。</p> \n <p>但是共享内存的通信方式是通过将共享的内存缓冲区直接附加到进程的虚拟地址空间中来实现的，因此，这些进程之间的读写操作的同步问题操作系统无法实现。必须由各进程利用其他同步工具解决。另外，由于内存实体存在于计算机系统中，所以只能由处于同一个计算机系统中的诸进程共享。不方便网络通信。</p> \n <p>共享内存块提供了在任意数量的进程之间进行高效双向通信的机制。每个使用者都可以读取写入数据，但是所有程序之间必须达成并遵守一定的协议，以防止诸如在读取信息之前覆写内存空间等竞争状态的出现。</p> \n <p>不幸的是，Linux 无法严格保证提供对共享内存块的独占访问，甚至是在您通过使用 IPC_PRIVATE 创建新的共享内存块的时候也不能保证访问的独占性。 同时，多个使用共享内存块的进程之间必须协调使用同一个键值。</p> \n <h3><a id=\"_937\"></a>进程间通信方式的选择</h3> \n <ul>\n  <li>PIPE 和 FIFO(有名管道)用来实现进程间相互发送非常短小的、频率很高的消息，这两种方式通常适用于两个进程间的通信。</li>\n  <li>共享内存用来实现进程间共享的、非常庞大的、读写操作频率很高的数据；这种方法适用于多进程间的通信。</li>\n  <li>其他考虑用 socket。主要应用在分布式开发中。</li>\n </ul> \n <h3><a id=\"_945\"></a>线程间通信方式</h3> \n <p>线程间通信方式主要包括消息队列、使用全局变量和使用事件。</p> \n <h4><a id=\"_949\"></a>消息队列</h4> \n <p>消息队列，是最常用的一种，也是最灵活的一种，通过自定义数据结构，可以传输复杂和简单的数据结构。</p> \n <p>在 Windows 程序设计中，每一个线程都可以拥有自己的消息队列（UI 线程默认自带消息队列和消息循环，工作线程需要手动实现消息循环），因此可以采用消息进行线程间通信 sendMessage，postMessage。</p> \n <ol>\n  <li>定义消息 <code>#define WM_THREAD_SENDMSG=WM_USER+20;</code></li>\n  <li>添加消息函数声明 <code>afx_msg int OnTSendmsg();</code></li>\n  <li>添加消息映射 <code>ON_MESSAGE(WM_THREAD_SENDMSG,OnTSM);</code></li>\n  <li>添加 OnTSM() 的实现函数；</li>\n  <li>在线程函数中添加 PostMessage 消息 Post 函数。</li>\n </ol> \n <h4><a id=\"_961\"></a>全局变量</h4> \n <p>进程中的线程间内存共享，这是比较常用的通信方式和交互方式。</p> \n <p>注：定义全局变量时最好使用 volatile 来定义，以防编译器对此变量进行优化。</p> \n <h4><a id=\"_967\"></a>使用事件</h4> \n <p>使用事件 CEvent 类实现线程间通信，Event 对象有两种状态：有信号和无信号，线程可以监视处于有信号状态的事件，以便在适当的时候执行对事件的操作。</p> \n <ol>\n  <li>创建一个 CEvent 类的对象：CEvent threadStart; 它默认处在未通信状态；</li>\n  <li>threadStart.SetEvent(); 使其处于通信状态；</li>\n  <li>调用 WaitForSingleObject() 来监视 CEvent 对象。</li>\n </ol> \n <h3><a id=\"_977\"></a>线程间同步方式</h3> \n <p>各个线程可以访问进程中的公共变量，资源，所以使用多线程的过程中需要注意的问题是如何防止两个或两个以上的线程同时访问同一个数据，以免破坏数据的完整性。数据之间的相互制约包括：</p> \n <ol>\n  <li>直接制约关系，即一个线程的处理结果，为另一个线程的输入，因此线程之间直接制约着，这种关系可以称之为同步关系。</li>\n  <li>间接制约关系，即两个线程需要访问同一资源，该资源在同一时刻只能被一个线程访问，这种关系称之为线程间对资源的互斥访问，某种意义上说互斥是一种制约关系更小的同步。</li>\n </ol> \n <h4><a id=\"_984\"></a>线程间的同步方式有四种</h4> \n <h4><a id=\"_986\"></a>临界区</h4> \n <p>临界区对应着一个 CcriticalSection 对象，当线程需要访问保护数据时，调用 EnterCriticalSection 函数；当对保护数据的操作完成之后，调用 LeaveCriticalSection 函数释放对临界区对象的拥有权，以使另一个线程可以夺取临界区对象并访问受保护的数据。</p> \n <p>PS: 关键段对象会记录拥有该对象的线程句柄即其具有 “线程所有权” 概念，即进入代码段的线程在 leave 之前，可以重复进入关键代码区域。所以关键段可以用于线程间的互斥，但不可以用于同步（同步需要在一个线程进入，在另一个线程 leave）</p> \n <h4><a id=\"_992\"></a>互斥量</h4> \n <p>互斥与临界区很相似，但是使用时相对复杂一些（互斥量为内核对象），不仅可以在同一应用程序的线程间实现同步，还可以在不同的进程间实现同步，从而实现资源的安全共享。</p> \n <p>PS:</p> \n <ol>\n  <li>互斥量由于也有线程所有权的概念，故也只能进行线程间的资源互斥访问，不能由于线程同步；</li>\n  <li>由于互斥量是内核对象，因此其可以进行进程间通信，同时还具有一个很好的特性，就是在进程间通信时完美的解决了 “遗弃” 问题。</li>\n </ol> \n <h4><a id=\"_1001\"></a>信号量</h4> \n <p>信号量的用法和互斥的用法很相似，不同的是它可以同一时刻允许多个线程访问同一个资源，PV 操作</p> \n <p>PS: 事件可以完美解决线程间的同步问题，同时信号量也属于内核对象，可用于进程间的通信。</p> \n <h4><a id=\"_1007\"></a>事件</h4> \n <p>事件分为手动置位事件和自动置位事件。事件 Event 内部它包含一个使用计数（所有内核对象都有），一个布尔值表示是手动置位事件还是自动置位事件，另一个布尔值用来表示事件有无触发。由 SetEvent() 来触发，由 ResetEvent() 来设成未触发。</p> \n <p>PS: 事件是内核对象,可以解决线程间同步问题，因此也能解决互斥问题。</p> \n <h3><a id=\"Linux_1013\"></a>Linux进程状态</h3> \n <h4><a id=\"Linux_1015\"></a>Linux进程状态教程</h4> \n <p>Linux 是一个多用户，多任务的系统，可以同时运行多个用户的多个程序，就必然会产生很多的进程，而每个进程会有不同的状态。</p> \n <h4><a id=\"Linux__1019\"></a>Linux 进程状态</h4> \n <table>\n  <thead>\n   <tr>\n    <th>状态</th>\n    <th>状态全称</th>\n    <th>描述</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td><em>R</em></td>\n    <td>TASK_RUNNING</td>\n    <td>可执行状态</td>\n   </tr>\n   <tr>\n    <td><em>S</em></td>\n    <td>TASK_INTERRUPTIBLE</td>\n    <td>可中断的睡眠状态</td>\n   </tr>\n   <tr>\n    <td><em>D</em></td>\n    <td>TASK_UNINTERRUPTIBLE</td>\n    <td>不可中断的睡眠状态</td>\n   </tr>\n   <tr>\n    <td><em>T</em></td>\n    <td>TASK_STOPPED or TASK_TRACED</td>\n    <td>暂停状态或跟踪状态</td>\n   </tr>\n   <tr>\n    <td><em>Z</em></td>\n    <td>TASK_DEAD - EXIT_ZOMBIE</td>\n    <td>退出状态，进程成为僵尸进程</td>\n   </tr>\n   <tr>\n    <td><em>X</em></td>\n    <td>TASK_DEAD - EXIT_DEAD</td>\n    <td>退出状态，进程即将被销毁</td>\n   </tr>\n  </tbody>\n </table> \n <h4><a id=\"Linux_1030\"></a>Linux进程状态详解</h4> \n <h5><a id=\"R_TASK_RUNNING_1032\"></a>R (TASK_RUNNING)，可执行状态</h5> \n <p>只有在该状态的进程才可能在 CPU 上运行。</p> \n <p>而同一时刻可能有多个进程处于可执行状态，这些进程的 task_struct 结构（进程控制块）被放入对应 CPU 的可执行队列中（一个进程最多只能出现在一个 CPU 的可执行队列中）。</p> \n <p>进程调度器的任务就是从各个 CPU 的可执行队列中分别选择一个进程在该 CPU 上运行。</p> \n <h5><a id=\"S_TASK_INTERRUPTIBLE__1040\"></a>S (TASK_INTERRUPTIBLE) 可中断的睡眠状态</h5> \n <p>处于这个状态的进程因为等待某某事件的发生（比如等待 socket 连接、等待信号量），而被挂起。</p> \n <p>这些进程的 task_struct 结构被放入对应事件的等待队列中。当这些事件发生时（由外部中断触发、或由其他进程触发），对应的等待队列中的一个或多个进程将被唤醒。</p> \n <p>通过 ps 命令我们会看到，一般情况下，进程列表中的绝大多数进程都处于 TASK_INTERRUPTIBLE 状态（除非机器的负载很高）。毕竟 CPU 就这么一两个，进程动辄几十上百个，如果不是绝大多数进程都在睡眠，CPU 又怎么响应得过来。</p> \n <h5><a id=\"D_TASK_UNINTERRUPTIBLE__1048\"></a>D (TASK_UNINTERRUPTIBLE) 不可中断的睡眠状态</h5> \n <p>与 TASK_INTERRUPTIBLE 状态类似，进程处于睡眠状态，但是此刻进程是不可中断的。不可中断，指的并不是 CPU 不响应外部硬件的中断，而是指进程不响应异步信号。</p> \n <p>绝大多数情况下，进程处在睡眠状态时，总是应该能够响应异步信号的。否则你将惊奇的发现，kill -9 竟然杀不死一个正在睡眠的进程了！于是我们也很好理解，为什么 ps 命令看到的进程几乎不会出现TASK_UNINTERRUPTIBLE 状态，而总是 TASK_INTERRUPTIBLE 状态。</p> \n <p>而 TASK_UNINTERRUPTIBLE 状态存在的意义就在于，内核的某些处理流程是不能被打断的。如果响应异步信号，程序的执行流程中就会被插入一段用于处理异步信号的流程（这个插入的流程可能只存在于内核态，也可能延伸到用户态），于是原有的流程就被中断了。</p> \n <p>在进程对某些硬件进行操作时（比如进程调用 read 系统调用对某个设备文件进行读操作，而 read 系统调用最终执行到对应设备驱动的代码，并与对应的物理设备进行交互），可能需要使用 TASK_UNINTERRUPTIBLE 状态对进程进行保护，以避免进程与设备交互的过程被打断，造成设备陷入不可控的状态。这种情况下的 TASK_UNINTERRUPTIBLE 状态总是非常短暂的，通过 ps 命令基本上不可能捕捉到。</p> \n <p>然后我们可以试验一下 TASK_UNINTERRUPTIBLE 状态的威力。不管 kill 还是 kill -9，这个 TASK_UNINTERRUPTIBLE 状态的父进程依然屹立不倒。</p> \n <h5><a id=\"T_TASK_STOPPED_or_TASK_TRACED_1060\"></a>T (TASK_STOPPED or TASK_TRACED)，暂停状态或跟踪状态</h5> \n <p>向进程发送一个 SIGSTOP 信号，它就会因响应该信号而进入 TASK_STOPPED 状态（除非该进程本身处于 TASK_UNINTERRUPTIBLE 状态而不响应信号）。（SIGSTOP 与 SIGKILL 信号一样，是非常强制的。不允许用户进程通过 signal 系列的系统调用重新设置对应的信号处理函数。）</p> \n <p>向进程发送一个 SIGCONT 信号，可以让其从 TASK_STOPPED 状态恢复到 TASK_RUNNING 状态。</p> \n <p>当进程正在被跟踪时，它处于 TASK_TRACED 这个特殊的状态。“正在被跟踪” 指的是进程暂停下来，等待跟踪它的进程对它进行操作。比如在 gdb 中对被跟踪的进程下一个断点，进程在断点处停下来的时候就处于 TASK_TRACED 状态。而在其他时候，被跟踪的进程还是处于前面提到的那些状态。</p> \n <p>对于进程本身来说，TASK_STOPPED 和 TASK_TRACED 状态很类似，都是表示进程暂停下来。</p> \n <p>而 TASK_TRACED 状态相当于在 TASK_STOPPED 之上多了一层保护，处于 TASK_TRACED 状态的进程不能响应 SIGCONT 信号而被唤醒。只能等到调试进程通过 ptrace 系统调用执行 PTRACE_CONT、PTRACE_DETACH 等操作（通过 ptrace 系统调用的参数指定操作），或调试进程退出，被调试的进程才能恢复 TASK_RUNNING 状态。</p> \n <h5><a id=\"Z_TASK_DEAD__EXIT_ZOMBIE_1072\"></a>Z (TASK_DEAD - EXIT_ZOMBIE)，退出状态，进程成为僵尸进程</h5> \n <p>进程在退出的过程中，处于 TASK_DEAD 状态。</p> \n <p>在这个退出过程中，进程占有的所有资源将被回收，除了 task_struct 结构（以及少数资源）以外。于是进程就只剩下 task_struct 这么个空壳，故称为僵尸。 之所以保留 task_struct，是因为 task_struct 里面保存了进程的退出码、以及一些统计信息。而其父进程很可能会关心这些信息。比如在 shell 中，$? 变量 就保存了最后一个退出的前台进程的退出码，而这个退出码往往被作为 if 语句的判断条件。</p> \n <p>当然，内核也可以将这些信息保存在别的地方，而将 task_struct 结构释放掉，以节省一些空间。但是使用 task_struct 结构更为方便，因为在内核中已经建立了从 pid 到 task_struct 查找关系，还有进程间的父子关系。释放掉 task_struct，则需要建立一些新的数据结构，以便让父进程找到它的子进程的退出信息。</p> \n <p>父进程可以通过 wait 系列的系统调用（如wait4、waitid）来等待某个或某些子进程的退出，并获取它的退出信息。然后 wait 系列的系统调用会顺便将子进程的尸体（task_struct）也释放掉。</p> \n <p>子进程在退出的过程中，内核会给其父进程发送一个信号，通知父进程来 “收尸”。这个信号默认是 SIGCHLD，但是在通过 clone 系统调用创建子进程时，可以设置这个信号。</p> \n <p>只要父进程不退出，这个僵尸状态的子进程就一直存在。那么如果父进程退出了呢，谁又来给子进程 “收尸”？</p> \n <p>当进程退出的时候，会将它的所有子进程都托管给别的进程（使之成为别的进程的子进程）。托管给谁呢？可能是退出进程所在进程组的下一个进程（如果存在的话），或者是 1 号进程。所以每个进程、每时每刻都有父进程存在。除非它是 1 号进程。1 号进程，pid 为 1 的进程，又称 init 进程。</p> \n <p>Linux 系统启动后，第一个被创建的用户态进程就是 init 进程。它有两项使命：</p> \n <ul>\n  <li>执行系统初始化脚本，创建一系列的进程（它们都是 init 进程的子孙）；</li>\n  <li>在一个死循环中等待其子进程的退出事件，并调用 waitpid 系统调用来完成 “收尸” 工作；</li>\n </ul> \n <p>init 进程不会被暂停、也不会被杀死（这是由内核来保证的）。它在等待子进程退出的过程中处于TASK_INTERRUPTIBLE 状态，“收尸” 过程中则处于 TASK_RUNNING 状态。</p> \n <h5><a id=\"X_TASK_DEAD__EXIT_DEAD_1095\"></a>X (TASK_DEAD - EXIT_DEAD)，退出状态，进程即将被销毁</h5> \n <p>而进程在退出过程中也可能不会保留它的 task_struct。比如这个进程是多线程程序中被 detach 过的进程（进程？线程？参见《linux线程浅析》）。或者父进程通过设置 SIGCHLD 信号的 handler 为 SIG_IGN，显式的忽略了 SIGCHLD 信号。（这是 posix 的规定，尽管子进程的退出信号可以被设置为 SIGCHLD 以外的其他信号。）</p> \n <p>此时，进程将被置于 EXIT_DEAD 退出状态，这意味着接下来的代码立即就会将该进程彻底释放。所以 EXIT_DEAD 状态是非常短暂的，几乎不可能通过 ps 命令捕捉到。</p> \n <h4><a id=\"_1103\"></a>进程的初始状态</h4> \n <p>进程是通过 fork 系列的系统调用（fork、clone、vfork）来创建的，内核（或内核模块）也可以通过 kernel_thread 函数创建内核进程。</p> \n <p>这些创建子进程的函数本质上都完成了相同的功能——将调用进程复制一份，得到子进程。（可以通过选项参数来决定各种资源是共享、还是私有。）</p> \n <p>那么既然调用进程处于 TASK_RUNNING 状态（否则，它若不是正在运行，又怎么进行调用？），则子进程默认也处于 TASK_RUNNING 状态。</p> \n <p>另外，在系统调用调用 clone 和内核函数 kernel_thread 也接受 CLONE_STOPPED 选项，从而将子进程的初始状态置为 TASK_STOPPED。</p> \n <h4><a id=\"_1115\"></a>进程状态变迁</h4> \n <p>进程自创建以后，状态可能发生一系列的变化，直到进程退出。而尽管进程状态有好几种，但是进程状态的变迁却只有两个方向——从 TASK_RUNNING 状态变为非 TASK_RUNNING 状态、或者从非 TASK_RUNNING 状态变为 TASK_RUNNING 状态。</p> \n <p>也就是说，如果给一个 TASK_INTERRUPTIBLE 状态的进程发送 SIGKILL 信号，这个进程将先被唤醒（进入 TASK_RUNNING 状态），然后再响应 SIGKILL 信号而退出（变为 TASK_DEAD 状态）。并不会从 TASK_INTERRUPTIBLE 状态直接退出。</p> \n <p>进程从非 TASK_RUNNING 状态变为 TASK_RUNNING 状态，是由别的进程（也可能是中断处理程序）执行唤醒操作来实现的。执行唤醒的进程设置被唤醒进程的状态为 TASK_RUNNING，然后将其 task_struct 结构加入到某个 CPU 的可执行队列中。于是被唤醒的进程将有机会被调度执行。</p> \n <p>而进程从 TASK_RUNNING 状态变为非 TASK_RUNNING 状态，则有两种途径：</p> \n <ul>\n  <li>响应信号而进入 TASK_STOPED 状态、或 TASK_DEAD 状态；</li>\n  <li>执行系统调用主动进入 TASK_INTERRUPTIBLE 状态（如 nanosleep 系统调用）、或 TASK_DEAD 状态（如 exit 系统调用）；或由于执行系统调用需要的资源得不到满足，而进入 TASK_INTERRUPTIBLE 状态或 TASK_UNINTERRUPTIBLE 状态（如 select 系统调用）。</li>\n </ul> \n <p>显然，这两种情况都只能发生在进程正在 CPU 上执行的情况下。</p> \n <h3><a id=\"_1132\"></a>线程的几种状态</h3> \n <p>线程也具有生命周期，主要包括 7 种状态，分别是出生状态、就绪状态、运行状态、等待状态、休眠状态、阻塞状态和死亡状态，如下图所示：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/d20c7c673a7544a583bd5bd38cdc4c98.png\" alt=\"线程的状态\"></p> \n <p>下面对线程生命周期中的 7 种状态做说明：</p> \n <ul>\n  <li>出生状态：用户在创建线程时所处的状态，在用户使用该线程实例调用 start() 方法之前，线程都处于出生状态。</li>\n  <li>就绪状态：也称可执行状态，当用户调用 start() 方法之后，线程处于就绪状态。</li>\n  <li>运行状态：当线程得到系统资源后进入运行状态。</li>\n  <li>等待状态：当处于运行状态下的线程调用 Thread 类的 wait() 方法时，该线程就会进入等待状态。进入等待状态的线程必须调用 Thread 类的 notify() 方法才能被唤醒。notifyAll() 方法是将所有处于等待状态下的线程唤醒。</li>\n  <li>休眠状态：当线程调用 Thread 类中的 sleep() 方法时，则会进入休眠状态。</li>\n  <li>阻塞状态：如果一个线程在运行状态下发出输入/输出请求，该线程将进入阻塞状态，在其等待输入/输出结束时，线程进入就绪状态。对阻塞的线程来说，即使系统资源关闭，线程依然不能回到运行状态。</li>\n  <li>死亡状态：当线程的 run() 方法执行完毕，线程进入死亡状态。</li>\n </ul> \n <p>提示：一旦线程进入可执行状态，它会在就绪状态与运行状态下辗转，同时也可能进入等待状态、休眠状态、阻塞状态或死亡状态。</p> \n <p>根据上图所示，可以总结出使线程处于就绪状态有如下几种方法：</p> \n <ul>\n  <li>调用 sleep() 方法。</li>\n  <li>调用 wait() 方法。</li>\n  <li>等待输入和输出完成。</li>\n </ul> \n <p>当线程处于就绪状态后，可以用如下几种方法使线程再次进入运行状态：</p> \n <ul>\n  <li>线程调用 notify() 方法。</li>\n  <li>线程调用 notifyAll() 方法。</li>\n  <li>线程调用 intermpt() 方法。</li>\n  <li>线程的休眠时间结束。</li>\n  <li>输入或者输出结束。</li>\n </ul> \n <h3><a id=\"_1166\"></a>进程调度</h3> \n <p>多道程序设计的目标是，无论何时都有进程运行，从而最大化 CPU 利用率。’</p> \n <p>分时系统的目的是在进程之间快速切换 CPU，以便用户在程序运行时能与其交互。</p> \n <p>为了满足这些目标，进程调度器选择一个可用进程（可能从多个可用进程集合中）到 CPU 上执行。</p> \n <p>如果有多个进程，那么余下的需要等待 CPU 空闲并能重新调度。</p> \n <h3><a id=\"_1176\"></a>进程调度的时机和方式</h3> \n <h4><a id=\"_1178\"></a>时机</h4> \n <p>进程调度的时机是什么呢？</p> \n <p>也就是说，什么时候会从就绪队列中选取一个进程，分配处理机给它呢？</p> \n <p>分为两种情况：当前进程主动放弃处理机 以及 当前进程被动放弃处理机。</p> \n <ul>\n  <li>当前进程主动放弃处理机：比如进程正常终止、运行过程中发生异常而终止、进程主动请求阻塞（如等待 I/O）</li>\n  <li>当前进程被动放弃处理机：比如进程的时间片用完、有更紧急的事需要处理（如 I/O 中断）、有更高优先级的进程进入就绪队列</li>\n </ul> \n <h4><a id=\"_1189\"></a>方式</h4> \n <p>根据进程运行的过程中，处理机能否被其它进程抢占，将调度分为两种方式：</p> \n <ul>\n  <li><strong>非抢占式：</strong> “非抢占” 即 “不能抢占”。一旦把处理机分配给某个进程后，除非该进程终止或者主动要求进入阻塞态，否则会一直运行下去，不允许其它进程抢占自己占有的处理机。</li>\n  <li><strong>抢占式：</strong> 把处理机分配给某个进程 A 后，如果有一个更重要、更紧急的进程 B 需要用到处理机，那么进程 A 会立即暂停，把处理机交给进程 B。</li>\n </ul> \n <h4><a id=\"_1196\"></a>补充</h4> \n <p>以下情况不会发生进程调度：</p> \n <ul>\n  <li>处理中断的时候：由于中断处理过程复杂，与硬件密切相关，很难做到在中断处理过程中进行进程切换。</li>\n  <li>进程在操作系统内核程序临界区的时候：注意是内核程序的临界区。普通临界区依然是有可能发生进程调度的。</li>\n  <li>进行原子操作的时候。</li>\n </ul> \n <h4><a id=\"_1206\"></a>调度队列</h4> \n <p>进程在进入系统时，会被加到作业队列，这个队列包括系统内的所有进程。驻留在内存中的、就绪的、等待运行的进程保存在就绪队列上。就绪队列通常用链表实现；其头节点有两个指针，用于指向链表的第一个和最后一个 PCB 块；每个 PCB 还包括一个指针，指向就绪队列的下一个 PCB，如下图。</p> \n <p>系统还有其他队列。当一个进程被分配了 CPU 后，它执行一段时间，最终退出，或被中断，或等待特定事件发生如 I/O 请求的完成。假设进程向一个共享设备如磁盘发出 I/O 请求。由于系统具有许多进程，磁盘可能忙于其他进程的 I/O 请求，因此该进程可能需要等待磁盘。等待特定 I/O 设备的进程列表，称为设备队列。每个设备都有自己的设备队列。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/f1d77158b3a94545b0d32a2f44072851.png\" alt=\"\"></p> \n <p>进程调度通常用队列图来表示，如下图所示。每个矩形框代表一个队列；这里具有两种队列：就绪队列和设备队列。圆圈表示服务队列的资源；箭头表示系统内的进程流向。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/a4e3783580b8442d9f19ceac8f988d8d.png\" alt=\"\"></p> \n <p>最初，新进程被加到就绪队列；它在就绪队列中等待，直到被选中执行或被分派。当该进程分配到 CPU 并执行时，以下事件可能发生：</p> \n <ul>\n  <li>进程可能发出 I/O 请求，并被放到 I/O 队列。</li>\n  <li>进程可能创建一个新的子进程，并等待其终止。</li>\n  <li>进程可能由于中断而被强制释放 CPU，并被放回到就绪队列。</li>\n </ul> \n <p>对于前面两种情况，进程最终从等待状态切换到就绪状态，并放回到就绪队列。进程重复这一循环直到终止；然后它会从所有队列中删除，其 PCB 和资源也被释放。</p> \n <h4><a id=\"_1226\"></a>调度程序</h4> \n <p>进程在整个生命周期中，会在各种调度队列之间迁移。操作系统为了调度必须按一定方式从这些队列中选择进程。进程选择通过适当调度器或调度程序来执行。</p> \n <p>通常，对于批处理系统，提交的进程多于可以立即执行的。这些进程会被保存到大容量存储设备（通常为磁盘）的缓冲池，以便以后执行。长期调度程序（或作业调度程序）从该池中选择进程，加到内存，以便执行。短期调度程序（或 CPU 调度程序）从准备执行的进程中选择进程，并分配 CPU。</p> \n <p>两种调度程序的主要区别是执行频率：</p> \n <ul>\n  <li>短期调度程序必须经常为 CPU 选择新的进程。进程可能执行几毫秒，就会等待 I/O 请求。通常，短期调度程序每 100ms 至少 执行一次。由于执行之间的时间短，短期调度程序必须快速。如果花费 10ms 来确定执行一个运行 100ms 的进程，那么 10/(100 + 10) = 9% 的 CPU 时间会用（浪费）在调度工作上。</li>\n  <li>长期调度程序执行并不频繁；在新进程的创建之间，可能有几分钟间隔。长期调度程序控制多道程序程度(内存中的进程数量）。如果多道程序程度稳定，那么创建进程的平均速度必须等于进程离开系统的平均速度。因此，只有在进程离开系统时，才需要长期调度程序的调度。由于每次执行之间的更长时间间隔，长期调度程序可以负担得起更多时间，以便决定应该选择执行哪个进程。</li>\n </ul> \n <p>重要的是，长期调度程序进行认真选择。通常，大多数进程可分为 I/O 为主或 CPU 为主，I/O 密集型进程执行 I/O 比执行计算需要花费更多时间。相反，CPU 密集型进程很少产生 I/O 请求，而是将更多时间用于执行计算。</p> \n <p>长期调度程序应该选择 I/O 密集型和 CPU 密集型的合理进程组合。因为如果 所有进程都是 I/O 密集型的，那么就绪队列几乎总是为空，从而短期调度程序没有什么可做。如果所有进程都是 CPU 密集型的，那么 I/O 等待队列几乎总是为空，从而设备没有得到使用，因而系统会不平衡。</p> \n <p>有的系统，可能没有或极少采用长期调度程序。例如，UNIX 或微软 Windows 的分时系统通常没有长期调度程序，只是简单将所有新进程放于内存，以供短期调度程序使用。这些系统的稳定性取决于物理限制（如可用的终端数）或用户的自我调整。如果多用户系统性能下降到令人难以接受，那么有的用户就会退出。</p> \n <p>有的操作系统如分时系统，可能引入一个额外的中期调度程序，如下图所示：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/6a5c6e3be5c14cae8bdc0a76832d9a3f.png\" alt=\"进程调度\"></p> \n <p>中期调度程序的核心思想是可将进程从内存（或从 CPU 竞争）中移出，从而降低多道程序程度。之后，进程可被重新调入内存，并从中断处继续执行。这种方案称为交换。</p> \n <p>通过中期调度程序，进程可换出，并在后来可换入。为了改善进程组合，或者由于内存需求改变导致过度使用内存从而需要释放内存，就有必要使用交换。</p> \n <h4><a id=\"_1251\"></a>上下文切换</h4> \n <p>前面提过，中断会导致 CPU 从执行当前任务改变到执行内核程序。这种操作在通用系统中经常发生。当中断发生时，系统需要保存当前运行在 CPU 上的进程的上下文，以便在处理后能够恢复上下文，即先挂起进程，再恢复进程。</p> \n <p>切换 CPU 到另一个进程需要保存当前进程状态和恢复另一个进程的状态，这个任务称为上下文切换。</p> \n <p>当进行上下文切换时，内核会将旧进程状态保存在其 PCB 中，然后加载经调度而要执行的新进程的上下文。上下文切换的时间是纯粹的开销，因为在切换时系统并没有做任何有用工作。上下文切换的速度因机器不同而有所不同，它依赖于内存速度、必须复制的寄存器数量、是否有特殊指令（如加载或存储所有寄存器的单个指令)。典型速度为几毫秒。</p> \n <p>上下文切换的时间与硬件支持密切相关。例如，有的处理器（如 Sun UltraSPARC）提供了多个寄存器组，上下文切换只需简单改变当前寄存器组的指针。当然，如果活动进程数量超过寄存器的组数，那么系统需要像以前一样在寄存器与内存之间进行数据复制。</p> \n <p>不仅如此，操作系统越复杂，上下文切换所要做的就越多，高级的内存管理技术在每次上下文切换时，所需切换的数据会更多。例如，在使用下一个进程的地址空间之前，需要保存当前进程的地址空间。如何保存地址空间，需要做什么才能保存等，取决于操作系统的内存管理方法。</p> \n <h3><a id=\"_1265\"></a>处理机调度的三个层次</h3> \n <h4><a id=\"_1267\"></a>定义</h4> \n <p>调度研究的问题是：</p> \n <p>面对有限的资源，如何处理任务执行的先后顺序。对于处理机调度来说，这个资源就是有限的处理机，而任务就是多个进程。</p> \n <p>故处理机调度研究的问题是：面对有限的处理机，如何从就绪队列中按照一定的算法选择一个进程并将处理机分配给它运行，从而实现进程的并发执行。</p> \n <p>处理机调度共有三个层次，这三个层次也是一个作业从提交开始到完成所经历的三个阶段。</p> \n <h4><a id=\"_1277\"></a>三个层次</h4> \n <p><strong>作业调度</strong></p> \n <p>作业调度也即高级调度，这个阶段可以看作是准备阶段。主要任务是按照一定的规则从外存上处于后备队列的作业中挑选一个或多个作业，为其分配内存，建立 PCB（进程） 等，使它们具备竞争处理机的能力。</p> \n <p>这个阶段进程的状态变化是：无 –&gt; 创建态 –&gt; 就绪态</p> \n <p><strong>内存调度</strong></p> \n <p>内存调度也即中级调度，这个阶段可以看作是优化阶段。主要任务是将暂时不能运行的进程对换到外存中，使它们挂起；而当挂起的进程具备运行条件时，它们会被重新对换回内存，得到激活。这个阶段的主要目的是提高内存利用率和系统吞吐量。</p> \n <p>这个阶段进程的状态变化是： 静止就绪态 –&gt; 活动就绪态，静止阻塞态 –&gt; 活动阻塞态</p> \n <p><strong>进程调度</strong></p> \n <p>进程调度即低级调度，这个阶段让进程真正运行起来。主要任务是按照某种算法，从就绪队列中选取一个进程，分配处理机给它。进程调度是最基本、次数最频繁的阶段。</p> \n <p>这个阶段进程的状态变化是： 就绪态 –&gt; 活动态</p> \n <h3><a id=\"_1299\"></a>进程调度算法</h3> \n <h4><a id=\"_1301\"></a>评价指标</h4> \n <ul>\n  <li>CPU 利用率：忙碌的时间 / 总时间</li>\n  <li>系统吞吐量：完成作业量 / 总时间</li>\n  <li>周转时间：作业完成时间 - 作业提交时间 = 作业实际运行的时间 + 等待时间</li>\n  <li>平均周转时间： 各作业周转时间之和 / 作业数</li>\n  <li>带权周转时间：周转时间 / 作业实际运行的时间</li>\n  <li>平均带权周转时间：各作业带权周转时间之和 / 作业数</li>\n  <li>等待时间：进程或者作业处于等待处理机状态的时间之和，即 周转时间 - 作业实际运行的时间 \n   <ul>\n    <li>对于进程来说，等待时间指的是进程建立后等待被服务的时间之和（由于等待 I/O 完成的期间也属于被服务时间，所以这个时间不计入等待时间）</li>\n    <li>对于作业来说，除了进程建立后的等待时间，还包括作业在外存后备队列中等待的时间</li>\n   </ul> </li>\n </ul> \n <p>平均等待时间：各作业等待时间之和 / 作业数</p> \n <p>响应时间：从用户提交请求到首次产生响应所用的时间</p> \n <h4><a id=\"_1317\"></a>早期批处理系统的调度算法</h4> \n <h5><a id=\"FCFS_1319\"></a>先来先服务调度算法（FCFS）</h5> \n <p>FCFS 算法即 “先来先服务” 算法，类似于我们生活中的排队，谁先来，谁就先享受服务。</p> \n <p>对于作业调度，它指的是谁先到达后备队列，谁就先出队，进而先被执行；对于进程调度，它指的是谁先到达就绪队列，谁就先出队，进而先被执行。</p> \n <p>看下面的例子：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/6247ac80b3f743d4a3e9cbb48caf73af.png\" alt=\"\"></p> \n <p>这个就是很自然的谁先到达，谁就先享受服务，所以顺序上就是从 P1 到 P4。注意这里的到达时间，就是前面说过的提交时间。这里不考虑等待 I/O 的情况，否则计算等待时间的时候还需要减去等待 I/O 的时间。</p> \n <ul>\n  <li>FCFS 算法是非抢占式的算法，不存在某个进程在执行的时候被其它进程抢占处理机的情况。</li>\n  <li>它的优点是公平、算法实现简单，并且不会导致饥饿（不管等多久，所有进程最后都会运行，不存在某个进程永远得不到处理机的情况）</li>\n  <li>缺点是对长作业有利、对短作业不利 —— 对于长作业，如果它先到，那么它自然无需做过多的等待，而即使是后到，它等待短作业的时间也是不足挂齿的，所以长作业怎么都不亏；对于短作业，如果它先到，自然也无需做过多等待，但是如果它后到，那么它不得不花很长的时间去等待长作业完成，然而它自己运行所需的时间却是很短的，所以说这个算法对短作业不利。在这种情况下，短作业的带权周转时间会很大，也即周转时间远远大于实际运行时间，表示有大量时间用于等待。</li>\n  <li>有时候也说 FCFS 算法对 CPU 繁忙型作业有利，对 I/O 繁忙型作业不利。这是因为 CPU 繁忙型作业的特点是需要大量的 CPU 时间进行计算，而很少请求 I/O 操作，通常视作长作业。</li>\n </ul> \n <h5><a id=\"SJF_1336\"></a>短作业优先（SJF）调度算法</h5> \n <p>SJF 算法即 “短作业优先” 算法，前面的算法问题在于对短作业不利，所以 SJF 算法优先顾及短作业，让当前已到达并且运行时间最短的进程先执行。SJF 算法有非抢占式（默认）版本和抢占式版本，抢占式版本也叫做 SRTN 算法，即最短剩余时间优先算法。</p> \n <p>先看非抢占式版本的例子：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/f31b76cda5124e9982ab25948801afe8.png\" alt=\"\"></p> \n <p>运行顺序的说明：</p> \n <p>注意这里虽然 P1 不是运行时间最短的，但是它是 当前最先到达且运行时间最短 的进程，所以它首先运行，并且在运行过程中，P2，P3，P4 陆续到达就绪队列。在 P1 运行完之后就需要调度了，这时候，就绪队列中满足“当前已到达且运行时间最短”的进程是 P3，所以 P3 运行；P3 运行完之后继续调度其它进程，P2 和 P4 运行时间都一样，不过 P2 首先到达，所以 P2 运行，最后再轮到 P4 运行。</p> \n <p>另外，由于这是非抢占式版本，所以除非进程终止或者其它原因，否则其它进程是无法与当前进程竞争处理机的。</p> \n <p>接着看抢占式版本的例子：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/656a296913d3406da16c3249ca6e4330.png\" alt=\"\"></p> \n <p>多了一个调度条件：</p> \n <p>由于这是抢占式版本，所以存在着进程之间对于处理机的竞争。也就是说，除了进程正常终止会发生调度之外，每次有新进程进入就绪队列的时候，也可能发生调度。而具体谁会被调度并夺得处理机，则是比较新到达进程的剩余时间与正在运行进程的剩余时间，前者如果更短，那么它将夺得处理机。</p> \n <p>下面是抢占式版本的相关指标计算：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/39e0ba838a3d4fb79e7d848985e3a21e.png\" alt=\"\"></p> \n <p>注意：</p> \n <p>一般可以认为，SJF 算法的平均等待时间、平均周转时间都是最少的（相比于其它算法），但是更准确地说，其实它的抢占式版本，也即 SRTN 算法，各项指标要比 SJF 算法更低。</p> \n <ul>\n  <li>SJF 算法的优点在于，它拥有 “最短的” 平均等待时间和平均周转时间</li>\n  <li>缺点在于，虽然这次顾及了短作业，但是没有顾及长作业，对长作业是不利的。因为一旦短作业源源不断进入，那么它们就会不断跑在长作业前面，导致长作业永远无法运行，产生“饥饿”甚至“饿死”现象。</li>\n  <li>另外一个缺点是，在实际实现中，要做到真正意义上的短作业优先，具有一定难度。</li>\n </ul> \n <h5><a id=\"HRRN__1370\"></a>HRRN 算法</h5> \n <p>HRRN 算法即高响应比优先算法，它优先调度响应比高的进程。</p> \n <p>响应比 = （ 等待时间+实际运行时间 ）/ 实际运行时间 = 等待时间 / 实际运行时间 + 1</p> \n <p>可以说它同时综合了 FCFS 算法和 SJF 算法的优点。为什么优先调度响应比高的进程？因为当两个进程的等待时间一样时，响应比越高的进程，它的实际运行时间越短，这一点类似于 SJF 算法，优先顾及运行时间短的进程；而当两个进程的实际运行时间一样时，响应比越高的进程，它的等待时间越长，等待时间越长说明该进程越先到达，这一点类似于 FCFS 算法，优先顾及先到达的进程。</p> \n <p>HRRN 是非抢占式的算法，因此只有当前运行进程正常放弃处理机的时候，才会计算哪个进程的响应比高，然后进行调度。</p> \n <p>看下面的例子：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/e4691e4c2c8b471e840cad288e1bd9c1.png\" alt=\"\"></p> \n <p>注意这里 “要求服务的时间” 就是实际需要运行的时间，等待时间则是从进程到达就绪队列的那一刻起，到发生进程调度这一段所花费的时间。</p> \n <p>HRRN 算法的优点是综合考虑了等待时间和实际运行时间，而且也不会导致长作业饥饿的问题（因为长作业等待时间变长之后，它的响应比也会变高，增加了可以被调度的机会）。</p> \n <h4><a id=\"_1388\"></a>总结</h4> \n <p>上面这几种算法主要关注对用户的公平性、平均周转时间、平均等待时间等评价系统整体性能的指标，但是不关心 “响应时间”，也并不区分任务的紧急程度，因此对于用户来说，交互性很糟糕。</p> \n <p>因此它们一般适合用于早期的批处理系统。下面介绍的算法则适合用于交互式系统。</p> \n <h4><a id=\"_1394\"></a>交互式系统的调度算法</h4> \n <h5><a id=\"RR_1396\"></a>RR算法</h5> \n <p>RR 算法即时间片轮转算法。像前面的算法的话，通常都是非抢占式的，也就是说，一个进程正常运行完，另一个进程才有机会被调度，整体呈现出 “顺序” 的特点；而 RR 算法的特点则在于 “公平分配”，按照进程到达就绪队列的顺序，轮流让每个进程执行一个相等长度的时间片，若在自己的时间片内没有执行完，则进程自动进入就绪队列队尾，并调度队头进程运行。整体呈现出“交替”的特点。因为进程即使没运行完也会发生调度，所以这是一个抢占式的算法。</p> \n <p>看下面的例子：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/f7aea801e8d7427398750b45221304a8.png\" alt=\"\"></p> \n <p>先来看时间片为 2 的情况：</p> \n <p><strong>0 时刻：</strong> 此时就绪队列为 P1(5)，P1 上处理机运行</p> \n <p><strong>2 时刻：</strong> P2 到达就绪队列队头，同时 P1 时间片用完，到达就绪队列队尾。此时就绪队列为 P2(4) —— P1(3)，P2 被调度，上处理机运行。</p> \n <p><strong>4 时刻：</strong> P3 到达就绪队列队尾，同时 P2 时间片用完，进入就绪队列，紧挨在 P3 后面。此时就绪队列为 P1(3) —— P3(1) ——P2(2)，P1 被调度，上处理机运行。</p> \n <p><strong>5 时刻：</strong> P4 到达就绪队列队尾，P1 时间片还没用完，仍然在运行。此时就绪队列为 P3(1) —— P2(2)——P4(6)</p> \n <p><strong>6 时刻：</strong> P1 时间片用完，进入就绪队列队尾，此时就绪队列为 P3(1) —— P2(2) —— P4(6) —— P1(1)。P3 被调度，上处理机运行。</p> \n <p><strong>7 时刻：</strong> 虽然 P3 有 2 个单位的时间片可用，但是它实际上只需要用到一个单位，所以 7 时刻的时候它正常运行完，轮到 P2 被调度。此时就绪队列为 P4(6) —— P1(1)。</p> \n <p><strong>9 时刻：</strong> P2 时间片用完，同时也正常运行结束。P4 被调度，上处理机运行。此时就绪队列为 P1(1)。</p> \n <p><strong>11 时刻：</strong> P4 时间片用完，到达就绪队列队尾。此时就绪队列为 P1(1) —— P4(4)。P1 被调度，上处理机运行。</p> \n <p><strong>12 时刻：</strong> 在 12 时刻的时候，P1 就已经运行结束。此时再次调度 P4 上处理机运行</p> \n <p><strong>14 时刻：</strong> P4 时间片用完，由于就绪队列中没有其它进程可供调度，所以让 P4 接着运行一个时间片</p> \n <p><strong>16 时刻：</strong> P4 正常运行结束。</p> \n <p>整个过程如下图所示：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/d961402cbe52486abe93d5edac29a199.png\" alt=\"\"></p> \n <p>再来看时间片为 5 的情况：</p> \n <p><strong>0 时刻：</strong> 此时就绪队列为 P1(5)，P1 上处理机运行</p> \n <p><strong>2 时刻：</strong> P2 到达就绪队列队头，P1 仍在运行</p> \n <p><strong>4 时刻：</strong> P3 到达就绪队列队尾，P1 仍在运行</p> \n <p><strong>5 时刻：</strong> P4 到达就绪队列队尾。P1 正常运行结束，时间片刚好用完。此时就绪队列是 P2(4)——P3(1)——P4(6)，所以 P2 被调度上处理机</p> \n <p><strong>9 时刻：</strong> 尽管时间片没有用完，但是 P2 正常运行结束，所以 P3 会被调度上处理机</p> \n <p><strong>10 时刻：</strong> P3 正常运行结束，同样调度 P4</p> \n <p><strong>15 时刻：</strong> P4 时间片用完，但是就绪队列没有可供调度的进程，所以 P4 还得继续运行</p> \n <p><strong>16 时刻：</strong> P4 正常运行结束</p> \n <p>整个过程如下图所示：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/821ca8dff9f642dfb74d11f0a3d28791.png\" alt=\"\"></p> \n <p>这里会发现，效果和使用 FCFS 算法是差不多的。实际上，如果时间片太大，那么 RR 算法会退化成 FCFS 算法，而且会增加进程响应时间，所以时间片应该设置得小一点；另一方面，时间片也不能设置得太小，否则进程切换会过于频繁，导致更多的时间用于切换而不是有效执行进程。</p> \n <p>总的来说，RR 算法的优点是公平、响应快，适用于分时操作系统；缺点则是进程切换频率相比其他算法会高一点，因此有一定的开销。另外它不区分任务的紧急程度，再紧急的任务，如果某个运行进程的时间片还没用完，这个任务也不会被调度。</p> \n <p>RR 算法不会导致饥饿，因为时间片一到自然就会切换到其它进程，不存在某个进程永远无法被调度的情况。</p> \n <h5><a id=\"_1460\"></a>优先级算法</h5> \n <p>优先级算法在某种程度上和 HRRN 算法很像，两者可以联系起来进行理解。</p> \n <p>前面我们所讲的算法都无法区分进程紧急程度，而优先级算法弥补了这个问题。它会给每个进程一个优先级，调度时会选择当前已到达并且优先级最高的进程。和 HRRN 算法一样，它也有非抢占式和抢占式两个版本。</p> \n <p>先看非抢占式版本：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/84fd771ae70142688006ad8d7b282947.png\" alt=\"\"></p> \n <p>这里和 HRRN 算法是很像的，进程会正常运行，直到结束之后才发生调度，在调度的时候会选择队列中优先级最高的进程。</p> \n <p>再看抢占式版本：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/a2441ffd2a7e4e42a47a678be895ea8d.png\" alt=\"\"></p> \n <p>这里同样和 HRRN 算法很像。除了正常运行结束会发生调度之外，每次就绪队列有新的进程到达时还会做一次检查，如果新到达进程优先级高于正在运行进程的优先级，那么新到达进程会抢占处理机。</p> \n <p>PS：在优先级算法中，就绪队列可能不止有一个，可以按照不同优先级分成很多种队列。另外还要注意，有的地方规定优先数越小，优先级越高，具体看题目要求。</p> \n <p>静态优先级和动态优先级：</p> \n <p>优先级还包括静态优先级和动态优先级。上面所讲的属于静态优先级，指的是进程的优先级在它创建的时候就确定了，此后一直不会改变；动态优先级则相对灵活很多，它会根据具体情况动态调整进程的优先级。</p> \n <ul>\n  <li>对于静态优先级，一般认为系统进程优先级要高于用户进程优先级；前台进程优先级高于后台进程优先级；I/O 型进程优先级会比较高。</li>\n  <li>于动态优先级，会尽量遵循公平的原则。也就是说，如果某个进程实在等得太久，那么不妨提高它的优先级，让他有机会被调度；反之，如果某个进程占用处理机时间过长，那么就要考虑降低它的优先级，不要让他一直“霸占”处理机了。另外，之前说过 I/O 型进程的优先级会很高，所以如果某个进程频繁进行 I/O 操作，也可以考虑提高它的优先级。</li>\n </ul> \n <p>总的来说，优先级算法的优点在于区分了各个进程的紧急程度，比较紧急重要的进程会优先得到处理，因此它适用于实时操作系统。另外，由于动态优先级的存在，使得它对进程的调度相对灵活很多。缺点则是，如果源源不断进来了一些高优先级的进程，那么优先级相对较低的进程可能一直无法执行，进而导致饥饿现象的发生。这点和 HRRN 算法也是很像的。（其实也可以把 HRRN 算法看作优先级算法的一种特殊情况，将响应比作为优先级评判的标准）</p> \n <h5><a id=\"_1489\"></a>多级反馈队列算法</h5> \n <p>多级反馈队列算法是对其他调度算法的折中权衡，它的分析过程会复杂很多。下面我们先给定多级反馈队列算法的几个规则，再结合图片文字理一理具体的过程。</p> \n <ul>\n  <li>有多个级别的就绪队列，各级队列优先级从高到低，时间片从小到大</li>\n  <li>每次有新进程到达，都会首先进入第一级队列，并按 FCFS 算法被分配时间片。如果时间片用完了而进程还没执行完，那么该进程将被送到下一级队列队尾。如果当前已经是最后一级，则重新放回当前队列队尾</li>\n  <li>当且仅当上层级别的队列为空时，下一级队列的进程才有机会被调度</li>\n  <li>关于抢占：如果某个进程运行的时候，比它所在队列级别更高的队列中有新进程到达，则那个新进程会抢占处理机，而当前正在运行的进程会被送到当前队列队尾</li>\n </ul> \n <p>下面我们结合图片来进行理解。</p> \n <p>在 0 时刻，P1 首先到达第一级就绪队列</p> \n <p><img src=\"https://img-blog.csdnimg.cn/a9ebaf3304764b9295e0b68ac63796e7.png\" alt=\"\"></p> \n <p>然后，它被调度，来到了处理机这里</p> \n <p><img src=\"https://img-blog.csdnimg.cn/414d3983cde448a4ac8ecf9cb0226a08.png\" alt=\"\"></p> \n <p>在 1 时刻，P1 时间片已经用完，但是进程还没执行完，所以这时候 P1 “降级”进入第二级就绪队列。同时，P2 作为新进程进入第一级就绪队列</p> \n <p><img src=\"https://img-blog.csdnimg.cn/a20f6a216ce647e3a9e3bc1c36ce5ba6.png\" alt=\"\"></p> \n <p>P2 被调度进入处理机</p> \n <p><img src=\"https://img-blog.csdnimg.cn/f17d71dadc464c82ad084b2e510b7188.png\" alt=\"\"></p> \n <p>在 2 时刻，P2 时间片已经用完，但是进程还没执行完，所以这时候 P2 也“降级”进入第二级就绪队列</p> \n <p><img src=\"https://img-blog.csdnimg.cn/e34332ac5c0148d386812005fe5fd73a.png\" alt=\"\"></p> \n <p>像前面所说的，“当且仅当上层级别的队列为空时，下一级队列的进程才有机会被调度”，此时第一级队列为空，所以开始调度第二级队列的进程。队头进程 P1 进入处理机</p> \n <p><img src=\"https://img-blog.csdnimg.cn/a50198ef96284c0ea4933a33df4e7bb0.png\" alt=\"\"></p> \n <p>在 3 时刻，P1 时间片没用完，所以继续执行；在 4 时刻，P1 时间片用完，进程却还没执行完，所以再次“降级”来到第三级就绪队列。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/2c6d38526b214148be406da1b2cff13f.png\" alt=\"\"></p> \n <p>此时，由于 P2 位于优先级更高的队列，所以 P2 被调度，来到处理机</p> \n <p><img src=\"https://img-blog.csdnimg.cn/738b9db7f4ce4dc7962faef008b08a5c.png\" alt=\"\"></p> \n <p>在 5 时刻，P2 时间片还没用完，所以还在正常执行。但是，P3 作为新进程到达了第一级就绪队列</p> \n <p><img src=\"https://img-blog.csdnimg.cn/0b4b83bc8c454f2bb6ed74a392a7e9fd.png\" alt=\"\"></p> \n <p>根据前面说的，“如果某个进程运行的时候，比它所在队列级别更高的队列中有新进程到达，则那个新进程会抢占处理机，而当前正在运行的进程会被送到当前队列队尾”，所以这时候 P3 抢占了处理机</p> \n <p><img src=\"https://img-blog.csdnimg.cn/58028a882c5849aeac7c603f8530a709.png\" alt=\"\"></p> \n <p>在 6 时刻，P3 时间片用完，且刚好进程也执行完了，所以这时候没有 P3 什么事了。由于 P2 所在队列优先级更高，所以此时 P2 被调度，来到处理机</p> \n <p><img src=\"https://img-blog.csdnimg.cn/44218bac10fd48179e33b3a6ce2fe22d.png\" alt=\"\"></p> \n <p>在 7 时刻，P2 时间片没用完，所以继续执行；在 8 时刻，P2 时间片用完了，且刚好进程也执行完了，所以这时候没有 P2 什么事了。此时还没完事的就剩下 P1 了，所以 P1 被调度</p> \n <p><img src=\"https://img-blog.csdnimg.cn/bf18292d408b47e7b12f8abc263ae6db.png\" alt=\"\"></p> \n <p>从 7 时刻被调度，一直到 10 时刻，P1 时间片用完了，但是进程还没执行完（剩下两个单位的时间），根据前面说的，“如果当前已经是最后一级，则重新放回当前队列队尾”，所以 P1 重新被送到第三级队列。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/db68294d5fd54c43b06c8f6074dcae58.png\" alt=\"\"></p> \n <p>P1 作为唯一的进程再次被调度，来到处理机</p> \n <p><img src=\"https://img-blog.csdnimg.cn/cfa29a9cb4b34014ae4d4f53e77f9cea.png\" alt=\"\"></p> \n <p>从 10 时刻被调度到 12 时刻，P1 终于执行完毕</p> \n <p><img src=\"https://img-blog.csdnimg.cn/7401e421b1904f4cacc8dc041b3f1916.png\" alt=\"\"></p> \n <p>最后再做一下总结：</p> \n <ul>\n  <li>优点： \n   <ul>\n    <li>对各类型进程相对公平（FCFS 的优点）：谁先进来，谁就会处于高级队列，优先得到服务</li>\n    <li>每个新到达的进程都可以很快就得到响应（RR 的优点）：新到达的进程首先在高级队列，可以很快得到响应</li>\n    <li>短进程只用较少的时间就可完成（SPF 的优点）：不需要经历过多的队列</li>\n    <li>可灵活地调整对各类进程的偏好程度，比如 CPU 密集型进程、I/O 密集型进程（拓展：可以将因 I/O 而阻塞的进程重新放回原队列，这样 I/O 型进程就可以保持较高优先级）</li>\n    <li>对各类型用户友好。<br> 对于终端型用户来说，他们提交的大多属于较小的交互型作业，系统只要能使这些作业在第一队列所规定的时间片内完成，便可使终端型作业用户都感到满意；对短批处理作业用户来说，只需在第一队列中执行一个时间片，或至多在第二和第三队列中各执行一个时间片即可完成；对长批处理作业用户来说，只要让作业依次在第 1, 2，…. n 个队列中运行，然后再按轮转方式运行，用户不必担心其作业长期得不到处理。</li>\n   </ul> </li>\n  <li>缺点：可能会导致饥饿。若有源源不断的短进程到达第一队列，那么这些进程会持续被调度，使得下面一级的那些进程一直得不到调度，导致饥饿现象的发生。</li>\n </ul> \n <h4><a id=\"_1571\"></a>总结</h4> \n <p>比起早期的批处理操作系统来说，由于计算机造价大幅降低，</p> \n <p>因此之后出现的交互式操作系统（包括分时操作系统、实时操作系统等）更注重系统的响应时间、公平性、平衡性等指标。</p> \n <p>而以上这三种算法恰好也能较好地满足交互式系统的需求。</p> \n <p>因此这三种算法适合用于交互式系统。( 比如 UNIX 使用的就是多级反馈队列调度算法）</p> \n <h3><a id=\"_1581\"></a>进程调度算法</h3> \n <h4><a id=\"FCFS_1583\"></a>先来先服务（FCFS）调度算法</h4> \n <p>处于就绪态的进程按先后顺序链入到就绪队列中，而FCFS调度算法按就绪进程进入就绪队列的先后次序选择当前最先进入就绪队列的进程来执行，直到此进程阻塞或结束，才进行下一次的进程选择调度。</p> \n <p>FCFS调度算法采用的是不可抢占的调度方式，一旦一个进程占有处理机，就一直运行下去，直到该进程完成其工作，或因等待某一事件而不能继续执行时，才释放处理机。</p> \n <p>操作系统如果采用这种进程调度方式，则一个运行时间长且正在运行的进程会使很多晚到的且运行时间短的进程的等待时间过长。</p> \n <h4><a id=\"SJF_1591\"></a>短作业优先（SJF）调度算法</h4> \n <p>其实目前作业的提法越来越少，我们姑且把 “作业” 用 “进程” 来替换，改称为短进程优先调度算法，此算法选择就绪队列中确切（或估计）运行时间最短的进程进入执行。</p> \n <p>它既可采用可抢占调度方式，也可采用不可抢占调度方式。可抢占的短进程优先调度算法通常也叫做最短剩余时间优先（Shortest Remaining Time First，SRTF）调度算法。短进程优先调度算法能有效地缩短进程的平均周转时间，提高系统的吞吐量，但不利于长进程的运行。</p> \n <p>而且如果进程的运行时间是 “估计” 出来的话，会导致由于估计的运行时间不一定准确，而不能实际做到短作业优先。</p> \n <h4><a id=\"RR_1599\"></a>时间片轮转（RR）调度算法</h4> \n <p>RR 调度算法与 FCFS 调度算法在选择进程上类似，但在调度的时机选择上不同。RR调度算法定义了一个的时间单元，称为时间片（或时间量）。一个时间片通常在1～100 ms之间。</p> \n <p>当正在运行的进程用完了时间片后，即使此进程还要运行，操作系统也不让它继续运行，而是从就绪队列依次选择下一个处于就绪态的进程执行，而被剥夺CPU使用的进程返回到就绪队列的末尾，等待再次被调度。</p> \n <p>时间片的大小可调整，如果时间片大到让一个进程足以完成其全部工作，这种算法就退化为FCFS调度算法；若时间片设置得很小，那么处理机在进程之间的进程上下文切换工作过于频繁，使得真正用于运行用户程序的时间减少。</p> \n <p>时间片可以静态设置好，也可根据系统当前负载状况和运行情况动态调整，时间片大小的动态调整需要考虑就绪态进程个数、进程上下文切换开销、系统吞吐量、系统响应时间等多方面因素。</p> \n <h4><a id=\"Highest_Response_Ratio_FirstHRRF_1609\"></a>高响应比优先（Highest Response Ratio First，HRRF）调度算法</h4> \n <p>HRRF 调度算法是介于先来先服务算法与最短进程优先算法之间的一种折中算法。先来先服务算法只考虑进程的等待时间而忽视了进程的执行时间，而最短进程优先调度算法只考虑用户估计的进程的执行时间而忽视了就绪进程的等待时间。</p> \n <p>HRRF调度算法二者兼顾，既考虑进程等待时间，又考虑进程的执行时间，为此定义了响应比（Rp）这个指标：</p> \n <p>Rp=（等待时间+预计执行时间）/执行时间=响应时间/执行时间</p> \n <p>上个表达式假设等待时间与预计执行时间之和等于响应时间。HRRF调度算法将选择Rp最大值的进程执行，这样既照顾了短进程又不使长进程的等待时间过长，改进了调度性能。</p> \n <p>但HRRF调度算法需要每次计算各各个进程的响应比Rp，这会带来较大的时间开销（特别是在就绪进程个数多的情况下）。</p> \n <h4><a id=\"MultiLevel_Feedback_Queue_1621\"></a>多级反馈队列（Multi-Level Feedback Queue）调度算法</h4> \n <p>在采用多级反馈队列调度算法的执行逻辑流程如下：</p> \n <ol>\n  <li>设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高，第二队次之，其余队列优先级依次降低。仅当第1～i-1个队列均为空时，操作系统调度器才会调度第i个队列中的进程运行。赋予各个队列中进程执行时间片的大小也各不相同。在优先级越高的队列中，每个进程的执行时间片就越小或越大（Linux-2.4内核就是采用这种方式）。</li>\n  <li>当一个就绪进程需要链入就绪队列时，操作系统首先将它放入第一队列的末尾，按FCFS的原则排队等待调度。若轮到该进程执行且在一个时间片结束时尚未完成，则操作系统调度器便将该进程转入第二队列的末尾，再同样按先来先服务原则等待调度执行。如此下去，当一个长进程从第一队列降到最后一个队列后，在最后一个队列中，可使用FCFS或RR调度算法来运行处于此队列中的进程。</li>\n  <li>如果处理机正在第i（i&gt;1）队列中为某进程服务时，又有新进程进入第k（k&lt;i）的队列，则新进程将抢占正在运行进程的处理机，即由调度程序把正在执行进程放回第i队列末尾，重新将处理机分配给处于第k队列的新进程。</li>\n </ol> \n <p>从MLFQ调度算法可以看出长进程无法长期占用处理机，且系统的响应时间会缩短，吞吐量也不错（前提是没有频繁的短进程）。所以MLFQ调度算法是一种合适不同类型应用特征的综合进程调度算法。</p> \n <h4><a id=\"_1631\"></a>最高优先级优先调度算法</h4> \n <p>进程的优先级用于表示进程的重要性及运行的优先性。一个进程的优先级可分为两种：静态优先级和动态优先级。静态优先级是在创建进程时确定的。一旦确定后，在整个进程运行期间不再改变。</p> \n <p>静态优先级一般由用户依据包括进程的类型、进程所使用的资源、进程的估计运行时间等因素来设置。一般而言，若进程需要的资源越多、估计运行的时间越长，则进程的优先级越低；反之，对于I/O bounded的进程可以把优先级设置得高。</p> \n <p>动态优先级是指在进程运行过程中，根据进程执行情况的变化来调整优先级。动态优先级一般根据进程占有CPU时间的长短、进程等待CPU时间的长短等因素确定。</p> \n <p>占有处理机的时间越长，则优先级越低，等待时间越长，优先级越高。那么进程调度器将根据静态优先级和动态优先级的总和现在优先级最高的就绪进程执行。</p> \n <h3><a id=\"_1643\"></a>聊聊：什么是线程，线程和进程的区别</h3> \n <p>这又是一道老生常谈的问题了，从操作系统的角度来回答一下吧。</p> \n <p>我们上面说到进程是正在运行的程序的实例，而线程其实就是进程中的单条流向，因为线程具有进程中的某些属性，所以线程又被称为轻量级的进程。浏览器如果是一个进程的话，那么浏览器下面的每个 tab 页可以看作是一个个的线程。</p> \n <p>下面是线程和进程持有资源的区别</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/a15a0a223dc9134a33a93939f2340c94.png\" alt=\"\"></p> \n <p>线程不像进程那样具有很强的独立性，线程之间会共享数据</p> \n <p>创建线程的开销要比进程小很多，因为创建线程仅仅需要<code>堆栈指针</code>和<code>程序计数器</code>就可以了，而创建进程需要操作系统分配新的地址空间，数据资源等，这个开销比较大。</p> \n <h3><a id=\"_1659\"></a>聊聊：有了进程为什么还要线程</h3> \n <p>不同进程之间切换实现并发，各自占有CPU实现并行</p> \n <p>但是这些也会导致缺点，</p> \n <p>一个进程只能做一件事，其他的进程来了会将其阻塞，为此引进了更小的粒度，</p> \n <p>线程减少程序在并发执行时所付出的时间和空间开销，提高并发性能</p> \n <h3><a id=\"_1671\"></a>聊聊：什么是进程和进程表</h3> \n <p>进程就是正在执行程序的实例，比如说 Web 程序就是一个进程，shell 也是一个进程，文章编辑器 typora 也是一个进程。</p> \n <p>操作系统负责管理所有正在运行的进程，操作系统会为每个进程分配特定的时间来占用 CPU，操作系统还会为每个进程分配特定的资源。</p> \n <p>操作系统为了跟踪每个进程的活动状态，维护了一个进程表。</p> \n <p>在进程表的内部，列出了每个进程的状态以及每个进程使用的资源等。</p> \n <h3><a id=\"_1683\"></a>聊聊：并发和并行</h3> \n <ul>\n  <li>并发是指宏观上在一段时间内能同时运行多个程序</li>\n  <li>并行则指同一时刻能运行多个指令（需要硬件支持，如多流水线、多核处理器或者分布式计算系统）</li>\n </ul> \n <p>操作系统通过引入进程和线程，使得程序能够并发运行</p> \n <ul>\n  <li>并行是指两个或者多个事件在同一时刻发生；</li>\n  <li>而并发是指两个或多个事件在同一时间间隔发生</li>\n </ul> \n <p>并行是在不同实体上的多个事件，并发是在同一实体上的多个事件；</p> \n <h3><a id=\"_1697\"></a>聊聊：多处理系统的优势</h3> \n <p>随着处理器的不断增加，我们的计算机系统由单机系统变为了多处理系统，多处理系统的吞吐量比较高，多处理系统拥有多个并行的处理器，这些处理器共享时钟、内存、总线、外围设备等。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/ee362ae17918ea855432988b46734b00.png\" alt=\"\"></p> \n <p>多处理系统由于可以共享资源，因此可以开源节流，省钱。整个系统的可靠性也随之提高。</p> \n <h3><a id=\"_1707\"></a>聊聊：什么是上下文切换</h3> \n <p>对于单核单线程 CPU 而言，在某一时刻只能执行一条 CPU 指令。</p> \n <p>上下文切换 (Context Switch) 是一种 <strong>将 CPU 资源从一个进程分配给另一个进程的机制</strong>。</p> \n <p>从用户角度看，计算机能够并行运行多个进程，这恰恰是操作系统通过快速上下文切换造成的结果。</p> \n <p>在切换的过程中，操作系统需要先存储当前进程的状态 (包括内存空间的指针，当前执行完的指令等等)，再读入下一个进程的状态，然后执行此进程。</p> \n <h3><a id=\"_1719\"></a>聊聊：使用多线程的好处是什么</h3> \n <p>多线程是程序员不得不知的基本素养之一，所以，下面我们给出一些多线程编程的好处</p> \n <ul>\n  <li>能够提高对用户的响应顺序</li>\n  <li>在流程中的资源共享</li>\n  <li>比较经济适用</li>\n  <li>能够对多线程架构有深入的理解</li>\n </ul> \n <h3><a id=\"_1730\"></a>聊聊：进程终止的方式</h3> \n <h4><a id=\"_1732\"></a>进程的终止</h4> \n <p>进程在创建之后，它就开始运行并做完成任务。然而，没有什么事儿是永不停歇的，包括进程也一样。进程早晚会发生终止，但是通常是由于以下情况触发的</p> \n <ul>\n  <li><code>正常退出(自愿的)</code></li>\n  <li><code>错误退出(自愿的)</code></li>\n  <li><code>严重错误(非自愿的)</code></li>\n  <li><code>被其他进程杀死(非自愿的)</code></li>\n </ul> \n <h4><a id=\"_1741\"></a>正常退出</h4> \n <p>多数进程是由于完成了工作而终止。当编译器完成了所给定程序的编译之后，编译器会执行一个系统调用告诉操作系统它完成了工作。这个调用在 UNIX 中是 <code>exit</code> ，在 Windows 中是 <code>ExitProcess</code>。面向屏幕中的软件也支持自愿终止操作。字处理软件、Internet 浏览器和类似的程序中总有一个供用户点击的图标或菜单项，用来通知进程删除它锁打开的任何临时文件，然后终止。</p> \n <h4><a id=\"_1745\"></a>错误退出</h4> \n <p>进程发生终止的第二个原因是发现严重错误，例如，如果用户执行如下命令</p> \n <pre><code class=\"prism language-c\">cc foo<span class=\"token punctuation\">.</span>c\n</code></pre> \n <p>为了能够编译 foo.c 但是该文件不存在，于是编译器就会发出声明并退出。在给出了错误参数时，面向屏幕的交互式进程通常并不会直接退出，因为这从用户的角度来说并不合理，用户需要知道发生了什么并想要进行重试，所以这时候应用程序通常会弹出一个对话框告知用户发生了系统错误，是需要重试还是退出。</p> \n <h4><a id=\"_1755\"></a>严重错误</h4> \n <p>进程终止的第三个原因是由进程引起的错误，通常是由于程序中的错误所导致的。例如，执行了一条非法指令，引用不存在的内存，或者除数是 0 等。在有些系统比如 UNIX 中，进程可以通知操作系统，它希望自行处理某种类型的错误，在这类错误中，进程会收到信号（中断），而不是在这类错误出现时直接终止进程。</p> \n <h4><a id=\"_1759\"></a>被其他进程杀死</h4> \n <p>第四个终止进程的原因是，某个进程执行系统调用告诉操作系统杀死某个进程。在 UNIX 中，这个系统调用是 kill。在 Win32 中对应的函数是 <code>TerminateProcess</code>（注意不是系统调用）。</p> \n <h3><a id=\"_1763\"></a>聊聊：进程间的通信方式</h3> \n <p>进程间的通信方式比较多，</p> \n <p>首先你需要理解下面这几个概念</p> \n <ul>\n  <li>竞态条件：即两个或多个线程同时对一共享数据进行修改，从而影响程序运行的正确性时，这种就被称为<code>竞态条件(race condition)</code>。</li>\n  <li>临界区：不仅<code>共享资源</code>会造成竞态条件，事实上共享文件、共享内存也会造成竞态条件、那么该如何避免呢？或许一句话可以概括说明：<strong>禁止一个或多个进程在同一时刻对共享资源（包括共享内存、共享文件等）进行读写</strong>。换句话说，我们需要一种 <code>互斥(mutual exclusion)</code> 条件，这也就是说，如果一个进程在某种方式下使用共享变量和文件的话，除该进程之外的其他进程就禁止做这种事（访问统一资源）。</li>\n </ul> \n <p>一个好的解决方案，应该包含下面四种条件</p> \n <ol>\n  <li>任何时候两个进程不能同时处于临界区</li>\n  <li>不应对 CPU 的速度和数量做任何假设</li>\n  <li>位于临界区外的进程不得阻塞其他进程</li>\n  <li>不能使任何进程无限等待进入临界区</li>\n </ol> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/afaf8ba674630efac18b445870ddab79.png\" alt=\"\"></p> \n <ul>\n  <li>忙等互斥：当一个进程在对资源进行修改时，其他进程必须进行等待，进程之间要具有互斥性，我们讨论的解决方案其实都是基于忙等互斥提出的。</li>\n </ul> \n <p>进程间的通信用专业一点的术语来表示就是 <code>Inter Process Communication，IPC</code>，它主要有下面 7。</p> \n <p>7种通信方式</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/72e9e7778f4f0361e9900b45a43bea83.png\" alt=\"\"></p> \n <ul>\n  <li><code>消息传递</code>：消息传递是进程间实现通信和同步等待的机制，使用消息传递，进程间的交流不需要共享变量，直接就可以进行通信；消息传递分为发送方和接收方</li>\n  <li><code>先进先出队列</code>：先进先出队列指的是两个不相关联进程间的通信，两个进程之间可以彼此相互进程通信，这是一种全双工通信方式</li>\n  <li><code>管道</code>：管道用于两个相关进程之间的通信，这是一种半双工的通信方式，如果需要全双工，需要另外一个管道。</li>\n  <li><code>直接通信</code>：在这种进程通信的方式中，进程与进程之间只存在一条链接，进程间要明确通信双方的命名。</li>\n  <li><code>间接通信</code>：间接通信是通信双方不会直接建立连接，而是找到一个中介者，这个中介者可能是个对象等等，进程可以在其中放置消息，并且可以从中删除消息，以此达到进程间通信的目的。</li>\n  <li><code>消息队列</code>：消息队列是内核中存储消息的链表，它由消息队列标识符进行标识，这种方式能够在不同的进程之间提供全双工的通信连接。</li>\n  <li><code>共享内存</code>：共享内存是使用所有进程之间的内存来建立连接，这种类型需要同步进程访问来相互保护。</li>\n </ul> \n <h3><a id=\"_1797\"></a>聊聊：进程间状态模型</h3> \n <h4><a id=\"_1799\"></a>进程的三态模型</h4> \n <p>当一个进程开始运行时，它可能会经历下面这几种状态</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/ffabc3e3e63c4c9ae0aa5f7ccae45dec.png\" alt=\"\"></p> \n <p>图中会涉及三种状态</p> \n <ol>\n  <li><code>运行态</code>：运行态指的就是进程实际占用 CPU 时间片运行时</li>\n  <li><code>就绪态</code>：就绪态指的是可运行，但因为其他进程正在运行而处于就绪状态</li>\n  <li><code>阻塞态</code>：阻塞态又被称为睡眠态，它指的是进程不具备运行条件，正在等待被 CPU 调度。</li>\n </ol> \n <p>逻辑上来说，运行态和就绪态是很相似的。这两种情况下都表示进程<code>可运行</code>，但是第二种情况没有获得 CPU 时间分片。第三种状态与前两种状态不同的原因是这个进程不能运行，CPU 空闲时也不能运行。</p> \n <p>三种状态会涉及四种状态间的切换，在操作系统发现进程不能继续执行时会发生<code>状态1</code>的轮转，在某些系统中进程执行系统调用，例如 <code>pause</code>，来获取一个阻塞的状态。在其他系统中包括 UNIX，当进程从管道或特殊文件（例如终端）中读取没有可用的输入时，该进程会被自动终止。</p> \n <p>转换 2 和转换 3 都是由进程调度程序（操作系统的一部分）引起的，进程本身不知道调度程序的存在。转换 2 的出现说明进程调度器认定当前进程已经运行了足够长的时间，是时候让其他进程运行 CPU 时间片了。当所有其他进程都运行过后，这时候该是让第一个进程重新获得 CPU 时间片的时候了，就会发生转换 3。</p> \n <blockquote> \n  <p><strong>程序调度指的是，决定哪个进程优先被运行和运行多久，这是很重要的一点</strong>。已经设计出许多算法来尝试平衡系统整体效率与各个流程之间的竞争需求。</p> \n </blockquote> \n <p>当进程等待的一个外部事件发生时（如从外部输入一些数据后），则发生转换 4。如果此时没有其他进程在运行，则立刻触发转换 3，该进程便开始运行，否则该进程会处于就绪阶段，等待 CPU 空闲后再轮到它运行。</p> \n <h4><a id=\"_1821\"></a>进程的五态模型</h4> \n <p>在三态模型的基础上，增加了两个状态，即 <code>新建</code> 和 <code>终止</code> 状态。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/b9b099d2f5fd05e40ccabd57279a95ff.png\" alt=\"\"></p> \n <ul>\n  <li>新建态：进程的新建态就是进程刚创建出来的时候</li>\n </ul> \n <blockquote> \n  <p>创建进程需要两个步骤：即为新进程分配所需要的资源和空间，设置进程为就绪态，并等待调度执行。</p> \n </blockquote> \n <ul>\n  <li>终止态：进程的终止态就是指进程执行完毕，到达结束点，或者因为错误而不得不中止进程。</li>\n </ul> \n <blockquote> \n  <p>终止一个进程需要两个步骤：</p> \n  <ol>\n   <li>先等待操作系统或相关的进程进行善后处理。</li>\n   <li>然后回收占用的资源并被系统删除。</li>\n  </ol> \n </blockquote> \n <h3><a id=\"_1838\"></a>聊聊：什么是僵尸进程</h3> \n <p>僵尸进程是已完成且处于终止状态，但在进程表中却仍然存在的进程。僵尸进程通常发生在父子关系的进程中，由于父进程仍需要读取其子进程的退出状态所造成的。</p> \n <h3><a id=\"_1844\"></a>聊聊：什么是守护、僵尸、孤儿进程</h3> \n <ul>\n  <li><strong>守护进程</strong>：运行在后台的一种特殊进程，<strong>独立于控制终端并周期性地执行某些任务</strong>。</li>\n  <li><strong>僵尸进程</strong>：一个进程 fork 子进程，子进程退出，而父进程没有wait/waitpid子进程，那么<strong>子进程的进程描述符仍保存在系统中</strong>，这样的进程称为僵尸进程。</li>\n  <li><strong>孤儿进程</strong>：一个<strong>父进程退出，而它的一个或多个子进程还在运行</strong>，这些子进程称为孤儿进程。（孤儿进程将由 init 进程收养并对它们完成状态收集工作）</li>\n </ul> \n <h3><a id=\"Semaphore_Vs_Mutex_1852\"></a>聊聊：Semaphore(信号量) Vs Mutex(互斥锁)</h3> \n <ul>\n  <li>当用户创立多个线程／进程时，如果不同线程／进程同时读写相同的内容，则可能造成读写错误，或者数据不一致。此时，需要通过加锁的方式，控制临界区(critical section)的访问权限。对于semaphore而言，在初始化变量的时候可以控制允许多少个线程／进程同时访问一个临界区，其他的线程／进程会被堵塞，直到有人解锁。</li>\n  <li>Mutex相当于只允许一个线程／进程访问的semaphore。此外，根据实际需要，人们还实现了一种读写锁(read-write lock)，它允许同时存在多个阅读者(reader)，但任何时候至多只有一个写者(writer)，且不能于读者共存。</li>\n </ul> \n <h3><a id=\"_1859\"></a>聊聊：进程调度策略有哪几种？</h3> \n <ul>\n  <li><strong>先来先服务</strong>：非抢占式的调度算法，按照请求的顺序进行调度。有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。另外，对<code>I/O</code>密集型进程也不利，因为这种进程每次进行<code>I/O</code>操作之后又得重新排队。</li>\n  <li><strong>短作业优先</strong>：非抢占式的调度算法，按估计运行时间最短的顺序进行调度。长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。</li>\n  <li><strong>最短剩余时间优先</strong>：最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。</li>\n  <li><strong>时间片轮转</strong>：将所有就绪进程按 <code>FCFS</code> 的原则排成一个队列，每次调度时，把 <code>CPU</code> 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 <code>CPU</code> 时间分配给队首的进程。<br> 时间片轮转算法的效率和时间片的大小有很大关系：因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。 而如果时间片过长，那么实时性就不能得到保证。</li>\n  <li><strong>优先级调度</strong>：为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。</li>\n </ul> \n <h3><a id=\"__1868\"></a>聊聊： 进程有哪些状态？</h3> \n <p>进程一共有<code>5</code>种状态，分别是创建、就绪、运行（执行）、终止、阻塞。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/20210615172817983.png\" alt=\"进程五种状态转换图\"></p> \n <ul>\n  <li>运行状态就是进程正在<code>CPU</code>上运行。在单处理机环境下，每一时刻最多只有一个进程处于运行状态。</li>\n  <li>就绪状态就是说进程已处于准备运行的状态，即进程获得了除<code>CPU</code>之外的一切所需资源，一旦得到<code>CPU</code>即可运行。</li>\n  <li>阻塞状态就是进程正在等待某一事件而暂停运行，比如等待某资源为可用或等待<code>I/O</code>完成。即使<code>CPU</code>空闲，该进程也不能运行。</li>\n </ul> \n <p><strong>运行态→阻塞态</strong>：往往是由于等待外设，等待主存等资源分配或等待人工干预而引起的。 <strong>阻塞态→就绪态</strong>：则是等待的条件已满足，只需分配到处理器后就能运行。 <strong>运行态→就绪态</strong>：不是由于自身原因，而是由外界原因使运行状态的进程让出处理器，这时候就变成就绪态。例如时间片用完，或有更高优先级的进程来抢占处理器等。 <strong>就绪态→运行态</strong>：系统按某种策略选中就绪队列中的一个进程占用处理器，此时就变成了运行态。</p> \n <h2><a id=\"_1882\"></a>死锁篇</h2> \n <h3><a id=\"_1884\"></a>聊聊：死锁是什么</h3> \n <p>死锁，是指多个进程在运行过程中因争夺资源而造成的一种僵局，处于僵持状态，没有外力的情况下无法推动</p> \n <h3><a id=\"_1888\"></a>聊聊：死锁产生条件</h3> \n <p>四个条件缺一不可</p> \n <ol>\n  <li>互斥条件：进程对所需求的资源具有排他性，若有其他进程请求该资源，请求进程只能等待。</li>\n  <li>不剥夺条件：进程在所获得的资源未释放前，不能被其他进程强行夺走，只能自己释放。</li>\n  <li>请求和保持条件：进程当前所拥有的资源在进程请求其他新资源时，由该进程继续占有。</li>\n  <li>循环等待条件：存在一种进程资源循环等待链，链中每个进程已获得的资源同时被链中下一个进程所请求。</li>\n </ol> \n <h3><a id=\"_1897\"></a>聊聊：解决死锁的基本方法</h3> \n <p>预防死锁</p> \n <p>避免死锁</p> \n <p>检测死锁</p> \n <p>解除死锁</p> \n <h4><a id=\"_1909\"></a>聊聊：死锁产生的原因</h4> \n <p>死锁产生的原因大致有两个：资源竞争和程序执行顺序不当</p> \n <h4><a id=\"_1913\"></a>聊聊：死锁产生的必要条件</h4> \n <p>资源死锁可能出现的情况主要有</p> \n <ul>\n  <li>互斥条件：每个资源都被分配给了一个进程或者资源是可用的</li>\n  <li>保持和等待条件：已经获取资源的进程被认为能够获取新的资源</li>\n  <li>不可抢占条件：分配给一个进程的资源不能强制的从其他进程抢占资源，它只能由占有它的进程显示释放</li>\n  <li>循环等待：死锁发生时，系统中一定有两个或者两个以上的进程组成一个循环，循环中的每个进程都在等待下一个进程释放的资源。</li>\n </ul> \n <h4><a id=\"_1922\"></a>聊聊：死锁的恢复方式</h4> \n <p>所以针对检测出来的死锁，我们要对其进行恢复，下面我们会探讨几种死锁的恢复方式</p> \n <h5><a id=\"_1926\"></a>通过抢占进行恢复</h5> \n <p>在某些情况下，可能会临时将某个资源从它的持有者转移到另一个进程。比如在不通知原进程的情况下，将某个资源从进程中强制取走给其他进程使用，使用完后又送回。这种恢复方式一般比较困难而且有些简单粗暴，并不可取。</p> \n <h5><a id=\"_1930\"></a>通过回滚进行恢复</h5> \n <p>如果系统设计者和机器操作员知道有可能发生死锁，那么就可以定期检查流程。进程的检测点意味着进程的状态可以被写入到文件以便后面进行恢复。检测点不仅包含<code>存储映像(memory image)</code>，还包含<code>资源状态(resource state)</code>。一种更有效的解决方式是不要覆盖原有的检测点，而是每出现一个检测点都要把它写入到文件中，这样当进程执行时，就会有一系列的检查点文件被累积起来。</p> \n <p>为了进行恢复，要从上一个较早的检查点上开始，这样所需要资源的进程会回滚到上一个时间点，在这个时间点上，死锁进程还没有获取所需要的资源，可以在此时对其进行资源分配。</p> \n <h5><a id=\"_1936\"></a>杀死进程恢复</h5> \n <p>最简单有效的解决方案是直接杀死一个死锁进程。但是杀死一个进程可能照样行不通，这时候就需要杀死别的资源进行恢复。</p> \n <p>另外一种方式是选择一个环外的进程作为牺牲品来释放进程资源。</p> \n <h4><a id=\"_1942\"></a>聊聊：如何破坏死锁</h4> \n <p>和死锁产生的必要条件一样，如果要破坏死锁，也是从下面四种方式进行破坏。</p> \n <h5><a id=\"_1946\"></a>破坏互斥条件</h5> \n <p>我们首先考虑的就是<strong>破坏互斥使用条件</strong>。如果资源不被一个进程独占，那么死锁肯定不会产生。如果两个打印机同时使用一个资源会造成混乱，打印机的解决方式是使用 <code>假脱机打印机(spooling printer)</code> ，这项技术可以允许多个进程同时产生输出，在这种模型中，实际请求打印机的唯一进程是打印机守护进程，也称为后台进程。后台进程不会请求其他资源。我们可以消除打印机的死锁。</p> \n <p>后台进程通常被编写为能够输出完整的文件后才能打印，假如两个进程都占用了假脱机空间的一半，而这两个进程都没有完成全部的输出，就会导致死锁。</p> \n <p>因此，尽量做到尽可能少的进程可以请求资源。</p> \n <h5><a id=\"_1954\"></a>破坏保持等待的条件</h5> \n <p>第二种方式是如果我们能阻止持有资源的进程请求其他资源，我们就能够消除死锁。一种实现方式是让所有的进程开始执行前请求全部的资源。如果所需的资源可用，进程会完成资源的分配并运行到结束。如果有任何一个资源处于频繁分配的情况，那么没有分配到资源的进程就会等待。</p> \n <p>很多进程<strong>无法在执行完成前就知道到底需要多少资源</strong>，如果知道的话，就可以使用银行家算法；还有一个问题是这样<strong>无法合理有效利用资源</strong>。</p> \n <p>还有一种方式是进程在请求其他资源时，先释放所占用的资源，然后再尝试一次获取全部的资源。</p> \n <h5><a id=\"_1962\"></a>破坏不可抢占条件</h5> \n <p>破坏不可抢占条件也是可以的。可以通过<code>虚拟化</code>的方式来避免这种情况。</p> \n <h5><a id=\"_1966\"></a>破坏循环等待条件</h5> \n <p>现在就剩最后一个条件了，循环等待条件可以通过多种方法来破坏。一种方式是制定一个标准，一个进程在任何时候只能使用一种资源。如果需要另外一种资源，必须释放当前资源。</p> \n <p>另一种方式是将所有的资源统一编号，如下图所示</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/7ce5535936464beb69579ba01c29c554.png\" alt=\"\"></p> \n <p>进程可以在任何时间提出请求，但是所有的请求都必须按照资源的顺序提出。如果按照此分配规则的话，那么资源分配之间不会出现环。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/6ad1e07bc21657672a7696b3b74bb2b2.png\" alt=\"\"></p> \n <h3><a id=\"_1978\"></a>聊聊：死锁类型</h3> \n <h4><a id=\"_1980\"></a>两阶段加锁</h4> \n <p>虽然很多情况下死锁的避免和预防都能处理，但是效果并不好。随着时间的推移，提出了很多优秀的算法用来处理死锁。例如在数据库系统中，一个经常发生的操作是请求锁住一些记录，然后更新所有锁定的记录。当同时有多个进程运行时，就会有死锁的风险。</p> \n <p>一种解决方式是使用 <code>两阶段提交(two-phase locking)</code>。顾名思义分为两个阶段，一阶段是进程尝试一次锁定它需要的所有记录。如果成功后，才会开始第二阶段，第二阶段是执行更新并释放锁。第一阶段并不做真正有意义的工作。</p> \n <p>如果在第一阶段某个进程所需要的记录已经被加锁，那么该进程会释放所有锁定的记录并重新开始第一阶段。从某种意义上来说，这种方法类似于预先请求所有必需的资源或者是在进行一些不可逆的操作之前请求所有的资源。</p> \n <p>不过在一般的应用场景中，两阶段加锁的策略并不通用。如果一个进程缺少资源就会半途中断并重新开始的方式是不可接受的。</p> \n <h4><a id=\"_1990\"></a>通信死锁</h4> \n <p>我们上面一直讨论的是资源死锁，资源死锁是一种死锁类型，但并不是唯一类型，还有通信死锁，也就是两个或多个进程在发送消息时出现的死锁。进程 A 给进程 B 发了一条消息，然后进程 A 阻塞直到进程 B 返回响应。假设请求消息丢失了，那么进程 A 在一直等着回复，进程 B 也会阻塞等待请求消息到来，这时候就产生<code>死锁</code>。</p> \n <p>尽管会产生死锁，但是这并不是一个资源死锁，因为 A 并没有占据 B 的资源。事实上，通信死锁并没有完全可见的资源。根据死锁的定义来说：每个进程因为等待其他进程引起的事件而产生阻塞，这就是一种死锁。相较于最常见的通信死锁，我们把上面这种情况称为<code>通信死锁(communication deadlock)</code>。</p> \n <p>通信死锁不能通过调度的方式来避免，但是可以使用通信中一个非常重要的概念来避免：<code>超时(timeout)</code>。在通信过程中，只要一个信息被发出后，发送者就会启动一个定时器，定时器会记录消息的超时时间，如果超时时间到了但是消息还没有返回，就会认为消息已经丢失并重新发送，通过这种方式，可以避免通信死锁。</p> \n <p>但是并非所有网络通信发生的死锁都是通信死锁，也存在资源死锁，下面就是一个典型的资源死锁。</p> \n <p>当一个数据包从主机进入路由器时，会被放入一个缓冲区，然后再传输到另外一个路由器，再到另一个，以此类推直到目的地。缓冲区都是资源并且数量有限。如下图所示，每个路由器都有 10 个缓冲区（实际上有很多）。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/f62d315f88069f0a7a5a3d07ac224473.png\" alt=\"\"></p> \n <p>假如路由器 A 的所有数据需要发送到 B ，B 的所有数据包需要发送到 D，然后 D 的所有数据包需要发送到 A 。没有数据包可以移动，因为在另一端没有缓冲区可用，这就是一个典型的资源死锁。</p> \n <h4><a id=\"_2006\"></a>活锁</h4> \n <p>某些情况下，当进程意识到它不能获取所需要的下一个锁时，就会尝试礼貌的释放已经获得的锁，然后等待非常短的时间再次尝试获取。可以想像一下这个场景：当两个人在狭路相逢的时候，都想给对方让路，相同的步调会导致双方都无法前进。</p> \n <p>现在假想有一对并行的进程用到了两个资源。它们分别尝试获取另一个锁失败后，两个进程都会释放自己持有的锁，再次进行尝试，这个过程会一直进行重复。很明显，这个过程中没有进程阻塞，但是进程仍然不会向下执行，这种状况我们称之为 <code>活锁(livelock)</code>。</p> \n <h4><a id=\"_2012\"></a>饥饿</h4> \n <p>与死锁和活锁的一个非常相似的问题是 <code>饥饿(starvvation)</code>。想象一下你什么时候会饿？一段时间不吃东西是不是会饿？对于进程来讲，最重要的就是资源，如果一段时间没有获得资源，那么进程会产生饥饿，这些进程会永远得不到服务。</p> \n <p>我们假设打印机的分配方案是每次都会分配给最小文件的进程，那么要打印大文件的进程会永远得不到服务，导致进程饥饿，进程会无限制的推后，虽然它没有阻塞。</p> \n <h3><a id=\"_2020\"></a>聊聊：什么是临界区，如何解决冲突？</h3> \n <p>每个进程中访问临界资源的那段程序称为临界区，</p> \n <p><strong>一次仅允许一个进程使用的资源称为临界资源。</strong></p> \n <p>解决冲突的办法：</p> \n <ul>\n  <li>如果有若干进程要求进入空闲的临界区，<strong>一次仅允许一个进程进入</strong>，如已有进程进入自己的临界区，则其它所有试图进入临界区的进程必须等待；</li>\n  <li>进入临界区的进程要在<strong>有限时间内退出</strong>。</li>\n  <li>如果进程不能进入自己的临界区，则应<strong>让出CPU</strong>，避免进程出现“忙等”现象。</li>\n </ul> \n <h3><a id=\"_2032\"></a>聊聊：什么是线程安全</h3> \n <p>如果多线程的程序运行结果是可预期的，而且与单线程的程序运行结果一样，那么说明是“线程安全”的。</p> \n <h3><a id=\"_2038\"></a>聊聊：同步与异步</h3> \n <h4><a id=\"_2040\"></a>同步：</h4> \n <ul>\n  <li>同步的定义：是指一个进程在执行某个请求的时候，若该请求需要一段时间才能返回信息，那么，这个进程将会一直等待下去，直到收到返回信息才继续执行下去。</li>\n  <li>特点：</li>\n </ul> \n <ol>\n  <li>同步是阻塞模式；</li>\n  <li>同步是按顺序执行，执行完一个再执行下一个，需要等待，协调运行；</li>\n </ol> \n <h4><a id=\"_2048\"></a>异步：</h4> \n <ul>\n  <li>是指进程不需要一直等下去，而是继续执行下面的操作，不管其他进程的状态。当有消息返回时系统会通知进程进行处理，这样可以提高执行的效率。</li>\n  <li>特点：</li>\n </ul> \n <ol>\n  <li>异步是非阻塞模式，无需等待；</li>\n  <li>异步是彼此独立，在等待某事件的过程中，继续做自己的事，不需要等待这一事件完成后再工作。线程是异步实现的一个方式。</li>\n </ol> \n <h3><a id=\"_2056\"></a>聊聊：同步与异步的优缺点：</h3> \n <ul>\n  <li>同步可以避免出现死锁，读脏数据的发生。一般共享某一资源的时候，如果每个人都有修改权限，同时修改一个文件，有可能使一个读取另一个人已经删除了内容，就会出错，同步就不会出错。但，同步需要等待资源访问结束，浪费时间，效率低。</li>\n  <li>异步可以提高效率，但，安全性较低。</li>\n </ul> \n <h2><a id=\"_2063\"></a>基础知识：系统调用</h2> \n <h3><a id=\"_2065\"></a>系统调用概述</h3> \n <p>计算机系统的各种硬件资源是有限的，在现代多任务操作系统上同时运行的多个进程都需要访问这些资源，为了更好的管理这些资源进程是不允许直接操作的，所有对这些资源的访问都必须有操作系统控制。也就是说操作系统是使用这些资源的唯一入口，而这个入口就是操作系统提供的系统调用（System Call）。在 Linux 中系统调用是用户空间访问内核的唯一手段，除异常和陷入外，他们是内核唯一的合法入口。</p> \n <p>一般情况下应用程序通过应用编程接口 API，而不是直接通过系统调用来编程。在 Unix 世界，最流行的 API 是基于 POSIX 标准的。</p> \n <p>操作系统一般是通过中断从用户态切换到内核态。中断就是一个硬件或软件请求，要求 CPU 暂停当前的工作，去处理更重要的事情。比如，在 x86 机器上可以通过 int 指令进行软件中断，而在磁盘完成读写操作后会向 CPU 发起硬件中断。</p> \n <p>中断有两个重要的属性，中断号和中断处理程序。中断号用来标识不同的中断，不同的中断具有不同的中断处理程序。在操作系统内核中维护着一个中断向量表（Interrupt Vector Table），这个数组存储了所有中断处理程序的地址，而中断号就是相应中断在中断向量表中的偏移量。</p> \n <p>一般地，系统调用都是通过软件中断实现的，x86 系统上的软件中断由 int $0x80 指令产生，而 128 号异常处理程序就是系统调用处理程序 system_call()，它与硬件体系有关，在 entry.S 中用汇编写。接下来就来看一下 Linux 下系统调用具体的实现过程。</p> \n <p>系统调用图如下图所示：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/ab16c44b15b74ceeaec4ae0cbbda2cb0.png\" alt=\"\"></p> \n <h3><a id=\"_2081\"></a>为什么需要系统调用</h3> \n <p>Linux 内核中设置了一组用于实现系统功能的子程序，称为系统调用。系统调用和普通库函数调用非常相似，只是系统调用由操作系统核心提供，运行于内核态，而普通的函数调用由函数库或用户自己提供，运行于用户态。</p> \n <p>一般的，进程是不能访问内核的。它不能访问内核所占内存空间也不能调用内核函数。CPU 硬件决定了这些（这就是为什么它被称作 “保护模式” ）。</p> \n <p>为了和用户空间上运行的进程进行交互，内核提供了一组接口。透过该接口，应用程序可以访问硬件设备和其他操作系统资源。这组接口在应用程序和内核之间扮演了使者的角色，应用程序发送各种请求，而内核负责满足这些请求(或者让应用程序暂时搁置)。实际上提供这组接口主要是为了保证系统稳定可靠，避免应用程序肆意妄行，惹出大麻烦。</p> \n <p>系统调用在用户空间进程和硬件设备之间添加了一个中间层。该层主要作用有三个：</p> \n <ol>\n  <li>它为用户空间提供了一种统一的硬件的抽象接口。比如当需要读些文件的时候，应用程序就可以不去管磁盘类型和介质，甚至不用去管文件所在的文件系统到底是哪种类型。</li>\n  <li>系统调用保证了系统的稳定和安全。作为硬件设备和应用程序之间的中间人，内核可以基于权限和其他一些规则对需要进行的访问进行裁决。举例来说，这样可以避免应用程序不正确地使用硬件设备，窃取其他进程的资源，或做出其他什么危害系统的事情。</li>\n  <li>每个进程都运行在虚拟系统中，而在用户空间和系统的其余部分提供这样一层公共接口，也是出于这种考虑。如果应用程序可以随意访问硬件而内核又对此一无所知的话，几乎就没法实现多任务和虚拟内存，当然也不可能实现良好的稳定性和安全性。在 Linux 中，系统调用是用户空间访问内核的惟一手段；除异常和中断外，它们是内核惟一的合法入口。</li>\n </ol> \n <h3><a id=\"APIPOSIXC_2095\"></a>API/POSIX/C库的区别与联系</h3> \n <p>一般情况下，应用程序通过应用编程接口(API)而不是直接通过系统调用来编程。这点很重要，因为应用程序使用的这种编程接口实际上并不需要和内核提供的系统调用一一对应。</p> \n <p>在 Unix 世界中，最流行的应用编程接口是基于 POSIX 标准的，其目标是提供一套大体上基于 Unix 的可移植操作系统标准。POSIX 是说明 API 和系统调用之间关系的一个极好例子。在大多数 Unix 系统上，根据 POSIX 而定义的 API 函数和系统调用之间有着直接关系。</p> \n <p>Linux 的系统调用像大多数 Unix 系统一样，作为 C 库的一部分提供如下图所示。C 库实现了 Unix 系统的主要 API，包括标准 C 库函数和系统调用。所有的 C 程序都可以使用 C 库，而由于 C 语言 本身的特点，其他语言也可以很方便地把它们封装起来使用。</p> \n <p>从程序员的角度看，系统调用无关紧要，他们只需要跟API打交道就可以了。相反，内核只跟系统调用打交道；库函数及应用程序是怎么使用系统调用不是内核所关心的。</p> \n <p>关于 Unix 的界面设计有一句通用的格言 “提供机制而不是策略”。换句话说，Unix 的系统调用抽象出了用于完成某种确定目的的函数。至干这些函数怎么用完全不需要内核去关心。区别对待机制(mechanism)和策略(policy)是 Unix 设计中的一大亮点。大部分的编程问题都可以被切割成两个部分:“需要提供什么功能”(机制)和“怎样实现这些功能”(策略)。</p> \n <h4><a id=\"_2107\"></a>区别</h4> \n <p>api 是函数的定义，规定了这个函数的功能，跟内核无直接关系。而系统调用是通过中断向内核发请求，实现内核提供的某些服务。</p> \n <h4><a id=\"_2111\"></a>联系</h4> \n <p>一个 api 可能会需要一个或多个系统调用来完成特定功能。通俗点说就是如果这个 api 需要跟内核打交道就需要系统调用，否则不需要。程序员调用的是 API（API 函数），然后通过与系统调用共同完成函数的功能。因此，API 是一个提供给应用程序的接口，一组函数，是与程序员进行直接交互的。</p> \n <p>系统调用则不与程序员进行交互的，它根据 API 函数，通过一个软中断机制向内核提交请求，以获取内核服务的接口。并不是所有的 API 函数都一一对应一个系统调用，有时，一个 API 函数会需要几个系统调用来共同完成函数的功能，甚至还有一些 API 函数不需要调用相应的系统调用（因此它所完成的不是内核提供的服务）。</p> \n <h3><a id=\"_2117\"></a>系统调用的实现原理</h3> \n <h4><a id=\"_2119\"></a>基本机制</h4> \n <p>前文已经提到了 Linux 下的系统调用是通过 0x80 实现的，但是我们知道操作系统会有多个系统调用（Linux 下有 319 个系统调用），而对于同一个中断号是如何处理多个不同的系统调用的？最简单的方式是对于不同的系统调用采用不同的中断号，但是中断号明显是一种稀缺资源，Linux 显然不会这么做；还有一个问题就是系统调用是需要提供参数，并且具有返回值的，这些参数又是怎么传递的？也就是说，对于系统调用我们要搞清楚两点：</p> \n <ol>\n  <li>系统调用的函数名称转换。</li>\n  <li>系统调用的参数传递。</li>\n </ol> \n <p>首先看第一个问题。实际上，Linux 中每个系统调用都有相应的系统调用号作为唯一的标识，内核维护一张系统调用表，sys_call_table，表中的元素是系统调用函数的起始地址，而系统调用号就是系统调用在调用表的偏移量。在 x86 上，系统调用号是通过 eax 寄存器传递给内核的。比如 fork() 的实现。</p> \n <p>用户空间的程序无法直接执行内核代码。它们不能直接调用内核空间中的函数，因为内核驻留在受保护的地址空间上。如果进程可以直接在内核的地址空间上读写的话，系统安全就会失去控制。所以，应用程序应该以某种方式通知系统，告诉内核自己需要执行一个系统调用，希望系统切换到内核态，这样内核就可以代表应用程序来执行该系统调用了。</p> \n <p>通知内核的机制是靠软件中断实现的。首先，用户程序为系统调用设置参数。其中一个参数是系统调用编号。参数设置完成后，程序执行“系统调用”指令。x86系统上的软中断由int产生。这个指令会导致一个异常：产生一个事件，这个事件会致使处理器切换到内核态并跳转到一个新的地址，并开始执行那里的异常处理程序。此时的异常处理程序实际上就是系统调用处理程序。它与硬件体系结构紧密相关。</p> \n <p>新地址的指令会保存程序的状态，计算出应该调用哪个系统调用，调用内核中实现那个系统调用的函数，恢复用户程序状态，然后将控制权返还给用户程序。系统调用是设备驱动程序中定义的函数最终被调用的一种方式。</p> \n <p>从系统分析的角度，linux的系统调用涉及 4 个方面的问题。</p> \n <h4><a id=\"sys_xxx_2136\"></a>响应函数sys_xxx</h4> \n <p>响应函数名以 “sys_” 开头，后跟该系统调用的名字。例如系统调用 fork() 的响应函数是 sys_fork()，exit() 的响应函数是 sys_exit()。</p> \n <h4><a id=\"_2140\"></a>系统调用表与系统调用号-=&gt;数组与下标</h4> \n <p>文件 include/asm/unisted.h 为每个系统调用规定了唯一的编号。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/4c055b27ee5b41478d309d95a9a04d5c.png\" alt=\"\"></p> \n <p>假设用 name 表示系统调用的名称，那么系统调用号与系统调用响应函数的关系是：以系统调用号 <code>_NR_name</code> 作为下标，可找出系统调用表 sys_call_table 中对应表项的内容，它正好是该系统调用的响应函数 sys_name 的入口地址。</p> \n <p>系统调用表 sys_call_table 记录了各 sys_name 函数在表中的位置，共 190 项。有了这张表，就很容易根据特定系统调用</p> \n <p><img src=\"https://img-blog.csdnimg.cn/bbbdfefb62134c53b4b4376c00f59821.png\" alt=\"\"></p> \n <p>在表中的偏移量，找到对应的系统调用响应函数的入口地址。系统调用表共 256 项，余下的项是可供用户自己添加的系统调用空间。</p> \n <p>在 Linux 中，每个系统调用被赋予一个系统调用号。这样，通过这个独一无二的号就可以关联系统调用。当用户空间的进程执行一个系统调用的时候，这个系统调用号就被用来指明到底是要执行哪个系统调用。进程不会提及系统调用的名称。</p> \n <p>系统调用号相当关键，一旦分配就不能再有任何变更，否则编译好的应用程序就会崩溃。Linux 有一个 “未实现” 系统调用 sys_ni_syscall()，它除了返回一 ENOSYS 外不做任何其他工作，这个错误号就是专门针对无效的系统调用而设的。</p> \n <p>因为所有的系统调用陷入内核的方式都一样，所以仅仅是陷入内核空间是不够的。因此必须把系统调用号一并传给内核。在 x86 上，系统调用号是通过 eax 寄存器传递给内核的。在陷人内核之前，用户空间就把相应系统调用所对应的号放入 eax 中了。这样系统调用处理程序一旦运行，就可以从 eax 中得到数据。其他体系结构上的实现也都类似。</p> \n <p>内核记录了系统调用表中的所有已注册过的系统调用的列表，存储在 sys_call_table 中。它与体系结构有关，一般在 entry.s 中定义。这个表中为每一个有效的系统调用指定了惟一的系统调用号。sys_call_table 是一张由指向实现各种系统调用的内核函数的函数指针组成的表：</p> \n <p>system_call() 函数通过将给定的系统调用号与 NR_syscalls 做比较来检查其有效性。如果它大于或者等于 NR syscalls,该函数就返回一 ENOSYS。否则，就执行相应的系统调用。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/2f2a7312473f4b1a8f913aaf295c01d5.png\" alt=\"\"></p> \n <h4><a id=\"INT_0x80_2166\"></a>进程的系统调用命令转换为INT 0x80中断的过程</h4> \n <p>宏定义 <code>_syscallN()</code> 见 (include/asm/unisted.h) 用于系统调用的格式转换和参数的传递。N 取 0~5 之间的整数。参数个数为 N 的系统调用由 <code>_syscallN()</code> 负责格式转换和参数传递。系统调用号放入 EAX 寄存器，启动 INT 0x80 后，规定返回值送 EAX 寄存器。</p> \n <h3><a id=\"_2172\"></a>聊聊：进程调度算法了解多少</h3> \n <p>先来先服务、短作业优先、最短剩余时间优先、</p> \n <ul>\n  <li>先来先服务 first-come first-serverd（FCFS） ：非抢占式，按照请求的顺序进行调度<br> 优点：有利长作业<br> 缺点：不利短作业，长作业需要执行很长时间，造成了短作业等待时间过长</li>\n  <li>短作业优先 shortest job first（SJF） ：非抢占式，估计运行时间最短的顺序进行调度<br> 缺点：长作业有可能会饿死，处于一直等待短作业执行完毕的状态。如果一直有短作业到来，那么长作业永远得不到调度</li>\n  <li>最短剩余时间优先 shortest remaining time next（SRTN） ：最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度，当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较，如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待</li>\n  <li>时间片轮转 ：将所有就绪进程按 FCFS （先来先服务）的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。<br> 时间片轮转算法的效率和时间片的大小有很大关系：因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。而如果时间片过长，那么实时性就不能得到保证。</li>\n  <li>优先级调度 ：为每个进程分配一个优先级，按优先级进行调度。<br> 为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级</li>\n  <li>多级反馈队列<br> 一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。<br> 多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,…。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合</li>\n </ul> \n <h3><a id=\"_2192\"></a>聊聊：调度算法都有哪些</h3> \n <p>调度算法分为三大类：</p> \n <ul>\n  <li>批处理中的调度、</li>\n  <li>交互系统中的调度、</li>\n  <li>实时系统中的调度</li>\n </ul> \n <h4><a id=\"_2200\"></a>批处理中的调度</h4> \n <h5><a id=\"_2202\"></a>先来先服务</h5> \n <p>很像是先到先得。。。可能最简单的非抢占式调度算法的设计就是 <code>先来先服务(first-come,first-serverd)</code>。使用此算法，将按照请求顺序为进程分配 CPU。最基本的，会有一个就绪进程的等待队列。当第一个任务从外部进入系统时，将会立即启动并允许运行任意长的时间。它不会因为运行时间太长而中断。当其他作业进入时，它们排到就绪队列尾部。当正在运行的进程阻塞，处于等待队列的第一个进程就开始运行。当一个阻塞的进程重新处于就绪态时，它会像一个新到达的任务，会排在队列的末尾，即排在所有进程最后。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/b33a9e9fd570a8f37ce9af9e83f5fc89.png\" alt=\"\"></p> \n <p>这个算法的强大之处在于易于理解和编程，在这个算法中，一个单链表记录了所有就绪进程。要选取一个进程运行，只要从该队列的头部移走一个进程即可；要添加一个新的作业或者阻塞一个进程，只要把这个作业或进程附加在队列的末尾即可。这是很简单的一种实现。</p> \n <p>不过，先来先服务也是有缺点的，那就是没有优先级的关系，试想一下，如果有 100 个 I/O 进程正在排队，第 101 个是一个 CPU 密集型进程，那岂不是需要等 100 个 I/O 进程运行完毕才会等到一个 CPU 密集型进程运行，这在实际情况下根本不可能，所以需要优先级或者抢占式进程的出现来优先选择重要的进程运行。</p> \n <h5><a id=\"_2212\"></a>最短作业优先</h5> \n <p>批处理中，第二种调度算法是 <code>最短作业优先(Shortest Job First)</code>，我们假设运行时间已知。例如，一家保险公司，因为每天要做类似的工作，所以人们可以相当精确地预测处理 1000 个索赔的一批作业需要多长时间。当输入队列中有若干个同等重要的作业被启动时，调度程序应使用最短优先作业算法</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/04d32a35c8a71071d15785cfec91bcad.png\" alt=\"\"></p> \n <p>如上图 a 所示，这里有 4 个作业 A、B、C、D ，运行时间分别为 8、4、4、4 分钟。若按图中的次序运行，则 A 的周转时间为 8 分钟，B 为 12 分钟，C 为 16 分钟，D 为 20 分钟，平均时间内为 14 分钟。</p> \n <p>现在考虑使用最短作业优先算法运行 4 个作业，如上图 b 所示，目前的周转时间分别为 4、8、12、20，平均为 11 分钟，可以证明最短作业优先是最优的。考虑有 4 个作业的情况，其运行时间分别为 a、b、c、d。第一个作业在时间 a 结束，第二个在时间 a + b 结束，以此类推。平均周转时间为 (4a + 3b + 2c + d) / 4 。显然 a 对平均值的影响最大，所以 a 应该是最短优先作业，其次是 b，然后是 c ，最后是 d 它就只能影响自己的周转时间了。</p> \n <blockquote> \n  <p>需要注意的是，在所有的进程都可以运行的情况下，最短作业优先的算法才是最优的。</p> \n </blockquote> \n <h5><a id=\"_2224\"></a>最短剩余时间优先</h5> \n <p>最短作业优先的抢占式版本被称作为 <code>最短剩余时间优先(Shortest Remaining Time Next)</code> 算法。使用这个算法，调度程序总是选择剩余运行时间最短的那个进程运行。当一个新作业到达时，其整个时间同当前进程的剩余时间做比较。如果新的进程比当前运行进程需要更少的时间，当前进程就被挂起，而运行新的进程。这种方式能够使短期作业获得良好的服务。</p> \n <h4><a id=\"_2228\"></a>交互式系统中的调度</h4> \n <p>交互式系统中在个人计算机、服务器和其他系统中都是很常用的，所以有必要来探讨一下交互式调度</p> \n <h5><a id=\"_2232\"></a>轮询调度</h5> \n <p>一种最古老、最简单、最公平并且最广泛使用的算法就是 <code>轮询算法(round-robin)</code>。每个进程都会被分配一个时间段，称为<code>时间片(quantum)</code>，在这个时间片内允许进程运行。如果时间片结束时进程还在运行的话，则抢占一个 CPU 并将其分配给另一个进程。如果进程在时间片结束前阻塞或结束，则 CPU 立即进行切换。轮询算法比较容易实现。调度程序所做的就是维护一个可运行进程的列表，就像下图中的 a，当一个进程用完时间片后就被移到队列的末尾，就像下图的 b。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/3a64fed6a450c4167cf606f4c06f1286.png\" alt=\"\"></p> \n <h5><a id=\"_2238\"></a>优先级调度</h5> \n <p>事实情况是不是所有的进程都是优先级相等的。例如，在一所大学中的等级制度，首先是院长，然后是教授、秘书、后勤人员，最后是学生。这种将外部情况考虑在内就实现了<code>优先级调度(priority scheduling)</code></p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/1d634f6cda1d5bb461f5becb95d4bf13.png\" alt=\"\"></p> \n <p>它的基本思想很明确，每个进程都被赋予一个优先级，优先级高的进程优先运行。</p> \n <p>但是也不意味着高优先级的进程能够永远一直运行下去，调度程序会在每个时钟中断期间降低当前运行进程的优先级。如果此操作导致其优先级降低到下一个最高进程的优先级以下，则会发生进程切换。或者，可以为每个进程分配允许运行的最大时间间隔。当时间间隔用完后，下一个高优先级的进程会得到运行的机会。</p> \n <h5><a id=\"_2248\"></a>最短进程优先</h5> \n <p>对于批处理系统而言，由于最短作业优先常常伴随着最短响应时间，一种方式是根据进程过去的行为进行推测，并执行估计运行时间最短的那一个。假设每个终端上每条命令的预估运行时间为 <code>T0</code>，现在假设测量到其下一次运行时间为 <code>T1</code>，可以用两个值的加权来改进估计时间，即<code>aT0+ (1- 1)T1</code>。通过选择 a 的值，可以决定是尽快忘掉老的运行时间，还是在一段长时间内始终记住它们。当 a = 1/2 时，可以得到下面这个序列</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/f008e30e605aa1f2e5a80d722c2b316d.png\" alt=\"\"></p> \n <p>可以看到，在三轮过后，T0 在新的估计值中所占比重下降至 1/8。</p> \n <p>有时把这种通过当前测量值和先前估计值进行加权平均从而得到下一个估计值的技术称作 <code>老化(aging)</code>。这种方法会使用很多预测值基于当前值的情况。</p> \n <h5><a id=\"_2258\"></a>彩票调度</h5> \n <p>有一种既可以给出预测结果而又有一种比较简单的实现方式的算法，就是 <code>彩票调度(lottery scheduling)</code>算法。他的基本思想为进程提供各种系统资源的<code>彩票</code>。当做出一个调度决策的时候，就随机抽出一张彩票，拥有彩票的进程将获得资源。比如在 CPU 进行调度时，系统可以每秒持有 50 次抽奖，每个中奖进程会获得额外运行时间的奖励。</p> \n <blockquote> \n  <p>可以把彩票理解为 buff，这个 buff 有 15% 的几率能让你产生 <code>速度之靴</code> 的效果。</p> \n </blockquote> \n <h5><a id=\"_2264\"></a>公平分享调度</h5> \n <p>如果用户 1 启动了 9 个进程，而用户 2 启动了一个进程，使用轮转或相同优先级调度算法，那么用户 1 将得到 90 % 的 CPU 时间，而用户 2 将之得到 10 % 的 CPU 时间。</p> \n <p>为了阻止这种情况的出现，一些系统在调度前会把进程的拥有者考虑在内。在这种模型下，每个用户都会分配一些CPU 时间，而调度程序会选择进程并强制执行。因此如果两个用户每个都会有 50% 的 CPU 时间片保证，那么无论一个用户有多少个进程，都将获得相同的 CPU 份额。</p> \n <h3><a id=\"_2270\"></a>聊聊：影响调度程序的指标是什么</h3> \n <p>会有下面几个因素决定调度程序的好坏</p> \n <ul>\n  <li>CPU 使用率：</li>\n </ul> \n <p>CPU 正在执行任务（即不处于空闲状态）的时间百分比。</p> \n <ul>\n  <li>等待时间</li>\n </ul> \n <p>这是进程轮流执行的时间，也就是进程切换的时间</p> \n <ul>\n  <li>吞吐量</li>\n </ul> \n <p>单位时间内完成进程的数量</p> \n <ul>\n  <li>响应时间</li>\n </ul> \n <p>这是从提交流程到获得有用输出所经过的时间。</p> \n <ul>\n  <li>周转时间</li>\n </ul> \n <p>从提交流程到完成流程所经过的时间。</p> \n <h3><a id=\"_RR__2294\"></a>聊聊：什么是 RR 调度算法</h3> \n <p><code>RR(round-robin)</code> 调度算法主要针对分时系统，RR 的调度算法会把时间片以相同的部分并循环的分配给每个进程，RR 调度算法没有优先级的概念。</p> \n <p>这种算法的实现比较简单，而且每个线程都会占有时间片，并不存在线程饥饿的问题。</p> \n <h2><a id=\"Copyonwrite_2302\"></a>Copy-on-write（写时拷贝）</h2> \n <p>copy-on-write，写时拷贝，是计算机程序设计领域的一种优化策略，</p> \n <p>其核心思想是，当有多个调用者都需要请求相同资源时，一开始资源只会有一份，多个调用者共同读取这一份资源，当某个调用者需要修改数据的时候，才会分配一块内存，将数据拷贝过去，供这个调用者使用，而其他调用者依然还是读取最原始的那份数据。</p> \n <p>每次有调用者需要修改数据时，就会重复一次拷贝流程，供调用者修改使用。</p> \n <p>使用 copy-on-write 可以避免或者减少数据的拷贝操作，极大的提高性能，其应用十分广泛，</p> \n <p>例如 Linux 的 fork 调用，Linux 的文件管理系统，一些数据库服务，Java 中的 CopyOnWriteArrayList，C98/C03 中的 std::string 等等。</p> \n <h3><a id=\"Linuxfork_2314\"></a>Linux中的fork()</h3> \n <p>Linux 在启动过程中，会初始化内核，而内核初始化的最后一步，是创建一个 PID 为 1 的超级进程，又叫做根进程。系统中所有的其他进程，都是由这个根进程直接或者间接产生的，而产生进程的方式，就是利用 fork 系统调用，fork 是类 Unix 操作系统上创建进程的主要方法。</p> \n <p>fork() 的函数原型很简单：</p> \n <pre><code class=\"prism language-c\"><span class=\"token class-name\">pid_t</span> <span class=\"token function\">fork</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre> \n <p>我们来看一个简单的例子：</p> \n <pre><code class=\"prism language-c\"><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;unistd.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;stdio.h&gt;</span></span>\n<span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token keyword\">int</span> pid <span class=\"token operator\">=</span> <span class=\"token function\">fork</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>pid <span class=\"token operator\">==</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token keyword\">return</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>pid <span class=\"token operator\">&gt;</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Hi, father: %d\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token function\">getpid</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">return</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span> <span class=\"token keyword\">else</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token function\">printf</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Hi, child: %d\\n\"</span><span class=\"token punctuation\">,</span> <span class=\"token function\">getpid</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">return</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>通过 gcc 编译之后执行，输出：</p> \n <pre><code class=\"prism language-bash\">Hi, father: <span class=\"token number\">7562</span>\nHi, child: <span class=\"token number\">7563</span>\n</code></pre> \n <p>从输出来看，if 和 else 居然都执行了，因为用 fork() 有个神奇的地方，一次调用，两次返回。</p> \n <p>调用 fork() 之后，会出现两个进程，一个是子进程，一个是父进程，在子进程中，fork() 返回 0，在父进程中，fork() 返回新创建的子进程的进程 ID，我们可以通过 fork() 函数的返回值来判断当前进程是子进程还是父进程。两个进程都会从调用 fork() 的地方继续执行。</p> \n <h4><a id=\"forkcopyonwrite_2355\"></a>fork()中的copy-on-write</h4> \n <p>fork 进程之后，父进程中的数据怎么办？常规思路是，给子进程重新开辟一块物理内存，将父进程的数据拷贝到子进程中，拷贝完之后，父进程和子进程之间的数据段和堆栈是相互独立的。这样做会带来两个问题：</p> \n <ul>\n  <li>拷贝本身会有 CPU 和内存的开销；</li>\n  <li>fork 出来的子进程在此后多会执行 exec() 系统调用。</li>\n </ul> \n <p>也就是说，绝大部分情况下，fork 一个子进程会耗费 CPU 和内存资源，但是马上又被子进程抛弃不用了，那么资源的开销就显得毫无意义，于是出于效率考虑，Linux 引入了 copy-on-write 技术。</p> \n <p>在 fork() 调用之后，只会给子进程分配虚拟内存地址，而父子进程的虚拟内存地址虽然不同，但是映射到物理内存上都是同一块区域，子进程的代码段、数据段、堆栈都是指向父进程的物理空间。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/42c3b44bc0f64f488bdcc39a2ffdde50.png\" alt=\"\"></p> \n <p>并且此时父进程中所有对应的内存页都会被标记为只读，父子进程都可以正常读取内存数据，当其中某个进程需要更新数据时，检测到内存页是 read-only 的，内存管理单元（MMU）便会抛出一个页面异常中断，（page-fault），在处理异常时，内核便会把触发异常的内存页拷贝一份（其他内存页还是共享的一份），让父子进程各自持有一份。</p> \n <p>这样做的好处不言而喻，能极大的提高 fork 操作时的效率，但是坏处是，如果 fork 之后，两个进程各自频繁的更新数据，则会导致大量的分页错误，这样就得不偿失了。</p> \n <h3><a id=\"JavaCopyOnWrite_2372\"></a>Java中的CopyOnWrite容器</h3> \n <p>Java 中有两个容器：CopyOnWriteArrayList 和 CopyOnWriteArraySet，从名字就可以看出，其实现思想也是参考了 copy-on-write 技术。</p> \n <p>当我们往一个 CopyOnWrite 的容器中添加数据的时候，并不会直接添加到当前容器中，而是会拷贝出一个新的容器，然后往新的容器里添加数据，在添加过程中，所有的读操作都会指向旧的容器，添加操作完成之后，再将原容器的引用指向新的容器。为了避免同时有多个线程更新数据，从而拷贝出多个容器的副本，会在拷贝容器的时候进行加锁。</p> \n <p>这样做的好处是对 CopyOnWrite 容器进行读操作的时候并不需要加锁，因为当前容器不会添加任何元素。所以 CopyOnWrite 容器也是一种读写分离的思想，读和写不同的容器。</p> \n <h3><a id=\"Cstdstring_2380\"></a>C++中的std::string</h3> \n <p>C98/C03 中的 std::string 使用了 copy-on-write 技术，在 C++11 标准中为了提高并行性取消了这一策略。</p> \n <p>C++ 在分配一个 string 对象时，会在数据区的前面多分配一点空间，用于存储 string 的引用计数。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/377dd25c22c24117bd1b2f39c4254ab1.png\" alt=\"\"></p> \n <p>当触发一个 string 的拷贝构造函数或者赋值函数时，便会对这个引用计数加一。需要修改内容时，如果引用计数不为零，表示有人在共享这块内存，那么自己需要先做一份拷贝，然后把引用计数减去一，再把数据拷贝过来。</p> \n <h3><a id=\"RedisCOW_2390\"></a>Redis中的COW</h3> \n <p>Redis 中，执行 BGSAVE 命令，来生成 RDB 文件时，本质就是调用了 Linux 的系统调用 fork() 命令，Linux 下 fork() 系统调用，实现了 copy-on-write 写时复制。</p> \n <h3><a id=\"Copy_On_Write_2394\"></a>Copy On Write技术实现原理</h3> \n <p>fork() 之后，kernel 把父进程中所有的内存页的权限都设为 read-only，然后子进程的地址空间指向父进程。当父子进程都只读内存时，相安无事。当其中某个进程写内存时，CPU 硬件检测到内存页是 read-only 的，于是触发页异常中断（page-fault），陷入 kernel 的一个中断例程。中断例程中，kernel 就会把触发的异常的页复制一份，于是父子进程各自持有独立的一份。</p> \n <h3><a id=\"Copy_On_Write_2398\"></a>Copy On Write技术好处</h3> \n <p>COW 技术可减少分配和复制大量资源时带来的瞬间延时。</p> \n <p>COW 技术可减少不必要的资源分配。比如 fork 进程时，并不是所有的页面都需要复制，父进程的代码段和只读数据段都不被允许修改，所以无需复制。</p> \n <h3><a id=\"Copy_On_Write_2404\"></a>Copy On Write技术缺点</h3> \n <p>如果在 fork() 之后，父子进程都还需要继续进行写操作，那么会产生大量的分页错误(页异常中断 page-fault)，这样就得不偿失。</p> \n <h3><a id=\"_2408\"></a>总结</h3> \n <p>fork 出的子进程共享父进程的物理空间，当父子进程有内存写入操作时，read-only 内存页发生中断，将触发的异常的内存页复制一份(其余的页还是共享父进程的)。</p> \n <p>fork 出的子进程功能实现和父进程是一样的。如果有需要，我们会用 exec() 把当前进程映像替换成新的进程文件，完成自己想要实现的功能。</p> \n <h2><a id=\"_2416\"></a>动态库与静态库区别</h2> \n <p>静态连接库就是把(lib)文件中用到的函数代码直接链接进目标程序，程序运行的时候不再需要其它的库文件；动态链接就是把调用的函数所在文件模块（DLL）和调用函数在文件中的位置等信息链接进目标程序，程序运行的时候再从DLL中寻找相应函数代码，因此需要相应 DLL 文件的支持。</p> \n <h3><a id=\"_2420\"></a>动态库与静态库</h3> \n <p>通常情况下，对函数库的链接是放在编译时期（compile time）完成的。所有相关的对象文件 （object file）与牵涉到的函数库（library）被链接合成一个可执行文件 （executable file）。程序在运行时，与函数库再无瓜葛，因为所有需要的函数已拷贝到自己门下。</p> \n <p>所以这些函数库被成为静态库（static libaray），通常文件 名为 “libxxx.a” 的形式。其实，我们也可以把对一些库函数的链接载入推迟到程序运行的时期（runtime）。这就是如雷贯耳的动态链接库（dynamic link library）技术。</p> \n <h3><a id=\"_2426\"></a>动态链接</h3> \n <p>动态链接方法：LoadLibrary()/GetProcessAddress() 和 FreeLibrary()，使用这种方式的程序并不在一开始就完成动态链接，而是直到真正调用动态库代码时，载入程序才计算(被调用的那部分)动态代码的逻辑地址，然后等到某个时候，程序又需要调用另外某块动态代码时，载入程序又去计算这部分代码的逻辑地址，所以，这种方式使程序初始化时间较短，但运行期间的性能比不上静态链接的程序。</p> \n <h3><a id=\"_2430\"></a>静态链接</h3> \n <p>静态链接方法：<code>#pragma comment(lib, \"test.lib\")</code> ，静态链接的时候，载入代码就会把程序会用到的动态代码或动态代码的地址确定下来。</p> \n <p>静态库的链接可以使用静态链接，动态链接库也可以使用这种方法链接导入库。</p> \n <h3><a id=\"_2436\"></a>静态库和动态库的区别</h3> \n <p>在软件开发的过程中，大家经常会或多或少的使用别人编写的或者系统提供的动态库或静态库，但是究竟是使用静态库还是动态库呢？他们的适用条件是什么呢？</p> \n <p>简单的说，静态库和应用程序编译在一起，在任何情况下都能运行，而动态库是动态链接，顾名思义就是在应用程序启动的时候才会链接，所以，当用户的系统上没有该动态库时，应用程序就会运行失败。再看它们的特点：</p> \n <h4><a id=\"_2442\"></a>动态库</h4> \n <ol>\n  <li>类库的名字一般是 libxxx.so</li>\n  <li>共享：多个应用程序可以使用同一个动态库，启动多个应用程序的时候，只需要将动态库加载到内存一次即可；</li>\n  <li>开发模块好：要求设计者对功能划分的比较好。</li>\n  <li>动态函数库的改变并不影响你的程序，所以动态函数库的升级比较方便。</li>\n </ol> \n <h4><a id=\"_2449\"></a>静态库</h4> \n <ol>\n  <li>类库的名字一般是 libxxx.a</li>\n  <li>代码的装载速度快，执行速度也比较快，因为编译时它只会把你需要的那部分链接进去。</li>\n  <li>应用程序相对比较大，如果多个应用程序使用的话，会被装载多次，浪费内存。</li>\n  <li>如果静态函数库改变了，那么你的程序必须重新编译。</li>\n </ol> \n <p>如果你的系统上有多个应用程序都使用该库的话，就把它编译成动态库，这样虽然刚启动的时候加载比较慢，但是多任务的时候会比较节省内存；如果你的系统上只有一到两个应用使用该库，并且使用的 API 比较少的话，就编译成静态库吧，一般的静态库还可以进行裁剪编译，这样应用程序可能会比较大，但是启动的速度会大大提高。</p> \n <h3><a id=\"_2458\"></a>静态库与动态库优缺点</h3> \n <h4><a id=\"_2460\"></a>静态链接库的优点</h4> \n <ol>\n  <li>代码装载速度快，执行速度略比动态链接库快；</li>\n  <li>只需保证在开发者的计算机中有正确的 .LIB 文件，在以二进制形式发布程序时不需考虑在用户的计算机上 .LIB 文件是否存在及版本问题，可避免 DLL 地狱等问题。</li>\n </ol> \n <h4><a id=\"_2465\"></a>动态链接库的优点</h4> \n <ol>\n  <li>更加节省内存并减少页面交换；</li>\n  <li>DLL 文件与 EXE 文件独立，只要输出接口不变（即名称、参数、返回值类型和调用约定不变），更换 DLL 文件不会对 EXE 文件造成任何影响，因而极大地提高了可维护性和可扩展性；</li>\n  <li>不同编程语言编写的程序只要按照函数调用约定就可以调用同一个 DLL 函数；</li>\n  <li>适用于大规模的软件开发，使开发过程独立、耦合度小，便于不同开发者和开发组织之间进行开发和测试。</li>\n </ol> \n <h4><a id=\"_2472\"></a>不足之处</h4> \n <ol>\n  <li>使用静态链接生成的可执行文件体积较大，包含相同的公共代码，造成浪费；</li>\n  <li>使用动态链接库的应用程序不是自完备的，它依赖的 DLL 模块也要存在，如果使用载入时动态链接，程序启动时发现 DLL 不存在，系统将终止程序并给出错误信息。<br> 而使用运行时动态链接，系统不会终止，但由于 DLL 中的导出函数不可用，程序会加载失败；速度比静态链接慢。当某个模块更新后，如果新模块与旧的模块不兼容，那么那些需要该模块才能运行的软件，统统撕掉。这在早期 Windows 中很常见。</li>\n </ol> \n <h2><a id=\"_2478\"></a>内核态与用户态</h2> \n <p><img src=\"https://img-blog.csdnimg.cn/bbb357f8359a493eb06a0325a89ffea3.png\" alt=\"\"></p> \n <h3><a id=\"_2484\"></a>概念</h3> \n <p>Linux 的设计哲学之一就是：对不同的操作赋予不同的执行等级，就是所谓特权的概念，即与系统相关的一些特别关键的操作必须由最高特权的程序来完成。</p> \n <p>Intel 的 X86 架构的 CPU 提供了 0 到 3 四个特权级，数字越小，特权越高，Linux 操作系统中主要采用了 0 和 3 两个特权级，分别对应的就是内核态(Kernel Mode)与用户态(User Mode)。</p> \n <ul>\n  <li><strong>内核态：</strong> CPU 可以访问内存所有数据,包括外围设备（硬盘、网卡），CPU 也可以将自己从一个程序切换到另一个程序；</li>\n  <li><strong>用户态：</strong> 只能受限的访问内存，且不允许访问外围设备，占用 CPU 的能力被剥夺，CPU 资源可以被其他程序获取；</li>\n </ul> \n <p>Linux 中任何一个用户进程被创建时都包含 2 个栈：内核栈，用户栈，并且是进程私有的，从用户态开始运行。内核态和用户态分别对应内核空间与用户空间，内核空间中存放的是内核代码和数据，而进程的用户空间中存放的是用户程序的代码和数据。不管是内核空间还是用户空间，它们都处于虚拟空间中。</p> \n <h3><a id=\"_2495\"></a>内核空间相关</h3> \n <ul>\n  <li>内核空间：存放的是内核代码和数据，处于虚拟空间；</li>\n  <li>内核态：当进程执行系统调用而进入内核代码中执行时，称进程处于内核态，此时CPU处于特权级最高的0级内核代码中执行，当进程处于内核态时，执行的内核代码会使用当前进程的内核栈，每个进程都有自己的内核栈；</li>\n  <li>CPU 堆栈指针寄存器指向：内核栈地址；</li>\n  <li>内核栈：进程处于内核态时使用的栈，存在于内核空间；</li>\n  <li>处于内核态进程的权利：处于内核态的进程，当它占有 CPU 的时候，可以访问内存所有数据和所有外设，比如硬盘，网卡等等；</li>\n </ul> \n <h3><a id=\"_2503\"></a>用户空间相关</h3> \n <ul>\n  <li>用户空间：存放的是用户程序的代码和数据，处于虚拟空间；</li>\n  <li>用户态：当进程在执行用户自己的代码（非系统调用之类的函数）时，则称其处于用户态，CPU 在特权级最低的3级用户代码中运行，当正在执行用户程序而突然被中断程序中断时，此时用户程序也可以象征性地称为处于进程的内核态，因为中断处理程序将使用当前进程的内核栈；</li>\n  <li>CPU 堆栈指针寄存器指向：用户堆栈地址；</li>\n  <li>用户堆栈：进程处于用户态时使用的堆栈，存在于用户空间；</li>\n  <li>处于用户态进程的权利：处于用户态的进程，当它占有 CPU 的时候，只可以访问有限的内存，而且不允许访问外设，这里说的有限的内存其实就是用户空间，使用的是用户堆栈；</li>\n </ul> \n <h3><a id=\"_2511\"></a>内核态和用户态的切换</h3> \n <h4><a id=\"_2513\"></a>系统调用</h4> \n <p>所有用户程序都是运行在用户态的，但是有时候程序确实需要做一些内核态的事情，例如从硬盘读取数据等。而唯一可以做这些事情的就是操作系统，所以此时程序就需要先操作系统请求以程序的名义来执行这些操作。这时需要一个这样的机制：用户态程序切换到内核态，但是不能控制在内核态中执行的指令。</p> \n <p>这种机制叫系统调用，在 CPU 中的实现称之为陷阱指令(Trap Instruction)。</p> \n <h4><a id=\"_2519\"></a>异常事件</h4> \n <p>当 CPU 正在执行运行在用户态的程序时，突然发生某些预先不可知的异常事件，这个时候就会触发从当前用户态执行的进程转向内核态执行相关的异常事件，典型的如缺页异常。</p> \n <h4><a id=\"_2523\"></a>外围设备的中断</h4> \n <p>当外围设备完成用户的请求操作后，会向 CPU 发出中断信号，此时，CPU 就会暂停执行下一条即将要执行的指令，转而去执行中断信号对应的处理程序，如果先前执行的指令是在用户态下，则自然就发生从用户态到内核态的转换。</p> \n <p>注意：系统调用的本质其实也是中断，相对于外围设备的硬中断，这种中断称为软中断，这是操作系统为用户特别开放的一种中断，如 Linux int 80h 中断。所以从触发方式和效果上来看，这三种切换方式是完全一样的，都相当于是执行了一个中断响应的过程。但是从触发的对象来看，系统调用是进程主动请求切换的，而异常和硬中断则是被动的。</p> \n <h3><a id=\"_2529\"></a>用户态到内核态具体的切换步骤</h3> \n <ol>\n  <li>从当前进程的描述符中提取其内核栈的 ss0 及 esp0 信息。</li>\n  <li>使用 ss0 和 esp0 指向的内核栈将当前进程的 cs, eip, eflags, ss, esp 信息保存起来，这个过程也完成了由用户栈到内核栈的切换过程，同时保存了被暂停执行的程序的下一条指令。</li>\n  <li>将先前由中断向量检索得到的中断处理程序的 cs, eip 信息装入相应的寄存器，开始执行中断处理程序，这时就转到了内核态的程序执行了。</li>\n </ol> \n <h2><a id=\"_2537\"></a>虚拟内存篇</h2> \n <h3><a id=\"_2539\"></a>虚拟内存教程</h3> \n <h4><a id=\"_2541\"></a>第一层理解</h4> \n <p>每个进程都有自己独立的 4G 内存空间，各个进程的内存空间具有类似的结构。</p> \n <p>一个新进程建立的时候，将会建立起自己的内存空间，此进程的数据，代码等从磁盘拷贝到自己的进程空间，哪些数据在哪里，都由进程控制表中的 task_struct 记录，task_struct 中记录中一条链表，记录中内存空间的分配情况，哪些地址有数据，哪些地址无数据，哪些可读，哪些可写，都可以通过这个链表记录。</p> \n <p>每个进程已经分配的内存空间，都与对应的磁盘空间映射，但是：</p> \n <ul>\n  <li>计算机明明没有那么多内存（n 个进程的话就需要 n*4G）内存</li>\n  <li>建立一个进程，就要把磁盘上的程序文件拷贝到进程对应的内存中去，对于一个程序对应的多个进程这种情况，浪费内存！</li>\n </ul> \n <h4><a id=\"_2552\"></a>第二层理解</h4> \n <p>每个进程的 4G 内存空间只是虚拟内存空间，每次访问内存空间的某个地址，都需要把地址翻译为实际物理内存地址。</p> \n <p>所有进程共享同一物理内存，每个进程只把自己目前需要的虚拟内存空间映射并存储到物理内存上。进程要知道哪些内存地址上的数据在物理内存上，哪些不在，还有在物理内存上的哪里，需要用页表来记录。</p> \n <p>页表的每一个表项分两部分，第一部分记录此页是否在物理内存上，第二部分记录物理内存页的地址（如果在的话）。当进程访问某个虚拟地址，去看页表，如果发现对应的数据不在物理内存中，则缺页异常。</p> \n <p>缺页异常的处理过程，就是把进程需要的数据从磁盘上拷贝到物理内存中，如果内存已经满了，没有空地方了，那就找一个页覆盖，当然如果被覆盖的页曾经被修改过，需要将此页写回磁盘</p> \n <h3><a id=\"_2562\"></a>虚拟内存总结</h3> \n <p>既然每个进程的内存空间都是一致而且固定的，所以链接器在链接可执行文件时，可以设定内存地址，而不用去管这些数据最终实际的内存地址，这是有独立内存空间的好处。</p> \n <p>当不同的进程使用同样的代码时，比如库文件中的代码，物理内存中可以只存储一份这样的代码，不同的进程只需要把自己的虚拟内存映射过去就可以了，节省内存。</p> \n <p>在程序需要分配连续的内存空间的时候，只需要在虚拟内存空间分配连续空间，而不需要实际物理内存的连续空间，可以利用碎片。</p> \n <p>另外，事实上，在每个进程创建加载时，内核只是为进程 “创建” 了虚拟内存的布局，具体就是初始化进程控制表中内存相关的链表，实际上并不立即就把虚拟内存对应位置的程序数据和代码（比如 .text .data 段）拷贝到物理内存中，只是建立好虚拟内存和磁盘文件之间的映射就好（叫做存储器映射），等到运行到对应的程序时，才会通过缺页异常，来拷贝数据。</p> \n <p>还有进程运行过程中，要动态分配内存，比如 malloc 时，也只是分配了虚拟内存，即为这块虚拟内存对应的页表项做相应设置，当进程真正访问到此数据时，才引发缺页异常。</p> \n <h3><a id=\"_2574\"></a>虚拟存储器</h3> \n <p>可以认为虚拟空间都被映射到了磁盘空间中，（事实上也是按需要映射到磁盘空间上，通过 mmap），并且由页表记录映射位置，当访问到某个地址的时候，通过页表中的有效位，可以得知此数据是否在内存中，如果不是，则通过缺页异常，将磁盘对应的数据拷贝到内存中，如果没有空闲内存，则选择牺牲页面，替换其他页面。</p> \n <p>mmap 是用来建立从虚拟空间到磁盘空间的映射的，可以将一个虚拟空间地址映射到一个磁盘文件上，当不设置这个地址时，则由系统自动设置，函数返回对应的内存地址（虚拟地址），当访问这个地址的时候，就需要把磁盘上的内容拷贝到内存了，然后就可以读或者写，最后通过 manmap 可以将内存上的数据换回到磁盘，也就是解除虚拟空间和内存空间的映射，这也是一种读写磁盘文件的方法，也是一种进程共享数据的方法 共享内存</p> \n <h3><a id=\"_2580\"></a>物理内存</h3> \n <p>在内核态申请内存比在用户态申请内存要更为直接，它没有采用用户态那种延迟分配内存技术。内核认为一旦有内核函数申请内存，那么就必须立刻满足该申请内存的请求，并且这个请求一定是正确合理的。相反，对于用户态申请内存的请求，内核总是尽量延后分配物理内存，用户进程总是先获得一个虚拟内存区的使用权，最终通过缺页异常获得一块真正的物理内存。</p> \n <h4><a id=\"_2584\"></a>物理内存的内核映射</h4> \n <p>IA32 架构中内核虚拟地址空间只有 1GB 大小（从 3GB 到 4GB），因此可以直接将 1GB 大小的物理内存（即常规内存）映射到内核地址空间，但超出 1GB 大小的物理内存（即高端内存）就不能映射到内核空间。为此，内核采取了下面的方法使得内核可以使用所有的物理内存。</p> \n <p>高端内存不能全部映射到内核空间，也就是说这些物理内存没有对应的线性地址。不过，内核为每个物理页框都分配了对应的页框描述符，所有的页框描述符都保存在 mem_map 数组中，因此每个页框描述符的线性地址都是固定存在的。内核此时可以使用 alloc_pages() 和 alloc_page() 来分配高端内存，因为这些函数返回页框描述符的线性地址。</p> \n <p>内核地址空间的后 128MB 专门用于映射高端内存，否则，没有线性地址的高端内存不能被内核所访问。这些高端内存的内核映射显然是暂时映射的，否则也只能映射 128MB 的高端内存。当内核需要访问高端内存时就临时在这个区域进行地址映射，使用完毕之后再用来进行其他高端内存的映射。</p> \n <p>由于要进行高端内存的内核映射，因此直接能够映射的物理内存大小只有 896MB，该值保存在 high_memory 中。内核地址空间的线性地址区间如下图所示</p> \n <h4><a id=\"_2594\"></a>物理内存管理机制</h4> \n <p>基于物理内存在内核空间中的映射原理，物理内存的管理方式也有所不同。内核中物理内存的管理机制主要有伙伴算法，slab 高速缓存和 vmalloc 机制。其中伙伴算法和slab高速缓存都在物理内存映射区分配物理内存，而 vmalloc 机制则在高端内存映射区分配物理内存。</p> \n <h4><a id=\"_2598\"></a>非连续内存区内存的分配</h4> \n <p>内核通过 vmalloc() 来申请非连续的物理内存，若申请成功，该函数返回连续内存区的起始地址，否则，返回NULL。</p> \n <p>vmalloc() 和 kmalloc() 申请的内存有所不同，kmalloc() 所申请内存的线性地址与物理地址都是连续的，而 vmalloc() 所申请的内存线性地址连续而物理地址则是离散的，两个地址之间通过内核页表进行映射。</p> \n <p>vmalloc() 的内存分配原理与用户态的内存分配相似，都是通过连续的虚拟内存来访问离散的物理内存，并且虚拟地址和物理地址之间是通过页表进行连接的，通过这种方式可以有效的使用物理内存。</p> \n <p>但是应该注意的是，vmalloc() 申请物理内存时是立即分配的，因为内核认为这种内存分配请求是正当而且紧急的；</p> \n <p>相反，用户态有内存请求时，内核总是尽可能的延后，毕竟用户态跟内核态不在一个特权级。</p> \n <h2><a id=\"_2610\"></a>页面置换算法</h2> \n <p>操作系统中的页面置换算法主要包括最佳置换算法（OPT，Optimal）、先进先出置换算法（FIFO）、最近最久未使用置换算法（LRU，Least Recently Used）、时钟置换算法和改进型的时钟置换算法。</p> \n <h3><a id=\"OPTOptimal_2614\"></a>最佳置换算法（OPT，Optimal）</h3> \n <h4><a id=\"_2616\"></a>算法思想</h4> \n <p>每次选择淘汰的页面将是以后永不使用，或者在最长时间内不再被访问的页面，这样可以保证最低的缺页率。</p> \n <h4><a id=\"_2620\"></a>举例说明</h4> \n <p>假设系统为进程分配了三个内存块，并考虑到有以下页面号引用串（会依次访问这些页面）：7,0,1,2,0,3,0,4,2,3,0,3,2,1,2,0,1,7,0,1。</p> \n <ol>\n  <li>第一个访问的是 7 号页，内存中没有此页，由缺页中断机构将 7 号页调入内存。此时有三个可用的内存块，不需要置换。即第一次(7) ：7</li>\n  <li>同理，第二个访问的是 0 号页，和第一次一样，第三次访问的是 1 号页，同样 1 号页也会被调入内存，1 号内被调入内存后，此时分配给该进程内存空间已占满。 \n   <ul>\n    <li>第二次(0)：7 0</li>\n    <li>第三次(1)：7 0 1</li>\n   </ul> </li>\n  <li>第四个访问的页是 2 号页，此时内存已经用完，需要将一个页调出内存，根据最佳置换算法，淘汰一个以后永不使用或最长时间不使用的，此时内存中的页有 7、0、1，查看待访问页号序列中这三个页号的先后位置，下图可以看到，0 号页和 1 号页在不久又会被访问到，而 7 号页需要被访问的时间最久。所以该算法会淘汰 7 号页。</li>\n </ol> \n <p><img src=\"https://img-blog.csdnimg.cn/4d32572726b945028f076c031e1d3c8a.png\" alt=\"\"></p> \n <pre><code>第一次(7) ：7\n第二次(0)：7 0\n第三次(1)：7 0 1\n第四次(2)：0 1 2\n</code></pre> \n <p>按照此算法依次执行，最后的结果如下：</p> \n <pre><code>第一次(7) ：7\n第二次(0)：7 0\n第三次(1)：7 0 1\n第四次(2)：0 1 2\n第五次(0)：0 1 2（命中）\n第六次(3) ：0 3 1\n第七次(0) ：0 3 1（命中）\n第八次(4) ：3 2 4\n第九次(2) ：3 2 4（命中）\n第十次(3) ：3 2 4（命中）\n第十一次(0) ：3 2 0\n第十二次(3) ：3 2 0（命中）\n.....\n</code></pre> \n <p>结果图：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/62db54214f7241429f7ef6211839c18c.png\" alt=\"\"></p> \n <p>整个过程缺页中断发生了 9 次，页面置换发生了 6 次。缺页率 = 9 / 20 = 45%。</p> \n <p>注：缺页时未必发生页面置换，若还有可用的空闲内存空间就不用进行页面置换。</p> \n <p>最佳置换算法可以保证最低的缺页率，但是实际上，只有进程执行的过程中才能知道接下来会访问到的是哪个页面。操作系统无法提前预判页面的访问序列。因此，最佳置换算法是无法实现的。</p> \n <h3><a id=\"FIFO_2667\"></a>先进先出置换算法（FIFO）</h3> \n <h4><a id=\"_2669\"></a>算法思想</h4> \n <p>每次选择淘汰的页面是最早进入内存的页面。</p> \n <h4><a id=\"_2673\"></a>举例说明</h4> \n <p>该算法很简单，每次淘汰最在内存中待时间最久的各个，下面分别给出系统为进程分为配三个内存块和四个内存块的执行情况图。访问序列为 3,2,1,0,3,2,4,3,2,1,0,4。</p> \n <p>分配三个内存块的情况：</p> \n <pre><code>第一次(3) ：3\n第二次(2) ：3 2\n第三次(1) ：3 2 1\n第四次(0) ：2 1 0\n第五次(3) ：1 0 3\n第六次(2) ：0 3 2\n第七次(4) ：3 2 4\n第八次(3) ：3 2 4（命中）\n第九次(2) ：3 2 4（命中）\n第十次(1) ：2 4 1\n第十一次(0) ：4 1 0\n第十二次(4) ：4 1 0（命中）\n</code></pre> \n <p>分配三个内存块时，缺页次数：9 次。</p> \n <p>分配四个内存块的情况：</p> \n <pre><code>第一次(3) ：3\n第二次(2) ：3 2\n第三次(1) ：3 2 1\n第四次(0) ：3 2 1 0\n第五次(3) ：3 2 1 0（命中）\n第六次(2) ：3 2 1 0 （命中）\n第七次(4) ：2 1 0 4\n第八次(3) ：1 0 4 3\n第九次(2) ：0 4 3 2\n第十次(1) ：4 3 2 1\n第十一次(0) ：3 2 1 0\n第十二次(4) ：2 1 0 4\n</code></pre> \n <p>分配四个内存块时，缺页次数：10 次。当为进程分配的物理块数增大时，缺页次数不减反增的异常现象称为贝莱迪（Belay）异常。</p> \n <p>只有 FIFO 算法会产生 Belay 异常。另外，FIFO 算法虽然实现简单，但是该算法与进程实际运行时的规律不适应。因为先进入的页面也有可能最经常被访问。因此，算法性能差。</p> \n <h3><a id=\"LRU_2717\"></a>最近最久未使用置换算法（LRU）</h3> \n <h4><a id=\"_2719\"></a>算法思想</h4> \n <p>每次淘汰的页面是最近最久未使用的页面。</p> \n <h4><a id=\"_2723\"></a>实现方法</h4> \n <p>赋予每个页面对应的页表项中，用访问字段记录该页面自上次被访问以来所经历的时间 t。当需要淘汰一个页面时，选择现有页面中 t 最大的页面，即最近最久未使用。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/c0ef03673e5f4586a7894e226f263cab.png\" alt=\"\"></p> \n <h4><a id=\"_2729\"></a>举例说明</h4> \n <p>加入某系统为某进程分配了四个内存块，并考虑到有以下页面号引用串：1,8,1,7,8,2,7,2,1,8,3,8,2,1,3,1,7,1,3,7</p> \n <p>这里先直接给出答案：</p> \n <pre><code>第一次(1) ：1\n第二次(8) ：1 8\n第三次(1) ：8 1 （命中）（由于1号页又被访问过了，所以放到最后）\n第四次(7) ：8 1 7\n第五次(8) ：1 7 8（命中）\n第六次(2) ：1 7 8 2\n第七次(7) ：1 8 2 7（命中）\n第八次(2) ：1 8 7 2（命中）\n第九次(1) ：8 7 2 1（命中）\n第十次(8) ：7 2 1 8（命中）\n第十一次(3) ：2 1 8 3\n第十二次(8) ：2 1 3 8（命中）\n第十三次(2) ：1 3 8 2（命中）\n第十四次(1) ：3 8 2 1（命中）\n第十五次(3) ：8 2 1 3（命中）\n第十六次(1) ：8 2 3 1（命中）\n第十七次(7) ：2 3 1 7\n....\n</code></pre> \n <p>这里前 10 次都 1、8、7、2 这四个页，四个内存块号正好可以满足，当第 11 次要访问的 3 号页进入内存时，需要从 1、8、7、2 这四个页淘汰一个页，按照该算法，从页号为3的开始，从右往左一次找到这 4 个页第一次出现的地方，在最左边的就是最近最少使用的页。</p> \n <p>如下图所示，所以该算法最终淘汰的是 7 号页。同时直接从第十次的访问结果 7 2 1 8 也可以直接看出，7 号页在最前面，是最久没有被访问过的，所以淘汰应该是 7 号页。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/1940c557c19949b5985f64ab5d43fb0b.png\" alt=\"\"></p> \n <p>结果图</p> \n <p><img src=\"https://img-blog.csdnimg.cn/e614080bdaf240b59fe6ecddd7c42a1e.png\" alt=\"\"></p> \n <h3><a id=\"_2766\"></a>时钟置换算法</h3> \n <h4><a id=\"_2768\"></a>算法思想</h4> \n <p>最佳置换算法性能最好，但无法实现。先进先出置换算法实现简单，但是算法性能差。最近最久未使用置换算法性能好，是最接近 OPT 算法性能的，但是实现起来需要专门的硬件支持，算法开销大。时钟置换算法是一种性能和开销均平衡的算法。又称 CLOCK 算法，或最近未用算法（NRU，Not Recently Used）。</p> \n <p>简单 CLOCK 算法算法思想：为每个页面设置一个访问位，再将内存中的页面都通过链接指针链接成一个循环队列。当某个页被访问时，其访问位置 1。当需要淘汰一个页面时，只需检查页的访问位。如果是 0，就选择该页换出；如果是 1，暂不换出，将访问位改为 0，继续检查下一个页面，若第一轮扫描中所有的页面都是 1，则将这些页面的访问位一次置为 0 后，再进行第二轮扫描（第二轮扫描中一定会有访问位为 0 的页面，因此简单的 CLOCK 算法选择一个淘汰页面最多会经过两轮扫描）。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/42da87fdab6447ab809b98a8ed1a46a9.png\" alt=\"\"></p> \n <p>例如，假设某系统为某进程分配了五个内存块，并考虑有以下页面号引用串：1,3,4,2,5,6,3,4,7。刚开始访问前 5 个页面，由于都是刚刚被访问所以它们的访问位都是 1，在内存的页面如下图所示：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/0509f907cbd445fbbb48dbe6727979ed.png\" alt=\"\"></p> \n <p>此时页面 6 需要进入内存，那么需要从中淘汰一个页面，于是从循环队列的队首（1 号页）开始扫描，尝试找到访问位为 0 的页面。经过一轮扫描发现所有的访问位都是 1，经过一轮扫描后，需要将所有的页面标志位设置为 0，如下图：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/4e69b046e29d4a34a4a55425943e5211.png\" alt=\"\"></p> \n <p>之后进行第二轮扫描，发现 1 号页的访问位为 0，所以换出 1 号页，同时指针指向下一页，如下图：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/884d09956d894672982b0bff34db9d81.png\" alt=\"\"></p> \n <p>接下来是访问 3 号页和 4 号页，这两个页都在内存中，直接访问，并将访问位改为 1。在访问 3 号页和 4 号页时指针不需要动，指针只有在缺页置换时才移动下一页。如下图：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/f1cf40fc00ca48c99127ab8c9814fbc3.png\" alt=\"\"></p> \n <p>最后，访问 7 号页，此时从 3 号页开始扫描循环队列，扫描过程中将访问位为 1 的页的访问位改为 0，并找到第一个访问位为 0 的页，即 2 号页，将 2 号页置换为 7 号页，最后将指针指向 7 号页的下一页，即 5 号页。如下图：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/58ef7166d00a461aa6f657be6d25ce94.png\" alt=\"\"></p> \n <p>这个算法指针在扫描的过程就像时钟一样转圈，才被称为时钟置换算法。</p> \n <h3><a id=\"_2798\"></a>改进型的时钟置换算法</h3> \n <h4><a id=\"_2800\"></a>算法思想</h4> \n <p>简单的时钟置换算法仅考虑到了一个页面最近是否被访问过。事实上，如果淘汰的页面没有被修改过，就不需要执行 I/O 操作写回外存。只有淘汰的页面被修改过时，才需要写回外存。因此，除了考虑一个页面最近有没有被访问过之外，操作系统还需要考虑页面有没有被修改过。</p> \n <p>改进型时钟置换算法的算法思想：在其他在条件相同时，应该优先淘汰没有被修改过的页面，从而来避免 I/O 操作。为了方便讨论，用（访问位，修改位）的形式表示各页面的状态。如（1,1）表示一个页面近期被访问过，且被修改过。</p> \n <h4><a id=\"_2806\"></a>算法规则</h4> \n <p>将所有可能被置换的页面排成一个循环队列：</p> \n <ol>\n  <li>第一轮：从当前位置开始扫描第一个（0,0）的页用于替换，本轮扫描不修改任何标志位。</li>\n  <li>第二轮：若第一轮扫描失败，则重新扫描，查找第一个（0,1）的页用于替换。本轮将所有扫描的过的页访问位设为 0。</li>\n  <li>第三轮：若第二轮扫描失败，则重新扫描，查找第一个（0,0）的页用于替换。本轮扫描不修改任何标志位。</li>\n  <li>第四轮：若第三轮扫描失败，则重新扫描，查找第一个（0,1）的页用于替换。</li>\n </ol> \n <p>由于第二轮已将所有的页的访问位都设为 0，因此第三轮、第四轮扫描一定会选中一个页，因此改进型 CLOCK 置换算法最多会进行四轮扫描。</p> \n <p><strong>第一轮就找到替换的页的情况</strong></p> \n <p>假设系统为进程分配了 5 个内存块，某时刻，各个页的状态如下图：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/7807375043df4c1d9387e836b9fc91fc.png\" alt=\"\"></p> \n <p>如果此时有新的页要进入内存，开始第一轮扫描就找到了要替换的页，即最下面的状态为（0,0）的页。</p> \n <p><strong>第二轮就找到替换的页的情况</strong></p> \n <p>某一时刻页面状态如下:</p> \n <p><img src=\"https://img-blog.csdnimg.cn/dba02ef3430e4750ba8c3649c095f279.png\" alt=\"\"></p> \n <p>如果此时有新的页要进入内存，开始第一轮扫描就发现没有状态为（0，0）的页，第一轮扫描后不修改任何标志位。所以各个页状态和上图一样。</p> \n <p>然后开始第二轮扫描，尝试找到状态为（0,1）的页，并将扫描过后的页的访问位设为 0，第二轮扫描找到了要替换的页。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/590008e113634684a7c9da8e8c00a3db.png\" alt=\"\"></p> \n <p><strong>第三轮就找到替换的页的情况</strong></p> \n <p>某一时刻页面状态如下:</p> \n <p><img src=\"https://img-blog.csdnimg.cn/5ab265676ca74dccb154464184bdacfe.png\" alt=\"\"></p> \n <p>第一轮扫描没有找到状态为（0,0）的页，且第一轮扫描不修改任何标志位，所以第一轮扫描后状态和上图一致。</p> \n <p>然后开始第二轮扫描，尝试找状态为（0,1）的页，也没有找到，第二轮扫描需要将访问位设为 1，第二轮扫描后，状态为下图：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/a8d4293bdace49e5b4467834bee36194.png\" alt=\"\"></p> \n <p>接着开始第三轮扫描，尝试找状态为（0，0）的页，此轮扫描不修改标志位，第三轮扫描就找到了要替换的页。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/dcc44173859b4d9ba3f7b462affdf55a.png\" alt=\"\"></p> \n <p><strong>第四轮就找到替换的页的情况</strong></p> \n <p>某一时刻页面状态如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/debe555c961e4b949ee57b4bcdca292a.png\" alt=\"\"></p> \n <p>具体的扫描过程和上面相同，这里只给出最后的结果，如下图：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/175fa7fc37674118990228966568c123.png\" alt=\"\"></p> \n <p>所以，改进型的 CLOCK 置换算法最多需要四轮扫描确定要置换的页。从上面的分析可以看出，改进型的 CLOCK 置换算法：</p> \n <ol>\n  <li>第一优先级淘汰的是最近没有访问且没有修改的页面。</li>\n  <li>第二优先级淘汰的是最近没有访问但修改的页面。</li>\n  <li>第三优先级淘汰的是最近访问但没有修改的页面。</li>\n  <li>第四优先级淘汰的是最近访问且修改的页面。</li>\n </ol> \n <p>第三、四优先级为什么是访问过的？因为如果到了第三轮扫描，所有页的访问位都在第二轮扫描被设置为了 0，如果访问位不是0的话，也达到不了第三轮扫描，前两轮就会被淘汰。</p> \n <p>所以到了第三轮，第四轮淘汰的页都是最近被访问过的。</p> \n <h3><a id=\"_2874\"></a>总结</h3> \n <p><img src=\"https://img-blog.csdnimg.cn/e02ba802d1da4f36a44f079517a1e941.png\" alt=\"\"></p> \n <h2><a id=\"_2880\"></a>软中断与硬中断</h2> \n <h3><a id=\"_2884\"></a>中断的基本概念</h3> \n <p>中断是指计算机在执行期间，系统内发生任何非寻常的或非预期的急需处理事件，使得 CPU 暂时中断当前正在执行的程序而转去执行相应的事件处理程序，待处理完毕后又返回原来被中断处继续执行或调度新的进程执行的过程。引起中断发生的事件被称为中断源。中断源向 CPU 发出的请求中断处理信号称为中断请求，而 CPU 收到中断请求后转到相应的事件处理程序称为中断响应。</p> \n <p>在有些情况下，尽管产生了中断源和发出了中断请求，但 CPU 内部的处理器状态字 PSW 的中断允许位已被清除，从而不允许 CPU 响应中断。这种情况称为禁止中断。CPU 禁止中断后只有等到 PSW 的中断允许位被重新设置后才能接收中断。禁止中断也称为关中断，PSW 的中断允许位的设置也被称为开中断。开中断和关中断是为了保证某段程序执行的原子性。</p> \n <p>还有一个比较常用的概念是中断屏蔽。中断屏蔽是指在中断请求产生之后，系统有选择地封锁一部分中断而允许另一部分中断仍能得到响应。不过，有些中断请求是不能屏蔽甚至不能禁止的，也就是说，这些中断具有最高优先级，只要这些中断请求一旦提出，CPU 必须立即响应。例如，电源掉电事件所引起的中断就是不可禁止和不可屏蔽的。</p> \n <h3><a id=\"_2892\"></a>中断的分类与优先级</h3> \n <p>根据系统对中断处理的需要，操作系统一般对中断进行分类并对不同的中断赋予不同的处理优先级，以便在不同的中断同时发生时，按轻重缓急进行处理。</p> \n <p>根据中断源产生的条件，可把中断分为外中断和内中断。外中断是指来自处理器和内存外部的中断，包括 IO 设备发出的 IO 中断、外部信号中断(例如用户键人 ESC 键)。各种定时器引起的时钟中断以及调试程序中设置的断点等引起的调试中断等。外中断在狭义上一般被称为中断。</p> \n <p>内中断主要指在处理器和内存内部产生的中断。内中断一般称为陷阱(trap)或异常。它包括程序运算引起的各种错误，如地址非法、校验错、页面失效、存取访问控制错、算术操作溢出、数据格式非法、除数为零、非法指令、用户程序执行特权指令、分时系统中的时间片中断以及从用户态到核心态的切换等都是陷阱的例子。</p> \n <p>为了按中断源的轻重缓急处理响应中断，操作系统为不同的中断赋予不同的优先级。例如在 UNIX 系统中，外中断和陷阱的优先级共分为 8 级。为了禁止中断或屏蔽中断，CPU 的处理器状态字 PSW 中也设有相应的优先级。如果中断源的优先级高于 PSW 的优先级，则 CPU 响应该中断源的请求；反之，CPU 屏蔽该中断源的中断请求。</p> \n <p>各中断源的优先级在系统设计时给定，在系统运行时是固定的。而处理器的优先级则根据执行情况由系统程序动态设定。</p> \n <p>除了在优先级的设置方面有区别之外，中断和陷阱还有如下主要区别：</p> \n <ul>\n  <li>陷阱通常由处理器正在执行的现行指令引起，而中断则是由与现行指令无关的中断源引起的。陷阱处理程序提供的服务为当前进程所用，而中断处理程序提供的服务则不是为了当前进程的。</li>\n  <li>CPU 执行完一条指令之后，下一条指令开始之前响应中断，而在一条指令执行中也可以响应陷阱。例如执行指令非法时，尽管被执行的非法指令不能执行结束，但 CPU 仍可对其进行处理。</li>\n </ul> \n <h3><a id=\"_2909\"></a>硬中断</h3> \n <ol>\n  <li>硬中断是由硬件产生的，比如，像磁盘，网卡，键盘，时钟等。每个设备或设备集都有它自己的 IRQ（中断请求）。基于 IRQ，CPU 可以将相应的请求分发到对应的硬件驱动上（注：硬件驱动通常是内核中的一个子程序，而不是一个独立的进程）。</li>\n  <li>处理中断的驱动是需要运行在 CPU 上的，因此，当中断产生的时候，CPU 会中断当前正在运行的任务，来处理中断。在有多核心的系统上，一个中断通常只能中断一颗 CPU（也有一种特殊的情况，就是在大型主机上是有硬件通道的，它可以在没有主 CPU 的支持下，可以同时处理多个中断。）。</li>\n  <li>硬中断可以直接中断 CPU。它会引起内核中相关的代码被触发。对于那些需要花费一些时间去处理的进程，中断代码本身也可以被其他的硬中断中断。</li>\n  <li>对于时钟中断，内核调度代码会将当前正在运行的进程挂起，从而让其他的进程来运行。它的存在是为了让调度代码（或称为调度器）可以调度多任务。</li>\n </ol> \n <h3><a id=\"_2916\"></a>软中断</h3> \n <ol>\n  <li>软中断的处理非常像硬中断。然而，它们仅仅是由当前正在运行的进程所产生的。</li>\n  <li>通常，软中断是一些对 I/O 的请求。这些请求会调用内核中可以调度 I/O 发生的程序。对于某些设备，I/O 请求需要被立即处理，而磁盘 I/O 请求通常可以排队并且可以稍后处理。根据 I/O 模型的不同，进程或许会被挂起直到 I/O 完成，此时内核调度器就会选择另一个进程去运行。I/O 可以在进程之间产生并且调度过程通常和磁盘 I/O 的方式是相同。</li>\n  <li>软中断仅与内核相联系。而内核主要负责对需要运行的任何其他的进程进行调度。一些内核允许设备驱动的一些部分存在于用户空间，并且当需要的时候内核也会调度这个进程去运行。</li>\n  <li>软中断并不会直接中断 CPU。也只有当前正在运行的代码（或进程）才会产生软中断。这种中断是一种需要内核为正在运行的进程去做一些事情（通常为 I/O）的请求。有一个特殊的软中断是 Yield 调用，它的作用是请求内核调度器去查看是否有一些其他的进程可以运行。</li>\n </ol> \n <h3><a id=\"_2923\"></a>硬中断与软中断之区别与联系</h3> \n <ol>\n  <li>硬中断是有外设硬件发出的，需要有中断控制器之参与。其过程是外设侦测到变化，告知中断控制器，中断控制器通过 CPU 或内存的中断脚通知 CPU，然后硬件进行程序计数器及堆栈寄存器之现场保存工作（引发上下文切换），并根据中断向量调用硬中断处理程序进行中断处理。</li>\n  <li>软中断则通常是由硬中断处理程序或者进程调度程序等软件程序发出的中断信号，无需中断控制器之参与，直接以一个 CPU 指令之形式指示 CPU 进行程序计数器及堆栈寄存器之现场保存工作(亦会引发上下文切换)，并调用相应的软中断处理程序进行中断处理(即我们通常所言之系统调用)。</li>\n  <li>硬中断直接以硬件的方式引发，处理速度快。软中断以软件指令之方式适合于对响应速度要求不是特别严格的场景。</li>\n  <li>硬中断通过设置 CPU 的屏蔽位可进行屏蔽，软中断则由于是指令之方式给出，不能屏蔽。</li>\n  <li>硬中断发生后，通常会在硬中断处理程序中调用一个软中断来进行后续工作的处理。</li>\n  <li>硬中断和软中断均会引起上下文切换(进程/线程之切换)，进程切换的过程是差不多的。</li>\n </ol> \n <h3><a id=\"_2932\"></a>中断处理过程</h3> \n <p>一旦 CPU 响应中断，转人中断处理程序，系统就开始进行中断处理。下面对中断处理过程进行详细说明：</p> \n <ol>\n  <li>CPU 检查响应中断的条件是否满足。CPU 响应中断的条件是：有来自于中断源的中断请求、CPU 允许中断。如果中断响应条件不满足，则中断处理无法进行。</li>\n  <li>如果 CPU 响应中断，则 CPU 关中断，使其进入不可再次响应中断的状态。</li>\n  <li>保存被中断进程现场。为了在中断处理结束后能使进程正确地返回到中断点，系统必须保存当前处理器状态字 PSW 和程序计数器 PC 等的值。这些值一般保存在特定堆栈或硬件寄存器中。</li>\n  <li>分析中断原因，调用中断处理子程序。在多个中断请求同时发生时，处理优先级最高的中断源发出的中断请求。在系统中，为了处理上的方便，通常都是针对不同的中断源编制有不同的中断处理子程序(陷阱处理子程序)。这些子程序的人口地址(或陷阱指令的人口地址)存放在内存的特定单元中。</li>\n </ol> \n <p>再者，不同的中断源也对应着不同的处理器状态字 PSW。这些不同的 PSW 被放在相应的内存单元中，与中断处理子程序人口地址一起构成中断向量。显然，根据中断或陷阱的种类，系统可由中断向量表迅速地找到该中断响应的优先级、中断处理子程序(或陷阱指令)的入口地址和对应的 PSW。</p> \n <ol>\n  <li>执行中断处理子程序。对陷阱来说，在有些系统中则是通过陷阱指令向当前执行进程发出软中断信号后调用对应的处理子程序执行。</li>\n  <li>退出中断，恢复被中断进程的现场或调度新进程占据处理器。</li>\n  <li>开中断，CPU 继续执行。</li>\n </ol> \n <h2><a id=\"_2947\"></a>中断与异常</h2> \n <p>在操作系统中引入核心态和用户态这两种工作状态后，就需要考虑这两种状态之间如何切换。操作系统内核工作在核心态，而用户程序工作在用户态。但系统不允许用户程序实现核心态的功能，而它们又必须使用这些功能。因此，需要在核心态建立一些 “门”，实现从用户态进入核心态。</p> \n <p>在实际操作系统中，CPU 运行上层程序时唯一能进入这些 “门” 的途径就是通过中断或异常。当中断或异常发生时，运行用户态的 CPU 会立即进入核心态，这是通过硬件实现的（例如，用一个特殊寄存器的一位来表示 CPU 所处的工作状态，0 表示核心态，1 表示用户态。若要进入核心态，只需将该位置 0 即可)。中断是操作系统中非常重要的一个概念，对一个运行在计算机上的实用操作系统而言，缺少了中断机制，将是不可想象的。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/94547d01a193487385dd1eb6d8608c5e.png\" alt=\"\"></p> \n <h3><a id=\"_2955\"></a>中断</h3> \n <p>中断(Interruption)，也称外中断，指来自 CPU 执行指令以外的事件的发生，如设备发出的 I/O 结束中断，表示设备输入/输出处理已经完成，希望处理机能够向设备发下一个输入 / 输出请求，同时让完成输入/输出后的程序继续运行。时钟中断，表示一个固定的时间片已到，让处理机处理计时、启动定时运行的任务等。这一类中断通常是与当前程序运行无关的事件，即它们与当前处理机运行的程序无关。</p> \n <h3><a id=\"_2959\"></a>异常</h3> \n <p>异常(Exception)，也称内中断、例外或陷入(Trap)，指源自 CPU 执行指令内部的事件，如程序的非法操作码、 地址越界、算术溢出、虚存系统的缺页以及专门的陷入指令等引起的事件。对异常的处理一般要依赖于当前程序的运行现场，而且异常不能被屏蔽，一旦出现应立即处理。关于内中断和外中断的联系与区别如下图所示：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/287bfea75cf3497cb48fc1e8dd8ef81b.png\" alt=\"\"></p> \n <h2><a id=\"_2967\"></a>中断面试题</h2> \n <h3><a id=\"_2969\"></a>聊聊：外中断和异常的区别</h3> \n <ul>\n  <li>外中断是指由CPU 执行指令以外的事件引起，如 I/O 完成中断（设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求）、时钟中断、控制台中断等</li>\n  <li>异常时由CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等</li>\n </ul> \n <p>相同点：<br> 最后都是由CPU发送给内核，由内核去处理，处理程序的流程设计上是相似的</p> \n <p>不同点：</p> \n <ol>\n  <li>产生源不相同，异常是由CPU产生的，而中断是由硬件设备产生的</li>\n  <li>内核需要根据是异常还是中断调用不同的处理程序</li>\n  <li>中断不是时钟同步的，这意味着中断可能随时到来；异常由于是CPU产生的，所以它是时钟同步的</li>\n  <li>当处理中断时，处于中断上下文中；处理异常时，处于进程上下文中</li>\n </ol> \n <h3><a id=\"_2986\"></a>内存的管理策略</h3> \n <p>当允许进程动态增长时，操作系统必须对内存进行更有效的管理，</p> \n <p>操作系统使用如下两种方法之一来得知内存的使用情况，分别为</p> \n <ul>\n  <li>1)位图(bitmap)</li>\n  <li>2)链表</li>\n </ul> \n <p>使用位图，将内存划为多个大小相等的块，比如一个32K的内存1K一块可以划为32块，则需要32位（4字节）来表示其使用情况，使用位图将已经使用的块标为1，位使用的标为0.而使用链表，则将内存按使用或未使用分为多个段进行链接，这个概念如图4所示。</p> \n <p>使用位图表示内存简单明了，但一个问题是当分配内存时必须在内存中搜索大量的连续0的空间，这是十分消耗资源的操作。</p> \n <p>相比之下，使用链表进行此操作将会更胜一筹。还有一些操作系统会使用双向链表，因为当进程销毁时，邻接的往往是空内存或是另外的进程。使用双向链表使得链表之间的融合变得更加容易。</p> \n <p>还有，当利用链表管理内存的情况下，创建进程时分配什么样的空闲空间也是个问题。</p> \n <p>通常情况下有如下几种算法来对进程创建时的空间进行分配。</p> \n <pre><code> 临近适应算法(Next fit)—从当前位置开始，搜索第一个能满足进程要求的内存空间\n 最佳适应算法(Best fit)—搜索整个链表，找到能满足进程要求最小内存的内存空间\n 最大适应算法(Wrost fit)—找到当前内存中最大的空闲空间\n 首次适应算法(First fit) —从链表的第一个开始，找到第一个能满足进程要求的内存空间\n</code></pre> \n <h3><a id=\"_3014\"></a>聊聊：中断的处理过程?</h3> \n <ol>\n  <li>保护现场：将当前执行程序的相关数据保存在寄存器中，然后入栈。</li>\n  <li>开中断：以便执行中断时能响应较高级别的中断请求。</li>\n  <li>中断处理</li>\n  <li>关中断：保证恢复现场时不被新中断打扰</li>\n  <li>恢复现场：从堆栈中按序取出程序数据，恢复中断前的执行状态。</li>\n </ol> \n <h3><a id=\"_3022\"></a>聊聊：中断和轮询有什么区别？</h3> \n <ul>\n  <li> <p>轮询：CPU对<strong>特定设备</strong>轮流询问。中断：通过<strong>特定事件</strong>提醒CPU。</p> </li>\n  <li> <p>轮询：效率低等待时间长，CPU利用率不高。中断：容易遗漏问题，CPU利用率不高。</p> </li>\n </ul> \n <h2><a id=\"Virtual_Memory_3030\"></a>虚拟内存(Virtual Memory)</h2> \n <p>虚拟内存是现代操作系统普遍使用的一种技术。</p> \n <p>很多情况下，现有内存无法满足仅仅一个大进程的内存要求(比如很多游戏，都是10G+的级别)。</p> \n <p>在早期的操作系统曾使用覆盖(overlays)来解决这个问题，将一个程序分为多个块，基本思想是先将块0加入内存，块0执行完后，将块1加入内存。</p> \n <p>依次往复，这个解决方案最大的问题是需要程序员去程序进行分块，这是一个费时费力让人痛苦不堪的过程。</p> \n <p>后来这个解决方案的修正版就是虚拟内存。</p> \n <p>虚拟内存的基本思想是，每个进程有用独立的逻辑地址空间，内存被分为大小相等的多个块,称为页(Page).</p> \n <p>每个页都是一段连续的地址。对于进程来看,逻辑上貌似有很多内存空间，其中一部分对应物理内存上的一块(称为页框，通常页和页框大小相等)，还有一些没加载在内存中的对应在硬盘上。</p> \n <p>而虚拟内存和物理内存的匹配是通过页表实现，页表存在MMU中，页表中每个项通常为32位，既4byte,除了存储虚拟地址和页框地址之外，还会存储一些标志位，比如是否缺页，是否修改过，写保护等。</p> \n <p>可以把MMU想象成一个接收虚拟地址项返回物理地址的方法。</p> \n <p>因为页表中每个条目是4字节，现在的32位操作系统虚拟地址空间会是2的32次方，即使每页分为4K，也需要2的20次方*4字节=4M的空间，为每个进程建立一个4M的页表并不明智。</p> \n <p>因此在页表的概念上进行推广，产生二级页表,二级页表每个对应4M的虚拟地址，而一级页表去索引这些二级页表，因此32位的系统需要1024个二级页表，虽然页表条目没有减少，但内存中可以仅仅存放需要使用的二级页表和一级页表，大大减少了内存的使用。</p> \n <h2><a id=\"_3056\"></a>操作系统快表</h2> \n <h3><a id=\"_3058\"></a>什么是快表</h3> \n <p>快表（TLB - translation lookaside buffer），直译为旁路快表缓冲，也可以理解为页表缓冲，地址变换高速缓存。</p> \n <p>由于页表存放在主存中，因此程序每次访存至少需要两次：一次访存获取物理地址，第二次访存才获得数据。提高访存性能的关键在于依靠页表的访问局部性。当一个转换的虚拟页号被使用时，它可能在不久的将来再次被使用到。</p> \n <p>TLB 是一种高速缓存，内存管理硬件使用它来改善虚拟地址到物理地址的转换速度。当前所有的个人桌面，笔记本和服务器处理器都使用 TLB 来进行虚拟地址到物理地址的映射。使用 TLB 内核可以快速的找到虚拟地址指向物理地址，而不需要请求 RAM 内存获取虚拟地址到物理地址的映射关系。这与 data cache 和 instruction caches 有很大的相似之处。</p> \n <h3><a id=\"TLB_3066\"></a>快表（TLB）原理</h3> \n <p>当 cpu 要访问一个虚拟地址/线性地址时，CPU 会首先根据虚拟地址的高 20 位（20 是 x86 特定的，不同架构有不同的值）在 TLB 中查找。如果是表中没有相应的表项，称为 TLB miss，需要通过访问慢速 RAM 中的页表计算出相应的物理地址。同时，物理地址被存放在一个 TLB 表项中，以后对同一线性地址的访问，直接从 TLB 表项中获取物理地址即可，称为 TLB hit。</p> \n <p>想像一下 x86_32 架构下没有 TLB 的存在时的情况，对线性地址的访问，首先从 PGD 中获取 PTE（第一次内存访问），在 PTE 中获取页框地址（第二次内存访问），最后访问物理地址，总共需要 3 次 RAM 的访问。如果有 TLB 存在，并且 TLB hit，那么只需要一次 RAM 访问即可。</p> \n <h3><a id=\"TLB_3072\"></a>TLB表项</h3> \n <p>TLB 内部存放的基本单位是页表条目，对应着 RAM 中存放的页表条目。页表条目的大小固定不变的，所以 TLB 容量越大，所能存放的页表条目越多，TLB hit 的几率也越大。但是 TLB 容量毕竟是有限的，因此 RAM 页表和 TLB 页表条目无法做到一一对应。因此 CPU 收到一个线性地址，那么必须快速做两个判断：</p> \n <ol>\n  <li>所需的也表示否已经缓存在 TLB 内部（TLB miss 或者 TLB hit）</li>\n  <li>所需的页表在 TLB 的哪个条目内</li>\n </ol> \n <p>为了尽量减少 CPU 做出这些判断所需的时间，那么就必须在 TLB 页表条目和内存页表条目之间的对应方式做足功夫。</p> \n <h4><a id=\"__full_associative_3081\"></a>全相连 - full associative</h4> \n <p>在这种组织方式下，TLB cache 中的表项和线性地址之间没有任何关系，也就是说，一个 TLB 表项可以和任意线性地址的页表项关联。这种关联方式使得 TLB 表项空间的利用率最大。但是延迟也可能相当的大，因为每次 CPU 请求，TLB 硬件都把线性地址和 TLB 的表项逐一比较，直到 TLB hit 或者所有 TLB 表项比较完成。特别是随着 CPU 缓存越来越大，需要比较大量的 TLB 表项，所以这种组织方式只适合小容量 TLB。</p> \n <h4><a id=\"_3085\"></a>直接匹配</h4> \n <p>每一个线性地址块都可通过模运算对应到唯一的 TLB 表项，这样只需进行一次比较，降低了 TLB 内比较的延迟。但是这个方式产生冲突的几率非常高，导致 TLB miss 的发生，降低了命中率。</p> \n <p>比如，我们假定 TLB cache 共包含 16 个表项，CPU 顺序访问以下线性地址块：1, 17 , 1, 33。当 CPU 访问地址块 1 时，1 mod 16 = 1，TLB 查看它的第一个页表项是否包含指定的线性地址块 1，包含则命中，否则从 RAM 装入；然后 CPU 方位地址块 17，17 mod 16 = 1，TLB 发现它的第一个页表项对应的不是线性地址块 17，TLB miss 发生，TLB 访问 RAM 把地址块 17 的页表项装入 TLB；CPU 接下来访问地址块 1，此时又发生了 miss，TLB 只好访问 RAM 重新装入地址块 1 对应的页表项。因此在某些特定访问模式下，直接匹配的性能差到了极点。</p> \n <h4><a id=\"__setassociative_3091\"></a>组相连 - set-associative</h4> \n <p>为了解决全相连内部比较效率低和直接匹配的冲突，引入了组相连。这种方式把所有的 TLB 表项分成多个组，每个线性地址块对应的不再是一个 TLB 表项，而是一个 TLB 表项组。CPU 做地址转换时，首先计算线性地址块对应哪个 TLB 表项组，然后在这个 TLB 表项组顺序比对。按照组长度，我们可以称之为 2 路，4 路，8 路。</p> \n <p>经过长期的工程实践，发现 8 路组相连是一个性能分界点。8 路组相连的命中率几乎和全相连命中率几乎一样，超过 8 路，组内对比延迟带来的缺点就超过命中率提高带来的好处了。</p> \n <p>这三种方式各有优缺点，组相连是个折衷的选择，适合大部分应用环境。当然针对不同的领域，也可以采用其他的 cache 组织形式。</p> \n <h3><a id=\"TLB_3099\"></a>TLB表项更新</h3> \n <p>TLB 表项更新可以有 TLB 硬件自动发起，也可以有软件主动更新：</p> \n <ol>\n  <li>TLB miss 发生后，CPU 从 RAM 获取页表项，会自动更新 TLB 表项</li>\n  <li>TLB 中的表项在某些情况下是无效的，比如进程切换，更改内核页表等，此时 CPU 硬件不知道哪些 TLB 表项是无效的，只能由软件在这些场景下，刷新 TLB。</li>\n </ol> \n <p>在 Linux kernel 软件层，提供了丰富的 TLB 表项刷新方法，但是不同的体系结构提供的硬件接口不同。比如 x86_32 仅提供了两种硬件接口来刷新 TLB 表项：</p> \n <ol>\n  <li>向 cr3 寄存器写入值时，会导致处理器自动刷新非全局页的 TLB 表项</li>\n  <li>在 Pentium Pro 以后，invlpg 汇编指令用来无效指定线性地址的单个 TLB 表项无效</li>\n </ol> \n <h2><a id=\"_3113\"></a>操作系统页表</h2> \n <h3><a id=\"_3115\"></a>什么是页表</h3> \n <p>页表是内存管理系统中的数据结构，用于向每个进程提供一致的虚拟地址空间，每个页表项保存的是虚拟地址到物理地址的映射以及一些管理标志。应用进程只能访问虚拟地址，内核必须借助页表和硬件把虚拟地址翻译为对物理地址的访问。</p> \n <h3><a id=\"_3119\"></a>页表作用</h3> \n <p>在使用虚拟地址空间的 Linux 操作系统上，每一个进程都工作在一个 4G 的地址空间上，其中 0~3G 是应用进程可以访问的 user 地址空间，是这个进程独有的，其他进程看不到也无法操作这个地址空间；3G~4G 是 kernel 地址空间，所有进程共享这部分地址空间。</p> \n <p>由于每个进程都有 3G 的私有进程空间，所以系统的物理内存无法对这些地址空间进行一一映射，因此 kernel 需要一种机制，把进程地址空间映射到物理内存上。当一个进程请求访问内存时，操作系统通过存储在 kernel 中的进程页表把这个虚拟地址映射到物理地址，如果还没有为这个地址建立页表项，那么操作系统就为这个访问的地址建立页表项。最基本的映射单位是 page，对应的是页表项 PTE。</p> \n <p>页表项和物理地址是多对一的关系，即多个页表项可以对应一个物理页面，因而支持共享内存的实现（几个进程同时共享物理内存）。</p> \n <h3><a id=\"_3127\"></a>页表的实现</h3> \n <p>实现虚拟地址到物理地址转换最容易想到的方法是使用数组，对虚拟地址空间的每一个页，都分配一个数组项。但是有一个问题，考虑 IA32 体系结构下，页面大小为 4KB，整个虚拟地址空间为 4GB，则需要包含 1M 个页表项，这还只是一个进程，因为每个进程都有自己独立的页表。因此，系统所有的内存都来存放页表项恐怕都不够。</p> \n <p>相像一下进程的虚拟地址空间，实际上大部分是空闲的，真正映射的区域几乎是汪洋大海中的小岛，因次我们可以考虑使用多级页表，可以减少页表内存使用量。实际上多级页表也是各种体系结构支持的，没有硬件支持，我们是没有办法实现页表转换的。</p> \n <p>为了减少页表的大小并忽略未做实际映射的区域，计算机体系结构的设计都会靠虑将虚拟地址划分为多个部分。具体的体系结构划分方式不同，比如 ARM7 和 IA32 就有不同的划分，在这里我们不讨论这部分内容。</p> \n <p>Linux 操作系统使用 4 级页表：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/3873750e1626441d85314a9c3916be68.png\" alt=\"\"></p> \n <p>图中 CR3 保存着进程页目录 PGD 的地址，不同的进程有不同的页目录地址。进程切换时，操作系统负责把页目录地址装入 CR3 寄存器。</p> \n <h4><a id=\"_3141\"></a>地址翻译过程如下</h4> \n <ol>\n  <li>对于给定的线性地址，根据线性地址的 bit22 ~ bit31 作为页目录项索引值，在 CR3 所指向的页目录中找到一个页目录项。</li>\n  <li>找到的页目录项对应着页表，根据线性地址的 bit12 ~ bit21 作为页表项索引值，在页表中找到一个页表项。</li>\n  <li>找到的页表项中包含着一个页面的地址，线性地址的 bit0 ~ bit11 作为页内偏移值和找到的页确定线性地址对应的物理地址。</li>\n </ol> \n <p>这个地址翻译过程完全是由硬件完成的。</p> \n <h4><a id=\"_3149\"></a>页表转化失败</h4> \n <p>在地址转换过程中，有两种情况会导致失败发生。</p> \n <ol>\n  <li>要访问的地址不存在，这通常意味着由于编程错误访问了无效的虚拟地址，操作系统必须采取某种措施来处理这种情况，对于现代操作系统，发送一个段错误给程序；或者要访问的页面还没有被映射进来，此时操作系统要为这个线性地址分配相应的物理页面，并更新页表。</li>\n  <li>要查找的页不在物理内存中，比如页已经交换出物理内存。在这种情况下需要把页从磁盘交换回物理内存。</li>\n </ol> \n <h4><a id=\"TLB_3156\"></a>TLB</h4> \n <p>CPU 的 Memory management unit(MMU) cache 了最近使用的页面映射。我们称之为 translation lookaside buffer(TLB)。TLB 是一个组相连的 cache。当一个虚拟地址需要转换成物理地址时，首先搜索 TLB。如果发现了匹配（TLB命中），那么直接返回物理地址并访问。然而，如果没有匹配项（TLB miss），那么就要从页表中查找匹配项，如果存在也要把结果写回 TLB。</p> \n <h3><a id=\"_3160\"></a>页表格式</h3> \n <p>页目录项和页表项大小都是 32bit(4 bytes)，由于 4KB 地址对齐的原因，页目录项和页表项只有 bit12 ~ bit31 用于地址，剩余的低 12bits 则用来描述页有关的附加信息。尽管这些位是特定于 CPU 的，下列位在 Linux 内核支持的大部分 CPU 都能找到：</p> \n <h4><a id=\"Present_3164\"></a>Present</h4> \n <p>页目录项和页表项都包含这个位。</p> \n <p>虚拟地址对应的物理页面不在内存中，比如页被交换出去，此时页表项的其他部分通常会代表不同的含义，因为不需要描述页在物理内存中的地址，相反，需要信息来找到换出的页。</p> \n <p>如果页目录或者页表项的 Present 位为 0， 那么 CPU 分页单元把虚拟地址存储到 CR2 中，然后生成一个异常 14：page fault 异常。</p> \n <h4><a id=\"Accessed_3172\"></a>Accessed</h4> \n <p>每次分页单元访问页面时，都会自动设置 Accessed 位，内核会定期检查该位，以便确定页的活跃程度，内核会选择不活跃的页面 swapout 到交换空间。注意分页单元只负责置位，清除位操作要内核自己执行。</p> \n <h4><a id=\"Dirty_3176\"></a>Dirty</h4> \n <p>仅仅存在于页表项，每当向页帧写入数据分页单元都会设置 dirty 标志，swap 进程可以通过这个位来决定是否选择这个页面进行交换。记住，分页单元不会清除这个标记，所以必须由操作系统来清除这个标记。</p> \n <h4><a id=\"ReadWrite_3180\"></a>Read/Write</h4> \n <p>包含了页面的读写权限，如果设置为 0，那么只有读权限；设置为 1，则有读写权限。</p> \n <h4><a id=\"UserSupervisor_3184\"></a>User/Supervisor</h4> \n <p>User 允许用户空间代码访问该页；Supervisor 只有内核才可以访问。</p> \n <h4><a id=\"Exec_3188\"></a>Exec</h4> \n <p>在较新的 64 bit 处理器上，分页单元支持 No eXec 位，因此 2.6.11 内核开始加入了这个标志。</p> \n <h3><a id=\"_3192\"></a>页表项的创建和操作</h3> \n <p>所有体系结构都要实现下面的页表项创建，释放和操作函数，以便于内存管理代码创建和销毁页表：</p> \n <table>\n  <thead>\n   <tr>\n    <th>函数</th>\n    <th>描述</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>mk_pte</td>\n    <td>创建一个页表项，必须将page实列和所需的访问权限作为参数传入</td>\n   </tr>\n   <tr>\n    <td>pte_page</td>\n    <td>获得页表项描述的页对应的page实列地址</td>\n   </tr>\n   <tr>\n    <td>pgd_alloc</td>\n    <td>分配并初始化可容纳一个完整目录表的内存（不是一个表项）</td>\n   </tr>\n   <tr>\n    <td>pud_alloc</td>\n    <td></td>\n   </tr>\n   <tr>\n    <td>pmd_alloc</td>\n    <td></td>\n   </tr>\n   <tr>\n    <td>pte_alloc</td>\n    <td></td>\n   </tr>\n   <tr>\n    <td>pgd_free</td>\n    <td>释放目录表占用的内存</td>\n   </tr>\n   <tr>\n    <td>pud_free</td>\n    <td></td>\n   </tr>\n   <tr>\n    <td>pmd_free</td>\n    <td></td>\n   </tr>\n   <tr>\n    <td>pte_free</td>\n    <td></td>\n   </tr>\n   <tr>\n    <td>set_pgd</td>\n    <td>设置页目录项中某项的值</td>\n   </tr>\n   <tr>\n    <td>set_pud</td>\n    <td></td>\n   </tr>\n   <tr>\n    <td>set_pmd</td>\n    <td></td>\n   </tr>\n   <tr>\n    <td>set_pte</td>\n    <td></td>\n   </tr>\n  </tbody>\n </table> \n <h2><a id=\"_3215\"></a>多级页表</h2> \n <h3><a id=\"_3217\"></a>单级页表存在的问题</h3> \n <p><img src=\"https://img-blog.csdnimg.cn/da455c2af1da461791fdd85317009a3d.png\" alt=\"\"></p> \n <p>假设某计算机系统按字节寻址，支持 32 位逻辑地址，采用分页存储管理，页面大小为 4KB，页表项长度为 4B。4KB = 212 B，因此页内地址要用 12 位表示，剩余 20 位表示页号。</p> \n <p>因此，该系统中用户进程最多有 220 页。相应的，一个进程的页表中，最多会有 220 个页表项，所以一个页表最大需要 220 * 4B = 222B。一个页框（内存块）大小为 4B，所以需要 222/212 = 210 个页框存储该页表。而页表的存储是需要连续存储的，因为根据页号查询页表的方法：K 号页对应的页表项的位置 = 页表起始地址 + K * 4B（页表项长度），所以这就要求页表的存储必须是连续的。</p> \n <p>回想一下，当初为什么使用页表，就是要将进程划分为一个个页面可以不用连续的存放在内存中，但是此时页表就需要 1024 个连续的页框，似乎和当时的目标有点背道而驰了…</p> \n <p>此外，根据局部性原理可知，很多时候，进程在一段时间内只需要访问某几个页面就可以正常运行了。因此也没有必要让整个页面都常驻内存。所以，单级页表存在以上两个问题。</p> \n <h3><a id=\"_3229\"></a>两级页表</h3> \n <p>如何解决页表过大需要连续存储的问题呢？这个问题可以参考进程太大需要连续存储的答案。因为页表必须连续存放，所以可以将页表再分页。</p> \n <p>解决方案：可以将长长的页表进行分组，使每个页面中刚好可以放下一个分组（如上面的例子中，页面的大小 4KB），每个页表项 4B，所以每个页面中可以存放 1K 个（1024）个页表项，因此每 1K 个连续的页表项为一组，每组刚好占一个页面，再讲各组离散的放在各个内存块中）。这样就需要为离散的页表再建立一张页表，称为页目录表，或外层页表，或顶层页表。</p> \n <p>还是上面的例子，32 位的逻辑地址空间，页表项大小为 4B，页面大小 4KB，则页内地址占 12 位，单级页表结构逻辑结构图如下图所示：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/3d41ad85d39849c095db282b84a63693.png\" alt=\"\"></p> \n <p>使用单级页表的情况：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/602a34ff968642ffa2a6df92ff792298.png\" alt=\"\"></p> \n <p>将页表分为分为 1024 个表，每个表中包含 1024 个页表项，形成二级页表。二级页表结构的逻辑地址结构如下图:</p> \n <p><img src=\"https://img-blog.csdnimg.cn/24eba9ee56d0420ba78987199cdf633e.png\" alt=\"\"></p> \n <p>两级页表如何实现地址转换：</p> \n <ol>\n  <li>按照地址结构将逻辑地址拆成三个部分。</li>\n  <li>从 PCB 中读取页目录起始地址，再根据一级页号查页目录表，找到下一级页表在内存中存放位置。</li>\n  <li>根据二级页号查表，找到最终想要访问的内存块号。</li>\n  <li>结合页内偏移量得到物理地址。</li>\n </ol> \n <p>下面以一个逻辑地址为例。将逻辑地址（0000000000,0000000001,11111111111）转换为物理地址的过程。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/e05daf7a84a64fe881336549ce55c0a4.png\" alt=\"\"></p> \n <h3><a id=\"_3258\"></a>虚拟存储技术</h3> \n <p>在解决了页必须连续存放的问题后，再看如何第二个问题：没有必要让整个页表常驻内存，因为进程一段时间内可能只需要访问某几个特定的页面。</p> \n <p>解决方案：可以在需要访问页面时才把页面调入内存——虚拟存储技术（后面再说）。可以在页表中增加一个标示位，用于表示该页表是否已经调入内存。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/6f1931ec910743e8b5676db0ad12502b.png\" alt=\"\"></p> \n <h3><a id=\"_3266\"></a>几个问题</h3> \n <p>1.若采用多级页表机制，则各级页表的大小不能超过一个页面。</p> \n <p>举例说明，某系统按字节编址，采用 40 位逻辑地址，页面大小为 4KB，页表项大小为 4B，假设采用纯页式存储，则要采用（）级页表，页内偏移量为（）位？</p> \n <p>页面大小 = 4KB，按字节编址，因此页内偏移量为 12 位。</p> \n <p>页号 = 40 - 12 = 28位。</p> \n <p>页面大小 = 4KB，页表项大小 = 4B，则每个页面可存放 1024 个页表项。因此各级页表最多包含 1024 个页表项，需要 10 个二进制位才能映射到 1024 个页表项，因此每级页表对应的页号应为 10 位二进制。共 28 位的页号至少要分为 3 级。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/1bafe4c973224113b1472e2404bc763b.png\" alt=\"\"></p> \n <ol start=\"2\">\n  <li>两级页表的访问次数分析（假设没有页表）： \n   <ol>\n    <li>第一次访问：访问内存中的页目录表。</li>\n    <li>访问内存中的二级目录。</li>\n    <li>访问目标内存单元。</li>\n   </ol> </li>\n </ol> \n <p>从上面可以看出，两级页表虽然解决了页表需要连续存储的问题，但是同时也增加了内存的访问次数。</p> \n <h3><a id=\"_3287\"></a>使用二级页表的优势</h3> \n <ol>\n  <li>使用多级页表可以使得页表在内存中离散存储。多级页表实际上是增加了索引，有了索引就可以定位到具体的项。举个例子：比如虚拟地址空间大小为 4G，每个页大小依然为 4K，如果使用一级页表的话，共有 2^20 个页表项，如果每一个页表项占 4B，那么存放所有页表项需要 4M，为了能够随机访问，那么就需要连续 4M 的内存空间来存放所有的页表项。<br> 随着虚拟地址空间的增大，存放页表所需要的连续空间也会增大，在操作系统内存紧张或者内存碎片较多时，这无疑会带来额外的开销。但是如果使用多级页表，我们可以使用一页来存放页目录项，页表项存放在内存中的其他位置，不用保证页目录项和页表项连续。</li>\n  <li>使用多级页表可以节省页表内存。使用一级页表，需要连续的内存空间来存放所有的页表项。多级页表通过只为进程实际使用的那些虚拟地址内存区请求页表来减少内存使用量。举个例子：一个进程的虚拟地址空间是 4GB，假如进程只使用 4MB 内存空间。对于一级页表，我们需要 4M 空间来存放这 4GB 虚拟地址空间对应的页表，然后可以找到进程真正使用的 4M 内存空间。也就是说，虽然进程实际上只使用了 4MB 的内存空间，但是为了访问它们我们需要为所有的虚拟地址空间建立页表。<br> 但是如果使用二级页表的话，一个页目录项可以定位 4M 内存空间，存放一个页目录项占 4K，还需要一页用于存放进程使用的 4M（4M=1024*4K，也就是用 1024 个页表项可以映射 4M 内存空间）内存空间对应的页表，总共需要 4K（页表）+4K（页目录）=8K 来存放进程使用的这 4M 内存空间对应页表和页目录项，这比使用一级页表节省了很多内存空间。</li>\n </ol> \n <p>当然，在这种情况下，使用多级页表确实是可以节省内存的。但是，我们需要注意另一种情况，如果进程的虚拟地址空间是 4GB，而进程真正使用的内存也是 4GB，如果是使用一级页表，则只需要 4MB 连续的内存空间存放页表，我们就可以寻址这 4GB 内存空间。而如果使用的是二级页表的话，我们需要 4MB 内存存放页表，还需要 4KB 内存来存放页目录项，此时多级页表反倒是多占用了内存空间。注意在大多数情况都是进程的 4GB 虚拟地址空间都是没有使用的，实际使用的都是小于 4GB 的，所以我们说多级页表可以节省页表内存。</p> \n <p>那么使用多级页表比使用以及页表有没有什么劣势呢？</p> \n <p>当然是有的。比如：使用以及页表时，读取内存中一页内容需要 2 次访问内存，第一次是访问页表项，第二次是访问要读取的一页数据。但如果是使用二级页表的话，就需要 3 次访问内存了，第一次访问页目录项，第二次访问页表项，第三次访问要读取的一页数据。访存次数的增加也就意味着访问数据所花费的总时间增加。</p> \n <h3><a id=\"_3300\"></a>总结</h3> \n <p>多级页表优势：</p> \n <ol>\n  <li>可以离散存储页表。</li>\n  <li>在某种意义上节省页表内存空间。</li>\n </ol> \n <p>多级页表劣势：</p> \n <ol>\n  <li>增加寻址次数，从而延长访存时间。</li>\n </ol> \n <h2><a id=\"_3313\"></a>局部性原理</h2> \n <h3><a id=\"_3315\"></a>什么是局部性原理</h3> \n <p>虚拟存储器的核心思路是根据程序运行时的局部性原理：一个程序运行时，在一小段时间内，只会用到程序和数据的很小一部分，仅把这部分程序和数据装入主存即可，更多的部分可以在需要用到时随时从辅存调入主存。在操作系统和相应硬件的支持下，数据在辅存和主存之间按程序运行的需要自动成批量地完成交换。</p> \n <p>局部性原理是虚拟内存技术的基础，正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就开始运行。早在 1968 年的时候，就有人指出我们的程序在执行的时候往往呈现局部性规律，也就是说在某个较短的时间段内，程序执行局限于某一小部分，程序访问的存储空间也局限于某个区域。</p> \n <p>局部性原理表现在以下两个方面：</p> \n <p><strong>时间局部性：</strong> 如果程序中的某条指令一旦执行，不久以后该指令很可能再次执行；如果某数据被访问过，不久以后该数据很可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。时间局部性是通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。</p> \n <p><strong>空间局部性：</strong> 一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。虚拟内存技术实际上就是建立了 “内存-外存” 的两级存储器的结构，利用局部性原理实现髙速缓存。</p> \n <p>基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其他部分留在外存，就可以启动程序执行。由于外存往往比内存大很多，所以我们运行的软件的内存大小实际上是可以比计算机系统实际的内存大小大的。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换到外存上，从而腾出空间存放将要调入内存的信息。</p> \n <p>可见，内-外存交换技术本质是一种时间换空间的策略，你用 CPU 的计算时间，页的调入调出花费的时间，换来了一个虚拟的更大的空间来支持程序的运行。</p> \n <h3><a id=\"_3331\"></a>示例</h3> \n <p>上面是通过理论来说明的，下面我们通过一段代码来看看局部性原理：</p> \n <pre><code class=\"prism language-c\">public <span class=\"token keyword\">int</span> <span class=\"token function\">sum</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> array<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token keyword\">int</span> sum <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> array<span class=\"token punctuation\">.</span>length<span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        sum <span class=\"token operator\">=</span> sum <span class=\"token operator\">+</span> array<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token keyword\">return</span> sum<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>从上面的这段代码来看，就是一个很简单的数组元素求和，这里我们主要看 sum 和 array 两个变量，我们可以看到 sum 在每次循环中都会用到，另外它只是一个简单变量，所以我们可以看到，sum 是符合我们上面提到的时间局部性，再访问一次后还会被继续访问到，但是它不存在我们所说的空间局部性了。</p> \n <p>相反的，array 数组中的每个元素只访问一次，另外数组底层的存储是连续的，所以 array 变量符合我们上面提到的空间局部性，但是不符合时间局部性。</p> \n <p>这只是局部性原理的简单示例，对于局部性原理还有很多地方会用到，我们如果能熟练的掌握和使用，对我们的帮助会很大的。</p> \n <h3><a id=\"_3351\"></a>相关应用</h3> \n <h4><a id=\"CPU_3353\"></a>CPU缓存</h4> \n <p>上面的示例其实很简单，相信大家都能理解，另外局部性原理其实在我们日常使用的软件中随处可见，并且在操作系统中也少不了。我们知道 CPU 的速度是非常快的，而且 CPU 与内存之间有多级缓存，如下图：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/1def7671303b4f7b9756773032398758.png\" alt=\"局部性原理\"></p> \n <p>为了充分的利用 CPU，操作系统会利用局部性原理，将高频的数据从内存中加载的缓存中，从而加快 CPU 的处理速度。</p> \n <h4><a id=\"_3361\"></a>广义局部性</h4> \n <p>其实我们的局部性原理不单单是上面提到的狭义性的局部性，还可以是广义的局部性。我们系统里面的热点数据，CDN 数据，微博的热点流量等等这些都利用了局部性原理。只是我们可能没有意识到而已，实际上已经在使用了。我们会通过 Redis 缓存热点数据，会通过 CDN 提前加载图片或者视频资源，等等，都是因为这些数据本身就符合局部性原理，合理的利用局部性可以得到了能效、成本上的提升。</p> \n <h4><a id=\"_3365\"></a>利弊结合</h4> \n <p>任何事情都是多面性的，局部性原理虽然我们使用起来很不错，可以提高系统性能，但是在有些场景下，我们是需要避免局部性原理的出现的。或者说出现了这种情况，我们需要人工处理。我们可以试想一下，如果在我们的一个大数据处理平台上，由于局部性原理的存在，导致我们部分节点数据庞大运算吃力，部分节点数据量小十分空闲，这种情况自然是不合理，我们就需要把数据按照业务场景进行重新分配，以达到整个集群的最大利用。</p> \n <h2><a id=\"_3371\"></a>分段与分页机制</h2> \n <h3><a id=\"_3373\"></a>分段机制</h3> \n <h4><a id=\"_3375\"></a>什么是分段机制</h4> \n <p>分段机制就是把虚拟地址空间中的虚拟内存组织成一些长度可变的称为段的内存块单元。</p> \n <h4><a id=\"_3379\"></a>什么是段</h4> \n <p>每个段由三个参数定义：段基地址、段限长和段属性。段的基地址、段限长以及段的保护属性存储在一个称为段描述符的结构项中。</p> \n <h4><a id=\"_3383\"></a>段的作用</h4> \n <p>段可以用来存放程序的代码、数据和堆栈，或者用来存放系统数据结构。</p> \n <h4><a id=\"_3387\"></a>段的存储地址</h4> \n <p>系统中所有使用的段都包含在处理器线性地址空间中。</p> \n <h4><a id=\"_3391\"></a>段选择符</h4> \n <p>逻辑地址包括一个段选择符或一个偏移量，段选择符是一个段的唯一标识，提供了段描述符表，段描述符表指明短的大小、访问权限和段的特权级、段类型以及段的第一个字节在线性地址空间中的位置（称为段的基地址）。逻辑地址的偏移量部分到段的基地址上就可以定位段中某个字节的位置。因此基地址加上偏移量就形成了处理器线性地址空间中的地址。</p> \n <h4><a id=\"_3395\"></a>逻辑地址到线性地址的变换过程</h4> \n <p><img src=\"https://img-blog.csdnimg.cn/ff1ce8ad87de41a79b8975f45c59fe63.png\" alt=\"\"></p> \n <p>如果没有开启分页，那么处理器直接把线性地址映射到物理地址，即线性地址被送到处理器地址总线上；如果对线性地址空间进行了分页处理，那么就会使用二级地址转换把线性地址转换成物理地址。</p> \n <h4><a id=\"_3401\"></a>虚拟地址到物理地址的变换过程</h4> \n <p><img src=\"https://img-blog.csdnimg.cn/a48edf1a869844528490247d6eb349d5.png\" alt=\"\"></p> \n <h3><a id=\"_3405\"></a>分页机制</h3> \n <h4><a id=\"_3407\"></a>什么是分页机制</h4> \n <p>分页机制在段机制之后进行的，它进一步将线性地址转换为物理地址。</p> \n <h4><a id=\"_3411\"></a>分页机制的存储</h4> \n <p>分页机制支持虚拟存储技术，在使用虚拟存储的环境中，大容量的线性地址空间需要使用小块的物理内存（RAM 或 ROM）以及某些外部存储空间来模拟。当使用分页时，每个段被划分成页面（通常每页为 4K 大小），页面会被存储于物理内存中或硬盘中。</p> \n <p>操作系统通过维护一个页目录和一些页表来留意这些页面。当程序（或任务）试图访问线性地址空间中的一个地址位置时，处理器就会使用页目录和页表把线性地址转换成一个物理地址，然后在该内存位置上执行所要求的操作。</p> \n <h4><a id=\"_3417\"></a>线性地址和物理地址之间的变换过程</h4> \n <p><img src=\"https://img-blog.csdnimg.cn/52b0819d8d0442d491e6c547ccce641f.png\" alt=\"\"></p> \n <h3><a id=\"_3421\"></a>聊聊：分段机制和分页机制的区别</h3> \n <ol>\n  <li>分页机制会使用大小固定的内存块，而分段管理则使用了大小可变的块来管理内存。</li>\n  <li>分页使用固定大小的块更为适合管理物理内存，分段机制使用大小可变的块更适合处理复杂系统的逻辑分区。</li>\n  <li>段表存储在线性地址空间，而页表则保存在物理地址空间。</li>\n </ol> \n <h3><a id=\"_3427\"></a>聊聊：分段分页优缺点</h3> \n <h4><a id=\"_3429\"></a>优点</h4> \n <ol>\n  <li>它减少了内存使用量。</li>\n  <li>分页表大小受到分段大小的限制。</li>\n  <li>分段表只有一个对应于一个实际分段的条目。</li>\n  <li>外部碎片不存在。</li>\n  <li>它简化了内存分配。</li>\n </ol> \n <h4><a id=\"_3437\"></a>缺点</h4> \n <ol>\n  <li>内部碎片将在那里。</li>\n  <li>与分页相比，分段复杂度要高得多。</li>\n  <li>分页表需要连续存储在内存中。</li>\n </ol> \n <h3><a id=\"_3445\"></a>聊聊：什么是逻辑地址/线性地址/物理地址</h3> \n <h4><a id=\"Logical_Address_3447\"></a>逻辑地址（Logical Address）</h4> \n <p>是指由程序产生的与段相关的偏移地址部分。例如，你在进行 C 语言 指针编程中，可以读取指针变量本身值(&amp; 操作)，实际上这个值就是逻辑地址，它是相对于你当前进程数据段的地址，不和绝对物理地址相干。</p> \n <p>只有在 Intel 实模式下，逻辑地址才和物理地址相等（因为实模式没有分段或分页机制,Cpu 不进行自动地址转换）；逻辑也就是在 Intel 保护模式下程序执行代码段限长内的偏移地址（假定代码段、数据段如果完全一样）。应用程序员仅需与逻辑地址打交道，而分段和分页机制对您来说是完全透明的，仅由系统编程人员涉及。应用程序员虽然自己可以直接操作内存，那也只能在操作系统给你分配的内存段操作。</p> \n <h4><a id=\"Linear_Address_3453\"></a>线性地址（Linear Address）</h4> \n <p>线性地址（Linear Address） 是逻辑地址到物理地址变换之间的中间层。程序代码会产生逻辑地址，或者说是段中的偏移地址，加上相应段的基地址就生成了一个线性地址。如果启用了分页机制，那么线性地址可以再经变换以产生一个物理地址。若没有启用分页机制，那么线性地址直接就是物理地址。Intel 80386 的线性地址空间容量为 4G（2 的 32 次方即 32 根地址总线寻址）。</p> \n <h4><a id=\"Physical_Address_3457\"></a>物理地址（Physical Address）</h4> \n <p>是指出现在 CPU 外部地址总线上的寻址物理内存的地址信号，是地址变换的最终结果地址。如果启用了分页机制，那么线性地址会使用页目录和页表中的项变换成物理地址。如果没有启用分页机制，那么线性地址就直接成为物理地址了。</p> \n <h4><a id=\"Virtual_Memory_3461\"></a>虚拟内存（Virtual Memory）</h4> \n <p>是指计算机呈现出要比实际拥有的内存大得多的内存量。因此它允许程序员编制并运行比实际系统拥有的内存大得多的程序。这使得许多大型项目也能够在具有有限内存资源的系统上实现。一个很恰当的比喻是：你不需要很长的轨道就可以让一列火车从上海开到北京。你只需要足够长的铁轨（比如说 3 公里）就可以完成这个任务。</p> \n <p>采取的方法是把后面的铁轨立刻铺到火车的前面，只要你的操作足够快并能满足要求，列车就能象在一条完整的轨道上运行。这也就是虚拟内存管理需要完成的任务。在 <strong>Linux</strong> 0.11 内核中，给每个程序（进程）都划分了总容量为64MB的虚拟内存空间。因此程序的逻辑地址范围是 0x0000000 到 0x4000000。</p> \n <p>有时我们也把逻辑地址称为虚拟地址。因为与虚拟内存空间的概念类似，逻辑地址也是与实际物理内存容量无关的。逻辑地址与物理地址的 “差距” 是 0xC0000000，是由于虚拟地址-&gt;线性地址-&gt;物理地址映射正好差这个值。这个值是由操作系统指定的。</p> \n <p>虚拟地址到物理地址的转化方法是与体系结构相关的。一般来说有分段、分页两种方式。以现在的 x86 cpu 为例，分段分页都是支持的。Memory Mangement Unit 负责从虚拟地址到物理地址的转化。逻辑地址是段标识+段内偏移量的形式，MMU 通过查询段表，可以把逻辑地址转化为线性地址。如果 cpu 没有开启分页功能，那么线性地址就是物理地址；如果 cpu 开启了分页功能，MMU 还需要查询页表来将线性地址转化为物理地址：</p> \n <pre><code>逻辑地址 ----（段表）---&gt; 线性地址 — （页表）—&gt; 物理地址\n</code></pre> \n <p>不同的逻辑地址可以映射到同一个线性地址上；不同的线性地址也可以映射到同一个物理地址上；所以是多对一的关系。另外，同一个线性地址，在发生换页以后，也可能被重新装载到另外一个物理地址上。所以这种多对一的映射关系也会随时间发生变化。</p> \n <h3><a id=\"_3477\"></a>聊聊：什么是虚拟内存？</h3> \n <p>虚拟内存就是说，让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。虚拟内存使用部分加载的技术，让一个进程或者资源的某些页面加载进内存，从而能够加载更多的进程，甚至能加载比内存大的进程，这样看起来好像内存变大了，这部分内存其实包含了磁盘或者硬盘，并且就叫做虚拟内存。</p> \n <h3><a id=\"_3483\"></a>聊聊：什么是分页？</h3> \n <p>把内存空间划分为<strong>大小相等且固定的块</strong>，作为主存的基本单位。因为程序数据存储在不同的页面中，而页面又离散的分布在内存中，<strong>因此需要一个页表来记录映射关系，以实现从页号到物理块号的映射。</strong></p> \n <p>访问分页系统中内存数据需要<strong>两次的内存访问</strong> (一次是从内存中访问页表，从中找到指定的物理块号，加上页内偏移得到实际物理地址；第二次就是根据第一次得到的物理地址访问内存取出数据)。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/20210615172819240.png\" alt=\"\"></p> \n <h3><a id=\"__3491\"></a>聊聊： 什么是分段？</h3> \n <p><strong>分页是为了提高内存利用率，而分段是为了满足程序员在编写代码的时候的一些逻辑需求(比如数据共享，数据保护，动态链接等)。</strong></p> \n <p>分段内存管理当中，<strong>地址是二维的，一维是段号，二维是段内地址；其中每个段的长度是不一样的，而且每个段内部都是从0开始编址的</strong>。由于分段管理中，每个段内部是连续内存分配，但是段和段之间是离散分配的，因此也存在一个逻辑地址到物理地址的映射关系，相应的就是段表机制。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/20210615172819749.png\" alt=\"\"></p> \n <h3><a id=\"_3499\"></a>聊聊：分页和分段有什区别？</h3> \n <ul>\n  <li>分页对程序员是透明的，但是分段需要程序员显式划分每个段。</li>\n  <li>分页的地址空间是一维地址空间，分段是二维的。</li>\n  <li>页的大小不可变，段的大小可以动态改变。</li>\n  <li>分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。</li>\n </ul> \n <h3><a id=\"_3508\"></a>聊聊：为什么使用两级页表</h3> \n <p>假设每个进程都占用了4G的线性地址空间，页表共含1M个表项，每个表项占4个字节，那么每个进程的页表要占据4M的内存空间。为了节省页表占用的空间，我们使用两级页表。每个进程都会被分配一个页目录，但是只有被实际使用页表才会被分配到内存里面。一级页表需要一次分配所有页表空间，两级页表则可以在需要的时候再分配页表空间。</p> \n <p>两级表结构的第一级称为页目录，存储在一个4K字节的页面中。页目录表共有1K个表项，每个表项为4个字节，并指向第二级表。线性地址的最高10位(即位31~位32)用来产生第一级的索引，由索引得到的表项中，指定并选择了1K个二级表中的一个表。</p> \n <p>两级表结构的第二级称为页表，也刚好存储在一个4K字节的页面中，包含1K个字节的表项，每个表项包含一个页的物理基地址。第二级页表由线性地址的中间10位(即位21~位12)进行索引，以获得包含页的物理地址的页表项，这个物理地址的高20位与线性地址的低12位形成了最后的物理地址，也就是页转化过程输出的物理地址。</p> \n <h3><a id=\"_3518\"></a>聊聊：地址变换中，有快表和没快表的区别</h3> \n <table>\n  <thead>\n   <tr>\n    <th>区别</th>\n    <th>地址变换过程</th>\n    <th>访问一个逻辑地址的访存次数</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>无快表</td>\n    <td>①算页号、页内偏移量 ②检查页号合法性 ③查页表，找到页面存放的内存块号 ④根据内存块号与页内偏移量得到物理地址 ⑤访问目标内存单元</td>\n    <td>两次访存</td>\n   </tr>\n   <tr>\n    <td>具有快表的地址</td>\n    <td>①算页号、页内偏移量 ②检查页号合法性 ③查快表。若命中，即可知道页面存放的内存块号，可直接进行⑤;若未命中则进行④， ④查页表，找到页面存放的内存块号，并且将页表项复制到快表中 ⑤根据内存块号与页内偏移量得到物理地址 ⑥访问目标内存单元</td>\n    <td>快表命中，只需一次访存快表未命中</td>\n   </tr>\n  </tbody>\n </table> \n <h3><a id=\"_3527\"></a>聊聊：动态分区分配算法的了解</h3> \n <ul>\n  <li> <p>首次适应算法：从低地址开始查找，找到第–个能满足大小的空闲分区。</p> <p>原理：空闲分区以地址递增的次序排列，每次分配内存时顺序查找</p> </li>\n  <li> <p>最佳适应算法：由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域。</p> <p>因此为了保证当“大进程”到来时能有连续的大片空间，可以尽可能多地留下大片的空闲区,即，优先使用更小的空闲区。原理：空闲分区按容量递增次序链接。每次分配内存时顺序查找</p> </li>\n  <li> <p>最坏适应算法：为了解决最佳适应算法的问题—即留下太多难以利用的小碎片，可以在每次分配时优先使用最大的连续空闲区，这样分配后剩余的空闲区就不会太小。原理：空闲分区按容量递减次序链接，每次分配内存时顺序查找</p> </li>\n  <li> <p>邻近适应算法：首次适应算法每次都从链头开始查找的。这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就能解决上述问题。原理：空闲分区以地址递增的顺序排列(可排成-一个循环链表)。每次分配内存时从上次查找结束的位置开始查找空闲分区链(或空闲分区表)，找到大小能满足要求的第一个空闲分区</p> </li>\n </ul> \n <p>总结：</p> \n <table>\n  <thead>\n   <tr>\n    <th>算法</th>\n    <th>算法思想</th>\n    <th>分区排列顺序</th>\n    <th>优点</th>\n    <th>缺点</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>首次适应</td>\n    <td>从头到尾找适合分区</td>\n    <td>空闲分区以地址递增次序排列</td>\n    <td>综合看性能最好，算法开销小，回收分区后一.般不需要对空闲分区队列重新排序</td>\n    <td></td>\n   </tr>\n   <tr>\n    <td>最佳适应</td>\n    <td>优先使用更小的分区，以保留更多大分区</td>\n    <td>空闲分区以容量递增次序排列</td>\n    <td>会有更多的大分区被保留下来，更能满足大进程需求</td>\n    <td>会产生很多太小的、难以利用的碎片;算法开销大，回收分区后可能需要对空闲分区队列重新排序</td>\n   </tr>\n   <tr>\n    <td>最坏适应</td>\n    <td>优先使用更大的分区，以防止产生太小的不可用的碎片</td>\n    <td>空闲分区以容量递减次序排列</td>\n    <td>可以减少难以利用的小片</td>\n    <td>大分区容易被用完，不利于大进程，算法开销大(原因同上)</td>\n   </tr>\n   <tr>\n    <td>邻近适应</td>\n    <td>由首次适应演变而来，每次从上次查找结束位置开始查找</td>\n    <td>空闲分区以地址递增次序排列(可排列成循环链表)</td>\n    <td>不用每次都从低地址的小分区开始检索。算法开销小(原因同首次适应算法)</td>\n    <td>会使高地址的大分区也被用完</td>\n   </tr>\n  </tbody>\n </table> \n <h3><a id=\"_3554\"></a>聊聊：几种典型的锁</h3> \n <ul>\n  <li>读写锁<br> （可以同时进行读）<br> 写者必须互斥（只允许一个写者写，也不能读者写者同时进行）<br> 写者优先于读者</li>\n  <li>互斥锁<br> 一次只能一个线程拥有互斥锁，其他线程只有等待<br> 互斥锁是在抢锁失败的情况下主动放弃CPU进入睡眠状态直到锁的状态改变时再唤醒，而操作系统负责线程调度，为了实现锁的状态发生改变时唤醒阻塞的线程或者进程，需要把锁交给操作系统管理，所以互斥锁在加锁操作时涉及上下文的切换</li>\n  <li>条件变量（同步）<br> 互斥锁一个明显的缺点是他只有两种状态：锁定和非锁定<br> 条件变量通过允许线程阻塞和等待另一个线程发送信号的方法弥补了互斥锁的不足，他常和互斥锁一起使用，以免出现竞态条件。当条件不满足时，线程往往解开相应的互斥锁并阻塞线程然后等待条件发生变化。一旦其他的某个线程改变了条件变量，他将通知相应的条件变量唤醒一个或多个正被此条件变量阻塞的线程。总的来说互斥锁是线程间互斥的机制，条件变量则是同步机制。</li>\n  <li>自旋锁<br> 如果进线程无法取得锁，进线程不会立刻放弃CPU时间片，而是一直循环尝试获取锁，直到获取为止<br> 如果别的线程长时期占有锁，那么自旋就是在浪费CPU做无用功，但是自旋锁一般应用于加锁时间很短的场景，这个时候效率比较高</li>\n </ul> \n <h3><a id=\"_3576\"></a>聊聊：常见的几种磁盘调度算法</h3> \n <p>磁盘块的时间的影响因素有：</p> \n <ul>\n  <li>旋转时间（主轴转动盘面，使得磁头移动到适当的扇区上）</li>\n  <li>寻道时间（制动手臂移动，使得磁头移动到适当的磁道上）</li>\n  <li>实际的数据传输时间</li>\n </ul> \n <p>其中，寻道时间最长，因此磁盘调度的主要目标是使磁盘的平均寻道时间最短。</p> \n <ol>\n  <li>先来先服务：按照磁盘请求的顺序进行调度。<br> 优点：公平<br> 缺点：未对寻道做任何优化，使平均寻道时间可能较长。</li>\n  <li>最短寻道时间优先<br> 优先调度与当前磁头所在磁道距离最近的磁道。<br> 缺点：不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。具体来说，两端的磁道请求更容易出现饥饿现象</li>\n  <li>电梯扫描算法<br> 电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。<br> 电梯算法（扫描算法）和电梯的运行过程类似，总是按一个方向来进行磁盘调度，直到该方向上没有未完成的磁盘请求，然后改变方向。<br> 因为考虑了移动方向，因此所有的磁盘请求都会被满足，解决了 SSTF 的饥饿问题</li>\n </ol> \n <h3><a id=\"__3597\"></a>聊聊： 什么叫抖动</h3> \n <p>如果对—个进程未分配它所要求的全部页面，有时就会出现分配的页面数增多但缺页率反而提高的异常现象。通俗的说刚刚换出的页面马上又要换入内存，刚刚换入的页面马上又要换出外存，这种频繁的页面调度行为称为抖动，或颠簸。</p> \n <p>原因：进程频繁访问的页面数目高于可用的物理块数(分配给进程的物理块不够)<br> 为进程分配的物理块太少，会使进程发生抖动现象。为进程分配的物理块太多，又会降低系统整体的并<br> 发度，降低某些资源的利用率</p> \n <p>为了研究为应该为每个进程分配多少个物理块，Denning 提出了进程工作集” 的概念</p> \n <h3><a id=\"_3607\"></a>聊聊：页面置换算法的了解</h3> \n <ul>\n  <li>最佳置换法(OPT)：每次选择淘汰的页面将是以后永不使用，或者在最长时间内不再被访问的页面，这样可以保证最低的缺页率<br> 最佳置换算法可以保证最低的缺页率，但实际上，只有在进程执行的过程中才能知道接下来会访问到的是哪个页面。操作系统无法提前预判页面访问序列。因此，最佳置换算法是无法实现的</li>\n  <li>先进先出置换算法(FIFO)：每次选择淘汰的页面是最早进入内存的页面<br> 把调入内存的页面根据调入的先后顺序排成一个队列，需要换出页面时选择队头页面队列，它最大长度取决于系统为进程分配了多少个内存块<br> 缺点：先进入的页面也有可能最经常被访问。因此，算法性能差。在FIFO算法下被反复调入和调<br> 出，并且有抖动现象</li>\n  <li>最近最久未使用置换算法(LRU)：每次淘汰的页面是最近最久未使用的页面<br> 赋予每个页面对应的页表项中，用访问字段记录该页面自上次被访问以来所经历的时间t(该算法的实现需要专门的硬件支持，虽然算法性能好，但是实现困难，开销大)。当需要淘汰一个页面时，选择现有页面中t值最大的，即最近最久未使用的页面。算法开销比较大</li>\n  <li>时钟置换算法(CLOCK)或者叫做或最近未用算法：循环扫描缓冲区像时钟一样转动<br> 为每个页面设置一个访问位，再将内存中的页面都通过链接指针链接成一个循环队列。当某页被访问时，其访问位置为1。当需要淘汰-一个页面时，只需检查页的访问位。如果是0，就选择该页换出;如果是1，则将它置为0，暂不换出，继续检查下一个页面，若第- - ~轮扫描中所有页面都是1，则将这些页面的访问位依次置为0后，再进行第二轮扫描(第二轮扫描中一定会有访问位为0的页面，因此简单的CLOCK算法选择–个淘汰页面最多会经过两轮扫描)</li>\n  <li>改进的时钟置换算法：使用访问位和修改位来判断是否置换该页面<br> 1类(A =0, M = 0)：表示该页面最近既未被访问，又未被修改，是最佳淘汰页。<br> 2类(A =0, M = 1)：表示该页面最近未被访问，但已被修改，并不是很好的淘汰页。<br> 3类(A =1, M = 0)：表示该页面最近已被访问，但未被修改，该页有可能再被访问。<br> 4类(A =1, M = 1)：表示该页最近已被访问且被修改，该页可能再被访问。</li>\n </ul> \n <p>总结：</p> \n <ol>\n  <li>最佳置换算法性OPT能最好，但无法实现；</li>\n  <li>先进先出置换算法实现简单，但算法性能差；</li>\n  <li>最近最久未使用置换算法性能好，是最接近OPT算法性能的，但是实现起来需要专门的硬件支持，算法开销大</li>\n  <li>CLOCK循环扫描各页面 第一轮淘汰访问位=0的，并将扫描过的页面访问位改为1。若第二轮没选中，则进行第二轮扫描。实现简单，算法开销小;但未考虑页面是否被修改过。</li>\n  <li>改进的clock：若用(访问位，修改位)的形式表述，则 第一轮:淘汰(0,0) ，第二轮:淘汰(0,1)，并将扫描过的页面访问位都置为0 ，第三轮:淘汰(0, 0)， 第四轮:淘汰(0, 1)。算法开销较小，性能也不错</li>\n </ol> \n <h3><a id=\"_3635\"></a>聊聊：页面替换算法有哪些？</h3> \n <p>在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。</p> \n <p>包括以下算法：</p> \n <ul>\n  <li><strong>最佳算法</strong>：所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。这是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。</li>\n  <li><strong>先进先出</strong>：选择换出的页面是最先进入的页面。该算法将那些经常被访问的页面也被换出，从而使缺页率升高。</li>\n  <li><strong>LRU</strong>：虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。<code>LRU</code> 将最近最久未使用的页面换出。为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。因为每次访问都需要更新链表，因此这种方式实现的 <code>LRU</code> 代价很高。</li>\n  <li><strong>时钟算法</strong>：时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。它将整个环形链表的每一个页面做一个标记，如果标记是<code>0</code>，那么暂时就不会被替换，然后时钟算法遍历整个环，遇到标记为<code>1</code>的就替换，否则将标记为<code>0</code>的标记为<code>1</code>。</li>\n </ul> \n <h3><a id=\"_3648\"></a>聊聊：页面置换算法都有哪些</h3> \n <p>在地址映射过程中，如果在页面中发现所要访问的页面不在内存中，那么就会产生一条缺页中断。</p> \n <p>当发生缺页中断时，如果操作系统内存中没有空闲页面，那么操作系统必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。而用来选择淘汰哪一页的规则叫做页面置换算法。</p> \n <p>下面我汇总的这些页面置换算法比较齐全，只给出简单介绍，算法具体的实现和原理读者可以自行了解。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/c3e84a224cf1b3770f8e894a26b05511.png\" alt=\"\"></p> \n <ul>\n  <li><code>最优算法</code>在当前页面中置换最后要访问的页面。不幸的是，没有办法来判定哪个页面是最后一个要访问的，<code>因此实际上该算法不能使用</code>。然而，它可以作为衡量其他算法的标准。</li>\n  <li><code>NRU</code> 算法根据 R 位和 M 位的状态将页面氛围四类。从编号最小的类别中随机选择一个页面。NRU 算法易于实现，但是性能不是很好。存在更好的算法。</li>\n  <li><code>FIFO</code> 会跟踪页面加载进入内存中的顺序，并把页面放入一个链表中。有可能删除存在时间最长但是还在使用的页面，因此这个算法也不是一个很好的选择。</li>\n  <li><code>第二次机会</code>算法是对 FIFO 的一个修改，它会在删除页面之前检查这个页面是否仍在使用。如果页面正在使用，就会进行保留。这个改进大大提高了性能。</li>\n  <li><code>时钟</code> 算法是第二次机会算法的另外一种实现形式，时钟算法和第二次算法的性能差不多，但是会花费更少的时间来执行算法。</li>\n  <li><code>LRU</code> 算法是一个非常优秀的算法，但是没有<code>特殊的硬件(TLB)</code>很难实现。如果没有硬件，就不能使用 LRU 算法。</li>\n  <li><code>NFU</code> 算法是一种近似于 LRU 的算法，它的性能不是非常好。</li>\n  <li><code>老化</code> 算法是一种更接近 LRU 算法的实现，并且可以更好的实现，因此是一个很好的选择</li>\n  <li>最后两种算法都使用了工作集算法。工作集算法提供了合理的性能开销，但是它的实现比较复杂。<code>WSClock</code> 是另外一种变体，它不仅能够提供良好的性能，而且可以高效地实现。</li>\n </ul> \n <p><strong>最好的算法是老化算法和WSClock算法</strong>。他们分别是基于 LRU 和工作集算法。他们都具有良好的性能并且能够被有效的实现。还存在其他一些好的算法，但实际上这两个可能是最重要的。</p> \n <h3><a id=\"_3672\"></a>聊聊：什么是按需分页</h3> \n <p>在操作系统中，进程是以页为单位加载到内存中的，按需分页是一种<code>虚拟内存</code>的管理方式。在使用请求分页的系统中，只有在尝试访问页面所在的磁盘并且该页面尚未在内存中时，也就发生了<code>缺页异常</code>，操作系统才会将磁盘页面复制到内存中。</p> \n <h3><a id=\"_3676\"></a>聊聊：什么是虚拟内存</h3> \n <p>虚拟内存 是一种内存分配方案，是一项可以用来辅助内存分配的机制。</p> \n <p>我们知道，应用程序是按页装载进内存中的。</p> \n <p>但并不是所有的页都会装载到内存中，计算机中的硬件和软件会将数据从 RAM 临时传输到磁盘中来弥补内存的不足。</p> \n <p>如果没有虚拟内存的话，</p> \n <p>一旦你将计算机内存填满后，计算机会对你说</p> \n <p>呃，不，<strong>对不起，您无法再加载任何应用程序，请关闭另一个应用程序以加载新的应用程序</strong>。</p> \n <p>对于虚拟内存，计算机可以执行操作是查看内存中最近未使用过的区域，然后将其复制到硬盘上。</p> \n <p>虚拟内存通过复制技术实现了 。</p> \n <p>复制是自动进行的，你无法感知到它的存在。</p> \n <h3><a id=\"_3696\"></a>聊聊：虚拟内存的实现方式</h3> \n <p>虚拟内存中，允许将一个作业分多次调入内存。釆用连续分配方式时，会使相当一部分内存空间都处于暂时或<code>永久</code>的空闲状态，造成内存资源的严重浪费，而且也无法从逻辑上扩大内存容量。因此，虚拟内存的实需要建立在离散分配的内存管理方式的基础上。</p> \n <p>虚拟内存的实现有以下三种方式：</p> \n <ul>\n  <li>请求分页存储管理。</li>\n  <li>请求分段存储管理。</li>\n  <li>请求段页式存储管理。</li>\n </ul> \n <p>不管哪种方式，都需要有一定的硬件支持。一般需要的支持有以下几个方面：</p> \n <ul>\n  <li>一定容量的内存和外存。</li>\n  <li>页表机制（或段表机制），作为主要的数据结构。</li>\n  <li>中断机构，当用户程序要访问的部分尚未调入内存，则产生中断。</li>\n  <li>地址变换机构，逻辑地址到物理地址的变换。</li>\n </ul> \n <h3><a id=\"_3713\"></a>聊聊：内存为什么要分段</h3> \n <p>内存是随机访问设备，对于内存来说，不需要从头开始查找，只需要直接给出地址即可。内存的分段是从 <code>8086 CPU</code> 开始的，8086 的 CPU 还是 16 位的寄存器宽，16 位的寄存器可以存储的数字范围是 2 的 16 次方，即 64 KB，8086 的 CPU 还没有 <code>虚拟地址</code>，只有物理地址，也就是说，如果两个相同的程序编译出来的地址相同，那么这两个程序是无法同时运行的。为了解决这个问题，操作系统设计人员提出了让 CPU 使用 <code>段基址 + 段内偏移</code> 的方式来访问任意内存。这样的好处是让程序可以 <code>重定位</code>，<strong>这也是内存为什么要分段的第一个原因</strong>。</p> \n <blockquote> \n  <p>那么什么是重定位呢？</p> \n </blockquote> \n <p>简单来说就是将程序中的指令地址改为另一个地址，地址处存储的内容还是原来的。</p> \n <p>CPU 采用段基址 + 段内偏移地址的形式访问内存，就需要提供专门的寄存器，这些专门的寄存器就是 <strong>CS、DS、ES 等</strong></p> \n <p>也就是说，程序中需要用到哪块内存，就需要先加载合适的段到段基址寄存器中，再给出相对于该段基址的段偏移地址即可。</p> \n <p>CPU 中的地址加法器会将这两个地址进行合并，从地址总线送入内存。</p> \n <p>8086 的 CPU 有 20 根地址总线，最大的寻址能力是 1MB，而段基址所在的寄存器宽度只有 16 位，最大为你 64 KB 的寻址能力，64 KB 显然不能满足 1MB 的最大寻址范围，所以就要把内存分段，每个段的最大寻址能力是 64KB，但是仍旧不能达到最大 1 MB 的寻址能力，所以这时候就需要 <code>偏移地址</code>的辅助，偏移地址也存入寄存器，同样为 64 KB 的寻址能力，这么一看还是不能满足 1MB 的寻址，所以 CPU 的设计者对地址单元动了手脚，将段基址左移 4 位，然后再和 16 位的段内偏移地址相加，就达到了 1MB 的寻址能力。</p> \n <p><strong>所以内存分段的第二个目的就是能够访问到所有内存</strong>。</p> \n <h3><a id=\"_3731\"></a>聊聊：物理地址、逻辑地址、有效地址、线性地址、虚拟地址的区别</h3> \n <p>物理地址就是内存中真正的地址，它就相当于是你家的门牌号，你家就肯定有这个门牌号，具有唯一性。</p> \n <p><strong>不管哪种地址，最终都会映射为物理地址</strong>。</p> \n <p>在实模式下，段基址 + 段内偏移经过地址加法器的处理，经过地址总线传输，最终也会转换为物理地址。</p> \n <p>但是在保护模式下，段基址 + 段内偏移被称为线性地址，不过此时的段基址不能称为真正的地址，而是会被称作为一个选择子的东西，选择子就是个索引，相当于数组的下标，通过这个索引能够在 GDT 中找到相应的段描述符，段描述符记录了<strong>段的起始、段的大小</strong>等信息，这样便得到了基地址。</p> \n <p>如果此时没有开启内存分页功能，那么这个线性地址可以直接当做物理地址来使用，直接访问内存。如果开启了分页功能，那么这个线性地址又多了一个名字，这个名字就是虚拟地址。</p> \n <p>不论在实模式还是保护模式下，段内偏移地址都叫做有效地址。有效抵制也是逻辑地址。</p> \n <p>线性地址可以看作是虚拟地址，虚拟地址不是真正的物理地址，但是虚拟地址会最终被映射为物理地址。</p> \n <p>下面是虚拟地址 -&gt; 物理地址的映射。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/65e5184eb68bfed16620575d637f6fc8.png\" alt=\"\"></p> \n <h3><a id=\"_3752\"></a>聊聊：空闲内存管理的方式</h3> \n <p>操作系统在动态分配内存时（malloc，new），需要对空间内存进行管理。一般采用了两种方式：位图和空闲链表。</p> \n <h4><a id=\"_3756\"></a>使用位图进行管理</h4> \n <p>使用位图方法时，内存可能被划分为小到几个字或大到几千字节的分配单元。每个分配单元对应于位图中的一位，0 表示空闲， 1 表示占用（或者相反）。一块内存区域和其对应的位图如下</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/8fb44bba6b5da2e1c9ce899279920c17.png\" alt=\"\"></p> \n <blockquote> \n  <p>图 a 表示一段有 5 个进程和 3 个空闲区的内存，刻度为内存分配单元，阴影区表示空闲（在位图中用 0 表示）；图 b 表示对应的位图；图 c 表示用链表表示同样的信息</p> \n </blockquote> \n <p>分配单元的大小是一个重要的设计因素，分配单位越小，位图越大。然而，即使只有 4 字节的分配单元，32 位的内存也仅仅只需要位图中的 1 位。<code>32n</code> 位的内存需要 n 位的位图，所以<strong>1 个位图只占用了 1/32 的内存</strong>。如果选择更大的内存单元，位图应该要更小。如果进程的大小不是分配单元的整数倍，那么在最后一个分配单元中会有大量的内存被浪费。</p> \n <p><code>位图</code>提供了一种简单的方法在固定大小的内存中跟踪内存的使用情况，因为<strong>位图的大小取决于内存和分配单元的大小</strong>。这种方法有一个问题，当决定为把具有 k 个分配单元的进程放入内存时，<code>内容管理器(memory manager)</code> 必须搜索位图，在位图中找出能够运行 k 个连续 0 位的串。在位图中找出制定长度的连续 0 串是一个很耗时的操作，这是位图的缺点。（可以简单理解为在杂乱无章的数组中，找出具有一大长串空闲的数组单元）</p> \n <h4><a id=\"_3768\"></a>使用空闲链表</h4> \n <p>另一种记录内存使用情况的方法是，维护一个记录已分配内存段和空闲内存段的链表，段会包含进程或者是两个进程的空闲区域。可用上面的图 c <strong>来表示内存的使用情况</strong>。链表中的每一项都可以代表一个 <code>空闲区(H)</code> 或者是<code>进程(P)</code>的起始标志，长度和下一个链表项的位置。</p> \n <p>在这个例子中，<code>段链表(segment list)</code>是按照地址排序的。这种方式的优点是，当进程终止或被交换时，更新列表很简单。一个终止进程通常有两个邻居（除了内存的顶部和底部外）。相邻的可能是进程也可能是空闲区，它们有四种组合方式。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/ac2910d4c57867a995aba278ca15e878.png\" alt=\"\"></p> \n <p>当按照地址顺序在链表中存放进程和空闲区时，有几种算法可以为创建的进程（或者从磁盘中换入的进程）分配内存。</p> \n <ul>\n  <li>首次适配算法：在链表中进行搜索，直到找到最初的一个足够大的空闲区，将其分配。除非进程大小和空间区大小恰好相同，否则会将空闲区分为两部分，一部分为进程使用，一部分成为新的空闲区。该方法是速度很快的算法，因为索引链表结点的个数较少。</li>\n  <li>下次适配算法：工作方式与首次适配算法相同，但每次找到新的空闲区位置后都记录当前位置，下次寻找空闲区从上次结束的地方开始搜索，而不是与首次适配放一样从头开始；</li>\n  <li>最佳适配算法：搜索整个链表，找出能够容纳进程分配的最小的空闲区。这样存在的问题是，尽管可以保证为进程找到一个最为合适的空闲区进行分配，但大多数情况下，这样的空闲区被分为两部分，一部分用于进程分配，一部分会生成很小的空闲区，而这样的空闲区很难再被进行利用。</li>\n  <li>最差适配算法：与最佳适配算法相反，每次分配搜索最大的空闲区进行分配，从而可以使得空闲区拆分得到的新的空闲区可以更好的被进行利用。</li>\n </ul> \n <h3><a id=\"_3787\"></a>聊聊：什么是交换空间？</h3> \n <p>操作系统把物理内存(physical RAM)分成一块一块的小内存，每一块内存被称为<strong>页(page)</strong>。当内存资源不足时，<strong>Linux把某些页的内容转移至硬盘上的一块空间上，以释放内存空间</strong>。硬盘上的那块空间叫做<strong>交换空间</strong>(swap space),而这一过程被称为交换(swapping)。<strong>物理内存和交换空间的总容量就是虚拟内存的可用容量。</strong></p> \n <p>用途：</p> \n <ul>\n  <li>物理内存不足时一些不常用的页可以被交换出去，腾给系统。</li>\n  <li>程序启动时很多内存页被用来初始化，之后便不再需要，可以交换出去。</li>\n </ul> \n <h3><a id=\"_3798\"></a>聊聊：什么是缓冲区溢出？有什么危害？</h3> \n <p>缓冲区溢出是指当计算机向缓冲区填充数据时超出了缓冲区本身的容量，溢出的数据覆盖在合法数据上。</p> \n <p>危害有以下两点：</p> \n <ul>\n  <li>程序崩溃，导致拒绝额服务</li>\n  <li>跳转并且执行一段恶意代码</li>\n </ul> \n <p>造成缓冲区溢出的主要原因是程序中没有仔细检查用户输入。</p> \n <h3><a id=\"_3813\"></a>聊聊：用户态（模式）与内核态（模式）</h3> \n <p>用户态和系统态是操作系统的两种运行状态：</p> \n <p>内核态：内核态运行的程序可以访问计算机的任何数据和资源，不受限制，包括外围设备，比如网卡、硬盘等。处于内核态的 CPU 可以从一个程序切换到另外一个程序，并且占用 CPU 不会发生抢占情况。切换进程，拥有最高权限。<br> 用户态：用户态运行的程序只能受限地访问内存，只能直接读取用户程序的数据，并且不允许访问外围设备，用户态下的 CPU 不允许独占，也就是说 CPU 能够被其他程序获取。<strong>大部分用户直接面对的程序都是运行在用户态</strong></p> \n <p>将操作系统的运行状态分为用户态和内核态，主要是为了对访问能力进行限制，防止随意进行一些比较危险的操作导致系统的崩溃，比如设置时钟、内存清理，这些都需要在内核态下完成 。</p> \n <p>用户模式和内核模式最根本区别就是是否拥有对硬件的控制权。</p> \n <p>如果用户模式想操作硬件，这时操作系统可以暴露一些借口给我们，比如创建销毁进程，让用户分配更多内存等操作。等几百个API供用户模式使用。</p> \n <h3><a id=\"3_3826\"></a>聊聊：用户态切换到内核态的3种方式</h3> \n <ol>\n  <li>系统调用<br> 这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使 用操作系统提供的服务程序完成工作，比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户 特别开放的一个中断来实现，例如Linux的int 80h中断。</li>\n  <li>外围设备的中断<br> 硬件中断，进程执行过程中，好比说用户点击了什么按钮，触发了按键中断，要赶紧去处理这个中断啊，保存进程上下文，切换到中断处理流程，处理完了，恢复进程上下文，返回用户态（返回之前可能会进行进程调度，选择一个更值得运行的进程投入运行态），进程继续执行</li>\n  <li>异常<br> 当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。</li>\n </ol> \n <h2><a id=\"_3841\"></a>文件系统篇</h2> \n <h3><a id=\"_3843\"></a>聊聊：如何提高文件系统性能的方式</h3> \n <p>访问磁盘的效率要比内存慢很多，具体如下图</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/7483542ef0d8fd2311b9578aa2458bbc.png\" alt=\"\"></p> \n <p>所以磁盘优化是很有必要的，下面我们会讨论几种优化方式</p> \n <h4><a id=\"_3851\"></a>高速缓存</h4> \n <p>最常用的减少磁盘访问次数的技术是使用 <code>块高速缓存(block cache)</code> 或者 <code>缓冲区高速缓存(buffer cache)</code>。高速缓存指的是一系列的块，它们在逻辑上属于磁盘，但实际上基于性能的考虑被保存在内存中。</p> \n <p>管理高速缓存有不同的算法，常用的算法是：检查全部的读请求，查看在高速缓存中是否有所需要的块。如果存在，可执行读操作而无须访问磁盘。如果检查块不再高速缓存中，那么首先把它读入高速缓存，再复制到所需的地方。之后，对同一个块的请求都通过<code>高速缓存</code>来完成。</p> \n <p>高速缓存的操作如下图所示</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/df73002e57f57a35bcb57ec683a146d9.png\" alt=\"\"></p> \n <p>由于在高速缓存中有许多块，所以需要某种方法快速确定所需的块是否存在。常用方法是将设备和磁盘地址进行散列操作。然后在散列表中查找结果。具有相同散列值的块在一个链表中连接在一起（这个数据结构是不是很像 HashMap?），这样就可以沿着冲突链查找其他块。</p> \n <p>如果高速缓存<code>已满</code>，此时需要调入新的块，则要把原来的某一块调出高速缓存，如果要调出的块在上次调入后已经被修改过，则需要把它写回磁盘。这种情况与分页非常相似。</p> \n <h4><a id=\"_3865\"></a>块提前读</h4> \n <p>第二个明显提高文件系统的性能是<strong>在需要用到块之前试图提前将其写入高速缓存从而提高命中率</strong>。许多文件都是<code>顺序读取</code>。如果请求文件系统在某个文件中生成块 k，文件系统执行相关操作并且在完成之后，会检查高速缓存，以便确定块 k + 1 是否已经在高速缓存。如果不在，文件系统会为 k + 1 安排一个预读取，因为文件希望在用到该块的时候能够直接从高速缓存中读取。</p> \n <p>当然，块提前读取策略只适用于实际顺序读取的文件。对随机访问的文件，提前读丝毫不起作用。甚至还会造成阻碍。</p> \n <h4><a id=\"_3871\"></a>减少磁盘臂运动</h4> \n <p>高速缓存和块提前读并不是提高文件系统性能的唯一方法。另一种重要的技术是<strong>把有可能顺序访问的块放在一起，当然最好是在同一个柱面上，从而减少磁盘臂的移动次数</strong>。当写一个输出文件时，文件系统就必须按照要求一次一次地分配磁盘块。如果用位图来记录空闲块，并且整个位图在内存中，那么选择与前一块最近的空闲块是很容易的。如果用空闲表，并且链表的一部分存在磁盘上，要分配紧邻的空闲块就会困难很多。</p> \n <p>不过，即使采用空闲表，也可以使用 <code>块簇</code> 技术。即不用块而用连续块簇来跟踪磁盘存储区。如果一个扇区有 512 个字节，有可能系统采用 1 KB 的块（2 个扇区），但却按每 2 块（4 个扇区）一个单位来分配磁盘存储区。这和 2 KB 的磁盘块并不相同，因为在高速缓存中它仍然使用 1 KB 的块，磁盘与内存数据之间传送也是以 1 KB 进行，但在一个空闲的系统上顺序读取这些文件，寻道的次数可以减少一半，从而使文件系统的性能大大改善。若考虑旋转定位则可以得到这类方法的变体。在分配块时，系统尽量把一个文件中的连续块存放在同一个柱面上。</p> \n <p>在使用 inode 或任何类似 inode 的系统中，另一个性能瓶颈是，读取一个很短的文件也需要两次磁盘访问：<strong>一次是访问 inode，一次是访问块</strong>。通常情况下，inode 的放置如下图所示</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/6c773e9c115f5d6d2329d60fa7331293.png\" alt=\"\"></p> \n <p>其中，全部 inode 放在靠近磁盘开始位置，所以 inode 和它所指向的块之间的平均距离是柱面组的一半，这将会需要较长时间的寻道时间。</p> \n <p>一个简单的改进方法是，在磁盘中部而不是开始处存放 inode ，此时，在 inode 和第一个块之间的寻道时间减为原来的一半。另一种做法是：将磁盘分成多个柱面组，每个柱面组有自己的 inode，数据块和空闲表，如上图 b 所示。</p> \n <p>当然，只有在磁盘中装有磁盘臂的情况下，讨论寻道时间和旋转时间才是有意义的。现在越来越多的电脑使用 <code>固态硬盘(SSD)</code>，对于这些硬盘，由于采用了和闪存同样的制造技术，使得随机访问和顺序访问在传输速度上已经较为相近，传统硬盘的许多问题就消失了。但是也引发了新的问题。</p> \n <h4><a id=\"_3887\"></a>磁盘碎片整理</h4> \n <p>在初始安装操作系统后，文件就会被不断的创建和清除，于是磁盘会产生很多的碎片，在创建一个文件时，它使用的块会散布在整个磁盘上，降低性能。删除文件后，回收磁盘块，可能会造成空穴。</p> \n <p>磁盘性能可以通过如下方式恢复：移动文件使它们相互挨着，并把所有的至少是大部分的空闲空间放在一个或多个大的连续区域内。Windows 有一个程序 <code>defrag</code> 就是做这个事儿的。Windows 用户会经常使用它，SSD 除外。</p> \n <p>磁盘碎片整理程序会在让文件系统上很好地运行。Linux 文件系统（特别是 ext2 和 ext3）由于其选择磁盘块的方式，在磁盘碎片整理上一般不会像 Windows 一样困难，因此很少需要手动的磁盘碎片整理。而且，固态硬盘并不受磁盘碎片的影响，事实上，在固态硬盘上做磁盘碎片整理反倒是多此一举，不仅没有提高性能，反而磨损了固态硬盘。所以碎片整理只会缩短固态硬盘的寿命。</p> \n <h3><a id=\"_3895\"></a>聊聊：磁盘臂调度算法</h3> \n <p>一般情况下，影响磁盘快读写的时间由下面几个因素决定</p> \n <ul>\n  <li>寻道时间 - 寻道时间指的就是将磁盘臂移动到需要读取磁盘块上的时间</li>\n  <li>旋转延迟 - 等待合适的扇区旋转到磁头下所需的时间</li>\n  <li>实际数据的读取或者写入时间</li>\n </ul> \n <p>这三种时间参数也是磁盘寻道的过程。一般情况下，寻道时间对总时间的影响最大，所以，有效的降低寻道时间能够提高磁盘的读取速度。</p> \n <p>如果磁盘驱动程序每次接收一个请求并按照接收顺序完成请求，这种处理方式也就是 <code>先来先服务(First-Come, First-served, FCFS)</code> ，这种方式很难优化寻道时间。因为每次都会按照顺序处理，不管顺序如何，有可能这次读完后需要等待一个磁盘旋转一周才能继续读取，而其他柱面能够马上进行读取，这种情况下每次请求也会排队。</p> \n <p>通常情况下，磁盘在进行寻道时，其他进程会产生其他的磁盘请求。磁盘驱动程序会维护一张表，表中会记录着柱面号当作索引，每个柱面未完成的请求会形成链表，链表头存放在表的相应表项中。</p> \n <p>一种对先来先服务的算法改良的方案是使用 <code>最短路径优先(SSF)</code> 算法，下面描述了这个算法。</p> \n <p>假如我们在对磁道 6 号进行寻址时，同时发生了对 11 , 2 , 4, 14, 8, 15, 3 的请求，如果采用先来先服务的原则，如下图所示</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/ada1f317c01b80a990c1fff9814dd5cb.png\" alt=\"\"></p> \n <p>我们可以计算一下磁盘臂所跨越的磁盘数量为 5 + 9 + 2 + 10 + 6 + 7 + 12 = 51，相当于是跨越了 51 次盘面，如果使用最短路径优先，我们来计算一下跨越的盘面</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/922a6bf067b7ad3774ce04dcb1b04026.png\" alt=\"\"></p> \n <p>跨越的磁盘数量为 4 + 1 + 1 + 4 + 3 + 3 + 1 = 17 ，相比 51 足足省了两倍的时间。</p> \n <p>但是，最短路径优先的算法也不是完美无缺的，这种算法照样存在问题，那就是<code>优先级</code> 问题，</p> \n <p>这里有一个原型可以参考就是我们日常生活中的电梯，电梯使用一种<code>电梯算法(elevator algorithm)</code> 来进行调度，从而满足协调效率和公平性这两个相互冲突的目标。电梯一般会保持向一个方向移动，直到在那个方向上没有请求为止，然后改变方向。</p> \n <p>电梯算法需要维护一个<code>二进制位</code>，也就是当前的方向位：<code>UP(向上)</code>或者是 <code>DOWN(向下)</code>。当一个请求处理完成后，磁盘或电梯的驱动程序会检查该位，如果此位是 UP 位，磁盘臂或者电梯仓移到下一个更高跌未完成的请求。如果高位没有未完成的请求，则取相反方向。当方向位是 <code>DOWN</code>时，同时存在一个低位的请求，磁盘臂会转向该点。如果不存在的话，那么它只是停止并等待。</p> \n <p>我们举个例子来描述一下电梯算法，比如各个柱面得到服务的顺序是 4，7，10，14，9，6，3，1 ，那么它的流程图如下</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/3ed6a4dc52294da67e1261210dd79729.png\" alt=\"\"></p> \n <p>所以电梯算法需要跨越的盘面数量是 3 + 3 + 4 + 5 + 3 + 3 + 1 = 22</p> \n <p>电梯算法通常情况下不如 SSF 算法。</p> \n <p>一些磁盘控制器为软件提供了一种检查磁头下方当前扇区号的方法，使用这样的控制器，能够进行另一种优化。如果对一个相同的柱面有两个或者多个请求正等待处理，驱动程序可以发出请求读写下一次要通过磁头的扇区。</p> \n <blockquote> \n  <p>这里需要注意一点，当一个柱面有多条磁道时，相继的请求可能针对不同的磁道，这种选择没有代价，因为选择磁头不需要移动磁盘臂也没有旋转延迟。</p> \n </blockquote> \n <p>对于磁盘来说，最影响性能的就是寻道时间和旋转延迟，所以一次只读取一个或两个扇区的效率是非常低的。出于这个原因，许多磁盘控制器总是读出多个扇区并进行高速缓存，即使只请求一个扇区时也是这样。一般情况下读取一个扇区的同时会读取该扇区所在的磁道或者是所有剩余的扇区被读出，读出扇区的数量取决于控制器的高速缓存中有多少可用的空间。</p> \n <p>磁盘控制器的高速缓存和操作系统的高速缓存有一些不同，磁盘控制器的高速缓存用于缓存没有实际被请求的块，而操作系统维护的高速缓存由显示地读出的块组成，并且操作系统会认为这些块在近期仍然会频繁使用。</p> \n <p>当同一个控制器上有多个驱动器时，操作系统应该为每个驱动器都单独的维护一个未完成的请求表。一旦有某个驱动器闲置时，就应该发出一个寻道请求来将磁盘臂移到下一个被请求的柱面。如果下一个寻道请求到来时恰好没有磁盘臂处于正确的位置，那么驱动程序会在刚刚完成传输的驱动器上发出一个新的寻道命令并等待，等待下一次中断到来时检查哪个驱动器处于闲置状态。</p> \n <h3><a id=\"RAID__3945\"></a>聊聊：RAID 的不同级别</h3> \n <p>RAID 称为 <code>磁盘冗余阵列</code>，简称 <code>磁盘阵列</code>。利用虚拟化技术把多个硬盘结合在一起，成为一个或多个磁盘阵列组，目的是提升性能或数据冗余。</p> \n <p>RAID 有不同的级别</p> \n <ul>\n  <li>RAID 0 - 无容错的条带化磁盘阵列</li>\n  <li>RAID 1 - 镜像和双工</li>\n  <li>RAID 2 - 内存式纠错码</li>\n  <li>RAID 3 - 比特交错奇偶校验</li>\n  <li>RAID 4 - 块交错奇偶校验</li>\n  <li>RAID 5 - 块交错分布式奇偶校验</li>\n  <li>RAID 6 - P + Q冗余</li>\n </ul> \n <h2><a id=\"IO__3959\"></a>IO 篇</h2> \n <h3><a id=\"_3961\"></a>聊聊：操作系统中的时钟是什么</h3> \n <p><code>时钟(Clocks)</code> 也被称为<code>定时器(timers)</code>，时钟/定时器对任何程序系统来说都是必不可少的。</p> \n <p>时钟负责维护时间、防止一个进程长期占用 CPU 时间等其他功能。</p> \n <p><code>时钟软件(clock software)</code> 也是一种设备驱动的方式。</p> \n <p>下面我们就来对时钟进行介绍，一般都是先讨论硬件再介绍软件，采用由下到上的方式，也是告诉你，底层是最重要的。</p> \n <h4><a id=\"_3971\"></a>时钟硬件</h4> \n <p>在计算机中有两种类型的时钟，这些时钟与现实生活中使用的时钟完全不一样。</p> \n <ul>\n  <li>比较简单的一种时钟被连接到 110 V 或 220 V 的电源线上，这样每个<code>电压周期</code>会产生一个中断，大概是 50 - 60 HZ。这些时钟过去一直占据支配地位。</li>\n  <li>另外的一种时钟由晶体振荡器、计数器和寄存器组成，示意图如下所示</li>\n </ul> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/f4f38c8a54dad02a8699e88af9211ea4.png\" alt=\"\"></p> \n <p>这种时钟称为<code>可编程时钟</code> ，可编程时钟有两种模式，</p> \n <p>一种是 <code>一键式(one-shot mode)</code>，当时钟启动时，会把存储器中的值复制到计数器中，然后，每次晶体的振荡器的脉冲都会使计数器 -1。当计数器变为 0 时，会产生一个中断，并停止工作，直到软件再一次显示启动。</p> \n <p>还有一种模式时 <code>方波(square-wave mode)</code> 模式，在这种模式下，当计数器变为 0 并产生中断后，存储寄存器的值会自动复制到计数器中，这种周期性的中断称为一个时钟周期。</p> \n <h3><a id=\"_3986\"></a>聊聊：设备控制器的主要功能</h3> \n <p>设备控制器是一个<code>可编址</code>的设备，当它仅控制一个设备时，它只有一个唯一的设备地址；</p> \n <p>如果设备控制器控制多个可连接设备时，则应含有多个设备地址，并使每一个设备地址对应一个设备。</p> \n <p>设备控制器主要分为两种：字符设备和块设备</p> \n <p>设备控制器的主要功能有下面这些</p> \n <ul>\n  <li>接收和识别命令：设备控制器可以接受来自 CPU 的指令，并进行识别。设备控制器内部也会有寄存器，用来存放指令和参数</li>\n  <li>进行数据交换：CPU、控制器和设备之间会进行数据的交换，CPU 通过总线把指令发送给控制器，或从控制器中并行地读出数据；控制器将数据写入指定设备。</li>\n  <li>地址识别：每个硬件设备都有自己的地址，设备控制器能够识别这些不同的地址，来达到控制硬件的目的，此外，为使 CPU 能向寄存器中写入或者读取数据，这些寄存器都应具有唯一的地址。</li>\n  <li>差错检测：设备控制器还具有对设备传递过来的数据进行检测的功能。</li>\n </ul> \n <h3><a id=\"_4001\"></a>聊聊：中断处理过程</h3> \n <p>中断处理方案有很多种，下面是 《<strong>ARM System Developer’s Guide</strong></p> \n <p><strong>Designing and Optimizing System Software</strong>》列出来的一些方案</p> \n <ul>\n  <li><code>非嵌套</code>的中断处理程序按照顺序处理各个中断，非嵌套的中断处理程序也是最简单的中断处理</li>\n  <li><code>嵌套</code>的中断处理程序会处理多个中断而无需分配优先级</li>\n  <li><code>可重入</code>的中断处理程序可使用优先级处理多个中断</li>\n  <li><code>简单优先级</code>中断处理程序可处理简单的中断</li>\n  <li><code>标准优先级</code>中断处理程序比低优先级的中断处理程序在更短的时间能够处理优先级更高的中断</li>\n  <li><code>高优先级</code> 中断处理程序在短时间能够处理优先级更高的任务，并直接进入特定的服务例程。</li>\n  <li><code>优先级分组</code>中断处理程序能够处理不同优先级的中断任务</li>\n </ul> \n <p>下面是一些通用的中断处理程序的步骤，不同的操作系统实现细节不一样</p> \n <ul>\n  <li>保存所有没有被中断硬件保存的寄存器</li>\n  <li>为中断服务程序设置上下文环境，可能包括设置 <code>TLB</code>、<code>MMU</code> 和页表，如果不太了解这三个概念，请参考另外一篇文章</li>\n  <li>为中断服务程序设置栈</li>\n  <li>对中断控制器作出响应，如果不存在集中的中断控制器，则继续响应中断</li>\n  <li>把寄存器从保存它的地方拷贝到进程表中</li>\n  <li>运行中断服务程序，它会从发出中断的设备控制器的寄存器中提取信息</li>\n  <li>操作系统会选择一个合适的进程来运行。如果中断造成了一些优先级更高的进程变为就绪态，则选择运行这些优先级高的进程</li>\n  <li>为进程设置 MMU 上下文，可能也会需要 TLB，根据实际情况决定</li>\n  <li>加载进程的寄存器，包括 PSW 寄存器</li>\n  <li>开始运行新的进程</li>\n </ul> \n <p>上面我们罗列了一些大致的中断步骤，不同性质的操作系统和中断处理程序能够处理的中断步骤和细节也不尽相同，下面是一个嵌套中断的具体运行步骤</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/282c5ad33dca523c85f046c84de9b1ee.png\" alt=\"\"></p> \n <h3><a id=\"_4032\"></a>聊聊：什么是设备驱动程序</h3> \n <p>在计算机中，设备驱动程序是一种计算机程序，它能够控制或者操作连接到计算机的特定设备。驱动程序提供了与硬件进行交互的软件接口，使操作系统和其他计算机程序能够访问特定设备，不用需要了解其硬件的具体构造。</p> \n <h3><a id=\"_DMA_4036\"></a>聊聊：什么是 DMA</h3> \n <p>DMA 的中文名称是直接内存访问，它意味着 CPU 授予 I/O 模块权限在不涉及 CPU 的情况下读取或写入内存。也就是 DMA 可以不需要 CPU 的参与。</p> \n <p>这个过程由称为 DMA 控制器（DMAC）的芯片管理。由于 DMA 设备可以直接在内存之间传输数据，而不是使用 CPU 作为中介，因此可以缓解总线上的拥塞。</p> \n <p>DMA 通过允许 CPU 执行任务，同时 DMA 系统通过系统和内存总线传输数据来提高系统并发性。</p> \n <h3><a id=\"_4046\"></a>聊聊：直接内存访问的特点</h3> \n <p>DMA 方式有如下特点：</p> \n <ul>\n  <li>数据传送以数据块为基本单位</li>\n  <li>所传送的数据从设备直接送入主存，或者从主存直接输出到设备上</li>\n  <li>仅在传送一个或多个数据块的开始和结束时才需 CPU 的干预，而整块数据的传送则是在控制器的控制下完成。</li>\n </ul> \n <p>DMA 方式和中断驱动控制方式相比，减少了 CPU 对 I/O 操作的干预，进一步提高了 CPU 与 I/O 设备的并行操作程度。</p> \n <p>DMA 方式的线路简单、价格低廉，适合高速设备与主存之间的成批数据传送，小型、微型机中的快速设备均采用这种方式，但其功能较差，不能满足复杂的 I/O 要求。</p> \n <h3><a id=\"IO_4062\"></a>聊聊：IO多路复用？</h3> \n <p><strong>IO多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，它就通知该进程。IO多路复用适用如下场合</strong>：</p> \n <ul>\n  <li>当客户处理多个描述字时（一般是交互式输入和网络套接口），必须使用I/O复用。</li>\n  <li>当一个客户同时处理多个套接口时，而这种情况是可能的，但很少出现。</li>\n  <li>如果一个TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到I/O复用。</li>\n  <li>如果一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用。</li>\n  <li>如果一个服务器要处理多个服务或多个协议，一般要使用I/O复用。</li>\n  <li>与多进程和多线程技术相比，I/O多路复用技术的最大优势是系统开销小，系统不必创建进程/线程，也不必维护这些进程/线程，从而大大减小了系统的开销。</li>\n </ul> \n <h3><a id=\"_4073\"></a>聊聊：硬链接和软链接有什么区别？</h3> \n <ul>\n  <li>硬链接就是在目录下创建一个条目，记录着文件名与 <code>inode</code> 编号，这个 <code>inode</code> 就是源文件的 <code>inode</code>。删除任意一个条目，文件还是存在，只要引用数量不为 <code>0</code>。但是硬链接有限制，它不能跨越文件系统，也不能对目录进行链接。</li>\n  <li>符号链接文件保存着源文件所在的绝对路径，在读取时会定位到源文件上，可以理解为 <code>Windows</code> 的快捷方式。当源文件被删除了，链接文件就打不开了。因为记录的是路径，所以可以为目录建立符号链接。</li>\n </ul> \n <h3><a id=\"_4080\"></a>聊聊：大小端模式</h3> \n <p>大端模式（Big-Endian）：指的是数据的低位保存在内存的高地址中，而数据的高位保存在内存的低地址中.</p> \n <p>小端模式（Little-Endian）：指的是数据的低位保存在内存的低地址中，而数据的高位保存在内存的高地址中</p> \n <p>本文收录于《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124790425\">尼恩Java面试宝典</a>》</p> \n <h2><a id=\"_4094\"></a>推荐阅读：</h2> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128670335\">Docker面试题（史上最全 + 持续更新）</a>》<br> 《 <a href=\"https://blog.csdn.net/crazymakercircle/article/details/128533821\">场景题：假设10W人突访，你的系统如何做到不 雪崩？</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124790425\">尼恩Java面试宝典</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057567\">Springcloud gateway 底层原理、核心实战 (史上最全)</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124120506\">Flux、Mono、Reactor 实战（史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125059491\">sentinel （史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057545\">Nacos (史上最全)</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/123420859\">分库分表 Sharding-JDBC 底层原理、核心实战（史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/114527369\">TCP协议详解 (史上最全)</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126992542\">clickhouse 超底层原理 + 高可用实操 （史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120702536\">nacos高可用（图解+秒懂+史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264803\">队列之王： Disruptor 原理、架构、源码 一文穿透</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264508\">环形队列、 条带环形队列 Striped-RingBuffer （史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125135726\">一文搞定：SpringBoot、SLF4j、Log4j、Logback、Netty之间混乱关系（史上最全）</a><br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128265067\">单例模式（史上最全）</a><br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125017316\">红黑树（ 图解 + 秒懂 + 史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/109459593\">分布式事务 （秒懂）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128123114\">缓存之王：Caffeine 源码、架构、原理（史上最全，10W字 超级长文）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/113751575\">缓存之王：Caffeine 的使用（史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126579528\">Java Agent 探针、字节码增强 ByteBuddy（史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120747767\">Docker原理（图解+秒懂+史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/116425814\">Redis分布式锁（图解 - 秒懂 - 史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85956246\">Zookeeper 分布式锁 - 图解 - 秒懂</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85922561\">Zookeeper Curator 事件监听 - 10分钟看懂</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83957259\">Netty 粘包 拆包 | 史上最全解读</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83758107\">Netty 100万级高并发服务器配置</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/102557988\">Springcloud 高并发 配置 （一文全懂）</a>》</p> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 1116);
INSERT INTO `crawlerblog` VALUES (123124015, 'Springcloud gateway (史上最全)', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <p>文章很长，而且持续更新，建议收藏起来，慢慢读！<a href=\"https://www.yuque.com/crazymakercircle/gkkw8s/khigna\"><strong>疯狂创客圈总目录 语雀版</strong></a> | <a href=\"https://gitee.com/crazymaker/SimpleCrayIM/blob/master/%E7%96%AF%E7%8B%82%E5%88%9B%E5%AE%A2%E5%9C%88%E6%80%BB%E7%9B%AE%E5%BD%95.md\"><strong>总目录 码云版</strong></a>| <a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\"><strong>总目录 博客园版</strong></a> 为您奉上珍贵的学习资源 ：</p> \n <ul>\n  <li> <p><strong>免费赠送 :<a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\">《尼恩Java面试宝典》持续更新+ 史上最全 + 面试必备 2000页+ </a> 面试必备 + 大厂必备 +涨薪必备</strong></p> </li>\n </ul> \n <ul>\n  <li> <p><strong>免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\">《Java高并发核心编程（卷1）》 </a> 面试必备 + 大厂必备 +涨薪必备</strong> 加尼恩免费领</p> </li>\n  <li> <p><strong>免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\">《Java高并发核心编程（卷2）》 </a> 面试必备 + 大厂必备 +涨薪必备</strong> 加尼恩免费领</p> </li>\n  <li> <p><strong>免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\">《Netty Zookeeper Redis 高并发实战》 </a> 面试必备 + 大厂必备 +涨薪必备</strong> 加尼恩免费领</p> </li>\n  <li> <p><strong>免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\">《SpringCloud Nginx高并发核心编程》 </a> 面试必备 + 大厂必备 +涨薪必备</strong> 加尼恩免费领</p> </li>\n  <li> <p><strong>免费赠送 资源宝库： Java 必备 百度网盘资源大合集 价值&gt;10000元</strong> <a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\">加尼恩领取</a> </p> </li>\n  <li><h2><a id=\"Java____httpswwwcnblogscomcrazymakercirclep13917138html_13\"></a>推荐：尼恩Java面试宝典（持续更新 + 史上最全 + 面试必备）<a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\">具体详情，请点击此链接</a></h2> <p>尼恩Java面试宝典，<strong>33个最新pdf</strong>，含<strong>2000多页</strong>，<strong>不断更新、持续迭代</strong> <a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\">具体详情，请点击此链接</a></p> <p><img src=\"https://img-blog.csdnimg.cn/d56e8af850e543e48f44ace26c437a78.png#pic_center#pic_center\" alt=\"在这里插入图片描述\"></p> \n   <hr> <h2><a id=\"1___SpringCloud_Gateway__21\"></a>1 SpringCloud Gateway 简介</h2> <p>SpringCloud Gateway 是 Spring Cloud 的一个全新项目，该项目是基于 Spring 5.0，Spring Boot 2.0 和 Project Reactor 等技术开发的网关，它旨在为微服务架构提供一种简单有效的统一的 API 路由管理方式。</p> <p>SpringCloud Gateway 作为 Spring Cloud 生态系统中的网关，目标是替代 Zuul，在Spring Cloud 2.0以上版本中，没有对新版本的Zuul 2.0以上最新高性能版本进行集成，仍然还是使用的Zuul 2.0之前的非Reactor模式的老版本。而为了提升网关的性能，SpringCloud Gateway是基于WebFlux框架实现的，而WebFlux框架底层则使用了高性能的Reactor模式通信框架Netty。</p> <p>Spring Cloud Gateway 的目标，不仅提供统一的路由方式，并且基于 Filter 链的方式提供了网关基本的功能，例如：安全，监控/指标，和限流。</p> <p><strong>特别说明</strong>：<br> Spring Cloud Gateway 底层使用了高性能的通信框架Netty。</p> <p>Netty 是高性能中间件的通讯底座， rocketmq 、seata、nacos 、sentinel 、redission 、dubbo 等太多、太多的的大名鼎鼎的中间件，无一例外都是基于netty。</p> <p>可以毫不夸张的说： <strong>netty 是进入大厂、走向高端 的必备技能</strong>。</p> <p>要想深入了解springcloud gateway ，<strong>最好是掌握netty 编程</strong>。</p> <p>有关 netty学习 具体请参见机工社出版 、尼恩的畅销书: <a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\">《<strong>Java高并发核心编程卷 1</strong>》</a></p> <h3><a id=\"11____Flux__Mono_reactor__41\"></a>1.1 本文姊妹篇 《Flux 和 Mono 、reactor实战 （史上最全）》</h3> <p>另外，如果要掌握 springcloud gateway 的过滤器编程，或者 掌握 springcloud gateway 开发，还必须：<br> <strong>具备 reactor 响应式编程的实战能力</strong></p> <p>有关 reactor 响应式编程的实战， 具体请参考本文姊妹篇：</p> <p><a href=\"https://www.cnblogs.com/crazymakercircle/p/16127013.html\">《Flux 和 Mono 、reactor实战 （史上最全）》</a></p> <h3><a id=\"12_____SpringCloud_Gateway__50\"></a>1.2 SpringCloud Gateway 特征</h3> <p>SpringCloud官方，对SpringCloud Gateway 特征介绍如下：</p> <p>（1）基于 Spring Framework 5，Project Reactor 和 Spring Boot 2.0</p> <p>（2）集成 Hystrix 断路器</p> <p>（3）集成 Spring Cloud DiscoveryClient</p> <p>（4）Predicates 和 Filters 作用于特定路由，易于编写的 Predicates 和 Filters</p> <p>（5）具备一些网关的高级功能：动态路由、限流、路径重写</p> <p>从以上的特征来说，和Zuul的特征差别不大。SpringCloud Gateway和Zuul主要的区别，还是在底层的通信框架上。</p> <p>简单说明一下上文中的三个术语：</p> <p><strong>（<strong>1</strong>）<strong>Filter</strong>（过滤器）</strong>：</p> <p>和Zuul的过滤器在概念上类似，可以使用它拦截和修改请求，并且对上游的响应，进行二次处理。过滤器为org.springframework.cloud.gateway.filter.GatewayFilter类的实例。</p> <p>（2）<strong>Route</strong>（路由）：</p> <p>网关配置的基本组成模块，和Zuul的路由配置模块类似。一个<strong>Route模块</strong>由一个 ID，一个目标 URI，一组断言和一组过滤器定义。如果断言为真，则路由匹配，目标URI会被访问。</p> <p><strong>（<strong>3</strong>）<strong>Predicate</strong>（断言）</strong>：</p> <p>这是一个 Java 8 的 Predicate，可以使用它来匹配来自 HTTP 请求的任何内容，例如 headers 或参数。<strong>断言的</strong>输入类型是一个 ServerWebExchange。</p> <h3><a id=\"13_____SpringCloud_Gateway_82\"></a><strong>1.3</strong> SpringCloud Gateway和架构</h3> <p>Spring在2017年下半年迎来了Webflux，Webflux的出现填补了Spring在响应式编程上的空白，Webflux的响应式编程不仅仅是编程风格的改变，而且对于一系列的著名框架，都提供了响应式访问的开发包，比如Netty、Redis等等。</p> <p>SpringCloud Gateway 使用的Webflux中的reactor-netty响应式编程组件，底层使用了Netty通讯框架。<br> <img src=\"https://img-blog.csdnimg.cn/img_convert/5e6132392b68db6ac788b7ce1bc11317.gif\" alt=\"在这里插入图片描述\"></p> <h3><a id=\"131_______SpringCloud_ZuulIO_93\"></a><strong>1.3.1</strong> SpringCloud Zuul的IO模型</h3> <p>Springcloud中所集成的Zuul版本，采用的是Tomcat容器，使用的是传统的Servlet IO处理模型。</p> <p>大家知道，servlet由servlet container进行生命周期管理。container启动时构造servlet对象并调用servlet init()进行初始化；container关闭时调用servlet destory()销毁servlet；container运行时接受请求，并为每个请求分配一个线程（一般从线程池中获取空闲线程）然后调用service()。</p> <p>弊端：servlet是一个简单的网络IO模型，当请求进入servlet container时，servlet container就会为其绑定一个线程，在并发不高的场景下这种模型是适用的，但是一旦并发上升，线程数量就会上涨，而线程资源代价是昂贵的（上线文切换，内存消耗大）严重影响请求的处理时间。在一些简单的业务场景下，不希望为每个request分配一个线程，只需要1个或几个线程就能应对极大并发的请求，这种业务场景下servlet模型没有优势。<br> <img src=\"https://img-blog.csdnimg.cn/img_convert/b55826b49f51733724b5016a9624c634.png\" alt=\"在这里插入图片描述\"></p> <p>所以Springcloud Zuul 是基于servlet之上的一个阻塞式处理模型，即spring实现了处理所有request请求的一个servlet（DispatcherServlet），并由该servlet阻塞式处理处理。所以Springcloud Zuul无法摆脱servlet模型的弊端。虽然Zuul 2.0开始，使用了Netty，并且已经有了大规模Zuul 2.0集群部署的成熟案例，但是，Springcloud官方已经没有集成改版本的计划了。</p> <h3><a id=\"132_______Webflux__107\"></a><strong>1.3.2</strong> Webflux 服务器</h3> <p>Webflux模式替换了旧的Servlet线程模型。用少量的线程处理request和response io操作，这些线程称为Loop线程，而业务交给响应式编程框架处理，响应式编程是非常灵活的，用户可以将业务中阻塞的操作提交到响应式框架的work线程中执行，而不阻塞的操作依然可以在Loop线程中进行处理，大大提高了Loop线程的利用率。官方结构图：</p> <p><img src=\"https://img-blog.csdnimg.cn/img_convert/ce74308cce70b47fd54b0075f4784dbe.png\" alt=\"在这里插入图片描述\"></p> <p>Webflux虽然可以兼容多个底层的通信框架，但是一般情况下，底层使用的还是Netty，毕竟，Netty是目前业界认可的最高性能的通信框架。而Webflux的Loop线程，正好就是著名的Reactor 模式IO处理模型的Reactor线程，如果使用的是高性能的通信框架Netty，这就是Netty的EventLoop线程。</p> <p>关于Reactor线程模型，和Netty通信框架的知识，是Java程序员的重要、必备的内功，个中的原理，具体请参见尼恩编著的《Netty、Zookeeper、Redis高并发实战》一书，这里不做过多的赘述。</p> <h3><a id=\"133________Spring_Cloud_Gateway_119\"></a><strong>1.3.3</strong> Spring Cloud Gateway的处理流程</h3> <p>客户端向 Spring Cloud Gateway 发出请求。然后在 Gateway Handler Mapping 中找到与请求相匹配的路由，将其发送到 Gateway Web Handler。Handler 再通过指定的过滤器链来将请求发送到我们实际的服务执行业务逻辑，然后返回。过滤器之间用虚线分开是因为过滤器可能会在发送代理请求之前（“pre”）或之后（“post”）执行业务逻辑。<br> <img src=\"https://img-blog.csdnimg.cn/img_convert/99004db1e9fa156ce999fe89ee1eda91.png\" alt=\"在这里插入图片描述\"></p> <h2><a id=\"2____124\"></a>2 路由配置方式</h2> <h3><a id=\"21______URI_126\"></a>2.1 基础URI路由配置方式</h3> <p>如果请求的目标地址，是单个的URI资源路径，配置文件示例如下：</p> <pre><code>server:\n  port: 8080\nspring:\n  application:\n    name: api-gateway\n  cloud:\n    gateway:\n      routes:\n        - id: url-proxy-1\n          uri: https://blog.csdn.net\n          predicates:\n            - Path=/csdn\n</code></pre> <p>各字段含义如下：</p> <p>id：我们自定义的路由 ID，保持唯一</p> <p>uri：目标服务地址</p> <p>predicates：路由条件，Predicate 接受一个输入参数，返回一个布尔值结果。该接口包含多种默认方法来将 Predicate 组合成其他复杂的逻辑（比如：与，或，非）。</p> <p>上面这段配置的意思是，配置了一个 id 为 url-proxy-1的URI代理规则，路由的规则为：</p> <p>当访问地址http://localhost:8080/csdn/1.jsp时，</p> <p>会路由到上游地址https://blog.csdn.net/1.jsp。</p> <h3><a id=\"22__163\"></a>2.2 基于代码的路由配置方式</h3> <p>转发功能同样可以通过代码来实现，我们可以在启动类 GateWayApplication 中添加方法 customRouteLocator() 来定制转发规则。</p> <pre><code>package com.springcloud.gateway;\n \nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.gateway.route.RouteLocator;\nimport org.springframework.cloud.gateway.route.builder.RouteLocatorBuilder;\nimport org.springframework.context.annotation.Bean;\n \n@SpringBootApplication\npublic class GatewayApplication {\n \n    public static void main(String[] args) {\n        SpringApplication.run(GatewayApplication.class, args);\n    }\n \n    @Bean\n    public RouteLocator customRouteLocator(RouteLocatorBuilder builder) {\n        return builder.routes()\n                .route(\"path_route\", r -&gt; r.path(\"/csdn\")\n                        .uri(\"https://blog.csdn.net\"))\n                .build();\n    }\n \n}\n</code></pre> <p>我们在yaml配置文件中注销掉相关路由的配置，重启服务，访问链接：http://localhost:8080/ csdn， 可以看到和上面一样的页面，证明我们测试成功。</p> <p>上面两个示例中 uri 都是指向了我的CSDN博客，在实际项目使用中可以将 uri 指向对外提供服务的项目地址，统一对外输出接口。</p> <h3><a id=\"23_____200\"></a>2.3 和注册中心相结合的路由配置方式</h3> <p>在uri的schema协议部分为自定义的lb:类型，表示从微服务注册中心（如Eureka）订阅服务，并且进行服务的路由。</p> <p>一个典型的示例如下：</p> <pre><code>server:\n  port: 8084\nspring:\n  cloud:\n    gateway:\n      routes:\n      - id: seckill-provider-route\n        uri: lb://seckill-provider\n        predicates:\n        - Path=/seckill-provider/**\n\n      - id: message-provider-route\n        uri: lb://message-provider\n        predicates:\n        - Path=/message-provider/**\n\napplication:\n  name: cloud-gateway\n\neureka:\n  instance:\n    prefer-ip-address: true\n  client:\n    service-url:\n      defaultZone: http://localhost:8888/eureka/\n\n\n</code></pre> <p>注册中心相结合的路由配置方式，与单个URI的路由配置，区别其实很小，仅仅在于URI的schema协议不同。单个URI的地址的schema协议，一般为http或者https协议。</p> <h2><a id=\"3_____244\"></a>3 路由 匹配规则</h2> <p>Spring Cloud Gateway 的功能很强大，我们仅仅通过 Predicates 的设计就可以看出来，前面我们只是使用了 predicates 进行了简单的条件匹配，其实 Spring Cloud Gataway 帮我们内置了很多 Predicates 功能。</p> <p>Spring Cloud Gateway 是通过 Spring WebFlux 的 HandlerMapping 做为底层支持来匹配到转发路由，Spring Cloud Gateway 内置了很多 Predicates 工厂，这些 Predicates 工厂通过不同的 HTTP 请求参数来匹配，多个 Predicates 工厂可以组合使用。</p> <p><img src=\"https://img-blog.csdnimg.cn/20200527213652534.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NzIyNDc1,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p> <p>gateWay的主要功能之一是转发请求，转发规则的定义主要包含三个部分</p> \n   <table>\n    <thead>\n     <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n     </tr>\n    </thead>\n    <tbody>\n     <tr>\n      <td>Route（路由）</td>\n      <td>路由是网关的基本单元，由ID、URI、一组Predicate、一组Filter组成，根据Predicate进行匹配转发。</td>\n      <td></td>\n     </tr>\n     <tr>\n      <td>Predicate（谓语、断言）</td>\n      <td>路由转发的判断条件，目前SpringCloud Gateway支持多种方式，常见如：Path、Query、Method、Header等，写法必须遵循 key=vlue的形式</td>\n      <td></td>\n     </tr>\n     <tr>\n      <td>Filter（过滤器）</td>\n      <td>过滤器是路由转发请求时所经过的过滤逻辑，可用于修改请求、响应内容</td>\n      <td></td>\n     </tr>\n    </tbody>\n   </table> \n   <blockquote> \n    <p>其中Route和Predicate必须同时申明</p> \n   </blockquote> <p>例子：</p> <pre><code>//通过配置文件配置\nspring:\n  cloud:\n    gateway:\n      routes:\n        - id: gate_route\n          uri: http://localhost:9023\n          predicates:\n          ## 当请求的路径为gate、rule开头的时，转发到http://localhost:9023服务器上\n            - Path=/gate/**,/rule/**\n        ### 请求路径前加上/app\n          filters:\n          - PrefixPath=/app\n</code></pre> <h4><a id=\"_281\"></a>说明：</h4> <p>此文的配置，大部分在demo 工程中已经验证，在 写的过程中， 可能有格式错误</p> <p>如果遇到问题，可以找尼恩</p> <h3><a id=\"31_______Predicate__289\"></a>3.1 Predicate 断言条件(转发规则)介绍</h3> <p>Predicate 来源于 Java 8，是 Java 8 中引入的一个函数，Predicate 接受一个输入参数，返回一个布尔值结果。该接口包含多种默认方法来将 Predicate 组合成其他复杂的逻辑（比如：与，或，非）。可以用于接口请求参数校验、判断新老数据是否有变化需要进行更新操作。</p> <p>在 Spring Cloud Gateway 中 Spring 利用 Predicate 的特性实现了各种路由匹配规则，有通过 Header、请求参数等不同的条件来进行作为条件匹配到对应的路由。网上有一张图总结了 Spring Cloud 内置的几种 Predicate 的实现。<br> <img src=\"https://img-blog.csdnimg.cn/img_convert/3e2ddc4d1c1335c232134b4bbe2625c6.gif\" alt=\"在这里插入图片描述\"></p> <p>说白了 Predicate 就是为了实现一组匹配规则，方便让请求过来找到对应的 Route 进行处理，接下来我们接下 Spring Cloud GateWay 内置几种 Predicate 的使用。</p> \n   <ul>\n    <li>转发规则（predicates），假设 转发uri都设定为<em><strong>http://localhost:9023</strong></em></li>\n   </ul> \n   <table>\n    <thead>\n     <tr>\n      <th>规则</th>\n      <th>实例</th>\n      <th>说明</th>\n     </tr>\n    </thead>\n    <tbody>\n     <tr>\n      <td>Path</td>\n      <td>- Path=/gate/<strong>,/rule/</strong></td>\n      <td>## 当请求的路径为gate、rule开头的时，转发到http://localhost:9023服务器上</td>\n     </tr>\n     <tr>\n      <td>Before</td>\n      <td>- Before=2017-01-20T17:42:47.789-07:00[America/Denver]</td>\n      <td>在某个时间之前的请求才会被转发到 http://localhost:9023服务器上</td>\n     </tr>\n     <tr>\n      <td>After</td>\n      <td>- After=2017-01-20T17:42:47.789-07:00[America/Denver]</td>\n      <td>在某个时间之后的请求才会被转发</td>\n     </tr>\n     <tr>\n      <td>Between</td>\n      <td>- Between=2017-01-20T17:42:47.789-07:00[America/Denver],2017-01-21T17:42:47.789-07:00[America/Denver]</td>\n      <td>在某个时间段之间的才会被转发</td>\n     </tr>\n     <tr>\n      <td>Cookie</td>\n      <td>- Cookie=chocolate, ch.p</td>\n      <td>名为chocolate的表单或者满足正则ch.p的表单才会被匹配到进行请求转发</td>\n     </tr>\n     <tr>\n      <td>Header</td>\n      <td>- Header=X-Request-Id, \\d+</td>\n      <td>携带参数X-Request-Id或者满足\\d+的请求头才会匹配</td>\n     </tr>\n     <tr>\n      <td>Host</td>\n      <td>- Host=www.hd123.com</td>\n      <td>当主机名为www.hd123.com的时候直接转发到http://localhost:9023服务器上</td>\n     </tr>\n     <tr>\n      <td>Method</td>\n      <td>- Method=GET</td>\n      <td>只有GET方法才会匹配转发请求，还可以限定POST、PUT等请求方式</td>\n     </tr>\n    </tbody>\n   </table> <h4><a id=\"152________317\"></a><strong>1.5.2</strong> 通过请求参数匹配</h4> <p>Query Route Predicate 支持传入两个参数，一个是属性名一个为属性值，属性值可以是正则表达式。</p> <pre><code>server:\n  port: 8080\nspring:\n  cloud:\n    gateway:\n      routes:\n      - id: query_route\n        uri: https://example.org\n        predicates:\n        - Query=smile\n\n</code></pre> <p>这样配置，只要请求中包含 smile 属性的参数即可匹配路由。</p> <p>使用 curl 测试，命令行输入:</p> <p>curl localhost:8080?smile=x&amp;id=2</p> <p>经过测试发现只要请求汇总带有 smile 参数即会匹配路由，不带 smile 参数则不会匹配。</p> <p>还可以将 Query 的值以键值对的方式进行配置，这样在请求过来时会对属性值和正则进行匹配，匹配上才会走路由。</p> <pre><code>server:\n  port: 8080\nspring:\n  cloud:\n    gateway:\n      routes:\n      - id: query_route\n        uri: https://example.org\n        predicates:\n            - Query=keep, pu.\n</code></pre> <p>这样只要当请求中包含 keep 属性并且参数值是以 pu 开头的长度为三位的字符串才会进行匹配和路由。</p> <p>使用 curl 测试，命令行输入:</p> <p>curl localhost:8080?keep=pub</p> <p>测试可以返回页面代码，将 keep 的属性值改为 pubx 再次访问就会报 404,证明路由需要匹配正则表达式才会进行路由。</p> <h4><a id=\"153________Header__362\"></a><strong>1.5.3</strong> 通过 Header 属性匹配</h4> <p>Header Route Predicate 和 Cookie Route Predicate 一样，也是接收 2 个参数，一个 header 中属性名称和一个正则表达式，这个属性值和正则表达式匹配则执行。</p> <pre><code>server:\n  port: 8080\nspring:\n  cloud:\n    gateway:\n      routes:\n      - id: query_route\n        uri: https://example.org\n        predicates:\n            - Header=X-Request-Id, \\d+\n</code></pre> <p>使用 curl 测试，命令行输入:</p> <p>curl http://localhost:8080 -H “X-Request-Id:88”</p> <p>则返回页面代码证明匹配成功。将参数-H \"X-Request-Id:88\"改为-H \"X-Request-Id:spring\"再次执行时返回404证明没有匹配。</p> <h4><a id=\"154________Cookie__383\"></a><strong>1.5.4</strong> 通过 Cookie 匹配</h4> <p>Cookie Route Predicate 可以接收两个参数，一个是 Cookie name ,一个是正则表达式，路由规则会通过获取对应的 Cookie name 值和正则表达式去匹配，如果匹配上就会执行路由，如果没有匹配上则不执行。</p> <pre><code>server:\n  port: 8080\nspring:\n  application:\n    name: api-gateway\n  cloud:\n    gateway:\n      routes:\n        -id: gateway-service\n          uri: https://www.baidu.com\n          order: 0\n          predicates:\n            - Cookie=sessionId, test\n</code></pre> <p>使用 curl 测试，命令行输入:</p> <p>curl http://localhost:8080 --cookie “sessionId=test”</p> <p>则会返回页面代码，如果去掉–cookie “sessionId=test”，后台汇报 404 错误。</p> <h4><a id=\"155________Host__411\"></a><strong>1.5.5</strong> 通过 Host 匹配</h4> <p>Host Route Predicate 接收一组参数，一组匹配的域名列表，这个模板是一个 ant 分隔的模板，用.号作为分隔符。它通过参数中的主机地址作为匹配规则。</p> <pre><code>server:\n  port: 8080\nspring:\n  cloud:\n    gateway:\n      routes:\n      - id: query_route\n        uri: https://example.org\n        predicates:\n          - Host=**.baidu.com\n</code></pre> <p>使用 curl 测试，命令行输入:</p> <p>curl http://localhost:8080 -H “Host: www.baidu.com”</p> <p>curl http://localhost:8080 -H “Host: md.baidu.com”</p> <p>经测试以上两种 host 均可匹配到 host_route 路由，去掉 host 参数则会报 404 错误。</p> <h4><a id=\"156________438\"></a><strong>1.5.6</strong> 通过请求方式匹配</h4> <p>可以通过是 POST、GET、PUT、DELETE 等不同的请求方式来进行路由。</p> <pre><code>server:\n  port: 8080\nspring:\n  cloud:\n    gateway:\n      routes:\n      - id: query_route\n        uri: https://example.org\n        predicates:\n            - Method=GET\n</code></pre> <p>使用 curl 测试，命令行输入:</p> <p># curl 默认是以 GET 的方式去请求</p> <p>curl http://localhost:8080</p> <p>测试返回页面代码，证明匹配到路由，我们再以 POST 的方式请求测试。</p> <p># curl 默认是以 GET 的方式去请求</p> <p>curl -X POST http://localhost:8080</p> <p>返回 404 没有找到，证明没有匹配上路由</p> <h4><a id=\"157________470\"></a><strong>1.5.7</strong> 通过请求路径匹配</h4> <p>Path Route Predicate 接收一个匹配路径的参数来判断是否走路由。</p> <pre><code>server:\n  port: 8080\nspring:\n  cloud:\n    gateway:\n      routes:\n      - id: query_route\n        uri: https://example.org\n        predicates:\n            -Path=/foo/{segment}\n</code></pre> <p>如果请求路径符合要求，则此路由将匹配，例如：/foo/1 或者 /foo/bar。</p> <p>使用 curl 测试，命令行输入:</p> <p>curl http://localhost:8080/foo/1</p> <p>curl http://localhost:8080/foo/xx</p> <p>curl http://localhost:8080/boo/xx</p> <p>经过测试第一和第二条命令可以正常获取到页面返回值，最后一个命令报404，证明路由是通过指定路由来匹配。</p> <h4><a id=\"158________ip__497\"></a><strong>1.5.8</strong> 通过请求 ip 地址进行匹配</h4> <p>Predicate 也支持通过设置某个 ip 区间号段的请求才会路由，RemoteAddr Route Predicate 接受 cidr 符号(IPv4 或 IPv6 )字符串的列表(最小大小为1)，例如 192.168.0.1/16 (其中 192.168.0.1 是 IP 地址，16 是子网掩码)。</p> <pre><code>server:\n  port: 8080\nspring:\n  cloud:\n    gateway:\n      routes:\n      - id: query_route\n        uri: https://example.org\n        predicates:\n            - RemoteAddr=192.168.1.1/24\n</code></pre> <p>可以将此地址设置为本机的 ip 地址进行测试。</p> <p>curl localhost:8080</p> <p>如果请求的远程地址是 192.168.1.10，则此路由将匹配。</p> <h4><a id=\"1510__520\"></a><strong>1.5.10</strong> <strong>组合使用</strong></h4> <pre><code>server:\n  port: 8080\nspring:\n  application:\n    name: api-gateway\n  cloud:\n    gateway:\n      routes:\n        - id: gateway-service\n          uri: https://www.baidu.com\n          order: 0\n          predicates:\n            - Host=**.foo.org\n            - Path=/headers\n            - Method=GET\n            - Header=X-Request-Id, \\d+\n            - Query=foo, ba.\n            - Query=baz\n            - Cookie=chocolate, ch.p\n\n</code></pre> <p>​</p> <p>各种 Predicates 同时存在于同一个路由时，请求必须同时满足所有的条件才被这个路由匹配。</p> <p>一个请求满足多个路由的断言条件时，请求只会被首个成功匹配的路由转发</p> <h3><a id=\"32_Filter_553\"></a>3.2 过滤器规则（Filter）</h3> <h4><a id=\"Filter_555\"></a>过滤器规则（Filter）</h4> \n   <table>\n    <thead>\n     <tr>\n      <th>过滤规则</th>\n      <th>实例</th>\n      <th>说明</th>\n     </tr>\n    </thead>\n    <tbody>\n     <tr>\n      <td>PrefixPath</td>\n      <td>- PrefixPath=/app</td>\n      <td>在请求路径前加上app</td>\n     </tr>\n     <tr>\n      <td>RewritePath</td>\n      <td>- RewritePath=/test, /app/test</td>\n      <td>访问localhost:9022/test,请求会转发到localhost:8001/app/test</td>\n     </tr>\n     <tr>\n      <td>SetPath</td>\n      <td>SetPath=/app/{path}</td>\n      <td>通过模板设置路径，转发的规则时会在路径前增加app，{path}表示原请求路径</td>\n     </tr>\n     <tr>\n      <td>RedirectTo</td>\n      <td></td>\n      <td>重定向</td>\n     </tr>\n     <tr>\n      <td>RemoveRequestHeader</td>\n      <td></td>\n      <td>去掉某个请求头信息</td>\n     </tr>\n    </tbody>\n   </table> <p>注：当配置多个filter时，优先定义的会被调用，剩余的filter将不会生效</p> <h4><a id=\"PrefixPath_567\"></a>PrefixPath</h4> <p>对所有的请求路径添加前缀：</p> <pre><code>spring:\n  cloud:\n    gateway:\n      routes:\n      - id: prefixpath_route\n        uri: https://example.org\n        filters:\n        - PrefixPath=/mypath\n\n</code></pre> <p>访问/hello的请求被发送到https://example.org/mypath/hello。</p> <h4><a id=\"RedirectTo_587\"></a>RedirectTo</h4> <p>重定向，配置包含重定向的返回码和地址：</p> <pre><code>spring:\n  cloud:\n    gateway:\n      routes:\n      - id: prefixpath_route\n        uri: https://example.org\n        filters:\n        - RedirectTo=302, https://acme.org\n\n</code></pre> <h4><a id=\"RemoveRequestHeader_605\"></a>RemoveRequestHeader</h4> <p>去掉某个请求头信息：</p> <pre><code>spring:\n  cloud:\n    gateway:\n      routes:\n      - id: removerequestheader_route\n        uri: https://example.org\n        filters:\n        - RemoveRequestHeader=X-Request-Foo\n</code></pre> <p>去掉请求头信息 X-Request-Foo</p> <h4><a id=\"RemoveResponseHeader_624\"></a>RemoveResponseHeader</h4> <p>去掉某个回执头信息：</p> <pre><code>spring:\n  cloud:\n    gateway:\n      routes:\n      - id: removerequestheader_route\n        uri: https://example.org\n        filters:\n        - RemoveResponseHeader=X-Request-Foo\n</code></pre> <h4><a id=\"RemoveRequestParameter_641\"></a>RemoveRequestParameter</h4> <p>去掉某个请求参数信息：</p> <pre><code>spring:\n  cloud:\n    gateway:\n      routes:\n      - id: removerequestparameter_route\n        uri: https://example.org\n        filters:\n        - RemoveRequestParameter=red\n</code></pre> <h4><a id=\"RewritePath_656\"></a>RewritePath</h4> <p>改写路径：</p> <pre><code>spring:\n  cloud:\n    gateway:\n      routes:\n      - id: rewrite_filter\n        uri: http://localhost:8081\n        predicates:\n        - Path=/test/**\n        filters:\n        - RewritePath=/where(?&lt;segment&gt;/?.*), /test(?&lt;segment&gt;/?.*)\n\n</code></pre> <p>/where/… 改成 test/…</p> <p>使用代码改下路径</p> <pre><code class=\"prism language-java\">	    <span class=\"token class-name\">RouteLocatorBuilder<span class=\"token punctuation\">.</span>Builder</span> builder <span class=\"token operator\">=</span> routeLocatorBuilder<span class=\"token punctuation\">.</span><span class=\"token function\">routes</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        builder\n                <span class=\"token punctuation\">.</span><span class=\"token function\">route</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"path_rote_at_guigu\"</span><span class=\"token punctuation\">,</span> r <span class=\"token operator\">-&gt;</span> r<span class=\"token punctuation\">.</span><span class=\"token function\">path</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"/guonei\"</span><span class=\"token punctuation\">)</span>\n                        <span class=\"token punctuation\">.</span><span class=\"token function\">uri</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"http://news.baidu.com/guonei\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n                <span class=\"token punctuation\">.</span><span class=\"token function\">route</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"csdn_route\"</span><span class=\"token punctuation\">,</span> r <span class=\"token operator\">-&gt;</span> r<span class=\"token punctuation\">.</span><span class=\"token function\">path</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"/csdn\"</span><span class=\"token punctuation\">)</span>\n                        <span class=\"token punctuation\">.</span><span class=\"token function\">uri</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"https://blog.csdn.net\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n                <span class=\"token punctuation\">.</span><span class=\"token function\">route</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"blog3_rewrite_filter\"</span><span class=\"token punctuation\">,</span> r <span class=\"token operator\">-&gt;</span> r<span class=\"token punctuation\">.</span><span class=\"token function\">path</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"/blog3/**\"</span><span class=\"token punctuation\">)</span>\n                        <span class=\"token punctuation\">.</span><span class=\"token function\">filters</span><span class=\"token punctuation\">(</span>f <span class=\"token operator\">-&gt;</span> f<span class=\"token punctuation\">.</span><span class=\"token function\">rewritePath</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"/blog3/(?&lt;segment&gt;.*)\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"/$\\\\{segment}\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n                        <span class=\"token punctuation\">.</span><span class=\"token function\">uri</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"https://blog.csdn.net\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n                <span class=\"token punctuation\">.</span><span class=\"token function\">route</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"rewritepath_route\"</span><span class=\"token punctuation\">,</span> r <span class=\"token operator\">-&gt;</span> r<span class=\"token punctuation\">.</span><span class=\"token function\">path</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"/baidu/**\"</span><span class=\"token punctuation\">)</span>\n                        <span class=\"token punctuation\">.</span><span class=\"token function\">filters</span><span class=\"token punctuation\">(</span>f <span class=\"token operator\">-&gt;</span> f<span class=\"token punctuation\">.</span><span class=\"token function\">rewritePath</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"/baidu/(?&lt;segment&gt;.*)\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"/$\\\\{segment}\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n                        <span class=\"token punctuation\">.</span><span class=\"token function\">uri</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"http://www.baidu.com\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n                <span class=\"token punctuation\">.</span><span class=\"token function\">build</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre> <h4><a id=\"SetPath_697\"></a>SetPath</h4> <p>设置请求路径，与RewritePath类似。</p> <pre><code>spring:\n  cloud:\n    gateway:\n      routes:\n      - id: setpath_route\n        uri: https://example.org\n        predicates:\n        - Path=/red/{segment}\n        filters:\n        - SetPath=/{segment}\n</code></pre> <p>如/red/blue的请求被转发到/blue。</p> <h4><a id=\"SetRequestHeader_718\"></a>SetRequestHeader</h4> <p>设置请求头信息。</p> <pre><code>spring:\n  cloud:\n    gateway:\n      routes:\n      - id: setrequestheader_route\n        uri: https://example.org\n        filters:\n        - SetRequestHeader=X-Request-Red, Blue\n</code></pre> <h4><a id=\"SetStatus_733\"></a>SetStatus</h4> <p>设置回执状态码。</p> <pre><code>spring:\n  cloud:\n    gateway:\n      routes:\n      - id: setstatusint_route\n        uri: https://example.org\n        filters:\n        - SetStatus=401\n</code></pre> <h4><a id=\"StripPrefix_748\"></a>StripPrefix</h4> <p>跳过指定路径。</p> <pre><code>spring:\n  cloud:\n    gateway:\n      routes:\n      - id: nameRoot\n        uri: https://nameservice\n        predicates:\n        - Path=/name/**\n        filters:\n        - StripPrefix=2\n</code></pre> <p>请求/name/blue/red会转发到/red。</p> <h4><a id=\"RequestSize_767\"></a>RequestSize</h4> <p>请求大小。</p> <pre><code>spring:\n  cloud:\n    gateway:\n      routes:\n      - id: request_size_route\n        uri: http://localhost:8080/upload\n        predicates:\n        - Path=/upload\n        filters:\n        - name: RequestSize\n          args:\n            maxSize: 5000000\n</code></pre> <p>超过5M的请求会返回413错误。</p> <h4><a id=\"Defaultfilters_788\"></a>Default-filters</h4> <p>对所有请求添加过滤器。</p> <pre><code>spring:\n  cloud:\n    gateway:\n      default-filters:\n      - AddResponseHeader=X-Response-Default-Red, Default-Blue\n      - PrefixPath=/httpbin\n</code></pre> <h3><a id=\"33__803\"></a>3.3 通过代码进行配置</h3> <p>通过代码进行配置，将路由规则设置为一个Bean即可：</p> <pre><code>	@Bean\n	public RouteLocator customRouteLocator(RouteLocatorBuilder builder) {\n		return builder.routes()\n			.route(\"path_route\", r -&gt; r.path(\"/get\")\n				.uri(\"http://httpbin.org\"))\n			.route(\"host_route\", r -&gt; r.host(\"*.myhost.org\")\n				.uri(\"http://httpbin.org\"))\n			.route(\"rewrite_route\", r -&gt; r.host(\"*.rewrite.org\")\n				.filters(f -&gt; f.rewritePath(\"/foo/(?&lt;segment&gt;.*)\", \"/${segment}\"))\n				.uri(\"http://httpbin.org\"))\n			.route(\"hystrix_route\", r -&gt; r.host(\"*.hystrix.org\")\n				.filters(f -&gt; f.hystrix(c -&gt; c.setName(\"slowcmd\")))\n				.uri(\"http://httpbin.org\"))\n			.route(\"hystrix_fallback_route\", r -&gt; r.host(\"*.hystrixfallback.org\")\n				.filters(f -&gt; f.hystrix(c -&gt; c.setName(\"slowcmd\").setFallbackUri(\"forward:/hystrixfallback\")))\n				.uri(\"http://httpbin.org\"))\n			.route(\"limit_route\", r -&gt; r\n				.host(\"*.limited.org\").and().path(\"/anything/**\")\n				.filters(f -&gt; f.requestRateLimiter(c -&gt; c.setRateLimiter(redisRateLimiter())))\n				.uri(\"http://httpbin.org\"))\n			.build();\n	}\n\n</code></pre> <h3><a id=\"32________839\"></a><strong>3.2</strong> 实现熔断降级</h3> <p>为什么要实现熔断降级？</p> <p>在分布式系统中，网关作为流量的入口，因此会有大量的请求进入网关，向其他服务发起调用，其他服务不可避免的会出现调用失败（超时、异常），失败时不能让请求堆积在网关上，需要快速失败并返回给客户端，想要实现这个要求，就必须在网关上做熔断、降级操作。</p> <p>为什么在网关上请求失败需要快速返回给客户端？</p> <p>因为当一个客户端请求发生故障的时候，这个请求会一直堆积在网关上，当然只有一个这种请求，网关肯定没有问题（如果一个请求就能造成整个系统瘫痪，那这个系统可以下架了），但是网关上堆积多了就会给网关乃至整个服务都造成巨大的压力，甚至整个服务宕掉。因此要对一些服务和页面进行有策略的降级，以此缓解服务器资源的的压力，以保证核心业务的正常运行，同时也保持了客户和大部分客户的得到正确的相应，所以需要网关上请求失败需要快速返回给客户端。</p> <pre><code>server.port: 8082\n\nspring:\n  application:\n    name: gateway\n  redis:\n      host: localhost\n      port: 6379\n      password: 123456\n  cloud:\n    gateway:\n      routes:\n        - id: rateLimit_route\n          uri: http://localhost:8000\n          order: 0\n          predicates:\n            - Path=/test/**\n          filters:\n            - StripPrefix=1\n            - name: Hystrix\n              args:\n                name: fallbackCmdA\n                fallbackUri: forward:/fallbackA\n\n  hystrix.command.fallbackCmdA.execution.isolation.thread.timeoutInMilliseconds: 5000\n</code></pre> <p>这里的配置，使用了两个过滤器：</p> <p>（1）过滤器StripPrefix，作用是去掉请求路径的最前面n个部分截取掉。</p> <p>StripPrefix=1就代表截取路径的个数为1，比如前端过来请求/test/good/1/view，匹配成功后，路由到后端的请求路径就会变成http://localhost:8888/good/1/view。</p> <p>（2）过滤器Hystrix，作用是通过Hystrix进行熔断降级</p> <p>当上游的请求，进入了Hystrix熔断降级机制时，就会调用fallbackUri配置的降级地址。需要注意的是，还需要单独设置Hystrix的commandKey的超时时间</p> <p>fallbackUri配置的降级地址的代码如下：</p> <pre><code>package org.gateway.controller;\n\nimport org.gateway.response.Response;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\npublic class FallbackController {\n\n    @GetMapping(\"/fallbackA\")\n    public Response fallbackA() {\n        Response response = new Response();\n        response.setCode(\"100\");\n        response.setMessage(\"服务暂时不可用\");\n        return response;\n    }\n}\n\n</code></pre> <h2><a id=\"4__918\"></a>4 高级配置</h2> <h3><a id=\"41________920\"></a>4.1 分布式限流</h3> <p>从某种意义上讲，令牌桶算法是对漏桶算法的一种改进，桶算法能够限制请求调用的速率，而令牌桶算法能够在限制调用的平均速率的同时还允许一定程度的突发调用。在令牌桶算法中，存在一个桶，用来存放固定数量的令牌。算法中存在一种机制，以一定的速率往桶中放令牌。每次请求调用需要先获取令牌，只有拿到令牌，才有机会继续执行，否则选择选择等待可用的令牌、或者直接拒绝。放令牌这个动作是持续不断的进行，如果桶中令牌数达到上限，就丢弃令牌，所以就存在这种情况，桶中一直有大量的可用令牌，这时进来的请求就可以直接拿到令牌执行，比如设置qps为100，那么限流器初始化完成一秒后，桶中就已经有100个令牌了，这时服务还没完全启动好，等启动完成对外提供服务时，该限流器可以抵挡瞬时的100个请求。所以，只有桶中没有令牌时，请求才会进行等待，最后相当于以一定的速率执行。<br> <img src=\"https://img-blog.csdnimg.cn/img_convert/0f8ca1474a2547c1cd5fa0148cbf6df2.png\" alt=\"在这里插入图片描述\"></p> <p>在Spring Cloud Gateway中，有Filter过滤器，因此可以在“pre”类型的Filter中自行实现上述三种过滤器。但是限流作为网关最基本的功能，Spring Cloud Gateway官方就提供了RequestRateLimiterGatewayFilterFactory这个类，适用在Redis内的通过执行Lua脚本实现了令牌桶的方式。具体实现逻辑在RequestRateLimiterGatewayFilterFactory类中，lua脚本在如下图所示的文件夹中：<br> <img src=\"https://img-blog.csdnimg.cn/img_convert/e2e8184e3b6ac5091722414e44fd7fee.png\" alt=\"在这里插入图片描述\"></p> <p>首先在工程的pom文件中引入gateway的起步依赖和redis的reactive依赖，代码如下：</p> <p>配置如下：</p> <pre><code>\nserver:\n  port: 8081\nspring:\n  cloud:\n    gateway:\n      routes:\n      - id: limit_route\n        uri: http://httpbin.org:80/get\n        predicates:\n        - After=2017-01-20T17:42:47.789-07:00[America/Denver]\n        filters:\n        - name: RequestRateLimiter\n          args:\n            key-resolver: \'#{@userKeyResolver}\'\n            redis-rate-limiter.replenishRate: 1\n            redis-rate-limiter.burstCapacity: 3\n  application:\n    name: cloud-gateway\n  redis:\n    host: localhost\n    port: 6379\n    database: 0\n</code></pre> <p>在上面的配置文件，指定程序的端口为8081，配置了 redis的信息，并配置了RequestRateLimiter的限流过滤器，该过滤器需要配置三个参数：</p> \n   <ul>\n    <li> <p>burstCapacity，令牌桶总容量。</p> </li>\n    <li> <p>replenishRate，令牌桶每秒填充平均速率。</p> </li>\n    <li> <p>key-resolver，用于限流的键的解析器的 Bean 对象的名字。它使用 SpEL 表达式根据#{@beanName}从 Spring 容器中获取 Bean 对象。</p> </li>\n   </ul> <p>这里根据用户ID限流，请求路径中必须携带userId参数</p> <pre><code>@Bean\n\nKeyResolver userKeyResolver() {\n  return exchange -&gt; Mono.just(exchange.getRequest().getQueryParams().getFirst(\"user\"));\n}\n\n \n</code></pre> <p>KeyResolver需要实现resolve方法，比如根据userid进行限流，则需要用userid去判断。实现完KeyResolver之后，需要将这个类的Bean注册到Ioc容器中。</p> <p>如果需要根据IP限流，定义的获取限流Key的bean为：</p> <pre><code>@Bean\npublic KeyResolver ipKeyResolver() {\n  return exchange -&gt; Mono.just(exchange.getRequest().getRemoteAddress().getHostName());\n}\n</code></pre> <p>通过exchange对象可以获取到请求信息，这边用了HostName，如果你想根据用户来做限流的话这边可以获取当前请求的用户ID或者用户名就可以了，比如：</p> <p>如果需要根据接口的URI进行限流，则需要获取请求地址的uri作为限流key，定义的Bean对象为：</p> <pre><code> \n@Bean\nKeyResolver apiKeyResolver() {\n  return exchange -&gt; Mono.just(exchange.getRequest().getPath().value());\n}\n\n</code></pre> <p>通过exchange对象可以获取到请求信息，这边用了HostName，如果你想根据用户来做限流的话这边可以获取当前请求的用户ID或者用户名就可以了，比如：</p> <p>如果需要根据接口的URI进行限流，则需要获取请求地址的uri作为限流key，定义的Bean对象为：</p> <pre><code> \n@Bean\nKeyResolver apiKeyResolver() {\n  return exchange -&gt; Mono.just(exchange.getRequest().getPath().value());\n}\n</code></pre> <h3><a id=\"42__1030\"></a>4.2 健康检查配置</h3> <p>admin-client、actuator健康检查配置，为之后的功能提供支持，此部分比较简单，不再赘述，加入以下maven依赖和配置</p> <h4><a id=\"maven_1034\"></a>maven依赖</h4> <pre><code>  &lt;dependency&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;\n &lt;/dependency&gt;\n&lt;dependency&gt;\n        &lt;groupId&gt;de.codecentric&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-admin-starter-client&lt;/artifactId&gt;\n        &lt;version&gt;2.1.0&lt;/version&gt;\n    &lt;/dependency&gt;\n&lt;dependency&gt;\n        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;\n    &lt;/dependency&gt;\n</code></pre> <h4><a id=\"_1048\"></a>配置文件</h4> <pre><code>spring:\n  application:\n    name: mas-cloud-gateway\n  boot:\n    admin:\n      client:\n      ### 本地搭建的admin-server\n        url: http://localhost:8011\neureka:\n  client:\n    registerWithEureka: true\n    fetchRegistry: true\n    healthcheck:\n      enabled: true\n    serviceUrl:\n      defaultZone: http://localhost:6887/eureka/\n    enabled: true\nfeign:\n  sentinel:\n    enabled: true\nmanagement:\n  endpoints:\n    web:\n      exposure:\n        include: \'*\'\n  endpoint:\n    health:\n      show-details: ALWAYS\n</code></pre> <p>若转发的目标地址为微服务中组件，不为具体ip:port形式的，应写成lb://mas-openapi-service形式，目标地址会从注册中心直接拉取</p> <h3><a id=\"43__1083\"></a>4.3 统一配置跨域请求：</h3> <p>现在的请求通过经过gateWay网关时，需要在网关统一配置跨域请求，需求所有请求通过</p> <pre><code>spring:\n  cloud:\n    gateway:\n      globalcors:\n        cors-configurations:\n          \'[/**]\':\n            allowed-origins: \"*\"\n            allowed-headers: \"*\"\n            allow-credentials: true\n            allowed-methods:\n              - GET\n              - POST\n              - DELETE\n              - PUT\n              - OPTION\n</code></pre> <h2><a id=\"5_Nacos_1107\"></a>5 整合Nacos</h2> <h3><a id=\"maven_1111\"></a>maven依赖</h3> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;\n    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n    &lt;parent&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;\n        &lt;version&gt;2.1.9.RELEASE&lt;/version&gt;\n        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;\n    &lt;/parent&gt;\n    &lt;groupId&gt;com.example&lt;/groupId&gt;\n    &lt;artifactId&gt;nacos_gateway&lt;/artifactId&gt;\n    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;\n    &lt;packaging&gt;war&lt;/packaging&gt;\n    &lt;name&gt;nacos_gateway&lt;/name&gt;\n    &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;\n\n    &lt;properties&gt;\n        &lt;java.version&gt;1.8&lt;/java.version&gt;\n        &lt;spring-cloud.version&gt;Greenwich.SR3&lt;/spring-cloud.version&gt;\n    &lt;/properties&gt;\n\n    &lt;dependencies&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;\n            &lt;scope&gt;test&lt;/scope&gt;\n        &lt;/dependency&gt;\n        &lt;!--gateway--&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;!--nacos dicovery--&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n    &lt;/dependencies&gt;\n\n    &lt;dependencyManagement&gt;\n        &lt;dependencies&gt;\n            &lt;dependency&gt;\n                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;\n                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;\n                &lt;type&gt;pom&lt;/type&gt;\n                &lt;scope&gt;import&lt;/scope&gt;\n            &lt;/dependency&gt;\n            &lt;dependency&gt;\n                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n                &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt;\n                &lt;version&gt;0.2.2.RELEASE&lt;/version&gt;\n                &lt;type&gt;pom&lt;/type&gt;\n                &lt;scope&gt;import&lt;/scope&gt;\n            &lt;/dependency&gt;\n        &lt;/dependencies&gt;\n    &lt;/dependencyManagement&gt;\n\n    &lt;build&gt;\n        &lt;plugins&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;\n            &lt;/plugin&gt;\n        &lt;/plugins&gt;\n    &lt;/build&gt;\n\n&lt;/project&gt;\n\n\n</code></pre> <p>需要注意在Gateway服务中的pom.xml文件中不要存在这个jar</p> <pre><code>        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt;\n            &lt;scope&gt;provided&lt;/scope&gt;\n        &lt;/dependency&gt;\n\n</code></pre> <p>否则调用接口时会报以下错误因为gateway使用的是webflux,默认使用netty,所以从依赖中排除 tomcat相关的依赖</p> <pre><code>java.lang.ClassCastException: org.springframework.core.io.buffer.DefaultDataBufferFactory cannot be cast to org.springframework.core.io.buffer.NettyDataBufferFactory\n	at org.springframework.cloud.gateway.filter.NettyWriteResponseFilter.lambda$filter$1(NettyWriteResponseFilter.java:82) ~[spring-cloud-gateway-core-2.1.3.RELEASE.jar:2.1.3.RELEASE]\n	at reactor.core.publisher.MonoDefer.subscribe(MonoDefer.java:44) [reactor-core-3.2.12.RELEASE.jar:3.2.12.RELEASE]\n\n</code></pre> <p>错误2 是由于 spring-boot-starter-web 引起</p> <h3><a id=\"Nacos_1211\"></a>服务发现配置：从Nacos获取微服务提供者清单</h3> <pre><code>server:\n  port: 9999\n\nspring:\n  application:\n    name: springcloud-gateway\n  profiles:\n    active: dev\n  cloud:\n    nacos:\n      discovery:\n        server-addr: ${NACOS_SERVER:cdh1:8848}\n      config:\n        server-addr: ${NACOS_SERVER:cdh1:8848}\n        prefix: springcloud-gateway\n        group: DEFAULT_GROUP\n        file-extension: yml\n        ext-config:\n          - data-id: crazymaker-db-dev.yml\n            group: DEFAULT_GROUP\n            refresh: true\n          - data-id: crazymaker-redis-dev.yml\n            group: DEFAULT_GROUP\n            refresh: true\n          - data-id: crazymaker-common-dev.yml\n            group: DEFAULT_GROUP\n            refresh: true\n          - data-id: some.properties\n            group: DEFAULT_GROUP\n            refresh: true\n    gateway:\n      enabled: true\n      discovery:\n        locator:\n          enabled: true  #开启从注册中心动态创建路由的功能，利用微服务名进行路由\n          lower-case-service-id: true\n          filters:\n            - args[name]: serviceId\n              name: Hystrix\n          predicates:\n            - args[pattern]: \'\"\'\'/\'\'+serviceId+\'\'/**\'\'\"\'\n              name: Path\n      routes:\n        - id: blog\n          uri: https://blog.csdn.net/\n          predicates:\n            - Path=/csdn\n        - id: blog1\n          uri: https://blog.csdn.net/\n          predicates:\n            - Path=/blog1/**\n          filters:\n            - RewritePath=/blog1/(?&lt;segment&gt;.*), /$\\{segment}\n        # 代理前  http://192.168.68.1:9999/blog1/crazymakercircle/article/details/80208650\n        #  代理后  https://blog.csdn.net/crazymakercircle/article/details/80208650\n        - id: service_provider_demo_route\n          uri: lb://service-provider-demo\n          predicates:\n            - Path=/provider/**\n        - id: service_provider_demo_route_filter\n          uri: lb://service-provider-demo\n          predicates:\n            - Path=/filter/**\n          filters:\n            - RewritePath=/filter/(?&lt;segment&gt;.*), /provider/$\\{segment}\n            - UserIdCheck\n        - id: service_consumer_demo_route\n          uri: lb://service-consumer-demo\n          predicates:\n            - Path=/consumer/**\n        - id: sentinel_demo_provider_route\n          uri: lb://sentinel-demo-provider\n          predicates:\n            - Path=/sentinel-demo/**\n        - id: uaa-provider_route\n          uri: lb://uaa-provider\n          predicates:\n            - Path=/uaa-provider/**\n    sentinel:\n      transport:\n        dashboard: cdh1:8849 #配置Sentinel dashboard地址\n        port: 8719   #这里配置的是本地端口\n      eager: true\n    inetutils:\n      timeout-seconds: 10\n      preferred-networks: ${SCAFFOLD_PREFERRED_NETWORKS:192.168.68.}\n      prefer-ip-address: true  #访问路径可以显示IP地址\n\n\nribbon:\n  eager-load:\n    enabled: true # 开启Ribbon的饥饿加载模式，启动时创建 RibbonClient\n  MaxAutoRetries: 1 # 同一台实例的最大重试次数，但是不包括首次调用，默认为1次\n  MaxAutoRetriesNextServer: 2  # 重试负载均衡其他实例的最大重试次数，不包括首次调用，默认为0次\n  OkToRetryOnAllOperations: true  # 是否对所有操作都重试，默认false\n  ServerListRefreshInterval: 2000 # 从注册中心刷新服务器列表信息的时间间隔，默认为2000毫秒，即2秒\n  retryableStatusCodes: 400,401,403,404,500,502,504\n  NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RetryRule #配置规则 重试\n  ConnectTimeout: 3000  #连接建立的超时时长，默认1秒\n  ReadTimeout: 3000 #处理请求的超时时间，默认为1秒\n  MaxTotalConnections: 1000  # 最大连接数\n  MaxConnectionsPerHost: 1000  # 每个host最大连接数\n  restclient:\n    enabled: true\n\n\nhystrix:\n  threadpool:\n    default:\n      coreSize: 10 # 线程池核心线程数\n      maximumSize: 20  # 线程池最大线程数\n      allowMaximumSizeToDivergeFromCoreSize: true   # 线程池最大线程数是否有效\n      keepAliveTimeMinutes: 10  # 设置可空闲时间，单位分钟\n    demo-provider:\n      coreSize: 20   # 线程池核心线程数\n      maximumSize: 100   # 线程池最大线程数\n      allowMaximumSizeToDivergeFromCoreSize: true   # 线程池最大线程数是否有效\n      keepAliveTimeMinutes: 20  # 设置可空闲时间，单位分钟\n  propagate:\n    request-attribute:\n      enabled: true\n  command:\n    default:  #全局默认配置\n      execution:  #线程隔离相关配置\n        timeout:\n          enabled: true   #是否给方法执行设置超时时间，默认为true。一般我们不要改。\n        isolation:\n          strategy: THREAD    #配置请求隔离的方式，这里是默认的线程池方式。还有一种信号量的方式semaphore，使用比较少。\n          thread:\n            timeoutInMilliseconds: 100000  #方式执行的超时时间，默认为1000毫秒，在实际场景中需要根据情况设置\n            interruptOnTimeout: true   #发生超时时是否中断方法的执行，默认值为true。不要改。\n            interruptOnCancel: false  #是否在方法执行被取消时中断方法，默认值为false。没有实际意义，默认就好！\n      circuitBreaker:   #熔断器相关配置\n        enabled: true   #是否启动熔断器，默认为true，false表示不要引入 Hystrix。\n        requestVolumeThreshold: 20     #启用熔断器功能窗口时间内的最小请求数，假设我们设置的窗口时间为10秒，\n        sleepWindowInMilliseconds: 5000    #此配置的作用是指定熔断器打开后多长时间内允许一次请求尝试执行，官方默认配置为5秒。\n        errorThresholdPercentage: 50   #窗口时间内超过50%的请求失败后就会打开熔断器将后续请求快速失败掉,默认配置为50\n      metrics:\n        rollingStats:\n          timeInMilliseconds: 10000\n          numBuckets: 10\n\n# 暴露监控端点\nmanagement:\n  endpoints:\n    web:\n      exposure:\n        include: \'*\'\n</code></pre> <h3><a id=\"nacos_1366\"></a>nacos实现动态配置</h3> <p>使用nacos实现动态路由，以上两种方式都是实现的静态配置路径，只能应对部分场景，接下来配置nacos实现动态配置以及配置的存储，由于gateWay并没有适配nacos，需要自定义监听器：</p> <pre><code>@Component\n@Slf4j\npublic class NacosDynamicRouteService implements ApplicationEventPublisherAware {\n  private String dataId = \"gateway-router\";\n  private String group = \"DEFAULT_GROUP\";\n  @Value(\"${spring.cloud.nacos.config.server-addr}\")\n  private String serverAddr;\n  @Autowired\n  private RouteDefinitionWriter routeDefinitionWriter;\n  private ApplicationEventPublisher applicationEventPublisher;\n  private static final List&lt;String&gt; ROUTE_LIST = new ArrayList&lt;&gt;();\n  @PostConstruct\n  public void dynamicRouteByNacosListener() {\n    try {\n      ConfigService configService = NacosFactory.createConfigService(serverAddr);\n      configService.getConfig(dataId, group, 5000);\n      configService.addListener(dataId, group, new Listener() {\n        @Override\n        public void receiveConfigInfo(String configInfo) {\n          clearRoute();\n          try {\n            if (StringUtil.isNullOrEmpty(configInfo)) {//配置被删除\n              return;\n            }\n            List&lt;RouteDefinition&gt; gatewayRouteDefinitions = JSONObject.parseArray(configInfo, RouteDefinition.class);\n            for (RouteDefinition routeDefinition : gatewayRouteDefinitions) {\n              addRoute(routeDefinition);\n            }\n            publish();\n          } catch (Exception e) {\n            log.error(\"receiveConfigInfo error\" + e);\n          }\n        }\n        @Override\n        public Executor getExecutor() {\n          return null;\n        }\n      });\n    } catch (NacosException e) {\n        log.error(\"dynamicRouteByNacosListener error\" + e);\n    }\n  }\n  private void clearRoute() {\n    for (String id : ROUTE_LIST) {\n      this.routeDefinitionWriter.delete(Mono.just(id)).subscribe();\n    }\n    ROUTE_LIST.clear();\n  }\n  private void addRoute(RouteDefinition definition) {\n    try {\n      routeDefinitionWriter.save(Mono.just(definition)).subscribe();\n      ROUTE_LIST.add(definition.getId());\n    } catch (Exception e) {\n log.error(\"addRoute error\" + e);\n    }\n  }\n  private void publish() {\n    this.applicationEventPublisher.publishEvent(new RefreshRoutesEvent(this.routeDefinitionWriter));\n  }\n  @Override\n  public void setApplicationEventPublisher(ApplicationEventPublisher applicationEventPublisher) {\n    this.applicationEventPublisher = applicationEventPublisher;\n  }\n\n</code></pre> <p>在nacos中增加一个规则：</p> <pre><code>[{\n    \"filters\": [],\n    \"id\": \"baidu_route\",\n    \"order\": 0,\n    \"predicates\": [{\n        \"args\": {\n            \"pattern\": \"/baidu\"\n        },\n        \"name\": \"Path\"\n    }],\n    \"uri\": \"https://www.baidu.com\"\n}]\n\n</code></pre> <p>访问网关的路由规则，能看到刚刚加入的规则，访问<em>http://localhost:9022/baidu</em>时请求直接被转发到百度的首页了。</p> <p><img src=\"https://img-blog.csdnimg.cn/20200325164150414.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ZvdXNlXw==,size_16,color_FFFFFF,t_70#pic_center\" alt=\"生效的路径\"></p> <h3><a id=\"predicatesfilters_1465\"></a>服务发现路由predicates和filters的自定义定义</h3> <p>可以将网关配置为基于使用DiscoveryClient注册中心注册的服务发现路由。</p> <p>要启用此功能，请设置spring.cloud.gateway.discovery.locator.enabled=true，并确保DiscoveryClient实现位于classpath上并已启用（如netflix eureka、consul或zookeeper）。</p> <h3><a id=\"_1471\"></a>为注册中心路由配置断言和过滤器</h3> <p>默认情况下，网关为通过DiscoveryClient创建的路由定义单个断言和过滤器。</p> <pre><code>默认情况下，网关为通过DiscoveryClient创建的路由定义单个断言和过滤器。\n\n默认断言是使用/serviceId/**定义的path断言，其中 serviceId 是DiscoveryClient中服务的ID。\n默认过滤器是使用正则表达式 /serviceId/(?.*)和替换的/${remaining}进行重写。这只是在请求被发送到下游之前从路径中截取掉 service id 。\n</code></pre> <p><strong>注意</strong></p> <p>这个默认的过滤器，老版本没有，这就要命了</p> <p><strong>尼恩这几天做 推送中台 架构实操的时候， 升级了一下 springcloud gateway，这就要要了命了</strong></p> <p>请求全部是404</p> <p>而且由于 响应式编程不是太好调试， 不过，尼恩不吃这套，喜欢深入敌后，进入源码后， 大概找到了 <strong>断言处理迭代</strong> 的地方， 看到了 10多个过滤器</p> <p>其中一个过滤器 rewrite， 干了一件匪夷所思的事情，把后端服务的前缀给剔除了， 如果前缀是 serviceId的话</p> <p>这就是咱们的问题所在：赶巧的是，咱后端微服务，需要路径前缀，并且，路径的前缀就是 serviceId</p> <p>这下子，这个springcloud gateway的 升级骚操作，把 路劲前缀搞没了，当然路由不过去了， <strong>害的我白瞎了2小时</strong></p> <p><img src=\"https://img-blog.csdnimg.cn/5d3b8cbbbac24ba7a2a64e46bc684826.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5p625p6E5biILeWwvOaBqQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> <p>翻阅官方的文档，按照官方说明：</p> <p>可以通过设置 spring.cloud.gateway.discovery.locator.predicates[x] and spring.cloud.gateway.discovery.locator.filters[y] 来， 去自定义 DiscoveryClient路由使用的断言和过滤器。</p> <p>当做了定制以后，默认的就没了，如果你想要保留默认功能，需要手动加上 默认断言和过滤器。</p> <p>下面是这样一个例子。</p> <p><strong>Example 69. application.properties</strong></p> <pre><code class=\"prism language-yml\">spring.cloud.gateway.discovery.locator.predicates<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>.name<span class=\"token punctuation\">:</span> Path\nspring.cloud.gateway.discovery.locator.predicates<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>.args<span class=\"token punctuation\">[</span>pattern<span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"\'/\'+serviceId+\'/**\'\"</span>\nspring.cloud.gateway.discovery.locator.predicates<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>.name<span class=\"token punctuation\">:</span> Host\nspring.cloud.gateway.discovery.locator.predicates<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>.args<span class=\"token punctuation\">[</span>pattern<span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"\'**.foo.com\'\"</span>\nspring.cloud.gateway.discovery.locator.filters<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>.name<span class=\"token punctuation\">:</span> Hystrix\nspring.cloud.gateway.discovery.locator.filters<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>.args<span class=\"token punctuation\">[</span>name<span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span> serviceId\nspring.cloud.gateway.discovery.locator.filters<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>.name<span class=\"token punctuation\">:</span> RewritePath\nspring.cloud.gateway.discovery.locator.filters<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>.args<span class=\"token punctuation\">[</span>regexp<span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"\'/\' + serviceId + \'/(?&lt;remaining&gt;.*)\'\"</span>\nspring.cloud.gateway.discovery.locator.filters<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>.args<span class=\"token punctuation\">[</span>replacement<span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"\'/${remaining}\'\"</span>\n</code></pre> <p>于是，需要去掉这个RewritePath过滤器，下面为nacos定制客户端的过滤器</p> <pre><code>    gateway:\n      enabled: true\n      discovery:\n        locator:\n          enabled: true  #开启从注册中心动态创建路由的功能，利用微服务名进行路由\n          lower-case-service-id: true\n          filters:\n            - args[name]: serviceId\n              name: Hystrix\n          predicates:\n            - args[pattern]: \'\"\'\'/\'\'+serviceId+\'\'/**\'\'\"\'\n              name: Path\n  \n</code></pre> <p>本质上，要不要去掉url的前缀，配置文件的下边，完全有规则可以自己配置，</p> <p>当然，官方希望为 微服务 DiscoveryClient 路由 增加一些过滤器，也是可以理解的</p> <p>不管怎么说，咱们这个场景下，只能覆盖 官方的默认的discovery.filters的配置啦， 于是进行了上边的修改</p> <p>修改之后，重启，</p> <p>再通过断点看过滤器，那个 rewrite 过滤器，没有了</p> <p><img src=\"https://img-blog.csdnimg.cn/6eb02d0ed525424290533befc80aa30f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5p625p6E5biILeWwvOaBqQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> <p>终于不是404的错误了</p> \n   <blockquote> \n    <p>看起来，springcloud 官方勤快的升级版本，也没有干什么有意义的事情， 做的很多都是花瓶的活儿</p> \n   </blockquote> <h1><a id=\"6_SwaggerAPI_1571\"></a>6 整合Swagger聚合微服务系统API文档</h1> <p>有关源码 具体请参见 疯狂创客圈的 crazy-springcloud 脚手架</p> <h2><a id=\"maven_1575\"></a>maven依赖</h2> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;\n    &lt;parent&gt;\n        &lt;artifactId&gt;cloud-center-alibaba&lt;/artifactId&gt;\n        &lt;groupId&gt;com.crazymaker.springcloud&lt;/groupId&gt;\n        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;\n    &lt;/parent&gt;\n    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n\n    &lt;groupId&gt;com.crazymaker.springcloud&lt;/groupId&gt;\n    &lt;artifactId&gt;springcloud-gateway-demo&lt;/artifactId&gt;\n    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;\n    &lt;name&gt;springcloud-gateway-demo&lt;/name&gt;\n    &lt;packaging&gt;jar&lt;/packaging&gt;\n\n\n    &lt;dependencies&gt;\n        &lt;!--gateway 网关依赖,内置webflux 依赖 --&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;!--新增sentinel--&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt;\n            &lt;artifactId&gt;sentinel-spring-cloud-gateway-adapter&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt;\n            &lt;artifactId&gt;sentinel-transport-simple-http&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n\n        &lt;!-- nacos服务注册发现依赖--&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;\n            &lt;exclusions&gt;\n                &lt;exclusion&gt;\n                    &lt;groupId&gt;com.google.guava&lt;/groupId&gt;\n                    &lt;artifactId&gt;guava&lt;/artifactId&gt;\n                &lt;/exclusion&gt;\n            &lt;/exclusions&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;mysql&lt;/groupId&gt;\n            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;\n            &lt;version&gt;${mysql.connector.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;!-- nacos配置服务依赖--&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;\n            &lt;exclusions&gt;\n                &lt;exclusion&gt;\n                    &lt;groupId&gt;com.google.guava&lt;/groupId&gt;\n                    &lt;artifactId&gt;guava&lt;/artifactId&gt;\n                &lt;/exclusion&gt;\n            &lt;/exclusions&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n\n\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\n            &lt;artifactId&gt;lombok&lt;/artifactId&gt;\n            &lt;optional&gt;true&lt;/optional&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;\n            &lt;scope&gt;test&lt;/scope&gt;\n        &lt;/dependency&gt;\n\n\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;\n            &lt;artifactId&gt;lombok&lt;/artifactId&gt;\n            &lt;optional&gt;true&lt;/optional&gt;\n        &lt;/dependency&gt;\n\n        &lt;dependency&gt;\n            &lt;groupId&gt;cn.hutool&lt;/groupId&gt;\n            &lt;artifactId&gt;hutool-all&lt;/artifactId&gt;\n            &lt;version&gt;${hutool.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;io.springfox&lt;/groupId&gt;\n            &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt;\n            &lt;version&gt;${swagger.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;io.springfox&lt;/groupId&gt;\n            &lt;artifactId&gt;springfox-swagger-common&lt;/artifactId&gt;\n            &lt;version&gt;${swagger.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;\n            &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;\n            &lt;version&gt;${swagger-ui.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-cloud-commons&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n    &lt;/dependencies&gt;\n    &lt;build&gt;\n        &lt;plugins&gt;\n\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;mainClass&gt;com.crazymaker.cloud.nacos.demo.gateway.starter.GatewayProviderApplication&lt;/mainClass&gt;\n                &lt;/configuration&gt;\n                &lt;executions&gt;\n                    &lt;execution&gt;\n                        &lt;goals&gt;\n                            &lt;goal&gt;repackage&lt;/goal&gt;\n                        &lt;/goals&gt;\n                    &lt;/execution&gt;\n                &lt;/executions&gt;\n            &lt;/plugin&gt;\n\n\n            &lt;plugin&gt;\n                &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;\n                &lt;version&gt;2.4.1&lt;/version&gt;\n                &lt;configuration&gt;\n                    &lt;descriptors&gt;\n                        &lt;descriptor&gt;src/main/assembly/assembly.xml&lt;/descriptor&gt;\n                    &lt;/descriptors&gt;\n                &lt;/configuration&gt;\n                &lt;executions&gt;\n                    &lt;execution&gt;\n                        &lt;id&gt;make-assembly&lt;/id&gt;\n                        &lt;phase&gt;package&lt;/phase&gt;\n                        &lt;goals&gt;\n                            &lt;goal&gt;single&lt;/goal&gt;\n                        &lt;/goals&gt;\n                    &lt;/execution&gt;\n                &lt;/executions&gt;\n            &lt;/plugin&gt;\n\n            &lt;!-- 添加docker-maven插件 --&gt;\n\n            &lt;plugin&gt;\n                &lt;groupId&gt;com.spotify&lt;/groupId&gt;\n                &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt;\n                &lt;version&gt;1.1.1&lt;/version&gt;\n                &lt;configuration&gt;\n                    &lt;imageName&gt;dockerlocal:5000/${project.artifactId}:${project.version}&lt;/imageName&gt;\n                    &lt;baseImage&gt;dockerlocal:5000/java&lt;/baseImage&gt;\n                    &lt;entryPoint&gt;[\"java\", \"-jar\", \"/${project.build.finalName}.jar\"]&lt;/entryPoint&gt;\n                    &lt;dockerDirectory&gt;docker&lt;/dockerDirectory&gt;\n                    &lt;resources&gt;\n                        &lt;resource&gt;\n                            &lt;targetPath&gt;/&lt;/targetPath&gt;\n                            &lt;directory&gt;${project.build.directory}&lt;/directory&gt;\n                            &lt;include&gt;${project.build.finalName}.jar&lt;/include&gt;\n                        &lt;/resource&gt;\n                    &lt;/resources&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n\n        &lt;/plugins&gt;\n    &lt;/build&gt;\n&lt;/project&gt;\n</code></pre> <h2><a id=\"_1758\"></a>配置文件</h2> <pre><code>package com.crazymaker.cloud.nacos.demo.gateway.config;\n\nimport lombok.AllArgsConstructor;\nimport org.springframework.cloud.gateway.config.GatewayProperties;\nimport org.springframework.cloud.gateway.route.RouteLocator;\nimport org.springframework.cloud.gateway.support.NameUtils;\nimport org.springframework.context.annotation.Primary;\nimport org.springframework.stereotype.Component;\nimport springfox.documentation.swagger.web.SwaggerResource;\nimport springfox.documentation.swagger.web.SwaggerResourcesProvider;\n\nimport java.util.ArrayList;\nimport java.util.List;\n\n/**\n * @ClassName SwaggerProvider\n * @PackageName com.ruoyi.gateway.config\n * @Description\n * @Author daiz\n * @Date 2019/8/16 10:04\n * @Version 1.0\n */\n@Component\n@Primary\n@AllArgsConstructor\npublic class SwaggerConfig implements SwaggerResourcesProvider\n{\n    public static final String API_URI = \"/v2/api-docs\";\n\n    private final RouteLocator routeLocator;\n\n    private final GatewayProperties gatewayProperties;\n\n    @Override\n    public List&lt;SwaggerResource&gt; get()\n    {\n        /**\n         * 网关应用名称,不需要在网关的swagger 上展示\n         */\n        String appName = \"springcloud-gateway\";\n\n        List&lt;SwaggerResource&gt; resources = new ArrayList&lt;&gt;();\n        List&lt;String&gt; routes = new ArrayList&lt;&gt;();\n        // 取出gateway的route\n        routeLocator.getRoutes().subscribe(route -&gt; routes.add(route.getId()));\n        // 结合配置的route-路径(Path)，和route过滤，只获取有效的route节点\n        // 打开下面注释可以自动扫描接入gateway的服务，为了演示，只扫描system\n        // gatewayProperties.getRoutes().stream().filter(routeDefinition -&gt;\n        // routes.contains(routeDefinition.getId()))\n        gatewayProperties.getRoutes().stream()\n                .filter(route -&gt; route.getUri().getHost() != null)\n                .filter(route -&gt; !appName.equals(route.getUri().getHost()))\n                .forEach(routeDefinition -&gt; routeDefinition.getPredicates().stream()\n                        .filter(predicateDefinition -&gt; (\"Path\").equalsIgnoreCase(predicateDefinition.getName()))\n                        .forEach(predicateDefinition -&gt; resources\n                                .add(swaggerResource(routeDefinition.getId(), predicateDefinition.getArgs()\n                                        .get(NameUtils.GENERATED_NAME_PREFIX + \"0\").replace(\"/**\", API_URI)))));\n        return resources;\n    }\n\n    private SwaggerResource swaggerResource(String name, String location)\n    {\n        SwaggerResource swaggerResource = new SwaggerResource();\n        swaggerResource.setName(name);\n        swaggerResource.setLocation(location);\n        swaggerResource.setSwaggerVersion(\"2.0\");\n        return swaggerResource;\n    }\n}\n</code></pre> <h2><a id=\"_1834\"></a>效果：</h2> <p><img src=\"https://img-blog.csdnimg.cn/20210112153623924.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p> <h1><a id=\"7_Gatway__1840\"></a>7 Gatway 网关的过滤器开发</h1> <h2><a id=\"71___1844\"></a>7.1 过滤器的执行次序</h2> <p>Spring-Cloud-Gateway 基于过滤器实现，同 zuul 类似，有<strong>pre</strong>和<strong>post</strong>两种方式的 filter,分别处理<strong>前置逻辑</strong>和<strong>后置逻辑</strong>。客户端的请求先经过<strong>pre</strong>类型的 filter，然后将请求转发到具体的业务服务，收到业务服务的响应之后，再经过<strong>post</strong>类型的 filter 处理，最后返回响应到客户端。</p> <p>过滤器执行流程如下，<strong>order 越大，优先级越低</strong></p> <p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-6LXWmpxi-1653951773534)(https://gitee.com/idea360/oss/raw/master/images/spring-cloud-gateway-fliter-order.png)]</p> <p>分为全局过滤器和局部过滤器</p> \n   <ul>\n    <li><strong>全局过滤器：</strong></li>\n   </ul> \n   <blockquote> \n    <p>对所有路由生效</p> \n    <p>2、接口用时统计</p> \n   </blockquote> \n   <ul>\n    <li><strong>局部过滤器：</strong></li>\n   </ul> \n   <blockquote> \n    <p>对指定路由生效</p> \n   </blockquote> <h3><a id=\"72_1868\"></a>7.2定义全局过滤器</h3> <p>实现 GlobalFilter 和 Ordered，重写相关方法，加入到spring容器管理即可，无需配置，全局过滤器对所有的路由都有效。</p> <p>全局过滤器举例：代码如下：</p> <pre><code>package com.crazymaker.cloud.nacos.demo.gateway.config;\n\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.cloud.gateway.filter.GatewayFilterChain;\nimport org.springframework.cloud.gateway.filter.GlobalFilter;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.core.Ordered;\nimport org.springframework.core.annotation.Order;\nimport org.springframework.web.server.ServerWebExchange;\nimport reactor.core.publisher.Mono;\n\n@Configuration\npublic class FilterConfig\n{\n\n    @Bean\n    @Order(-1)\n    public GlobalFilter a()\n    {\n        return new AFilter();\n    }\n\n    @Bean\n    @Order(0)\n    public GlobalFilter b()\n    {\n        return new BFilter();\n    }\n\n    @Bean\n    @Order(1)\n    public GlobalFilter c()\n    {\n        return new CFilter();\n    }\n\n\n    @Slf4j\n    public class AFilter implements GlobalFilter, Ordered\n    {\n\n        @Override\n        public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain)\n        {\n            log.info(\"AFilter前置逻辑\");\n            return chain.filter(exchange).then(Mono.fromRunnable(() -&gt;\n            {\n                log.info(\"AFilter后置逻辑\");\n            }));\n        }\n\n        //   值越小，优先级越高\n//    int HIGHEST_PRECEDENCE = -2147483648;\n//    int LOWEST_PRECEDENCE = 2147483647;\n        @Override\n        public int getOrder()\n        {\n            return HIGHEST_PRECEDENCE + 100;\n        }\n    }\n\n    @Slf4j\n    public class BFilter implements GlobalFilter, Ordered\n    {\n        @Override\n        public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain)\n        {\n            log.info(\"BFilter前置逻辑\");\n            return chain.filter(exchange).then(Mono.fromRunnable(() -&gt;\n            {\n                log.info(\"BFilter后置逻辑\");\n            }));\n        }\n\n\n        //   值越小，优先级越高\n//    int HIGHEST_PRECEDENCE = -2147483648;\n//    int LOWEST_PRECEDENCE = 2147483647;\n        @Override\n        public int getOrder()\n        {\n            return HIGHEST_PRECEDENCE + 200;\n        }\n    }\n\n    @Slf4j\n    public class CFilter implements GlobalFilter, Ordered\n    {\n\n        @Override\n        public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain)\n        {\n            log.info(\"CFilter前置逻辑\");\n            return chain.filter(exchange).then(Mono.fromRunnable(() -&gt;\n            {\n                log.info(\"CFilter后置逻辑\");\n            }));\n        }\n\n        //   值越小，优先级越高\n//    int HIGHEST_PRECEDENCE = -2147483648;\n//    int LOWEST_PRECEDENCE = 2147483647;\n        @Override\n        public int getOrder()\n        {\n            return HIGHEST_PRECEDENCE + 300;\n        }\n    }\n}\n</code></pre> <h3><a id=\"73_1991\"></a>7.3定义局部过滤器</h3> <p>步骤：</p> <p>1 需要实现GatewayFilter, Ordered，实现相关的方法</p> <p>2 加入到过滤器工厂，并且注册到spring容器中。</p> <p>3、在配置文件中进行配置，如果不配置则不启用此过滤器规则。</p> <p>局部过滤器举例, 对请求头部的 user-id 进行校验，代码如下：</p> <p>1 需要实现GatewayFilter, Ordered，实现相关的方法</p> <pre><code>package com.crazymaker.cloud.nacos.demo.gateway.filter;\n\nimport lombok.extern.slf4j.Slf4j;\nimport org.apache.commons.lang3.StringUtils;\nimport org.springframework.cloud.gateway.filter.GatewayFilter;\nimport org.springframework.cloud.gateway.filter.GatewayFilterChain;\nimport org.springframework.cloud.gateway.filter.GlobalFilter;\nimport org.springframework.core.Ordered;\nimport org.springframework.http.HttpStatus;\nimport org.springframework.stereotype.Component;\nimport org.springframework.web.server.ServerWebExchange;\nimport reactor.core.publisher.Mono;\n\n//@Component\n@Slf4j\npublic class UserIdCheckGateWayFilter implements GatewayFilter, Ordered\n{\n    @Override\n    public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain)\n    {\n        String url = exchange.getRequest().getPath().pathWithinApplication().value();\n        log.info(\"请求URL:\" + url);\n        log.info(\"method:\" + exchange.getRequest().getMethod());\n       /*   String secret = exchange.getRequest().getHeaders().getFirst(\"secret\");\n        if (StringUtils.isBlank(secret))\n        {\n            return chain.filter(exchange);\n        }*/\n         //获取param 请求参数\n        String uname = exchange.getRequest().getQueryParams().getFirst(\"uname\");\n        //获取header\n        String userId = exchange.getRequest().getHeaders().getFirst(\"user-id\");\n        log.info(\"userId：\" + userId);\n\n        if (StringUtils.isBlank(userId))\n        {\n            log.info(\"*****头部验证不通过，请在头部输入  user-id\");\n            //终止请求，直接回应\n            exchange.getResponse().setStatusCode(HttpStatus.NOT_ACCEPTABLE);\n            return exchange.getResponse().setComplete();\n        }\n        return chain.filter(exchange);\n    }\n\n    //   值越小，优先级越高\n//    int HIGHEST_PRECEDENCE = -2147483648;\n//    int LOWEST_PRECEDENCE = 2147483647;\n    @Override\n    public int getOrder()\n    {\n        return HIGHEST_PRECEDENCE;\n    }\n}\n\n\n\n\n</code></pre> <p>2 加入到过滤器工厂，并且注册到spring容器中。</p> <pre><code>package com.crazymaker.cloud.nacos.demo.gateway.config;\n\nimport com.crazymaker.cloud.nacos.demo.gateway.filter.UserIdCheckGateWayFilter;\nimport org.springframework.cloud.gateway.filter.GatewayFilter;\nimport org.springframework.cloud.gateway.filter.factory.AbstractGatewayFilterFactory;\nimport org.springframework.stereotype.Component;\n\n\n@Component\npublic class UserIdCheckGatewayFilterFactory extends AbstractGatewayFilterFactory&lt;Object&gt;\n{\n    @Override\n    public GatewayFilter apply(Object config)\n    {\n        return new UserIdCheckGateWayFilter();\n    }\n}\n</code></pre> <p>3、在配置文件中进行配置，如果不配置则不启用此过滤器规则。</p> <pre><code>        - id: service_provider_demo_route_filter\n          uri: lb://service-provider-demo\n          predicates:\n            - Path=/filter/**\n          filters:\n            - RewritePath=/filter/(?&lt;segment&gt;.*), /provider/$\\{segment}\n            - UserIdCheck\n</code></pre> <h2><a id=\"8_Sentinel_2117\"></a>8 整合Sentinel完成流控和降级</h2> <h3><a id=\"maven_2119\"></a>maven依赖</h3> <p>使用Sentinel作为gateWay的限流、降级、系统保护工具</p> <pre><code>     &lt;!--alibaba 流量卫士--&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt;\n            &lt;artifactId&gt;sentinel-core&lt;/artifactId&gt;\n            &lt;version&gt;${sentinel.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n       &lt;dependency&gt;\n            &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt;\n            &lt;artifactId&gt;sentinel-spring-cloud-gateway-adapter&lt;/artifactId&gt;\n            &lt;version&gt;1.7.1&lt;/version&gt;\n        &lt;/dependency&gt;\n\n</code></pre> <h3><a id=\"_2146\"></a>配置文件</h3> <p>客户端配置：在配置文件中增加下列配置，dashboard就可以轻松管理客户端了，还有一种方式是在启动时加入</p> <pre><code>spring:\n  cloud:\n    sentinel:\n      transport:\n        ## VM\n        ##-Djava.net.preferIPv4Stack=true -Dcsp.sentinel.dashboard.server=localhost:8080 -Dcsp.sentinel.api.port=8666 -Dproject.name=gateway -Dcsp.sentinel.app.type=1\n        dashboard: localhost:8880\n        port: 8880\n\n</code></pre> <h3><a id=\"_2164\"></a>限流规则通用配置</h3> <p>由于sentinel的工作原理其实借助于全局的filter进行请求拦截并计算出是否进行限流、熔断等操作的，增加SentinelGateWayFilter配置</p> <pre><code>  @Bean//拦截请求\n  @Order(Ordered.HIGHEST_PRECEDENCE)\n  public GlobalFilter sentinelGatewayFilter() {\n    return new SentinelGatewayFilter();\n  }\n</code></pre> <p>sentinel 不仅支持通过硬代码方式进行资源的申明，还能通过注解方式进行声明，为了让注解生效，还需要配置切面类SentinelResourceAspect</p> <pre><code>   @Bean\n  public SentinelResourceAspect sentinelResourceAspect() {\n    return new SentinelResourceAspect();\n  }\n</code></pre> <p>sentinel拦截包括了视图、静态资源等，需要配置viewResolvers以及拦截之后的异常，我们也可以自定义抛出异常的提示</p> <pre><code>  public SentinelConfig(ObjectProvider&lt;List&lt;ViewResolver&gt;&gt; viewResolversProvider,\n                        ServerCodecConfigurer serverCodecConfigurer) {\n    this.viewResolvers = viewResolversProvider.getIfAvailable(Collections::emptyList);\n    this.serverCodecConfigurer = serverCodecConfigurer;\n  }\n\n  @Bean//自定义异常\n  @Order(Ordered.HIGHEST_PRECEDENCE)\n  public ExceptionHandler sentinelGatewayBlockExceptionHandler() {\n    // Register the block exception handler for Spring Cloud Gateway.\n    return new ExceptionHandler(viewResolvers, serverCodecConfigurer);\n  }\n</code></pre> <p>自定义异常提示：当发生限流、熔断异常时，会返回定义的提示信息。</p> <pre><code>    /**\n     * 配置限流的异常处理器:SentinelGatewayBlockExceptionHandler\n     */\n    @Bean\n    @Order(Ordered.HIGHEST_PRECEDENCE)\n    public SentinelGatewayBlockExceptionHandler sentinelGatewayBlockExceptionHandler() {\n        return new SentinelGatewayBlockExceptionHandlerEX(viewResolvers, serverCodecConfigurer);\n    }\n\n\n</code></pre> <pre><code>不需要额外的配置，sentinel就已经可以正常工作了\n</code></pre> <h3><a id=\"_2226\"></a>限流规则设置</h3> <p>1 资源定义：定义API组</p> <p>2 定义限流规则</p> \n   <blockquote> \n    <p>具体请参见学习视频</p> \n   </blockquote> <h3><a id=\"_2236\"></a>网关限流参数</h3> <p>其中网关限流规则 GatewayFlowRule的字段解释如下：</p> \n   <ul>\n    <li> <p>resource：资源名称，可以是网关中的 route 名称或者用户自定义的 API 分组名称。</p> </li>\n    <li> <p>resourceMode：规则是针对 API Gateway 的 route（RESOURCE_MODE_ROUTE_ID）还是用户在 Sentinel 中定义的 API 分组（RESOURCE_MODE_CUSTOM_API_NAME），默认是 route。</p> </li>\n    <li> <p>grade：限流指标维度，同限流规则的 grade 字段。</p> </li>\n    <li> <p>count：限流阈值</p> </li>\n    <li> <p>intervalSec：统计时间窗口，单位是秒，默认是 1 秒。</p> </li>\n    <li> <p>controlBehavior：流量整形的控制效果，同限流规则的 controlBehavior 字段，目前支持快速失败和匀速排队两种模式，默认是快速失败。</p> </li>\n    <li> <p>burst：应对突发请求时额外允许的请求数目。</p> </li>\n    <li> <p>maxQueueingTimeoutMs：匀速排队模式下的最长排队时间，单位是毫秒，仅在匀速排队模式下生效。</p> </li>\n    <li> <p>paramItem</p> <p>参数限流配置。若不提供，则代表不针对参数进行限流，该网关规则将会被转换成普通流控规则；否则会转换成热点规则。其中的字段：</p> \n     <ul>\n      <li>parseStrategy：从请求中提取参数的策略，目前支持提取来源 IP（PARAM_PARSE_STRATEGY_CLIENT_IP）、Host（PARAM_PARSE_STRATEGY_HOST）、任意 Header（PARAM_PARSE_STRATEGY_HEADER）和任意 URL 参数（PARAM_PARSE_STRATEGY_URL_PARAM）四种模式。</li>\n      <li>fieldName：若提取策略选择 Header 模式或 URL 参数模式，则需要指定对应的 header 名称或 URL 参数名称。</li>\n      <li>pattern：参数值的匹配模式，只有匹配该模式的请求属性值会纳入统计和流控；若为空则统计该请求属性的所有值。（1.6.2 版本开始支持）</li>\n      <li>matchStrategy：参数值的匹配策略，目前支持精确匹配（PARAM_MATCH_STRATEGY_EXACT）、子串匹配（PARAM_MATCH_STRATEGY_CONTAINS）和正则匹配（PARAM_MATCH_STRATEGY_REGEX）。（1.6.2 版本开始支持）</li>\n     </ul> </li>\n   </ul> <p>用户可以通过 GatewayRuleManager.loadRules(rules) 手动加载网关规则，或通过 GatewayRuleManager.register2Property(property) 注册动态规则源动态推送（推荐方式）。</p> <h2><a id=\"_2271\"></a>参考文献</h2> <p>官方文档</p> <p>https://cloud.spring.io/spring-cloud-gateway/reference/html</p> <p>https://cloud.spring.io/spring-cloud-gateway/reference/html/#configuring-predicates-and-filters-for-discoveryclient-routes</p> <p>https://www.cnblogs.com/satire/p/15092894.html</p></li>\n </ul> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 12407);
INSERT INTO `crawlerblog` VALUES (123124016, 'Nacos (史上最全)', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <p>文章很长，而且持续更新，建议收藏起来，慢慢读！ <a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\"><strong>总目录 博客园版</strong></a> 为您奉上珍贵的学习资源 ：</p> \n <ul>\n  <li> <p><strong>免费赠送 :<a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\">《尼恩Java面试宝典》持续更新+ 史上最全 + 面试必备 2000页+ </a> 面试必备 + 大厂必备 +涨薪必备</strong></p> </li>\n </ul> \n <ul>\n  <li> <p><strong>免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\">《Java高并发核心编程（卷1）》 </a> 面试必备 + 大厂必备 +涨薪必备</strong> 加尼恩免费领</p> </li>\n  <li> <p><strong>免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\">《Java高并发核心编程（卷2）》 </a> 面试必备 + 大厂必备 +涨薪必备</strong> 加尼恩免费领</p> </li>\n  <li> <p><strong>免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\">《Netty Zookeeper Redis 高并发实战》 </a> 面试必备 + 大厂必备 +涨薪必备</strong> 加尼恩免费领</p> </li>\n  <li> <p><strong>免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\">《SpringCloud Nginx高并发核心编程》 </a> 面试必备 + 大厂必备 +涨薪必备</strong> 加尼恩免费领</p> </li>\n  <li> <p><strong>免费赠送 资源宝库： Java 必备 百度网盘资源大合集 价值&gt;10000元</strong> <a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\">加尼恩领取</a> </p> </li>\n  <li><h2><a id=\"Java____httpswwwcnblogscomcrazymakercirclep13917138html_13\"></a>推荐：尼恩Java面试宝典（持续更新 + 史上最全 + 面试必备）<a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\">具体详情，请点击此链接</a></h2> <p>尼恩Java面试宝典，<strong>33个最新pdf</strong>，含<strong>2000多页</strong>，<strong>不断更新、持续迭代</strong> <a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\">具体详情，请点击此链接</a></p> <p><img src=\"https://img-blog.csdnimg.cn/d56e8af850e543e48f44ace26c437a78.png#pic_center#pic_center\" alt=\"在这里插入图片描述\"></p> \n   <hr> <h2><a id=\"1Nacos___22\"></a>1、Nacos 优势</h2> <pre><code>问题，既然有了Eureka ，为啥还要用Nacos？\n</code></pre> <p>而 Nacos 作为微服务核心的服务注册与发现中心，让大家在 Eureka 和 Consule 之外有了新的选择，开箱即用，上手简洁，暂时也没发现有太大的坑。</p> <h3><a id=\"11eureka_32\"></a>1.1与eureka对比</h3> \n   <blockquote> \n    <p>1 eureka 2.0闭源码了。</p> \n    <p>2 从官网来看nacos 的注册的实例数是大于eureka的,</p> \n    <p>3 因为nacos使用的raft协议,nacos集群的一致性要远大于eureka集群.</p> \n   </blockquote> <p>分布式一致性协议 Raft，自 2013 年论文发表，之后就受到了技术领域的热捧，与其他的分布式一致性算法比，Raft 相对比较简单并且易于实现，这也是 Raft 能异军突起的主要因素。</p> <p><img src=\"https://img-blog.csdnimg.cn/20191014133644698.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hpYW9IYW5adW9GZW5nWmhvdQ==,size_16,color_FFFFFF,t_70\" alt=\"img\"></p> \n   <blockquote> \n    <h2><a id=\"Raft__50\"></a>Raft 的数据一致性策略</h2> \n    <p>Raft 协议强依赖 Leader 节点来确保集群数据一致性。即 client 发送过来的数据均先到达 Leader 节点，Leader 接收到数据后，先将数据标记为 uncommitted 状态，随后 Leader 开始向所有 Follower 复制数据并等待响应，在获得集群中大于 N/2 个 Follower 的已成功接收数据完毕的响应后，Leader 将数据的状态标记为 committed，随后向 client 发送数据已接收确认，在向 client 发送出已数据接收后，再向所有 Follower 节点发送通知表明该数据状态为committed。</p> \n   </blockquote> <h3><a id=\"12springcloud_config__56\"></a>1.2与springcloud config 对比</h3> <h4><a id=\"_58\"></a>三大优势：</h4> \n   <ul>\n    <li> <p>springcloud config大部分场景结合git 使用, 动态变更还需要依赖Spring Cloud Bus 消息总线来通过所有的客户端变化.</p> </li>\n    <li> <p>springcloud config不提供可视化界面</p> </li>\n    <li> <p>nacos config使用长连接更新配置, 一旦配置有变动后，通知Provider的过程非常的迅速, 从速度上秒杀springcloud原来的config几条街,</p> </li>\n   </ul> <h2><a id=\"2Spring_Cloud_Alibaba__68\"></a>2、Spring Cloud Alibaba 套件</h2> <p>目前 Spring Cloud Alibaba 主要有三个组件：</p> \n   <ul>\n    <li> <p>Nacos：一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。</p> </li>\n    <li> <p>Sentinel：把流量作为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。</p> </li>\n    <li> <p>AliCloud OSS: 阿里云对象存储服务（Object Storage Service，简称<br> OSS），是阿里云提供的海量、安全、低成本、高可靠的云存储服务。您可以在任何应用、任何时间、任何地点存储和访问任意类型的数据。</p> </li>\n   </ul> <h3><a id=\"Spring_Cloud_Alibaba_Spring_Cloud_Netflix_78\"></a>Spring Cloud Alibaba 套件和Spring Cloud Netflix套件类比</h3> <p>仔细看看各组件的功能描述，Spring Cloud Alibaba 套件和Spring Cloud Netflix套件大致的对应关系：</p> \n   <ul>\n    <li>Nacos = Eureka/Consule + Config + Admin</li>\n    <li>Sentinel = Hystrix + Dashboard + Turbine</li>\n    <li>Dubbo = Ribbon + Feign</li>\n    <li>RocketMQ = RabbitMQ</li>\n    <li>Schedulerx = Quartz</li>\n    <li>AliCloud OSS、AliCloud SLS 这三个应该是独有的<br> 链路跟踪（Sleuth、Zipkin）不知道会不会在 Sentinel 里<br> 以上只是猜测，待我从坑里爬出来之后再回来更新。也欢迎大家一起交流探讨~<br> 这里我就先试试 Nacos。</li>\n   </ul> <h2><a id=\"3Nacos__92\"></a>3、Nacos 的架构和安装</h2> <h3><a id=\"31Nacos__94\"></a>3.1、Nacos 的架构</h3> <p><img src=\"https://img-blog.csdnimg.cn/20190329154650649.png\" alt=\"image\"></p> <p>这是 Nacos 的架构图，可以看到它确实是融合了服务注册发现中心、配置中心、服务管理等功能，类似于 Eureka/Consule + Config + Admin 的合体。</p> <p>另外通过官方文档发现，Nacos 除了可以和 Spring Cloud 集成，还可以和 Spring、SpringBoot 进行集成。</p> <p>不过我们只关注于 Spring Cloud，别的就略过了，直接上手实战吧。</p> <h3><a id=\"32Nacos_Server__106\"></a>3.2、Nacos Server 的下载和安装</h3> <p>在使用 Nacos 之前，需要先下载 Nacos 并启动 Nacos Server。</p> \n   <blockquote> \n    <p>安装的参考教程：</p> \n    <p>https://www.cnblogs.com/crazymakercircle/p/11992539.html</p> \n   </blockquote> <h2><a id=\"4Nacos_Server__118\"></a>4、Nacos Server 的运行</h2> <h3><a id=\"41_122\"></a>4.1两种模式</h3> <p>Nacos Server 有两种运行模式：</p> \n   <ul>\n    <li>standalone</li>\n    <li>cluster</li>\n   </ul> <h3><a id=\"42standalone__129\"></a>4.2、standalone 模式</h3> <p>此模式一般用于 demo 和测试，不用改任何配置，直接敲以下命令执行</p> <pre><code>sh bin/startup.sh -m standalone\n</code></pre> <p>Windows 的话就是</p> <pre><code>cmd bin/startup.cmd -m standalone\n</code></pre> <p>然后从 http://cdh1:8848/nacos/index.html 进入控制台就能看到如下界面了</p> <p><img src=\"https://img-blog.csdnimg.cn/20190329154915102.png\" alt=\"image\"></p> <p>默认账号和密码为：nacos nacos</p> <h3><a id=\"43cluster__151\"></a>4.3、cluster 模式</h3> <p>测试环境，可以先用 standalone 模式撸起来，享受 coding 的快感，但是，生产环境可以使用 cluster 模式。</p> <h4><a id=\"cluster__MySQL_155\"></a>cluster 模式需要依赖 MySQL，然后改两个配置文件：</h4> <pre><code>conf/cluster.conf\nconf/application.properties\n\n</code></pre> <p>大致如下：</p> <p>1： cluster.conf，填入要运行 Nacos Server 机器的 ip</p> <pre><code>192.168.100.155\n192.168.100.156\n\n</code></pre> \n   <ol start=\"2\">\n    <li>修改NACOS_PATH/conf/application.properties，加入 MySQL 配置</li>\n   </ol> <pre><code>db.num=1\ndb.url.0=jdbc:mysql://localhost:3306/nacos_config?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true\ndb.user=root\ndb.password=root\n</code></pre> <p>创建一个名为nacos_config的 database，将NACOS_PATH/conf/nacos-mysql.sql中的表结构导入刚才创建的库中，这几张表的用途就自己研究吧</p> <h3><a id=\"44_Nacos_Server__186\"></a>4.4 Nacos Server 的配置数据是存在哪里呢？</h3> <pre><code>问题来了： Nacos Server 的配置数据是存在哪里呢？\n</code></pre> <p>我们没有对 Nacos Server 做任何配置，那么数据只有两个位置可以存储：</p> \n   <ul>\n    <li>内存</li>\n    <li>本地数据库</li>\n   </ul> <p>如果我们现在重启刚刚在运行的 Nacos Server，会发现刚才加的 nacos.properties 配置还在，说明不是内存存储的。</p> <p>这时候我们打开NACOS_PATH/data，会发现里边有个derby-data目录，我们的配置数据现在就存储在这个库中。</p> \n   <blockquote> \n    <p>Derby 是 Java 编写的数据库，属于 Apache 的一个开源项目</p> \n   </blockquote> <p>如果将数据源改为我们熟悉的 MySQL 呢？当然可以。</p> \n   <blockquote> \n    <p>注意：不支持 MySQL 8.0 版本</p> \n   </blockquote> <p>这里有两个坑：</p> \n   <blockquote> \n    <p>Nacos Server 的数据源是用 Derby 还是 MySQL 完全是由其运行模式决定的：</p> \n   </blockquote> <pre><code>standalone 的话仅会使用 Derby，即使在 application.properties 里边配置 MySQL 也照样无视；\ncluster 模式会自动使用 MySQL，这时候如果没有 MySQL 的配置，是会报错的。\n</code></pre> <p>官方提供的 cluster.conf 示例如下</p> <pre><code>#it is ip\n#example\n10.10.109.214\n11.16.128.34\n11.16.128.36\n\n</code></pre> <p>以上配置结束后，运行 Nacos Server 就能看到效果了。</p> <h2><a id=\"5_1Nacos_233\"></a>5 实战1：使用Nacos作为注册中心</h2> <h3><a id=\"_235\"></a>实战的工程</h3> <p>实战的工程的目录结构如下：</p> <p><img src=\"https://img-blog.csdnimg.cn/20210104193150374.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p> <h3><a id=\"51Nacos___Client_241\"></a>5.1如何使用Nacos Client组件</h3> <h4><a id=\"_Spring_Cloud_Alibaba__BOM_245\"></a>首先引入 Spring Cloud Alibaba 的 BOM</h4> <pre><code>&lt;parent&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;\n    &lt;version&gt;2.0.4.RELEASE&lt;/version&gt;\n    &lt;relativePath/&gt;\n&lt;/parent&gt;\n&lt;properties&gt;\n    &lt;spring-cloud.version&gt;Finchley.SR2&lt;/spring-cloud.version&gt;\n    &lt;spring-cloud-alibaba.version&gt;0.2.0.RELEASE&lt;/spring-cloud-alibaba.version&gt;\n&lt;/properties&gt;\n&lt;dependencyManagement&gt;\n    &lt;dependencies&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt;\n            &lt;version&gt;${spring-cloud-alibaba.version}&lt;/version&gt;\n            &lt;type&gt;pom&lt;/type&gt;\n            &lt;scope&gt;import&lt;/scope&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;\n            &lt;version&gt;${spring-cloud.version}&lt;/version&gt;\n            &lt;type&gt;pom&lt;/type&gt;\n            &lt;scope&gt;import&lt;/scope&gt;\n        &lt;/dependency&gt;\n    &lt;/dependencies&gt;\n&lt;/dependencyManagement&gt;\n\n</code></pre> <p>这里版本号有坑，文档上说和 Spring Boot 2.0.x 版本兼容，但是实测 2.0.6.RELEASE 报错</p> <pre><code>java.lang.NoClassDefFoundError: org/springframework/core/env/EnvironmentCapable\n\n</code></pre> <h3><a id=\"52_288\"></a>5.2、演示的模块结构</h3> <p>服务注册中心和服务发现的服务端都是由 Nacos Server 来提供的，我们只需要提供 Service 向其注册就好了。</p> <p>这里模拟提供两个 service：provider 和 consumer</p> <pre><code>alibaba\n├── service-provider-demo\n│   ├── pom.xml\n│   └── src\n└── sevice-consumer-demo\n│   ├── pom.xml\n│   └── src\n└── pom.xml\n\n</code></pre> <h3><a id=\"53provider___308\"></a>5.3、provider 微服务</h3> <h4><a id=\"step1_provider__consumer__pom__312\"></a>step1：在 provider 和 consumer 的 pom 添加以下依赖：</h4> <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;\n&lt;/dependency&gt;\n\n</code></pre> <h4><a id=\"step2_330\"></a>step2：启动类</h4> <p>使用 Spring Cloud 的原生注解 @EnableDiscoveryClient 开启服务注册与发现</p> <pre><code>package com.crazymaker.cloud.nacos.demo.starter;\n\nimport com.crazymaker.springcloud.standard.context.SpringContextUtil;\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient;\nimport org.springframework.context.ConfigurableApplicationContext;\nimport org.springframework.core.env.Environment;\nimport springfox.documentation.swagger2.annotations.EnableSwagger2;\n\nimport java.util.List;\n\n@EnableSwagger2\n@SpringBootApplication\n@EnableDiscoveryClient\n@Slf4j\npublic class ServiceProviderApplication {\n    public static void main(String[] args) {\n        ConfigurableApplicationContext applicationContext =   SpringApplication.run(ServiceProviderApplication.class, args);\n\n        Environment env = applicationContext.getEnvironment();\n        String port = env.getProperty(\"server.port\");\n        String path = env.getProperty(\"server.servlet.context-path\");\n        System.out.println(\"\\n--------------------------------------\\n\\t\" +\n                \"Application is running! Access URLs:\\n\\t\" +\n                \"Local: \\t\\thttp://localhost:\" + port + path+ \"/index.html\\n\\t\" +\n               \"swagger-ui: \\thttp://localhost:\" + port + path + \"/swagger-ui.html\\n\\t\" +\n                \"----------------------------------------------------------\");\n\n    }\n}\n</code></pre> <h4><a id=\"step3_Rest__369\"></a>step3：服务提供者的 Rest 服务接口</h4> <p>service-provider-demo 提供 一个非常简单的 Rest 服务接口以供访问</p> <pre><code>package com.crazymaker.cloud.nacos.demo.controller;\n\nimport org.springframework.web.bind.annotation.PathVariable;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RequestMethod;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\n@RequestMapping(\"/echo\")\npublic class EchoController {\n    //回显服务\n    @RequestMapping(value = \"/{string}\", method = RequestMethod.GET)\n    public String echo(@PathVariable String string) {\n        return \"echo: \" + string;\n    }\n}\n\n</code></pre> <h4><a id=\"step4_395\"></a>step4：配置文件</h4> <pre><code>spring:\n  application:\n    name: service-provider-demo\n  cloud:\n    nacos:\n      discovery:\n        server-addr: ${NACOS_SERVER:cdh1:8848}\nserver:\n  port: 18080\n</code></pre> <h4><a id=\"step5swagger_UI_411\"></a>step5：启动之后，通过swagger UI访问：</h4> <p><img src=\"https://img-blog.csdnimg.cn/20210104153259531.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p> <h3><a id=\"54Consumer_RPC_419\"></a>5.4、Consumer 微服务演示RPC远程调用</h3> <p>在 NacosConsumerApplication 中集成 RestTemplate 和 Ribbon</p> <pre><code>@LoadBalanced\n@Bean\npublic RestTemplate restTemplate() {\n  return new RestTemplate();\n}\n\n</code></pre> <h4><a id=\"controller__432\"></a>消费者的controller 类</h4> <pre><code>package com.crazymaker.cloud.nacos.demo.consumer.controller;\n\nimport com.crazymaker.cloud.nacos.demo.consumer.client.EchoClient;\nimport io.swagger.annotations.Api;\nimport io.swagger.annotations.ApiOperation;\nimport org.springframework.web.bind.annotation.PathVariable;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RequestMethod;\nimport org.springframework.web.bind.annotation.RestController;\n\nimport javax.annotation.Resource;\n\n@RestController\n@RequestMapping(\"/echo\")\n@Api(tags = \"服务- 消费者\")\npublic class EchoConsumerController {\n\n\n    //注入 @FeignClient 注解配置 所配置的 EchoClient 客户端Feign实例\n    @Resource\n    EchoClient echoClient;\n\n\n    //回显服务\n    @ApiOperation(value = \"消费回显服务接口\")\n    @RequestMapping(value = \"/{string}\", method = RequestMethod.GET)\n    public String echoRemoteEcho(@PathVariable String string) {\n        return \"provider echo is:\" + echoClient.echo(string);\n    }\n}\n\n\n</code></pre> <h4><a id=\"_471\"></a>消费者配置文件</h4> <pre><code>spring:\n  application:\n    name: sevice-consumer-demo\n  cloud:\n    nacos:\n      discovery:\n        server-addr: 127.0.0.1:8848\nserver:\n  port: 18081\n\n</code></pre> <h4><a id=\"swagger_UI_488\"></a>通过swagger UI访问消费者：</h4> <p><img src=\"https://img-blog.csdnimg.cn/20210104155555838.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p> <p>访问远程的echo API：</p> <p><img src=\"https://img-blog.csdnimg.cn/20210104163056237.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p> <p><img src=\"https://img-blog.csdnimg.cn/20210104163124914.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p> <h3><a id=\"55_504\"></a>5.5涉及到的演示地址：</h3> <p>服务提供者 service-provider-demo：</p> <p><a href=\"http://localhost:18080/provider/swagger-ui.html#/Echo_%E6%BC%94%E7%A4%BA\">http://localhost:18080/provider/swagger-ui.html#/Echo_%E6%BC%94%E7%A4%BA</a></p> <p>服务消费者：</p> <p>[http://localhost:18081/consumer/swagger-ui.html#/%E6%9C%8D%E5%8A%A1-%20%E6%B6%88%E8%B4%B9%E8%80%85/echoRemoteEchoUsingGET](http://localhost:18081/consumer/swagger-ui.html#/服务- 消费者/echoRemoteEchoUsingGET)</p> <p>注册中心Nacos：</p> <p>http://cdh1:8848/nacos/index.html#/serviceManagement?dataId=&amp;group=&amp;appName=&amp;namespace=</p> <h3><a id=\"56Nacos_Console_524\"></a>5.6、Nacos Console</h3> <p>这时候查看 Nacos Console 也能看到已注册的服务列表及其详情</p> <p><img src=\"https://img-blog.csdnimg.cn/20210104155420489.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p> <h2><a id=\"62Nacos_534\"></a>6、实战2：使用Nacos作为配置中心</h2> <h3><a id=\"61_538\"></a>6.1、基本概念</h3> <h4><a id=\"1_Profile_540\"></a>1. Profile</h4> <p>Java项目一般都会有多个Profile配置，用于区分开发环境，测试环境，准生产环境，生成环境等，每个环境对应一个properties文件（或是yml/yaml文件），然后通过设置 spring.profiles.active 的值来决定使用哪个配置文件。</p> <p>例子：</p> <pre><code>spring:\n  application:\n    name: sharding-jdbc-provider\n  jpa:\n    hibernate:\n      ddl-auto: none\n      dialect: org.hibernate.dialect.MySQL5InnoDBDialect\n      show-sql: true\n  profiles:\n     active: sharding-db-table    # 分库分表配置文件\n    #active: atomiclong-id    # 自定义主键的配置文件\n    #active: replica-query    # 读写分离配置文件\n</code></pre> <p>Nacos Config的作用就把这些文件的内容都移到一个统一的配置中心，即方便维护又支持实时修改后动态刷新应用。</p> <h4><a id=\"2_Data_ID_567\"></a>2. Data ID</h4> <p>当使用Nacos Config后，Profile的配置就存储到Data ID下，即一个Profile对应一个Data ID</p> <p>Data ID的拼接格式：${prefix} - ${spring.profiles.active} . ${file-extension}</p> \n   <ul>\n    <li> <p>prefix 默认为 spring.application.name 的值，也可以通过配置项 spring.cloud.nacos.config.prefix 来配置</p> </li>\n    <li> <p>spring.profiles.active 取 spring.profiles.active 的值，即为当前环境对应的 profile</p> </li>\n    <li> <p>file-extension 为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension 来配置</p> </li>\n   </ul> <h4><a id=\"3_Group_581\"></a>3. Group</h4> <p>Group 默认为 DEFAULT_GROUP，可以通过 spring.cloud.nacos.config.group 来配置，当配置项太多或者有重名时，可以通过分组来方便管理</p> <p>最后就和原来使用springcloud一样通过@RefreshScope 和@Value注解即可</p> <h3><a id=\"62_Nacosconsole__589\"></a>6.2 通过Nacos的console 去增加配置</h3> <p>这回首先要在nacos中配置相关的配置，打开Nacos配置界面，依次创建2个Data ID</p> \n   <ul>\n    <li>nacos-config-demo-dev.yaml 开发环境的配置</li>\n    <li>nacos-config-demo-test.yaml 测试环境的配置</li>\n   </ul> <h4><a id=\"1nacosconfigdemodevyaml_596\"></a>1、nacos-config-demo-dev.yaml</h4> <p>内容如下图：</p> <p><img src=\"https://img-blog.csdnimg.cn/20210104174312428.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p> <h4><a id=\"2nacosconfigdemosityaml_604\"></a>2、nacos-config-demo-sit.yaml</h4> \n   <blockquote> \n    <p>内容如下图：</p> \n   </blockquote> <p><img src=\"https://img-blog.csdnimg.cn/20210104174236932.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p> <h3><a id=\"63_Nacos__Config_Client_612\"></a>6.3 使用Nacos Config Client组件</h3> <p>问题2：微服务Provider实例上，如何使用Nacos Config Client组件的有哪些步骤？</p> <h4><a id=\"1_nacos_config__620\"></a>1 加载nacos config 的客户端依赖：</h4> <pre><code class=\"prism language-html\"><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>dependency</span><span class=\"token punctuation\">&gt;</span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>groupId</span><span class=\"token punctuation\">&gt;</span></span>org.springframework.cloud<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>groupId</span><span class=\"token punctuation\">&gt;</span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>artifactId</span><span class=\"token punctuation\">&gt;</span></span>spring-cloud-starter-alibaba-nacos-config<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>artifactId</span><span class=\"token punctuation\">&gt;</span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>version</span><span class=\"token punctuation\">&gt;</span></span>${nacos.version}<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>version</span><span class=\"token punctuation\">&gt;</span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>dependency</span><span class=\"token punctuation\">&gt;</span></span>\n</code></pre> <h4><a id=\"_630\"></a>启动类</h4> <pre><code>package com.crazymaker.cloud.nacos.demo.consumer.starter;\n\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration;\nimport org.springframework.boot.autoconfigure.data.redis.RedisRepositoriesAutoConfiguration;\nimport org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;\nimport org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration;\nimport org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration;\nimport org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration;\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient;\nimport org.springframework.cloud.openfeign.EnableFeignClients;\nimport org.springframework.context.ConfigurableApplicationContext;\nimport org.springframework.core.env.Environment;\nimport springfox.documentation.swagger2.annotations.EnableSwagger2;\n\n@EnableSwagger2\n@EnableDiscoveryClient\n@Slf4j\n@SpringBootApplication(\n        scanBasePackages =\n                {\n                        \"com.crazymaker.cloud.nacos.demo\",\n                        \"com.crazymaker.springcloud.standard\"\n                },\n        exclude = {SecurityAutoConfiguration.class,\n                //排除db的自动配置\n                DataSourceAutoConfiguration.class,\n                DataSourceTransactionManagerAutoConfiguration.class,\n                HibernateJpaAutoConfiguration.class,\n                //排除redis的自动配置\n                RedisAutoConfiguration.class,\n                RedisRepositoriesAutoConfiguration.class})\n//启动Feign\n@EnableFeignClients(basePackages =\n        {\"com.crazymaker.cloud.nacos.demo.consumer.client\"})\npublic class ConfigDomeProviderApplication\n{\n    public static void main(String[] args)\n    {\n        ConfigurableApplicationContext applicationContext = null;\n        try\n        {\n            applicationContext = SpringApplication.run(ConfigDomeProviderApplication.class, args);\n            System.out.println(\"Server startup done.\");\n        } catch (Exception e)\n        {\n            log.error(\"服务启动报错\", e);\n            return;\n        }\n\n        Environment env = applicationContext.getEnvironment();\n        String port = env.getProperty(\"server.port\");\n        String path = env.getProperty(\"server.servlet.context-path\");\n        System.out.println(\"\\n----------------------------------------------------------\\n\\t\" +\n                \"Application is running! Access URLs:\\n\\t\" +\n                \"Local: \\t\\thttp://localhost:\" + port + path + \"/index.html\\n\\t\" +\n                \"swagger-ui: \\thttp://localhost:\" + port + path + \"/swagger-ui.html\\n\\t\" +\n                \"----------------------------------------------------------\");\n\n    }\n}\n</code></pre> <h4><a id=\"_700\"></a>控制类：</h4> <pre><code>package com.crazymaker.cloud.nacos.demo.config.controller;\n\nimport io.swagger.annotations.Api;\nimport io.swagger.annotations.ApiOperation;\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.web.bind.annotation.PathVariable;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RequestMethod;\nimport org.springframework.web.bind.annotation.RestController;\n\nimport javax.annotation.Resource;\n\n@RestController\n@RequestMapping(\"/config\")\n@Api(tags = \"Nacos 配置中心演示\")\npublic class ConfigGetController {\n\n\n    @Value(\"${foo.bar:empty}\")\n    private String bar;\n\n\n    @Value(\"${spring.datasource.username:empty}\")\n    private String dbusername;\n\n    //获取配置的内容\n    @ApiOperation(value = \"获取配置的内容\")\n    @RequestMapping(value = \"/bar\", method = RequestMethod.GET)\n    public String getBar() {\n        return \"bar is :\"+bar;\n    }\n    //获取配置的内容\n    @ApiOperation(value = \"获取配置的db username\")\n    @RequestMapping(value = \"/dbusername\", method = RequestMethod.GET)\n    public String getDbusername() {\n        return \"db username is :\"+bar;\n    }\n}\n\n</code></pre> <h4><a id=\"2_bootstrap_744\"></a>2 bootstrap配置文件</h4> <p>然后是在配置文件(bootstrap.yml)中加入以下的内容：</p> <pre><code class=\"prism language-html\">spring:\n  application:\n    name: nacos-config-demo-provider\n  profiles:\n    active:  dev\n  cloud:\n    nacos:\n      discovery:\n        server-addr: ${NACOS_SERVER:cdh1:8848}\n      config:\n        server-addr: ${NACOS_SERVER:cdh1:8848}\n        prefix: nacos-config-demo\n        group: DEFAULT_GROUP\n        file-extension: yaml\nserver:\n  port: 18083\n  servlet:\n    context-path: /config\n\n</code></pre> <h3><a id=\"64__772\"></a>6.4 测试结果</h3> <p>启动程序，通过swagger ui访问：</p> \n   <blockquote> \n    <p>http://localhost:18083/config/swagger-ui.html#</p> \n   </blockquote> <p><img src=\"https://img-blog.csdnimg.cn/20210104180120300.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p> <p>执行结果如下：</p> <p><img src=\"https://img-blog.csdnimg.cn/20210104180306705.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p> <h3><a id=\"64__788\"></a>6.4 可以端如何与服务端的配置文件相互对应</h3> \n   <ul>\n    <li> <p>config.prefix 来对应主配置文件</p> </li>\n    <li> <p>使用spring.cloud.nacos.config.ext-config 选项来对应更多的文件</p> <p>eg：</p> </li>\n   </ul> <pre><code>spring:\n  application:\n    name: nacos-config-demo-provider\n  profiles:\n    active: dev\n  cloud:\n    nacos:\n      discovery:\n        server-addr: ${NACOS_SERVER:cdh1:8848}\n      config:\n        server-addr: ${NACOS_SERVER:cdh1:8848}\n        prefix: nacos-config-demo\n        group: DEFAULT_GROUP\n        file-extension: yaml\n        ext-config:\n          - data-id: crazymaker-db-dev.yml\n            group: DEFAULT_GROUP\n            refresh: true\n          - data-id: crazymaker-redis-dev.yml\n            group: DEFAULT_GROUP\n            refresh: true\n          - data-id: crazymaker-common-dev.yml\n            group: DEFAULT_GROUP\n            refresh: true\n          - data-id: some.properties\n            group: DEFAULT_GROUP\n            refresh: true\n\n</code></pre> <p>启动程序，发现可以获取到其他data-id的配置 ,大家可以自行配置。</p> <h3><a id=\"7_835\"></a>7、配置的隔离</h3> <p>在实际的应用中，存在着以下几种环境隔离的要求：</p> <p>1、开发环境、测试环境、准生产环境和生产环境需要隔离</p> <p>2、不同项目需要隔离</p> <p>3、同一项目，不同的模块需要隔离</p> <p>可以通过三种方式来进行配置隔离：Nacos的服务器、namespace命名空间、group分组，在bootstrap.yml文件中可以通过配置Nacos的server-addr、namespace和group来区分不同的配置信息。</p> \n   <ul>\n    <li>Nacos的服务器 spring.cloud.nacos.config.server-addr</li>\n    <li>Nacos的命名空间 spring.cloud.nacos.config.namespace，注意，这里使用命名空间的ID不是名称</li>\n    <li>Nacos的分组 spring.cloud.nacos.config.group</li>\n   </ul> <h3><a id=\"8_nacos_853\"></a>8 nacos集群搭建</h3> <p>如果我们要搭建集群的话，那么肯定是不能用内嵌的数据库，不然数据无法共享。所以，集群搭建的时候我们需要将Nacos对接Mysql进行数据存储。</p> <p>集群模式跟我们平时进行扩容是一样的，可以通过Nginx转发到多个节点，最前面挂一个域名即可，如下图：<img src=\"https://img-blog.csdnimg.cn/20190807114946379.png\" alt=\"在这里插入图片描述\"></p> <h3><a id=\"IP_863\"></a>IP规划</h3> <p>通常如果我们只是为了体验的话，直接在本地起动3个实例就可以了，没必要真的去搞三台服务器，下面我们就以在本地的方式来搭建集群。 将Nacos的解压包复制分成3份，分别是:</p> <p>nacos<br> nacos1<br> nacos2</p> <p>进入nacos的conf目录，编辑application.properties文件，增加数据库配置</p> <pre><code># 指定数据源为Mysql\nspring.datasource.platform=mysql\n\n# 数据库实例数量\ndb.num=1\ndb.url.0=jdbc:mysql://localhost:3306/nacos?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true\ndb.user=root\ndb.password=123456\n</code></pre> <p>复制代码同样的步骤进入nacos1和nacos2操作一遍，唯一需要修改的就是application.properties文件中的server.port，默认nacos的server.port=8848，</p> <p>我们在本地启动三个实例，那么端口肯定会冲突，所以其他2个实例的端口我们需要进行修改，比如nacos1修改成8847，nacos2修改成8846。<br> 数据库配置信息好了后，我们需要将对应的数据库和表进行初始化，数据库脚本在conf目录下的nacos-mysql.sql中，执行即可。</p> <p>最后一步需要配置一份集群节点信息，配置文件在conf目录下的cluster.conf.example文件，我们进行重命名成cluster.conf。 然后编辑cluster.conf文件，增加3个节点的信息，格式为IP:PORT，三个目录都一致即可。</p> <pre><code>127.0.0.1:8848\n127.0.0.1:8847\n127.0.0.1:8846\n</code></pre> <p>启动的话直接到bin目录下，执行./startup.sh就可以了，默认就是集群模式，不需要加任何参数。</p> <h3><a id=\"_905\"></a>集群的使用</h3> <p>上面的集群，虽然可用， 但仍不是真正的集群， 我们一般不会这么用。nacos集群的使用一般有4种方式：</p> \n   <ul>\n    <li> <p>http://ip1:port/openAPI 直连ip模式，不同的节点，则需要修改ip才可以使用。</p> </li>\n    <li> <p>http://VIP:port/openAPI VIP模式高可用，客户端vip即可，VIP下面挂server真实ip，部署比较麻烦，需要部署vip（keepalive）。</p> </li>\n    <li> <p>http://nacos.com:port/openAPI 域名模式，可读性好，而且换ip方便，在host文件配置本地域名即可。</p> </li>\n    <li> <p>http://反向代理:port/openAPI 反向代理模式</p> </li>\n   </ul> \n   <blockquote> \n    <p>这里介绍一下反向代理模式。</p> \n   </blockquote> <p>关于Nginx的安装和配置，本文就不进行讲解了，不会的可以自己去尝试下，反向代理模式 核心配置如下：</p> <pre><code>upstream nacos_server {\n  server 127.0.0.1:8848;\n  server 127.0.0.1:8847;\n  server 127.0.0.1:8846;\n}\n\nserver {\nlisten 8648;\n   server_name localhost;\n  #charset koi8-r;\n  #access_log logs/host.access.log main;\n  location / {\n     proxy_pass http://nacos_server;\n     index index.html index.htm;\n   }\n}\n\n \n</code></pre> <p>整体来说，nacos的集群搭建方式还是挺简单的，没什么特别要注意的，最好是能通过域名的方式来进行访问，另外数据库这块如果上生产环境，也需要考虑高可用问题，至少也得有个主从。</p> <p>8648 的nginx 提供的 nacos 服务接口，可以自定义。 我们访问</p> <p>http://localhost:8648/nacos/#/clusterManagement?dataId=&amp;group=&amp;appName=&amp;namespace=&amp;serverId=</p> <p>，就可以看到：</p> <p><img src=\"https://img-blog.csdnimg.cn/img_convert/67bb27130e750323a89d8043ea6bfe27.png\" alt=\"img\"></p> <p>我们可以简单测试一下，杀掉 一个的 nacos ，看服务是否正常。 后面，我们对微服务提供nacos服务的时候，只要配置这个nginx 端口就好了！！</p></li>\n </ul> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 4279);
INSERT INTO `crawlerblog` VALUES (123124017, 'TCP协议详解 (史上最全)', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <p>文章很长，建议收藏起来，慢慢读! <a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\"><strong>疯狂创客圈</strong></a>为小伙伴奉上以下珍贵的学习资源：</p> \n <ul>\n  <li><strong>疯狂创客圈 经典图书 ： <a href=\"https://www.cnblogs.com/crazymakercircle/p/11397271.html\">《Netty Zookeeper Redis 高并发实战》</a> 面试必备 + 大厂必备 + 涨薪必备</strong></li>\n  <li><strong>疯狂创客圈 经典图书 ： <a href=\"https://www.cnblogs.com/crazymakercircle/p/13878143.html\">《SpringCloud、Nginx高并发核心编程》</a> 面试必备 + 大厂必备 + 涨薪必备</strong></li>\n  <li>资源宝库： Java程序员必备 网盘资源大集合 价值&gt;1000元 <strong>随便取</strong> GO-&gt;【<a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\"><strong>博客园总入口</strong></a> 】</li>\n  <li>独孤九剑：<a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\"><strong>Netty灵魂实验</strong></a> ： 本地 <strong>100W连接</strong> 高并发实验，<a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\"><strong>瞬间提升Java内力</strong></a></li>\n  <li>最纯粹的技术交流：<strong><a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\">和大厂 小伙伴、技术高手、架构师 进行 纯粹的的技术问题交流、探讨求助、问题围观学习</a></strong></li>\n </ul> \n <hr> \n <h2><a id=\"2_Java__21__8\"></a>推荐2：史上最全 Java 面试题 21 个专题</h2> \n <table>\n  <thead>\n   <tr>\n    <th align=\"left\">史上最全 Java 面试题 21 个专题</th>\n    <th>阿里、京东、美团、头条… 随意挑、横着走！！！</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td align=\"left\">1： JVM面试题（史上最强、持续更新、吐血推荐）</td>\n    <td><a href=\"https://www.cnblogs.com/crazymakercircle/p/14365820.html\">https://www.cnblogs.com/crazymakercircle/p/14365820.html</a></td>\n   </tr>\n   <tr>\n    <td align=\"left\">2：Java基础面试题（史上最全、持续更新、吐血推荐）</td>\n    <td><a href=\"https://www.cnblogs.com/crazymakercircle/p/14366081.html\">https://www.cnblogs.com/crazymakercircle/p/14366081.html</a></td>\n   </tr>\n   <tr>\n    <td align=\"left\">4：设计模式面试题 （史上最全、持续更新、吐血推荐）</td>\n    <td><a href=\"https://www.cnblogs.com/crazymakercircle/p/14367101.html\">https://www.cnblogs.com/crazymakercircle/p/14367101.html</a></td>\n   </tr>\n   <tr>\n    <td align=\"left\">5：架构设计面试题 （史上最全、持续更新、吐血推荐）</td>\n    <td><a href=\"https://www.cnblogs.com/crazymakercircle/p/14367907.html\">https://www.cnblogs.com/crazymakercircle/p/14367907.html</a></td>\n   </tr>\n   <tr>\n    <td align=\"left\">还有 21篇<strong>必刷、必刷</strong> 的面试题</td>\n    <td>更多 …， 请参见【<a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\"> 疯狂创客圈 高并发 总目录</a> 】</td>\n   </tr>\n  </tbody>\n </table> \n <hr> \n <h2><a id=\"3_____19\"></a>推荐3： 疯狂创客圈 高质量 博文</h2> \n <table>\n  <thead>\n   <tr>\n    <th align=\"left\">springCloud 高质量 博文</th>\n    <th></th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td align=\"left\"><a href=\"https://www.cnblogs.com/crazymakercircle/p/14231815.html\"> nacos 实战（史上最全）</a></td>\n    <td><a href=\"https://www.cnblogs.com/crazymakercircle/p/14285001.html\"> sentinel （史上最全+入门教程）</a></td>\n   </tr>\n   <tr>\n    <td align=\"left\"><a href=\"https://www.cnblogs.com/crazymakercircle/p/14312282.html\"> springcloud + webflux 高并发实战</a></td>\n    <td><a href=\"https://www.cnblogs.com/crazymakercircle/p/14302151.html\"> Webflux（史上最全）</a></td>\n   </tr>\n   <tr>\n    <td align=\"left\"><a href=\"https://www.cnblogs.com/crazymakercircle/p/11704077.html\"> SpringCloud gateway （史上最全）</a></td>\n    <td><a href=\"https://www.cnblogs.com/crazymakercircle/p/14499211.html\"><strong>TCP/IP图解 （史上最全）</strong></a></td>\n   </tr>\n   <tr>\n    <td align=\"left\"><a href=\"https://www.cnblogs.com/crazymakercircle/p/10225159.html\">10分钟看懂， Java NIO 底层原理</a></td>\n    <td><a href=\"https://www.cnblogs.com/crazymakercircle/p/11965726.html\">Feign原理 （图解）</a></td>\n   </tr>\n   <tr>\n    <td align=\"left\">更多精彩博文 …</td>\n    <td>请参见【<a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\"> 疯狂创客圈 高并发 总目录</a> 】</td>\n   </tr>\n  </tbody>\n </table> \n <hr> \n <p>TCP/IP协议包含了一系列的协议，也叫TCP/IP协议族（TCP/IP Protocol Suite，或TCP/IP<br> Protocols），简称TCP/IP。TCP/IP协议族提供了点对点的连结机制，并且将传输数据帧的封装、寻址、传输、路由以及接收方式，都予以标准化。</p> \n <h2><a id=\"TCPIP_35\"></a>TCP/IP协议的分层模型</h2> \n <p>在展开介绍TCP/IP协议之前，首先介绍一下七层ISO模型。国际标准化组织ISO为了使网络应用更为普及，推出了OSI参考模型，即开放式系统互联（Open<br> System Interconnect）模型，<br> 一般都叫OSI参考模型。OSI参考模型是ISO组织在1985年发布的网络互连模型，其含义就是为所有公司使用一个统一的规范来控制网络，这样所有公司遵循相同的通信规范，网络就能互联互通了。</p> \n <h3><a id=\"OSI_42\"></a>OSI模型的七层框架</h3> \n <p>OSI模型定义了网络互连的七层框架（物理层、数据链路层、网络层、传输层、会话层、表示层、应用层），每一层实现各自的功能和协议，并完成与相邻层的接口通信。OSI模型各层的通信协议，大致举例如下表所示：</p> \n <p>表：OSI模型各层的通信协议举例</p> \n <table>\n  <thead>\n   <tr>\n    <th>应用层</th>\n    <th>HTTP、SMTP、SNMP、FTP、Telnet、SIP、SSH、NFS、RTSP、XMPP、Whois、ENRP、等等</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>表示层</td>\n    <td>XDR、ASN.1、SMB、AFP、NCP、等等</td>\n   </tr>\n   <tr>\n    <td>会话层</td>\n    <td>ASAP、SSH、RPC、NetBIOS、ASP、Winsock、BSD Sockets、等等</td>\n   </tr>\n   <tr>\n    <td>传输层</td>\n    <td>TCP、UDP、TLS、RTP、SCTP、SPX、ATP、IL、等等</td>\n   </tr>\n   <tr>\n    <td>网络层</td>\n    <td>IP、ICMP、IGMP、IPX、BGP、OSPF、RIP、IGRP、EIGRP、ARP、RARP、X.25、等等</td>\n   </tr>\n   <tr>\n    <td>数据链路层</td>\n    <td>以太网、令牌环、HDLC、帧中继、ISDN、ATM、IEEE 802.11、FDDI、PPP、等等</td>\n   </tr>\n   <tr>\n    <td>物理层</td>\n    <td>例如铜缆、网线、光缆、无线电等等</td>\n   </tr>\n  </tbody>\n </table> \n <p>TCP/IP协议是Internet互联网最基本的协议，其在一定程度上参考了七层ISO模型。OSI模型共有七层，从下到上分别是物理层、数据链路层、网络层、运输层、会话层、表示层和应用层。但是这显然是有些复杂的，所以在TCP/IP协议中，七层被简化为了四个层次。TCP/IP模型中的各种协议，依其功能不同，被分别归属到这四层之中，常被视为是简化过后的七层OSI模型。</p> \n <h3><a id=\"TCPIPISO_61\"></a>TCP/IP协议与七层ISO模型的对应关系</h3> \n <p>TCP/IP协议与七层ISO模型的对应关系，大致如下图所示：<br> <img src=\"https://img-blog.csdnimg.cn/20210308123113714.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70#pic_center\" alt=\"在这里插入图片描述\"></p> \n <p>图：TCP/IP协议与七层ISO模型的对应关系</p> \n <p>TCP/IP协议的应用层的主要协议有HTTP、Telnet、FTP、SMTP等，是用来读取来自传输层的数据或者将数据传输写入传输层；传输层的主要协议有UDP、TCP，实现端对端的数据传输；网络层的主要协议有ICMP、IP、IGMP，主要负责网络中数据包的传送等；链路层有时也称作数据链路层或网络接口层，主要协议有ARP、RARP，<br> 通常包括操作系统中的设备驱动程序和计算机中对应的网络接口卡，它们一起处理与传输媒介（如电缆或其他物理设备）的物理接口细节。</p> \n <p>（一）TCP/IP协议的应用层</p> \n <p>应用层包括所有和应用程序协同工作，并利用基础网络交换应用程序的业务数据的协议。一些特定的程序被认为运行在这个层上，该层协议所提供的服务能直接支持用户应用。应用层协议包括HTTP（万维网服务）、FTP（文件传输）、SMTP（电子邮件）、SSH（安全远程登陆）、DNS（域名解析）以及许多其他协议。</p> \n <p>（二）TCP/IP协议的传输层</p> \n <p>传输层的协议，解决了诸如端到端可靠性问题，能确保数据可靠的到达目的地，甚至能保证数据按照正确的顺序到达目的地。传输层的主要功能大致如下：</p> \n <p>（1）为端到端连接提供传输服务；</p> \n <p>（2）这种传输服务分为可靠和不可靠的，其中TCP是典型的可靠传输，而UDP则是不可靠传输；</p> \n <p>（3）为端到端连接提供流量控制、差错控制、QoS(Quality of<br> Service)服务质量等管理服务。</p> \n <p>传输层主要有两个性质不同的协议：TCP传输控制协议和UDP用户数据报协议。</p> \n <p>TCP协议是一个面向连接的、可靠的传输协议，它提供一种可靠的字节流，能保证数据完整、无损并且按顺序到达。TCP尽量连续不断地测试网络的负载并且控制发送数据的速度以避免网络过载。另外，TCP试图将数据按照规定的顺序发送。</p> \n <p>UDP协议是一个无连接的数据报协议，是一个“尽力传递”和“不可靠”协议，不会对数据包是否已经到达目的地进行检查，并且不保证数据包按顺序到达。</p> \n <p>总体来说，TCP协议传输效率低，但可靠性强；UDP协议传输效率高，但可靠性略低，适用于传输可靠性要求不高、体量小的数据（比如QQ聊天数据）。</p> \n <p>（三）TCP/IP协议的网络层</p> \n <p>TCP/IP协议网络层的作用是在复杂的网络环境中为要发送的数据报找到一个合适的路径进行传输。简单来说，网络层负责将数据传输到目标地址，目标地址可以是多个网络通过路由器连接而成的某一个地址。另外，网络层负责寻找合适的路径到达对方计算机，并把数据帧传送给对方，网络层还可以实现拥塞控制、网际互连等功能。网络层协议的代表包括：ICMP、IP、IGMP等。</p> \n <p>（四）TCP/IP协议的链路层</p> \n <p>链路层有时也称作数据链路层或网络接口层，用来处理连接网络的硬件部分。该层既包括操作系统硬件的设备驱动、NIC（网卡）、光纤等物理可见部分，还包括连接器等一切传输媒介。在这一层，数据的传输单位为比特。其主要协议有ARP、RARP等。</p> \n <h2><a id=\"_MAC_104\"></a>图解 物理层：使用MAC解决设备的身份证问题</h2> \n <h3><a id=\"_106\"></a>通信的原始时代</h3> \n <p>很久很久之前，你不与任何其他电脑相连接，孤苦伶仃。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/c116974d56c675f7538797a22e91c0a5.png\" alt=\"image\"></p> \n <p>直到有一天，你希望与另一台电脑 B 建立通信，于是你们各开了一个网口，用一根<strong>网线</strong>连接了起来。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/a836e2da1f508613647ca30447a76720.png\" alt=\"image\"></p> \n <p>用一根网线连接起来怎么就能\"通信\"了呢？我可以给你讲 IO、讲中断、讲缓冲区，但这不是研究网络时该关心的问题。</p> \n <p>如果你纠结，要么去研究一下操作系统是如何处理网络 IO 的，要么去研究一下包是如何被网卡转换成电信号发送出去的，要么就仅仅把它当做电脑里有个小人在<strong>开枪</strong>吧~</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/1072881fab34b4a2e55f26b28b80df88.gif\" alt=\"image.gif\"></p> \n <p>反正，你们就是连起来了，并且可以通信。</p> \n <p>有一天，一个新伙伴 C 加入了，但聪明的你们很快发现，可以每个人开<strong>两个网口</strong>，用一共<strong>三根网线</strong>，彼此相连。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/3ed1eec2d396a3e47d5ef4c54f6cabed.png\" alt=\"image\"></p> \n <p>随着越来越多的人加入，你发现身上开的网口实在太多了，而且网线密密麻麻，混乱不堪。（而实际上一台电脑根本开不了这么多网口，所以这种连线只在理论上可行，所以连不上的我就用红色虚线表示了，就是这么严谨哈哈~）</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/00ab6bac211258aedd99d2633d105664.png\" alt=\"image\"></p> \n <h3><a id=\"_132\"></a>集线器的诞生</h3> \n <p>于是你们发明了一个中间设备，你们将网线都插到这个设备上，由这个设备做转发，就可以彼此之间通信了，本质上和原来一样，只不过网口的数量和网线的数量减少了，不再那么混乱。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/c33959d3b2df76cd5beb599561e098e9.png\" alt=\"image\"></p> \n <p>你给它取名叫<strong>集线器</strong>，它仅仅是无脑将电信号<strong>转发到所有出口（广播）</strong>，不做任何处理，你觉得它是没有智商的，因此把人家定性在了<strong>物理层</strong>。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/00f213db8eb3a7d6735c026de3833ca1.gif\" alt=\"image.gif\"></p> \n <p>由于转发到了所有出口，那 BCDE 四台机器怎么知道数据包是不是发给自己的呢？</p> \n <p>首先，你要给所有的连接到交换机的设备，都起个名字。原来你们叫 ABCD，但现在需要一个更专业的，<strong>全局唯一</strong>的名字作为标识，你把这个更高端的名字称为 <strong>MAC 地址</strong>。</p> \n <p>你的 MAC 地址是 aa-aa-aa-aa-aa-aa，你的伙伴 b 的 MAC 地址是 bb-bb-bb-bb-bb-bb，以此类推，不重复就好。</p> \n <p>这样，A 在发送数据包给 B 时，只要在头部拼接一个这样结构的数据，就可以了。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/6b1e9c8e0c27da30b41d0115d3dd1194.png\" alt=\"image\"></p> \n <p>B 在收到数据包后，根据头部的目标 MAC 地址信息，判断这个数据包的确是发给自己的，于是便<strong>收下</strong>。</p> \n <p>其他的 CDE 收到数据包后，根据头部的目标 MAC 地址信息，判断这个数据包并不是发给自己的，于是便<strong>丢弃</strong>。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/e44f6748c5c296f8e37a7eb18d764cb5.gif\" alt=\"image\"></p> \n <p>虽然集线器使整个布局干净不少，但原来我只要发给电脑 B 的消息，现在却要发给连接到集线器中的所有电脑，这样既不安全，又不节省网络资源。</p> \n <h2><a id=\"_MAC__164\"></a>图解 数据链路：使用交换机解决MAC 地址映射问题</h2> \n <h3><a id=\"_166\"></a>集线器的问题</h3> \n <p>如果把这个集线器弄得更智能一些，<strong>只发给目标 MAC 地址指向的那台电脑</strong>，就好了。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/9b6ad2350fab1e911a2c8531cba5693d.gif\" alt=\"image\"></p> \n <h3><a id=\"_174\"></a>交换机的诞生</h3> \n <p>虽然只比集线器多了这一点点区别，但看起来似乎有智能了，你把这东西叫做<strong>交换机</strong>。也正因为这一点点智能，你把它放在了另一个层级，<strong>数据链路层</strong>。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/d13e6e7fb9838fe0acd6370692d57f92.png\" alt=\"image\"></p> \n <p>如上图所示，你是这样设计的。</p> \n <p>交换机内部维护一张 <strong>MAC 地址表</strong>，记录着每一个 MAC 地址的设备，连接在其哪一个端口上。</p> \n <table>\n  <thead>\n   <tr>\n    <th>MAC 地址</th>\n    <th>端口</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>bb-bb-bb-bb-bb-bb</td>\n    <td>1</td>\n   </tr>\n   <tr>\n    <td>cc-cc-cc-cc-cc-cc</td>\n    <td>3</td>\n   </tr>\n   <tr>\n    <td>aa-aa-aa-aa-aa-aa</td>\n    <td>4</td>\n   </tr>\n   <tr>\n    <td>dd-dd-dd-dd-dd-dd</td>\n    <td>5</td>\n   </tr>\n  </tbody>\n </table> \n <p>假如你仍然要发给 B 一个数据包，构造了如下的数据结构从网口出去。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/913f402efac18571df11fb219e09f11e.png\" alt=\"image\"></p> \n <p>到达交换机时，交换机内部通过自己维护的 MAC 地址表，发现<strong>目标机器 B 的 MAC 地址 bb-bb-bb-bb-bb-bb 映射到了端口 1 上</strong>，于是把数据从 1 号端口发给了 B，完事~</p> \n <p>你给这个通过这样传输方式而组成的小范围的网络，叫做<strong>以太网</strong>。</p> \n <p>当然最开始的时候，MAC 地址表是空的，是怎么逐步建立起来的呢？</p> \n <p>假如在 MAC 地址表为空是，你给 B 发送了如下数据</p> \n <p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-quHDePVL-1615262768771)(https://upload-images.jianshu.io/upload_images/19816137-2195d8e3fa05f616.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)]</p> \n <p>由于这个包从端口 4 进入的交换机，所以此时交换机就可以在 MAC地址表记录第一条数据：</p> \n <p><strong>MAC：aa-aa-aa-aa-aa-aa-aa<br> 端口：4</strong></p> \n <p>交换机看目标 MAC 地址（bb-bb-bb-bb-bb-bb）在地址表中并没有映射关系，于是将此包发给了<strong>所有端口</strong>，也即发给了所有机器。</p> \n <p>之后，只有机器 B 收到了确实是发给自己的包，于是做出了<strong>响应</strong>，响应数据从端口 1 进入交换机，于是交换机此时在地址表中更新了第二条数据：</p> \n <p><strong>MAC：bb-bb-bb-bb-bb-bb<br> 端口：1</strong></p> \n <p>过程如下</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/ae47c4fd0533b29cfce00a78e784e362.gif\" alt=\"image\"></p> \n <p>经过该网络中的机器不断地通信，交换机最终将 MAC 地址表建立完毕~</p> \n <p>随着机器数量越多，交换机的端口也不够了，但聪明的你发现，只要将多个交换机连接起来，这个问题就轻而易举搞定~</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/96c4da16c077389b994e7526f2ba73f0.png\" alt=\"image\"></p> \n <p>你完全不需要设计额外的东西，只需要按照之前的设计和规矩来，按照上述的接线方式即可完成所有电脑的互联，所以交换机设计的这种规则，真的很巧妙。你想想看为什么（比如 A 要发数据给 F）。</p> \n <p>但是你要注意，上面那根红色的线，最终在 MAC 地址表中可不是一条记录呀，而是要把 EFGH 这四台机器与该端口（端口6）的映射全部记录在表中。</p> \n <h3><a id=\"MAC__231\"></a>MAC 地址和端口的映射记录</h3> \n <p>最终，<strong>两个交换机将分别记录 A ~ H 所有机器的映射记录</strong>。</p> \n <p><strong>左边的交换机</strong></p> \n <table>\n  <thead>\n   <tr>\n    <th>MAC 地址</th>\n    <th>端口</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>bb-bb-bb-bb-bb-bb</td>\n    <td>1</td>\n   </tr>\n   <tr>\n    <td>cc-cc-cc-cc-cc-cc</td>\n    <td>3</td>\n   </tr>\n   <tr>\n    <td>aa-aa-aa-aa-aa-aa</td>\n    <td>4</td>\n   </tr>\n   <tr>\n    <td>dd-dd-dd-dd-dd-dd</td>\n    <td>5</td>\n   </tr>\n   <tr>\n    <td>ee-ee-ee-ee-ee-ee</td>\n    <td>6</td>\n   </tr>\n   <tr>\n    <td>ff-ff-ff-ff-ff-ff</td>\n    <td>6</td>\n   </tr>\n   <tr>\n    <td>gg-gg-gg-gg-gg-gg</td>\n    <td>6</td>\n   </tr>\n   <tr>\n    <td>hh-hh-hh-hh-hh-hh</td>\n    <td>6</td>\n   </tr>\n  </tbody>\n </table> \n <p><strong>右边的交换机</strong></p> \n <table>\n  <thead>\n   <tr>\n    <th>MAC 地址</th>\n    <th>端口</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>bb-bb-bb-bb-bb-bb</td>\n    <td>1</td>\n   </tr>\n   <tr>\n    <td>cc-cc-cc-cc-cc-cc</td>\n    <td>1</td>\n   </tr>\n   <tr>\n    <td>aa-aa-aa-aa-aa-aa</td>\n    <td>1</td>\n   </tr>\n   <tr>\n    <td>dd-dd-dd-dd-dd-dd</td>\n    <td>1</td>\n   </tr>\n   <tr>\n    <td>ee-ee-ee-ee-ee-ee</td>\n    <td>2</td>\n   </tr>\n   <tr>\n    <td>ff-ff-ff-ff-ff-ff</td>\n    <td>3</td>\n   </tr>\n   <tr>\n    <td>gg-gg-gg-gg-gg-gg</td>\n    <td>4</td>\n   </tr>\n   <tr>\n    <td>hh-hh-hh-hh-hh-hh</td>\n    <td>6</td>\n   </tr>\n  </tbody>\n </table> \n <p>这在只有 8 台电脑的时候还好，甚至在只有几百台电脑的时候，都还好，所以这种交换机的设计方式，已经足足支撑一阵子了。</p> \n <p>但很遗憾，人是贪婪的动物，很快，电脑的数量就发展到几千、几万、几十万。</p> \n <h2><a id=\"_IP_267\"></a>图解 传输层：IP地址和路由器</h2> \n <h3><a id=\"_269\"></a>二层交换机的问题</h3> \n <p>交换机已经无法记录如此庞大的映射关系了。</p> \n <p>此时你动了歪脑筋，你发现了问题的根本在于，连出去的那根红色的网线，后面不知道有多少个设备不断地连接进来，从而使得地址表越来越大。</p> \n <p>那我可不可以让那根红色的网线，接入一个<strong>新的设备</strong>，这个设备就跟电脑一样有自己独立的 MAC 地址，而且同时还能帮我把数据包做一次<strong>转发</strong>呢？</p> \n <p>这个设备就是<strong>路由器，<strong>它的功能就是，作为一台独立的拥有 MAC 地址的设备，并且可以帮我把数据包做一次转发</strong>，<strong>你把它定在了</strong>网络层。</strong></p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/635d579c31b4ab410cd05715bc764741.png\" alt=\"image\"></p> \n <p>注意，路由器的每一个端口，都有独立的 MAC 地址</p> \n <p>好了，现在交换机的 MAC 地址表中，只需要多出一条 MAC 地址 ABAB 与其端口的映射关系，就可以成功把数据包转交给路由器了，这条搞定。</p> \n <p>那如何做到，把发送给 C 和 D，甚至是把发送给 DEFGH… 的数据包，统统先发送给路由器呢？</p> \n <p>不难想到这样一个点子，假如电脑 C 和 D 的 MAC 地址拥有共同的前缀，比如分别是</p> \n <p><strong>C 的 MAC 地址：FFFF-FFFF-CCCC</strong> <strong>D 的 MAC 地址：FFFF-FFFF-DDDD</strong></p> \n <p>那我们就可以说，将目标 MAC 地址为 <strong>FFFF-FFFF-？开头的</strong>，统统先发送给路由器。</p> \n <p>这样是否可行呢？答案是否定的。</p> \n <h3><a id=\"IP_295\"></a>IP地址的诞生</h3> \n <p>我们先从现实中 MAC 地址的结构入手，MAC地址也叫物理地址、硬件地址，长度为 48 位，一般这样来表示</p> \n <p><strong>00-16-EA-AE-3C-40</strong></p> \n <p>它是由网络设备制造商生产时烧录在网卡的EPROM（一种闪存芯片，通常可以通过程序擦写）。</p> \n <p>其中<strong>前 24 位（00-16-EA）代表网络硬件制造商的编号</strong>，后 24 位（AE-3C-40）是该厂家自己分配的，一般表示系列号。</p> \n <p>只要不更改自己的 MAC 地址，MAC 地址在世界是唯一的。形象地说，MAC地址就如同身份证上的身份证号码，具有唯一性。</p> \n <p>那如果你希望向上面那样表示将目标 MAC 地址为 <strong>FFFF-FFFF-？开头的</strong>，统一从路由器出去发给某一群设备（后面会提到这其实是子网的概念），那你就需要要求某一子网下统统买一个厂商制造的设备，要么你就需要要求厂商在生产网络设备烧录 MAC 地址时，提前按照你规划好的子网结构来定 MAC 地址，并且日后这个网络的结构都不能轻易改变。</p> \n <p>这显然是不现实的。</p> \n <p>于是你发明了一个新的地址，给每一台机器一个 32 位的编号，如：</p> \n <p><strong>11000000101010000000000000000001</strong></p> \n <p>你觉得有些不清晰，于是把它分成四个部分，中间用点相连。</p> \n <p><strong>11000000.10101000.00000000.00000001</strong></p> \n <p>你还觉得不清晰，于是把它转换成 10 进制。</p> \n <p><strong>192.168.0.1</strong></p> \n <p>最后你给了这个地址一个响亮的名字，<strong>IP 地址</strong>。现在每一台电脑，同时有自己的 MAC 地址，又有自己的 IP 地址，只不过 IP 地址是<strong>软件层面</strong>上的，可以随时修改，MAC 地址一般是无法修改的。</p> \n <p>这样一个可以随时修改的 IP 地址，就可以根据你规划的网络拓扑结构，来调整了。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/bbcfa3e647d0bdb78a9b69cf6157c68d.png\" alt=\"image\"></p> \n <p>如上图所示，假如我想要发送数据包给 ABCD 其中一台设备，不论哪一台，我都可以这样描述，<strong>“将 IP 地址为 192.168.0 开头的全部发送给到路由器，之后再怎么转发，交给它！”</strong>，巧妙吧。</p> \n <h3><a id=\"_331\"></a>路由器的诞生</h3> \n <p>路由器诞生了，专门负责IP地址的寻找。那报文交给路由器之后，路由器又是怎么把数据包准确转发给指定设备的呢？</p> \n <p>别急我们慢慢来。</p> \n <p>我们先给上面的组网方式中的每一台设备，加上自己的 IP 地址</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/3e0e17cfa7a0fed1b604890ef4e1cca5.png\" alt=\"image\"></p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/84e319b3429e1000bdd3a2c2aca74fc8.png\" alt=\"image.gif\"></p> \n <p>现在两个设备之间传输，除了加上数据链路层的头部之外，还要再增加一个网络层的头部。</p> \n <p>假如 A 给 B 发送数据，由于它们直接连着交换机，所以 A 直接发出如下数据包即可，其实网络层没有体现出作用。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/ec10004d89fc45b41721099b7408b5f0.png\" alt=\"image\"></p> \n <p>但假如 A 给 C 发送数据，A 就需要先转交给路由器，然后再由路由器转交给 C。由于最底层的传输仍然需要依赖以太网，所以数据包是分成两段的。</p> \n <p>A ~ 路由器这段的包如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/36f94ba80eb664a50698787f4ba34a85.png\" alt=\"image\"></p> \n <p>路由器到 C 这段的包如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/adc2e43a9763d4cadae0b5abc55d636e.png\" alt=\"image\"></p> \n <p>好了，上面说的两种情况（A-&gt;B，A-&gt;C），相信细心的读者应该会有不少疑问，下面我们一个个来展开。</p> \n <h3><a id=\"_361\"></a>子网的由来</h3> \n <p><strong>A 给 C 发数据包，怎么知道是否要通过路由器转发呢？</strong></p> \n <p><strong>答案：子网</strong></p> \n <p>如果源 IP 与目的 IP 处于一个子网，直接将包通过交换机发出去。</p> \n <p>如果源 IP 与目的 IP 不处于一个子网，就交给路由器去处理。</p> \n <p>好，那现在只需要解决，什么叫处于一个子网就好了。</p> \n <ul>\n  <li> <p>192.168.0.1 和 192.168.0.2 处于同一个子网</p> </li>\n  <li> <p>192.168.0.1 和 192.168.1.1 处于不同子网</p> </li>\n </ul> \n <p>这两个是我们人为规定的，即我们想表示，对于 192.168.0.1 来说：</p> \n <p><strong>192.168.0.xxx 开头的，就算是在一个子网，否则就是在不同的子网。</strong></p> \n <p>那对于计算机来说，怎么表达这个意思呢？于是人们发明了<strong>子网掩码</strong>的概念</p> \n <p>假如某台机器的子网掩码定为 255.255.255.0</p> \n <p>这表示，将源 IP 与目的 IP 分别同这个子网掩码进行<strong>与运算****，相等则是在一个子网，不相等就是在不同子网</strong>，就这么简单。</p> \n <p>比如</p> \n <ul>\n  <li> <p><strong>A电脑</strong>：192.168.0.1 &amp; 255.255.255.0 = 192.168.0.0</p> </li>\n  <li> <p><strong>B电脑</strong>：192.168.0.2 &amp; 255.255.255.0 = 192.168.0.0</p> </li>\n  <li> <p><strong>C电脑</strong>：192.168.1.1 &amp; 255.255.255.0 = 192.168.1.0</p> </li>\n  <li> <p><strong>D电脑</strong>：192.168.1.2 &amp; 255.255.255.0 = 192.168.1.0</p> </li>\n </ul> \n <p>那么 A 与 B 在同一个子网，C 与 D 在同一个子网，但是 A 与 C 就不在同一个子网，与 D 也不在同一个子网，以此类推。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/7e6a21dbdc49b7a772f1348e542cdfef.png\" alt=\"image\"></p> \n <p>所以如果 A 给 C 发消息，A 和 C 的 IP 地址分别 &amp; A 机器配置的子网掩码，发现不相等，则 A 认为 C 和自己不在同一个子网，于是把包发给路由器，就不管了，<strong>之后怎么转发，A 不关心</strong>。</p> \n <p><strong>A 如何知道，哪个设备是路由器？</strong></p> \n <p><strong>答案：在 A 上要设置默认网关</strong></p> \n <p>上一步 A 通过是否与 C 在同一个子网内，判断出自己应该把包发给路由器，那路由器的 IP 是多少呢？</p> \n <p>其实说发给路由器不准确，应该说 A 会把包发给<strong>默认网关</strong>。</p> \n <p>对 A 来说，A 只能<strong>直接</strong>把包发给同处于一个子网下的某个 IP 上，所以发给路由器还是发给某个电脑，对 A 来说也不关心，只要这个设备有个 IP 地址就行。</p> \n <p>所以<strong>默认网关，就是 A 在自己电脑里配置的一个 IP 地址</strong>，以便在发给不同子网的机器时，发给这个 IP 地址。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/0c30114bad824d8d262469cea973210a.png\" alt=\"image\"></p> \n <p>仅此而已！</p> \n <h3><a id=\"Mac_419\"></a>路由表的由来（和Mac表的由来好像，都是逼出来的）</h3> \n <p><strong>路由器如何知道C在哪里？</strong></p> \n <p><strong>答案：路由表</strong></p> \n <p>现在 A 要给 C 发数据包，已经可以成功发到路由器这里了，最后一个问题就是，<strong>路由器怎么知道，收到的这个数据包，该从自己的哪个端口出去</strong>，才能直接（或间接）地最终到达目的地 C 呢。</p> \n <p>路由器收到的数据包有目的 IP 也就是 C 的 IP 地址，需要转化成从自己的哪个端口出去，很容易想到，应该有个表，就像 MAC 地址表一样。</p> \n <p>这个表就叫<strong>路由表</strong>。</p> \n <p>至于这个路由表是怎么出来的，有很多路由算法，本文不展开，因为我也不会哈哈~</p> \n <p>不同于 MAC 地址表的是，路由表并不是一对一这种明确关系，我们下面看一个路由表的结构。</p> \n <table>\n  <thead>\n   <tr>\n    <th>目的地址</th>\n    <th>子网掩码</th>\n    <th>下一跳</th>\n    <th>端口</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>192.168.0.0</td>\n    <td>255.255.255.0</td>\n    <td></td>\n    <td>0</td>\n   </tr>\n   <tr>\n    <td>192.168.0.254</td>\n    <td>255.255.255.255</td>\n    <td></td>\n    <td>0</td>\n   </tr>\n   <tr>\n    <td>192.168.1.0</td>\n    <td>255.255.255.0</td>\n    <td></td>\n    <td>1</td>\n   </tr>\n   <tr>\n    <td>192.168.1.254</td>\n    <td>255.255.255.255</td>\n    <td></td>\n    <td>1</td>\n   </tr>\n  </tbody>\n </table> \n <p>我们学习一种新的表示方法，由于子网掩码其实就表示前多少位表示子网的网段，所以如 192.168.0.0（255.255.255.0） 也可以简写为 192.168.0.0/24</p> \n <table>\n  <thead>\n   <tr>\n    <th>目的地址</th>\n    <th>下一跳</th>\n    <th>端口</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>192.168.0.0/24</td>\n    <td></td>\n    <td>0</td>\n   </tr>\n   <tr>\n    <td>192.168.0.254/32</td>\n    <td></td>\n    <td>0</td>\n   </tr>\n   <tr>\n    <td>192.168.1.0/24</td>\n    <td></td>\n    <td>1</td>\n   </tr>\n   <tr>\n    <td>192.168.1.254/32</td>\n    <td></td>\n    <td>1</td>\n   </tr>\n  </tbody>\n </table> \n <p>这就很好理解了，路由表就表示，<strong>192.168.0.xxx 这个子网下的，都转发到 0 号端口，192.168.1.xxx 这个子网下的，都转发到 1 号端口</strong>。下一跳列还没有值，我们先不管</p> \n <p>配合着结构图来看（这里把子网掩码和默认网关都补齐了）</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/e48fef70877bae108f18a636b6e2d64f.gif\" alt=\"image\"></p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/aec5c1d6632ac1c38314c03832a6bb51.png\" alt=\"image.gif\"></p> \n <p><strong>刚才说的都是 IP 层，但发送数据包的数据链路层需要知道 MAC 地址，可是我只知道 IP 地址该怎么办呢？</strong></p> \n <p><strong>答案：arp</strong></p> \n <p>假如你（A）此时<strong>不知道</strong>你同伴 B 的 MAC 地址（现实中就是不知道的，刚刚我们只是假设已知），你只知道它的 IP 地址，你该怎么把数据包准确传给 B 呢？</p> \n <p>答案很简单，在网络层，<strong>我需要把 IP 地址对应的 MAC 地址找到</strong>，也就是通过某种方式，找到 <strong>192.168.0.2</strong> 对应的 MAC 地址 <strong>BBBB</strong>。</p> \n <p>这种方式就是 <strong>arp 协议</strong>，同时电脑 A 和 B 里面也会有一张 <strong>arp 缓存表</strong>，表中记录着 <strong>IP 与 MAC 地址</strong>的对应关系。</p> \n <table>\n  <thead>\n   <tr>\n    <th>IP 地址</th>\n    <th>MAC 地址</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>192.168.0.2</td>\n    <td>BBBB</td>\n   </tr>\n  </tbody>\n </table> \n <p>一开始的时候这个表是<strong>空的</strong>，电脑 A 为了知道电脑 B（192.168.0.2）的 MAC 地址，将会<strong>广播</strong>一条 arp 请求，B 收到请求后，带上自己的 MAC 地址给 A 一个<strong>响应</strong>。此时 A 便更新了自己的 arp 表。</p> \n <p>这样通过大家不断广播 arp 请求，最终所有电脑里面都将 arp 缓存表更新完整。</p> \n <h2><a id=\"_479\"></a>图解：整个传输过程</h2> \n <p><strong>从各个节点的视角来看</strong></p> \n <h3><a id=\"_483\"></a><strong>电脑视角</strong>：</h3> \n <ul>\n  <li> <p>首先我要知道我的 IP 以及对方的 IP</p> </li>\n  <li> <p>通过子网掩码判断我们是否在同一个子网</p> </li>\n  <li> <p>在同一个子网就通过 arp 获取对方 mac 地址直接扔出去</p> </li>\n  <li> <p>不在同一个子网就通过 arp 获取默认网关的 mac 地址直接扔出去</p> </li>\n </ul> \n <h3><a id=\"_493\"></a><strong>交换机视角：</strong></h3> \n <ul>\n  <li> <p>我收到的数据包必须有目标 MAC 地址</p> </li>\n  <li> <p>通过 MAC 地址表查映射关系</p> </li>\n  <li> <p>查到了就按照映射关系从我的指定端口发出去</p> </li>\n  <li> <p>查不到就所有端口都发出去</p> </li>\n </ul> \n <p><strong>路由器视角：</strong></p> \n <ul>\n  <li> <p>我收到的数据包必须有目标 IP 地址</p> </li>\n  <li> <p>通过路由表查映射关系</p> </li>\n  <li> <p>查到了就按照映射关系从我的指定端口发出去（不在任何一个子网范围，走其路由器的默认网关也是查到了）</p> </li>\n  <li> <p>查不到则返回一个路由不可达的数据包</p> </li>\n </ul> \n <p>如果你嗅觉足够敏锐，你应该可以感受到下面这句话：</p> \n <p>网络层（IP协议）本身没有传输包的功能，包的实际传输是委托给数据链路层（以太网中的交换机）来实现的。</p> \n <p><strong>涉及到的三张表分别是</strong></p> \n <ul>\n  <li> <p>交换机中有 <strong>MAC 地址</strong>表用于映射 MAC 地址和它的端口</p> </li>\n  <li> <p>路由器中有<strong>路由表</strong>用于映射 IP 地址(段)和它的端口</p> </li>\n  <li> <p>电脑和路由器中都有** arp 缓存表**用于缓存 IP 和 MAC 地址的映射关系</p> </li>\n </ul> \n <p><strong>这三张表是怎么来的</strong></p> \n <ul>\n  <li> <p>MAC 地址表是通过以太网内各节点之间不断通过交换机通信，不断完善起来的。</p> </li>\n  <li> <p>路由表是各种路由算法 + 人工配置逐步完善起来的。</p> </li>\n  <li> <p>arp 缓存表是不断通过 arp 协议的请求逐步完善起来的。</p> </li>\n </ul> \n <p>知道了以上这些，目前网络上两个节点是如何发送数据包的这个过程，就完全可以解释通了！</p> \n <h3><a id=\"_535\"></a>参考的网络拓扑图</h3> \n <p>那接下来我们就放上参考的 <strong>最后一个</strong>网络拓扑图吧，请做好 <strong>战斗</strong> 准备！</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/a889e11a36f66f1645d918e754a0a173.png\" alt=\"image\"></p> \n <p>这时路由器 1 连接了路由器 2，所以其路由表有了下一条地址这一个概念，所以它的路由表就变成了这个样子。如果匹配到了有下一跳地址的一项，则需要再次匹配，找到其端口，并找到下一跳 IP 的 MAC 地址。</p> \n <p>也就是说找来找去，最终必须能映射到一个端口号，然后从这个端口号把数据包发出去。</p> \n <table>\n  <thead>\n   <tr>\n    <th>目的地址</th>\n    <th>下一跳</th>\n    <th>端口</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>192.168.0.0/24</td>\n    <td></td>\n    <td>0</td>\n   </tr>\n   <tr>\n    <td>192.168.0.254/32</td>\n    <td></td>\n    <td>0</td>\n   </tr>\n   <tr>\n    <td>192.168.1.0/24</td>\n    <td></td>\n    <td>1</td>\n   </tr>\n   <tr>\n    <td>192.168.1.254/32</td>\n    <td></td>\n    <td>1</td>\n   </tr>\n   <tr>\n    <td>192.168.2.0/24</td>\n    <td>192.168.100.5</td>\n    <td></td>\n   </tr>\n   <tr>\n    <td>192.168.100.0/24</td>\n    <td></td>\n    <td>2</td>\n   </tr>\n   <tr>\n    <td>192.168.100.4/32</td>\n    <td></td>\n    <td>2</td>\n   </tr>\n  </tbody>\n </table> \n <h3><a id=\"_A__F__555\"></a><strong>这时如果 A 给 F 发送一个数据包，能不能通呢？如果通的话整个过程是怎样的呢？</strong></h3> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/da2d65dda084a873779b01f59ff606aa.png\" alt=\"image\"></p> \n <p>思考一分钟…</p> \n <p><strong>详细过程动画描述：</strong></p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/6740f3b2596d7bf32d214a40f58603ec.gif\" alt=\"image\"></p> \n <h3><a id=\"_565\"></a><strong>详细过程文字描述：</strong></h3> \n <p><strong>1.</strong> 首先 A（192.168.0.1）通过子网掩码（255.255.255.0）计算出自己与 F（192.168.2.2）并不在同一个子网内，于是决定发送给默认网关（192.168.0.254）</p> \n <p><strong>2.</strong> A 通过 ARP 找到 默认网关 192.168.0.254 的 MAC 地址。</p> \n <p><strong>3.</strong> A 将源 MAC 地址（AAAA）与网关 MAC 地址（ABAB）封装在数据链路层头部，又将源 IP 地址（192.168.0.1）和目的 IP 地址（192.168.2.2）（注意这里千万不要以为填写的是默认网关的 IP 地址，从始至终这个数据包的两个 IP 地址都是不变的，只有 MAC 地址在不断变化）封装在网络层头部，然后发包</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/7bb8957a74eef0cdc7f36df7a05702dd.png\" alt=\"image\"></p> \n <p><strong>4.</strong> 交换机 1 收到数据包后，发现目标 MAC 地址是 ABAB，转发给路由器1</p> \n <p><strong>5.</strong> 数据包来到了路由器 1，发现其目标 IP 地址是 192.168.2.2，查看其路由表，发现了下一跳的地址是 192.168.100.5*</p> \n <p><strong>6.</strong> 所以此时路由器 1 需要做两件事，第一件是再次匹配路由表，发现匹配到了端口为 2，于是将其封装到数据链路层，最后把包从 2 号口发出去。</p> \n <p><strong>7.</strong> 此时路由器 2 收到了数据包，看到其目的地址是 192.168.2.2，查询其路由表，匹配到端口号为 1，准备从 1 号口把数据包送出去。</p> \n <p><strong>8.</strong> 但此时路由器 2 需要知道 192.168.2.2 的 MAC 地址了，于是查看其 arp 缓存，找到其 MAC 地址为 FFFF，将其封装在数据链路层头部，并从 1 号端口把包发出去。</p> \n <p><strong>9.</strong> 交换机 3 收到了数据包，发现目的 MAC 地址为 FFFF，查询其 MAC 地址表，发现应该从其 6 号端口出去，于是从 6 号端口把数据包发出去。</p> \n <p>**10.**F 最终收到了数据包！**并且发现目的 MAC 地址就是自己，于是收下了这个包</p> \n <h2><a id=\"HTTP_590\"></a>HTTP报文传输原理</h2> \n <p>利用TCP/IP进行网络通信时，数据包会按照分层顺序与对方进行通信。发送端从应用层往下走，接收端从链路层往上走。从客户端到服务器的数据，每一帧数据的传输的顺序都为：应用层-&gt;运输层-&gt;网络层-&gt;链路层-&gt;链路层-&gt;网络层-&gt;运输层-&gt;应用层。</p> \n <h3><a id=\"HTTP_595\"></a>HTTP报文传输过程</h3> \n <p>以一个HTTP请求的传输为例，请求从HTTP客户端（如浏览器）和HTTP服务端应用的传输过程，大致如下图所示：<br> <img src=\"https://img-blog.csdnimg.cn/20210308122800578.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70#pic_center\" alt=\"在这里插入图片描述\"></p> \n <p>图：HTTP请求报文的分层传输过程</p> \n <h3><a id=\"_602\"></a>数据封装和分用</h3> \n <p>接下来，为大家介绍一下数据封装和分用。</p> \n <p>数据通过互联网传输的时候不可能是光秃秃的不加标识，如果这样数据就会乱。所以数据在发送的时候，需要加上特定标识，加上特定标识的过程叫做数据的封装，在数据使用的时候再去掉特定标识，去掉特定标识的过程就叫做分用。TCP/IP协议的数据封装和分用过程，大致如下图所示：<br> <img src=\"https://img-blog.csdnimg.cn/20210308122819964.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70#pic_center\" alt=\"在这里插入图片描述\"></p> \n <p>图：TCP/IP协议的数据封装和分用过程</p> \n <p>在数据封装时，数据经过每个层都会打上该层特定标识，添加上头部。</p> \n <p>在传输层封装时，添加的报文首部时要存入一个应用程序的标识符，无论TCP和UDP都用一个16位的端口号来表示不同的应用程序，并且都会将源端口和目的端口存入报文首部中。</p> \n <p>在网络层封装时，IP首部会标识处理数据的协议类型，或者说标识出网络层数据帧所携带的上层数据类型，如TCP、UDP、ICMP、IP、IGMP等等。<br> 具体来说，会在IP首部中存入一个长度为8位的数值，称作协议域：<br> 1表示为ICMP协议、2表示为IGMP协议、6表示为TCP协议、17表示为UDP协议、等等。IP首部还会标识发送方地址（源IP）和接收方地址（目标IP）。</p> \n <p>在链路层封装时，网络接口分别要发送和接收IP、ARP和RARP等多种不同协议的报文，因此也必须在以太网的帧首部中加入某种形式的标识，以指明所处理的协议类型，为此，以太网的报文帧的首部也有一个16位的类型域，标识出以太网数据帧所携带的上层数据类型，如IPv4、ARP、IPV6、PPPoE等等。</p> \n <p>数据封装和分用的过程大致为：发送端每通过一层会增加该层的首部，接收端每通过一层则删除该层的首部。</p> \n <p>总体来说，TCP/IP分层管理、数据封装和分用的好处：分层之后若需改变相关设计，只需替换变动的层。各层之间的接口部分规划好之后，每个层次内部的设计就可以自由改动。层次化之后，设计也变得相对简单：各个层只需考虑分派给自己的传输任务。</p> \n <p>TCP/IP与OSI的区别主要有哪些呢？除了TCP/IP与OSI在分层模块上稍有区别，更重要的区别为：OSI参考模型注重“通信协议必要的功能是什么”，而TCP/IP则更强调“在计算机上实现协议应该开发哪种程序”。</p> \n <p>实际上，在传输过程中，数据报文会在不同的物理网络之间传递，还是以一个HTTP请求的传输为例，请求在不同物理网络之间的传输过程，大致如下图所示：<br> <img src=\"https://img-blog.csdnimg.cn/20210308122843370.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70#pic_center\" alt=\"在这里插入图片描述\"></p> \n <p>图：HTTP请求在不同物理网络之间的传输过程</p> \n <p>数据包在不同物理网络之间的传输过程中，网络层会通过路由器去对不同的网络之间的数据包进行存储、分组转发处理。构造互连网最简单的方法是把两个或多个网络通过路由器进行连接。路由器可以简单理解为一种特殊的用于网络互连的硬件盒，其作用是为不同类型的物理网络提供连接：以太网、令牌环网、点对点的链接和FDDI（光纤分布式数据接口）等等。</p> \n <p>物理网络之间通过路由器进行互连，随着增加不同类型的物理网络，可能会有很多个路由器，但是对于应用层来说仍然是一样的，TCP协议栈为大家屏蔽了物理层的复杂性。总之，物理细节和差异性的隐藏，使得互联网TCP/IP传输的功能变得非常强大。</p> \n <p>接下来，开始为大家介绍与传输性能有密切关系的内容：TCP传输层的三次握手建立连接，四次挥手释放连接。不过在此之前，还得先介绍一下TCP报文协议。</p> \n <h2><a id=\"TCP_641\"></a>TCP协议的报文格式</h2> \n <p>在TCP/IP协议栈中，IP协议层只关心如何使数据能够跨越本地网络边界的问题，而不关心数据如何传输。整体TCP/IP协议栈，共同配合一起解决数据如何通过许许多多个点对点通路，顺利传输到达目的地。一个点对点通路被称为一“跳”（hop），通过TCP/IP协议栈，网络成员能够在许多“跳”的基础上建立相互的数据通路。</p> \n <p>传输层TCP协议提供了一种面向连接的、可靠的字节流服务，其数据帧格式，大致如下图所示：<br> <img src=\"https://img-blog.csdnimg.cn/20210308122904344.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70#pic_center\" alt=\"在这里插入图片描述\"></p> \n <p>图：传输层TCP协议的数据帧格式</p> \n <p>一个传输层TCP协议的数据帧，大致包含以下字段：</p> \n <h3><a id=\"_653\"></a>（一）源端口号</h3> \n <p>源端口号表示报文的发送端口，占16位。源端口和源IP地址组合起来，可以标识报文的发送地址。</p> \n <h3><a id=\"_657\"></a>（二）目的端口号</h3> \n <p>目的端口号表示报文的接收端口，占16位。目的端口和目的IP地址相结合，可以标识报文的接收地址。</p> \n <p>TCP协议是基于IP协议的基础上传输的，TCP报文中的源端口号+源IP，与TCP报文中的目的端口号+目的IP一起，组合起来唯一性的确定一条TCP连接。</p> \n <h3><a id=\"Sequence_Number_663\"></a>（三）序号（Sequence Number）</h3> \n <p>TCP传输过程中，在发送端出的字节流中，传输报文中的数据部分的每一个字节都有它的编号。序号（Sequence<br> Number）占32位，发起方发送数据时，都需要标记序号。</p> \n <p>序号（Sequence Number）的语义与SYN控制标志（Control<br> Bits）的值有关。根据控制标志（Control Bits）中的SYN是否为1，序号（Sequence<br> Number）表达不同的含义：</p> \n <p>（1）当SYN = 1时，当前为连接建立阶段，此时的序号为初始序号ISN((Initial Sequence<br> Number)，通过算法来随机生成序号；</p> \n <p>（2）当SYN = 0时在数据传输正式开始时，第一个报文的序号为 ISN +<br> 1，后面的报文的序号，为前一个报文的SN值+TCP报文的净荷字节数(不包含TCP头)。比如，如果发送端发送的一个TCP帧的净荷为12byte，序号为5，则发送端接着发送的下一个数据包的时候，序号的值应该设置为5+12=17。</p> \n <p>在数据传输过程中，TCP协议通过序号（Sequence<br> Number）对上层提供有序的数据流。发送端可以用序号来跟踪发送的数据量；接收端可以用序号识别出重复接收到的TCP包，从而丢弃重复包；对于乱序的数据包，接收端也可以依靠序号对其进行排序。</p> \n <h3><a id=\"Acknowledgment_Number_681\"></a>（四）确认序号（Acknowledgment Number）</h3> \n <p>确认序号（Acknowledgment<br> Number）标识了报文接收端期望接收的字节序列。如果设置了ACK控制位，确认序号的值表示一个准备接收的包的序列码，注意，它所指向的是准备接收的包，也就是下一个期望接收的包的序列码。</p> \n <p>举个例子，假设发送端（如Client）发送3个净荷为1000byte、起始SN序号为1的数据包给Server服务端，Server每收到一个包之后，需要回复一个ACK响应确认数据包给Client。ACK响应数据包的ACK<br> Number值，为每个Client包的为SN+包净荷，既表示Server已经确认收到的字节数，还表示期望接收到的下一个Client发送包的SN序号，具体的ACK值如下图左边的正常传输部分所示。<br> <img src=\"https://img-blog.csdnimg.cn/20210308123045409.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70#pic_center\" alt=\"在这里插入图片描述\"></p> \n <p>图：传输过程的确认序号（Acknowledgment Number）值示例图</p> \n <p>在上图的左边部分，Server第1个ACK包的ACK<br> Number值为1001，是通过Client第1个包的SN+包净荷=1+1000计算得到，表示期望第2个Client包的SN序号为1001；Server第2个ACK包的ACK<br> Number值为2001，为Client第2个包的SN+包净荷=2001，表示期望第3个Server包的SN为2001，以此类推。</p> \n <p>如果发生错误，假设Server在处理Client的第二个发送包异常，Server仍然回复一个ACK<br> Number值为1001的确认包，则Client的第二个数据包需要重复发送，具体的ACK值如上图右边的正常传输部分所示。</p> \n <p>只有控制标志的ACK标志为1时，数据帧中的确认序号ACK<br> Number才有效。TCP协议规定，连接建立后，所有发送的报文的ACK必须为1，也就是建立连接后，所有报文的确认序号有效。如果是SYN类型的报文，其ACK标志为0，故没有确认序号。</p> \n <h3><a id=\"_704\"></a>（五）头部长度</h3> \n <p>该字段占用4位，用来表示TCP报文首部的长度，单位是4bit位。其值所表示的并不是字节数，而是头部的所含有的32bit的数目（或者倍数），或者4个字节的倍数，所以TCP头部最多可以有60字节（4*15=60）。没有任何选项字段的TCP头部长度为20字节，所以其头部长度为5，可以通过20/4=5计算得到。</p> \n <h3><a id=\"6_708\"></a>（六）预留6位</h3> \n <p>头部长度后面预留的字段长度为6位，作为保留字段，暂时没有什么用处。</p> \n <h3><a id=\"_712\"></a>（七）控制标志</h3> \n <p>控制标志（Control<br> Bits）共6个bit位，具体的标志位为：URG、ACK、PSH、RST、SYN、FIN。6个标志位的说明，如下表所示。</p> \n <p>表：TCP报文控制标志（Control Bits）说明</p> \n <table>\n  <thead>\n   <tr>\n    <th>标志位</th>\n    <th>说明</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>URG</td>\n    <td>占1位，表示紧急指针字段有效。URG位指示报文段里的上层实体（数据）标记为“紧急”数据。当URG=1时，其后的紧急指针指示紧急数据在当前数据段中的位置(相对于当前序列号的字节偏移量)，TCP接收方必须通知上层实体。</td>\n   </tr>\n   <tr>\n    <td>ACK</td>\n    <td>占1位，置位ACK=1表示确认号字段有效；TCP协议规定，接建立后所有发送的报文的ACK必须为1；当ACK=0时，表示该数据段不包含确认信息。当ACK=1时，表示该报文段包括一个对已被成功接收报文段的确认序号Acknowledgment Number，该序号同时也是下一个报文的预期序号。</td>\n   </tr>\n   <tr>\n    <td>PSH</td>\n    <td>占1位，表示当前报文需要请求推（push）操作；当PSH=1时，接收方在收到数据后立即将数据交给上层，而不是直到整个缓冲区满。</td>\n   </tr>\n   <tr>\n    <td>RST</td>\n    <td>占1位，置位RST=1表示复位TCP连接；用于重置一个已经混乱的连接，也可用于拒绝一个无效的数据段或者拒绝一个连接请求。如果数据段被设置了RST位，说明报文发送方有问题发生。</td>\n   </tr>\n   <tr>\n    <td>SYN</td>\n    <td>占1位，在连接建立时用来同步序号。当SYN=1而ACK=0时，表明这是一个连接请求报文。对方若同意建立连接，则应在响应报文中使SYN=1和ACK=1。 综合一下，SYN置1就表示这是一个连接请求或连接接受报文。</td>\n   </tr>\n   <tr>\n    <td>FIN</td>\n    <td>占1位，用于在释放TCP连接时，标识发送方比特流结束，用来释放一个连接。当 FIN = 1时，表明此报文的发送方的数据已经发送完毕，并要求释放连接。</td>\n   </tr>\n  </tbody>\n </table> \n <p>在连接建立的三次握手过程中，若只是单个SYN置位，表示的只是建立连接请求。如果SYN和ACK同时置位为1，表示的建立连接之后的响应。</p> \n <h3><a id=\"_730\"></a>（八）窗口大小：</h3> \n <p>长度为16位，共2个字节。此字段用来进行流量控制。流量控制的单位为字节数，这个值是本端期望一次接收的字节数。</p> \n <h3><a id=\"_734\"></a>（九）校验和：</h3> \n <p>长度为16位，共2个字节。对整个TCP报文段，即TCP头部和TCP数据进行校验和计算，接收端用于对收到的数据包进行验证。</p> \n <h3><a id=\"_738\"></a>（十）紧急指针：</h3> \n <p>长度为16位，2个字节。它是一个偏移量，和SN序号值相加表示紧急数据最后一个字节的序号。</p> \n <p>以上十项内容是TCP报文首部必须的字段，也称固有字段，长度为20个字节。接下来是TCP报文的可选项和填充部分。</p> \n <h3><a id=\"_744\"></a>（十一）可选项和填充部分</h3> \n <p>可选项和填充部分的长度为4n字节（n是整数），该部分是根据需要而增加的选项。如果不足4n字节，要加填充位，使得选项长度为32位（4字节）的整数倍，具体的做法是在这个字段中加入额外的零，以确保TCP头是32位（4字节）的整数倍。</p> \n <p>最常见的选项字段是MSS（Maximum Segment<br> Size最长报文大小），每个连接方通常都在通信的第一个报文段（SYN标志为1的那个段）中指明这个选项字段，表示当前连接方所能接受的最大报文段的长度。</p> \n <p>由于可选项和填充部分不是必须的，所以TCP报文首部最小长度为20个字节。</p> \n <p>至此，TCP报文首部的字段，就全部介绍完了。TCP报文首部的后面，接着的是数据部分，不过数据部分是可选的。在一个连接建立和一个连接终止时，双方交换的报文段仅有TCP首部。如果一方没有数据要发送，也使用没有任何数据的首部来确认收到的数据，比如在处理超时的过程中，也会发送不带任何数据的报文段。</p> \n <p>总体来说，TCP协议的可靠性，主要通过以下几点来保障：</p> \n <p>（1）应用数据分割成TCP认为最适合发送的数据块。这部分是通过MSS（最大数据包长度）选项来控制的，通常这种机制也被称为一种协商机制，MSS规定了TCP传往另一端的最大数据块的长度。值得注意的是，MSS只能出现在SYN报文段中，若一方不接收来自另一方的MSS值，则MSS就定为536字节。一般来讲，MSS值还是越大越好，这样可以提高网络的利用率。</p> \n <p>（2）重传机制。设置定时器，等待确认包，如果定时器超时还没有收到确认包，则报文重传。</p> \n <p>（3）对首部和数据进行校验。</p> \n <p>（4）接收端对收到的数据进行排序，然后交给应用层。</p> \n <p>（5）接收端丢弃重复的数据。</p> \n <p>（6）TCP还提供流量控制，主要是通过滑动窗口来实现流量控制。</p> \n <p>至此TCP协议的数据帧格式介绍完了。接下来开始为大家重点介绍：TCP传输层的三次握手建立连接，四次挥手释放连接。</p> \n <h2><a id=\"TCP_771\"></a>TCP的三次握手</h2> \n <p>TCP连接的建立时，双方需要经过三次握手，而断开连接时，双方需要经过四次分手，那么，其三次握手和四次分手分别做了什么呢？又是如何进行的呢？</p> \n <p>通常情况下，建立连接的双方，由一端打开一个监听套接字（ServerSocket）来监听来自请求方的TCP（Socket）连接，当服务器端监听开始时，必须做好准备接受外来的连接，在Java中该操作通过创建一个ServerSocket服务监听套接字实例来完成，此操作会调用底层操作系统（如Linux）的C代码中三个函数socket()、bind()、listen()<br> 来完成。开始监听之后，服务器端就做好接受外来连接的准备，如果监听到建立新连接的请求，会开启一个传输套接字，称之为被动打开（Passive<br> Open）。</p> \n <p>一段简单的服务端监听新连接请求，并且被动打开（Passive<br> Open）传输套接字的Java示例代码，具体如下：</p> \n <pre><code>public class SocketServer {\n\npublic static void main(String[] args) {\n\ntry {\n\n// 创建服务端socket\n\nServerSocket serverSocket = new ServerSocket(8080);\n\n//循环监听等待客户端的连接\n\nwhile(true){\n\n//监听到客户端连接，传输套接字被动开启\n\nSocket socket = serverSocket.accept();\n\n//开启线程进行连接的IO处理\n\nServerThread thread = new ServerThread(socket);\n\nthread.start();\n\n......\n\n}\n\n} catch (Exception e) {\n\n// 处理异常\n\ne.printStackTrace();\n\n}\n\n}\n\n}\n</code></pre> \n <p>客户端在发起连接建立时，Java代码通过创建Socket实例，调用底层的connect(…)方法，主动打开(Active<br> Open)Socket连接。套接字监听方在收到请求之后，监听方和发起方（客户端）之间就会建立一条的连接通道，该通道由双方IP和双方端口所唯一确定。</p> \n <p>一段简单的客户端连接主动打开(Active Open)的Java示例代码，具体如下：</p> \n <pre><code>public class SocketClient {\n\npublic static void main(String[] args) throws InterruptedException {\n\ntry {\n\n// 和服务器创建连接\n\nSocket socket = new Socket(\"localhost\",8080);\n\n// 写入给监听方的输出流\n\nOutputStream os = socket.getOutputStream();\n\n…..\n\n// 读取监听方的输入流\n\nInputStream is = socket.getInputStream();\n\n…..\n\n} catch (Exception e) {\n\ne.printStackTrace();\n\n}\n\n}\n\n}\n</code></pre> \n <h3><a id=\"_864\"></a>三次握手过程</h3> \n <p>TCP连接的建立时，双方需要经过三次握手，具体过程如下：</p> \n <p>（1）第一次握手：Client进入SYN_SENT状态，发送一个SYN帧来主动打开传输通道，该帧的SYN标志位被设置为1，同时会带上Client分配好的SN序列号，该SN是根据时间产生的一个随机值，通常情况下每间隔4ms会加1。除此之外，SYN帧还会带一个MSS（最大报文段长度）可选项的值，表示客户端发送出去的最大数据块的长度。</p> \n <p>（2）第二次握手：Server端在收到SYN帧之后，会进入SYN_RCVD状态，同时返回SYN+ACK帧给Client，主要目的在于通知Client，Server端已经收到SYN消息，现在需要进行确认。Server端发出的SYN+ACK帧的ACK标志位被设置为1，其确认序号AN（Acknowledgment<br> Number）值被设置为Client的SN+1；SYN+ACK帧的SYN标志位被设置为1，SN值为Server端生成的SN序号；SYN+ACK帧的MSS（最大报文段长度）表示的是Server端的最大数据块长度。</p> \n <p>（3）第三次握手：Client在收到Server的第二次握手SYN+ACK确认帧之后，首先将自己的状态会从SYN_SENT变成ESTABLISHED，表示自己方向的连接通道已经建立成功，Client可以发送数据给Server端了。然后，Client发ACK帧给Server端，该ACK帧的ACK标志位被设置为1，其确认序号AN（Acknowledgment<br> Number）值被设置为Server端的SN序列号+1。还有一种情况，Client可能会将ACK帧和第一帧要发送的数据，合并到一起发送给Server端。</p> \n <p>（4）Server端在收到Client的ACK帧之后，会从SYN_RCVD状态会进入ESTABLISHED状态，至此，Server方向的通道连接建立成功，Server可以发送数据给Client，TCP的全双工连接建立完成。</p> \n <h3><a id=\"_878\"></a>三次握手的图解</h3> \n <p>三次握手的交互过程，具体如下图所示：<br> <img src=\"https://img-blog.csdnimg.cn/20210308122934847.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70#pic_center\" alt=\"在这里插入图片描述\"></p> \n <p>图：TCP建立的连接时三次握手示意图</p> \n <p>Client和Server完成了三次握手后，双方就进入了数据传输的阶段。数据传输完成后，连接将断开，连接断开的过程需要经历四次挥手。</p> \n <h2><a id=\"TCP_888\"></a>TCP的四次挥手</h2> \n <p>业务数据通信完成之后，TCP连接开始断开（或者拆接）的过程，在这个过程中连接的每个端的都能独立地、主动的发起，断开的过程TCP协议使用了四路挥手操作。</p> \n <h3><a id=\"_893\"></a>四次挥手具体过程</h3> \n <p>四次挥手具体过程，具体如下：</p> \n <p>（1）第一次挥手：主动断开方（可以是客户端，也可以是服务器端），向对方发送一个FIN结束请求报文，此报文的FIN位被设置为1，并且正确设置Sequence<br> Number（序列号）和Acknowledgment<br> Number（确认号）。发送完成后，主动断开方进入FIN_WAIT_1状态，这表示主动断开方没有业务数据要发送给对方，准备关闭SOCKET连接了。</p> \n <p>（2）第二次挥手：正常情况下，在收到了主动断开方发送的FIN断开请求报文后，被动断开方会发送一个ACK响应报文，报文的Acknowledgment<br> Number（确认号）值为断开请求报文的Sequence Number<br> （序列号）加1，该ACK确认报文的含义是：“我同意你的连接断开请求”。之后，被动断开方就进入了CLOSE-WAIT（关闭等待）状态，TCP协议服务会通知高层的应用进程，对方向本地方向的连接已经关闭，对方已经没有数据要发送了，若本地还要发送数据给对方，对方依然会接受。被动断开方的CLOSE-WAIT（关闭等待）还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。</p> \n <p>主动断开方在收到了ACK报文后，由FIN_WAIT_1转换成FIN_WAIT_2状态。</p> \n <p>（3）第三次挥手：在发送完成ACK报文后，被动断开方还可以继续完成业务数据的发送，待剩余数据发送完成后，或者CLOSE-WAIT（关闭等待）截止后，被动断开方会向主动断开方发送一个FIN+ACK结束响应报文，表示被动断开方的数据都发送完了，然后，被动断开方进入LAST_ACK状态。</p> \n <p>（4）第四次挥手：主动断开方收在到FIN+ACK断开响应报文后，还需要进行最后的确认，向被动断开方发送一个ACK确认报文，然后，自己就进入TIME_WAIT状态，等待超时后最终关闭连接。处于TIME_WAIT状态的主动断开方，在等待完成2MSL的时间后，如果期间没有收到其他报文，则证明对方已正常关闭，主动断开方的连接最终关闭。</p> \n <p>被动断开方在收到主动断开方的最后的ACK报文以后，最终关闭了连接，自己啥也不管了。</p> \n <h3><a id=\"_913\"></a>四次挥手图解</h3> \n <p>四次挥手的全部交互过程，具体如下图所示：<br> <img src=\"https://img-blog.csdnimg.cn/20210308122951816.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70#pic_center\" alt=\"在这里插入图片描述\"></p> \n <p>图：TCP建立的连接时四次挥手的示意图</p> \n <p>处于TIME_WAIT状态的主动断开方，在等待完成2MSL的时间后，才真正关闭连接通道，其等待的时间为什么是2MSL呢？</p> \n <p>2MSL翻译过来就是两倍的MSL。MSL全称为Maximum Segment<br> Lifetime，指的是一个TCP报文片段在网络中最大的存活时间，具体来说，2MSL对应于一次消息的来回（一个发送和一个回复）所需的最大时间。如果直到2MSL，主动断开方都没有再一次收到对方的报文（如FIN报文），则可以推断ACK已经被对方成功接收，此时，主动断开方将最终结束自己的TCP连接。所以，TCP的TIME_WAIT状态也称为2MSL等待状态。</p> \n <p>有关MSL的具体的时间长度，在RFC1122协议中推荐为2分钟。在SICS（瑞典计算机科学院）开发的一个小型开源的TCP/IP协议栈——LwIP开源协议栈中MSL默认为1分钟。在源自Berkeley的TCP协议栈实现中MSL默认长度为30秒。总体来说，TIME_WAIT（2MSL）等待状态的时间长度，一般维持在1-4分钟之间。</p> \n <p>通过三次握手建立连接和四次挥手拆除连接，一次TCP的连接建立及拆除，至少进行7次通信，可见其成本是很高的。</p> \n <h2><a id=\"_930\"></a>三次握手、四次挥手的常见面试题</h2> \n <p>有关TCP的连接建立的三次握手及拆除过程的四次挥手的面试问题，是技术面试过程中的出现频率很高的重点和难点问题，常见问题大致如下：</p> \n <h3><a id=\"1_935\"></a>问题（1）：为什么关闭连接的需要四次挥手，而建立连接却只要三次握手呢？</h3> \n <p>关闭连接时，被动断开方在收到对方的FIN结束请求报文时，很可能业务数据没有发送完成，并不能立即关闭连接，被动方只能先回复一个ACK响应报文，告诉主动断开方：“你发的FIN报文我收到了，只有等到我所有的业务报文都发送完了，我才能真正的结束，在结束之前，我会发你FIN+ACK报文的，你先等着”。所以，被动断开方的确认报文，需要拆开成为两步，故总体就需要四步挥手。</p> \n <p>而在建立连接场景中，Server端的应答可以稍微简单一些。当Server端收到Client端的SYN连接请求报文后，其中ACK报文表示对请求报文的应答，SYN报文用来表示服务端的连接也已经同步开启了，而ACK报文和SYN报文之间，不会有其他报文需要发送，故而可以合二为一，可以直接发送一个SYN+ACK报文。所以，在建立连接时，只需要三次握手即可。</p> \n <h3><a id=\"2_941\"></a>问题（2）：为什么连接建立的时候是三次握手，可以改成两次握手吗？</h3> \n <p>三次握手完成两个重要的功能：一是双方都做好发送数据的准备工作，而且双方都知道对方已准备好；二是双方完成初始SN序列号的协商，双方的SN序列号在握手过程中被发送和确认。</p> \n <p>如果把三次握手改成两次握手，可能发生死锁。两次握手的话，缺失了Client的二次确认ACK帧，假想的TCP建立的连接时二次挥手，可以如下图所示：<br> <img src=\"https://img-blog.csdnimg.cn/20210308123012842.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70#pic_center\" alt=\"在这里插入图片描述\"></p> \n <p>图：假想的TCP建立的连接时二次握手的示意图</p> \n <p>在假想的TCP建立的连接时二次握手过程中，Client发送Server发送一个SYN请求帧，Server收到后发送了确认应答SYN+ACK帧。按照两次握手的协定，Server认为连接已经成功地建立了，可以开始发送数据帧。这个过程中，如果确认应答SYN+ACK帧在传输中被丢失，Client没有收到，Client将不知道Server是否已准备好，也不知道Server的SN序列号，Client认为连接还未建立成功，将忽略Server发来的任何数据分组，会一直等待Server的SYN+ACK确认应答帧。而Server在发出的数据帧后，一直没有收到对应的ACK确认后就会产生超时，重复发送同样的数据帧。这样就形成了死锁。</p> \n <h3><a id=\"3TIMEWAIT2MSL_952\"></a>问题（3）：为什么主动断开方在TIME-WAIT状态必须等待2MSL的时间？</h3> \n <p>原因之一：主动断开方等待2MSL的时间，是为了确保两端都能最终关闭。假设网络是不可靠的，被动断开方发送FIN+ACK报文后，其主动方的ACK响应报文有可能丢失，这时候的被动断开方处于LAST-ACK状态的，由于收不到ACK确认被动方一直不能正常的进入CLOSED状态。在这种场景下，被动断开方会超时重传FIN+ACK断开响应报文，如果主动断开方在2MSL时间内，收到这个重传的FIN+ACK报文，会重传一次ACK报文，后再一次重新启动2MSL计时等待，这样，就能确保被动断开方能收到ACK报文，从而能确保被动方顺利进入到CLOSED状态。只有这样，双方都能够确保关闭。反过来说，如果主动断开方在发送完ACK响应报文后，不是进入TIME_WAIT状态去等待2MSL时间，而是立即释放连接，则将无法收到被动方重传的FIN+ACK报文，所以不会再发送一次ACK确认报文，此时处于LAST-ACK状态的被动断开方，无法正常进入到CLOSED状态。</p> \n <p>原因之二：防止“旧连接的已失效的数据报文”出现在新连接中。主动断开方在发送完最后一个ACK报文后，再经过2MSL，才能最终关闭和释放端口，这就意味着，相同端口的新TCP新连接，需要在2MSL的时间之后，才能够正常的建立。2MSL这段时间内，旧连接所产生的所有数据报文，都已经从网络中消失了，从而，确保了下一个新的连接中不会出现这种旧连接请求报文。</p> \n <h3><a id=\"4Client_958\"></a>问题（4）：如果已经建立了连接，但是Client端突然出现故障了怎么办？</h3> \n <p>TCP还设有一个保活计时器，Client端如果出现故障，Server端不能一直等下去，这样会浪费系统资源。每收到一次Client客户端的数据帧后，Server端都的保活计时器会复位。计时器的超时时间通常是设置为2小时，若2小时还没有收到Client端的任何数据帧，Server端就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，Server端就认为Client端出了故障，接着就关闭连接。如果觉得保活计时器的两个多小时的间隔太长，可以自行调整TCP连接的保活参数。</p> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 43078);
INSERT INTO `crawlerblog` VALUES (123124018, 'Sharding-JDBC 实战（史上最全）', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <p>文章很长，而且持续更新，建议收藏起来，慢慢读！ <a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\"><strong>Java 高并发 发烧友社群：疯狂创客圈（总入口）</strong></a> 奉上以下珍贵的学习资源：</p> \n <ul>\n  <li><strong>免费赠送 经典图书 ： <a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\"> 极致经典 + 社群大片好评 《 Java 高并发 三部曲 》</a> 面试必备 + 大厂必备 + 涨薪必备</strong></li>\n  <li><strong>免费赠送 经典图书 ： <a href=\"https://www.cnblogs.com/crazymakercircle/p/11397271.html\">《Netty Zookeeper Redis 高并发实战》</a> 面试必备 + 大厂必备 +涨薪必备</strong> （加尼恩领取）</li>\n  <li><strong>免费赠送 经典图书 ： <a href=\"https://www.cnblogs.com/crazymakercircle/p/13878143.html\">《SpringCloud、Nginx高并发核心编程》</a> 面试必备 + 大厂必备 + 涨薪必备</strong> （加尼恩领取）</li>\n  <li><strong>免费赠送 资源宝库： Java 必备 百度网盘资源大合集 价值&gt;10000元</strong> （加尼恩领取）</li>\n </ul> \n <h2><a id=\"ShardingJDBC__9\"></a>Sharding-JDBC 实战（史上最全）</h2> \n <p>在开始 Sharding-JDBC分库分表具体实战之前，</p> \n <p>必要先了解分库分表的一些核心概念。</p> \n <h4><a id=\"_17\"></a>分库分表的背景：</h4> \n <p>传统的将数据集中存储⾄单⼀数据节点的解决⽅案，在性能、可⽤性和运维成本这三⽅⾯已经难于满⾜互联⽹的海量数据场景。</p> \n <p>随着业务数据量的增加，原来所有的数据都是在一个数据库上的，网络IO及文件IO都集中在一个数据库上的，因此CPU、内存、文件IO、网络IO都可能会成为系统瓶颈。</p> \n <p>当业务系统的数据容量接近或超过单台服务器的容量、QPS/TPS接近或超过单个数据库实例的处理极限等，</p> \n <p>此时，往往是采用垂直和水平结合的数据拆分方法，把数据服务和数据存储分布到多台数据库服务器上。</p> \n <h4><a id=\"_35\"></a>容量瓶颈：</h4> \n <p>从性能⽅⾯来说，由于关系型数据库⼤多采⽤ B+ 树类型的索引，</p> \n <p>数据量超过一定大小，B+Tree 索引的高度就会增加，而每增加一层高度，整个索引扫描就会多一次 IO 。</p> \n <p>在数据量超过阈值的情况下，索引深度的增加也将使得磁盘访问的 IO 次数增加，进而导致查询性能的下降；</p> \n <blockquote> \n  <p>一般的存储容量是多少呢？ 请参见 3 高架构秒杀部分内容。</p> \n </blockquote> \n <h4><a id=\"_45\"></a>吞吐量瓶颈：</h4> \n <p>同时，⾼并发访问请求也使得集中式数据库成为系统的最⼤瓶颈。</p> \n <blockquote> \n  <p>一般的吞吐量是多少呢？ 请参见 3 高架构秒杀部分内容。</p> \n </blockquote> \n <p>在传统的关系型数据库⽆法满⾜互联⽹场景需要的情况下，将数据存储⾄原⽣⽀持分布式的 NoSQL 的尝试越来越多。</p> \n <p>但 NoSQL 并不能包治百病，而关系型数据库的地位却依然不可撼动。</p> \n <blockquote> \n  <p>如果进行sql、nosql数据库的选型呢？ 请参见 推送中台架构部分的内容。</p> \n </blockquote> \n <h2><a id=\"_61\"></a>分治模式在存储领域的落地</h2> \n <p>分治模式在存储领域的使用：<strong>数据分⽚</strong></p> \n <p>数据分⽚指按照某个维度将存放在单⼀数据库中的数据， 分散地存放⾄多个数据库或表中以达到提升性能瓶颈以及可⽤性的效果。</p> \n <p>数据分⽚的有效⼿段是对关系型数据库进⾏分库和分表。</p> \n <p>分库能够⽤于有效的分散对数据库单点的访问量；</p> \n <blockquote> \n  <p>分库的合理的时机， 请参见 3 高架构秒杀部分内容。</p> \n </blockquote> \n <p>分表能够⽤于有效的数据量超过可承受阈值而产⽣的查询瓶颈, 解决MySQL 单表性能问题</p> \n <blockquote> \n  <p>分表的合理的时机， 请参见 3 高架构秒杀部分内容。</p> \n </blockquote> \n <p>使⽤多主多从的分⽚⽅式，可以有效的避免数据单点，从而提升数据架构的可⽤性。</p> \n <p>通过分库和分表进⾏数据的拆分来使得各个表的数据量保持在阈值以下，以及对流量进⾏疏导应对⾼访问量，是应对⾼并发和海量数据系统的有效⼿段。</p> \n <p>数据分⽚的拆分⽅式⼜分为垂直分⽚和⽔平分⽚。</p> \n <h3><a id=\"_97\"></a>分库分表的问题</h3> \n <h4><a id=\"_99\"></a>分库导致的事务问题</h4> \n <p>不过，由于目前采用柔性事务居多，<strong>实际上，分库的事务性能也是很高的，有关柔性事务，请参见疯狂创客圈的专题博文:</strong></p> \n <p><a href=\"https://www.cnblogs.com/crazymakercircle/p/14375424.html\">分布式事务面试题 （史上最全、持续更新、吐血推荐）</a></p> \n <h2><a id=\"ShardingJDBC_111\"></a>Sharding-JDBC简介</h2> \n <p>Sharding-JDBC 是<strong>当当网</strong>开源的适用于微服务的分布式数据访问基础类库，完整的实现了分库分表，读写分离和分布式主键功能，并初步实现了柔性事务。</p> \n <p>从 2016 年开源至今，在经历了整体架构的数次精炼以及稳定性打磨后，如今它已积累了足够的底蕴。</p> \n <p>官方的网址如下:</p> \n <p>http://shardingsphere.apache.org/index_zh.html</p> \n <p>ShardingSphere是一套开源的分布式数据库中间件解决方案组成的生态圈，它由Sharding-JDBC、Sharding-Proxy 和 Sharding-Sidecar这3款相互独立的产品组成。</p> \n <p>他们均提供标准化的数据分片、分布式事务 和 数据库治理功能，可适用于如Java同构、异构语言、云原生等各种多样化的应用场景。</p> \n <blockquote> \n  <p>Apache ShardingSphere 是一套开源的分布式数据库中间件解决方案组成的生态圈，它由 JDBC、Proxy 和 Sidecar（规划中）这 3 款相互独立，却又能够混合部署配合使用的产品组成。 它们均提供标准化的数据分片、分布式事务和数据库治理功能，可适用于如 Java 同构、异构语言、云原生等各种多样化的应用场景。</p> \n </blockquote> \n <p>Apache ShardingSphere 定位为关系型数据库中间件，旨在充分合理地在分布式的场景下利用关系型数据库的计算和存储能力，而并非实现一个全新的关系型数据库。 它通过关注不变，进而抓住事物本质。关系型数据库当今依然占有巨大市场，是各个公司核心业务的基石，未来也难于撼动，我们目前阶段更加关注在原有基础上的增量，而非颠覆。</p> \n <blockquote> \n  <p>Apache ShardingSphere 5.x 版本开始致力于可插拔架构，项目的功能组件能够灵活的以可插拔的方式进行扩展。 目前，数据分片、读写分离、数据加密、影子库压测等功能，以及 MySQL、PostgreSQL、SQLServer、Oracle 等 SQL 与协议的支持，均通过插件的方式织入项目。 开发者能够像使用积木一样定制属于自己的独特系统。Apache ShardingSphere 目前已提供数十个 SPI 作为系统的扩展点，仍在不断增加中。</p> \n </blockquote> \n <p>ShardingSphere 已于2020年4月16日成为 Apache 软件基金会的顶级项目。</p> \n <h3><a id=\"ShardingJDBC_133\"></a>Sharding-JDBC的优势</h3> \n <p>Sharding-JDBC直接封装JDBC API，可以理解为增强版的JDBC驱动，旧代码迁移成本几乎为零：</p> \n <ul>\n  <li>可适用于任何基于Java的<strong>ORM框架</strong>，如JPA、Hibernate、Mybatis、Spring JDBC Template或直接使用JDBC。</li>\n  <li>可基于任何第三方的数据库连接池，如DBCP、C3P0、 BoneCP、Druid等。</li>\n  <li>理论上可支持任意实现JDBC规范的数据库。虽然目前仅支持MySQL，但已有支持Oracle、SQLServer等数据库的计划。</li>\n </ul> \n <p>Sharding-JDBC定位为轻量Java框架，使用客户端直连数据库，以jar包形式提供服务，无proxy代理层，无需额外部署，无其他依赖，DBA也无需改变原有的运维方式。</p> \n <p>Sharding-JDBC分片策略灵活，可支持等号、between、in等多维度分片，也可支持多分片键。</p> \n <p>SQL解析功能完善，支持聚合、分组、排序、limit、or等查询，并支持Binding Table以及笛卡尔积表查询。</p> \n <h3><a id=\"_149\"></a>与常见开源产品对比</h3> \n <p>下表仅列出在数据库分片领域非常有影响力的几个项目：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/bed1cb2b6c2d87e0c5c6a00d3a8a28f3.png\" alt=\"img\"></p> \n <p>通过以上表格可以看出，Cobar（MyCat）属于中间层方案，在应用程序和MySQL之间搭建一层Proxy。</p> \n <p>中间层介于应用程序与数据库间，需要做一次转发，而基于JDBC协议并无额外转发，直接由应用程序连接数据库，性能上有些许优势。这里并非说明中间层一定不如客户端直连，除了性能，需要考虑的因素还有很多，中间层更便于实现监控、数据迁移、连接管理等功能。</p> \n <p>Cobar-Client、TDDL和Sharding-JDBC均属于客户端直连方案。</p> \n <p>此方案的优势在于轻便、兼容性、性能以及对DBA影响小。其中Cobar-Client的实现方式基于ORM（Mybatis）框架，其兼容性与扩展性不如基于JDBC协议的后两者。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/2b845b628c3cd6df0ca354e15438a2b7.png\" alt=\"img\"></p> \n <p>目前常用的就是Cobar（MyCat）与Sharding-JDBC两种方案</p> \n <h3><a id=\"MyCAT_169\"></a>MyCAT</h3> \n <p>MyCAT是社区爱好者在阿里cobar基础上进行二次开发，解决了cobar当时存 在的一些问题，并且加入了许多新的功能在其中。目前MyCAT社区活 跃度很高，</p> \n <p>目前已经有一些公司在使用MyCAT。</p> \n <p>总体来说支持度比 较高，也会一直维护下去，发展到目前的版本，已经不是一个单纯的MySQL代理了，</p> \n <p>它的后端可以支持MySQL, SQL Server, Oracle, <a href=\"http://www.2cto.com/database/DB2/\">DB2</a>, PostgreSQL等主流数据库，也支持MongoDB这种新型NoSQL方式的存储，未来还会支持更多类型的存储。</p> \n <p>MyCAT是一个强大的数据库中间件，不仅仅可以用作读写分离，以及分表分库、容灾管理，而且可以用于多租户应用开发、云平台基础设施，让你的架构具备很强的适应性和灵活性，</p> \n <p>借助于即将发布的MyCAT只能优化模块，系统的数据访问瓶颈和热点一目了然，</p> \n <p>根据这些统计分析数据，你可以自动或手工调整后端存储，将不同的表隐射到不同存储引擎上，而整个应用的代码一行也不用改变。</p> \n <p>MyCAT是在Cobar基础上发展的版本，两个显著提高：</p> \n <ul>\n  <li> <p>后端由BIO改为NIO，并发量有大幅提高；</p> </li>\n  <li> <p>增加了对Order By, Group By, Limit等聚合功能</p> </li>\n </ul> \n <p>（虽然Cobar也可以支持Order By, Group By, Limit语法，但是结果没有进行聚合，只是简单返回给前端，聚合功能还是需要业务系统自己完成, 适用于<strong>有专门团队维护的大型企业、或者大团队</strong>。）</p> \n <h3><a id=\"ShardingJDBC_193\"></a>Sharding-JDBC</h3> \n <p>Sharding-JDBC定位为轻量Java框架，使用客户端直连数据库，以jar包形式提供服务，无proxy代理层，无需额外部署，无其他依赖，DBA也无需改变原有的运维方式。</p> \n <p><strong>所以 ，适用于中小企业、或者中小团队</strong>。</p> \n <p>Sharding-JDBC分片策略灵活，可支持等号、between、in等多维度分片，也可支持多分片键。</p> \n <p>SQL解析功能完善，支持聚合、分组、排序、limit、or等查询，并支持Binding Table以及笛卡尔积表查询。</p> \n <h4><a id=\"ShardingJDBC__203\"></a>Sharding-JDBC 功能列表</h4> \n <ul>\n  <li>分库 &amp; 分表</li>\n  <li>读写分离</li>\n  <li>分布式主键</li>\n </ul> \n <h2><a id=\"_213\"></a>高并发数据分片的两大工作</h2> \n <p>一般情况下，开发维度的数据分片，大多是以水平切分模式（水平分库、分表）为基础来说的，</p> \n <p>垂直分片主要在于 运维维度，或者 或者做存储的深级改造的时候。</p> \n <h3><a id=\"_219\"></a>数据分片的工作</h3> \n <p><strong>简单来说，数据分片的工作分为两大工作 :</strong></p> \n <h3><a id=\"_223\"></a><strong>第一大工作：分片的拆分</strong></h3> \n <h4><a id=\"es__227\"></a>es 的数据分片的背后原理</h4> \n <blockquote> \n  <p>参见视频</p> \n </blockquote> \n <h4><a id=\"rediscluster_231\"></a>rediscluster的数据分片的背后原理</h4> \n <p><strong>表的拆分：</strong></p> \n <p>将一张大表 t_order ，拆分生成数个表结构完全一致的小表 t_order_0、t_order_1、···、t_order_n，</p> \n <p>每张小表，只存储大表中的一部分数据，</p> \n <h3><a id=\"_245\"></a><strong>第二大工作：分片的路由</strong></h3> \n <p>当执行一条SQL时，会通过 路由策略 ， 将数据**route(路由)**到不同的分片内。</p> \n <p>面临的问题：</p> \n <ul>\n  <li> <p>分片建的选择</p> </li>\n  <li> <p>分片策略的选择</p> </li>\n  <li> <p>分片算法的选择</p> </li>\n </ul> \n <h4><a id=\"_266\"></a>什么是数据分片?</h4> \n <p>按照分片规则把数据分到若干个shard、partition当中</p> \n <p><img src=\"https://img-blog.csdnimg.cn/0a279ce477794f999afbbce98ca9de81.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5p625p6E5biILeWwvOaBqQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <h2><a id=\"_276\"></a>主要的分片算法</h2> \n <h3><a id=\"range__278\"></a>range 分片</h3> \n <p>一种是按照 range 来分，就是每个片，一段连续的数据，这个一般是按比如<strong>时间范围/数据范围</strong>来的，但是这种一般较少用，因为很容易发生<strong>数据倾斜</strong>，大量的流量都打在<strong>最新的数据</strong>上了。</p> \n <p>比如，安装数据范围分片，把1到100个数字，要保存在3个节点上</p> \n <p>按照顺序分片，把数据平均分配三个节点上</p> \n <ul>\n  <li>1号到33号数据保存到节点1上</li>\n  <li>34号到66号数据保存到节点2上</li>\n  <li>67号到100号数据保存到节点3上</li>\n </ul> \n <p><img src=\"https://img-blog.csdnimg.cn/ca934fd159f04ab987632d9c6af9df10.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"ID_302\"></a>ID取模分片</h3> \n <p>此种分片规则将数据分成n份（通常dn节点也为n），从而将数据均匀的分布于各个表中，或者各节点上。</p> \n <p>扩容方便。</p> \n <blockquote> \n  <p>ID取模分片常用在关系型数据库的设计</p> \n </blockquote> \n <p>具体请参见 秒杀视频的 亿级库表架构设计</p> \n <h3><a id=\"hash__318\"></a>hash 哈希分布</h3> \n <p>使用hash 算法，获取key的哈希结果，再按照规则进行分片，这样可以保证数据被打散，同时保证数据分布的比较均匀</p> \n <p>哈希分布方式分为三个分片方式：</p> \n <ul>\n  <li>哈希取余分片</li>\n  <li>一致性哈希分片</li>\n  <li>虚拟槽分片</li>\n </ul> \n <h4><a id=\"_330\"></a>哈希取余模分片</h4> \n <p>例如1到100个数字，对每个数字进行哈希运算，然后对每个数的哈希结果除以节点数进行取余，余数为1则保存在第1个节点上，余数为2则保存在第2个节点上，余数为0则保存在第3个节点，这样可以保证数据被打散，同时保证数据分布的比较均匀</p> \n <p>比如有100个数据，对每个数据进行hash运算之后，与节点数进行取余运算，根据余数不同保存在不同的节点上</p> \n <p><img src=\"https://img-blog.csdnimg.cn/747a76fe40a140ae8ac40c461eb2c155.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5p625p6E5biILeWwvOaBqQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>哈希取余分片是非常简单的一种分片方式</p> \n <h5><a id=\"_350\"></a>哈希取模分片有一个问题</h5> \n <blockquote> \n  <p>即当增加或减少节点时，原来节点中的80%的数据会进行迁移操作，对所有数据重新进行分布</p> \n </blockquote> \n <p>哈希取余分片，建议使用多倍扩容的方式，例如以前用3个节点保存数据，扩容为比以前多一倍的节点即6个节点来保存数据，这样只需要适移50%的数据。</p> \n <p>数据迁移之后，第一次无法从缓存中读取数据，必须先从数据库中读取数据，然后回写到缓存中，然后才能从缓存中读取迁移之后的数据</p> \n <p><img src=\"https://img-blog.csdnimg.cn/d82bfb39f4e24c438781b02ec9e8664f.png\" alt=\"img\"></p> \n <p>哈希取余分片优点：</p> \n <ul>\n  <li>配置简单：对数据进行哈希，然后取余</li>\n </ul> \n <p>哈希取余分片缺点：</p> \n <ul>\n  <li>数据节点伸缩时，导致数据迁移</li>\n  <li>迁移数量和添加节点数据有关，建议翻倍扩容</li>\n </ul> \n <h4><a id=\"_377\"></a>一致性哈希分片</h4> \n <p>一致性哈希原理：</p> \n <blockquote> \n  <p>将所有的数据当做一个token环，</p> \n  <p>token环中的数据范围是0到2的32次方。</p> \n  <p>然后为每一个数据节点分配一个token范围值，这个节点就负责保存这个范围内的数据。</p> \n </blockquote> \n <p><img src=\"https://img-blog.csdnimg.cn/52c335750c024a09a698fde2a8e75240.png\" alt=\"img\"></p> \n <p>对每一个key进行hash运算，被哈希后的结果在哪个token的范围内，则按顺时针去找最近的节点，这个key将会被保存在这个节点上。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/8d28e7874a562e0dffae92eed2158922.png\" alt=\"img\"></p> \n <h3><a id=\"_399\"></a>一致性哈希分片的节点扩容</h3> \n <p>在下面的图中：</p> \n <ul>\n  <li> <p>有4个key被hash之后的值在在n1节点和n2节点之间，按照顺时针规则，这4个key都会被保存在n2节点上</p> </li>\n  <li> <p>如果在n1节点和n2节点之间添加n5节点，当下次有key被hash之后的值在n1节点和n5节点之间，这些key就会被保存在n5节点上面了</p> </li>\n </ul> \n <p>下图的例子里，添加n5节点之后：</p> \n <ul>\n  <li>数据迁移会在n1节点和n2节点之间进行</li>\n  <li>n3节点和n4节点不受影响</li>\n  <li>数据迁移范围被缩小很多</li>\n </ul> \n <p>同理，如果有1000个节点，此时添加一个节点，受影响的节点范围最多只有千分之2。所以，一致性哈希一般用在节点比较多的时候，节点越多，扩容时受影响的节点范围越少</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/2d1f7f28a5674909d6de5032a1813f94.png\" alt=\"img\"></p> \n <p>分片方式：哈希 + 顺时针(优化取余)</p> \n <p>一致性哈希分片优点：</p> \n <ul>\n  <li>一致性哈希算法解决了分布式下数据分布问题。比如在缓存系统中，通过一致性哈希算法把缓存键映射到不同的节点上，由于算法中虚拟节点的存在，哈希结果一般情况下比较均匀。</li>\n  <li>节点伸缩时，只影响邻近节点，但是还是有数据迁移</li>\n </ul> \n <blockquote> \n  <p>“但没有一种解决方案是银弹，能适用于任何场景。所以实践中一致性哈希算法有哪些缺陷，或者有哪些场景不适用呢？”</p> \n </blockquote> \n <p>一致性哈希分片缺点：</p> \n <blockquote> \n  <p>一致性哈希在大批量的数据场景下负载更加均衡，但是在数据规模小的场景下，会出现单位时间内某个节点完全空闲的情况出现。</p> \n </blockquote> \n <h4><a id=\"__442\"></a>虚拟槽分片 (范围分片的变种)</h4> \n <blockquote> \n  <p>Redis Cluster在设计中没有使用一致性哈希（Consistency Hashing），而是使用数据分片引入哈希槽（hash slot）来实现；</p> \n </blockquote> \n <p>虚拟槽分片是Redis Cluster采用的分片方式.</p> \n <p>虚拟槽分片 ，可以理解为范围分片的变种， hash取模分片+范围分片， 把hash值取余数分为n段，一个段给一个节点负责</p> \n <p><img src=\"https://img-blog.csdnimg.cn/803e64d51c064737aa2bc5b008f402e0.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5p625p6E5biILeWwvOaBqQ==,size_15,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <h2><a id=\"es_454\"></a>es的数据分片两大工作</h2> \n <h3><a id=\"Shards_458\"></a>Shards</h3> \n <p>代表索引分片，es可以把一个完整的索引分成多个分片，这样的好处是可以把一个大的索引拆分成多个，分布到不同的节点上。构成分布式搜索。</p> \n <blockquote> \n  <p>分片的数量只能在索引创建前指定，并且索引创建后不能更改。（why，大家可以独立思考一下!）</p> \n </blockquote> \n <p><strong>分片配置建议：</strong></p> \n <p>每个分片大小不要超过30G，硬盘条件好的话，不建议超过100G.</p> \n <p>（官方推荐，每个shard的数据量应该在20GB - 50GB）。</p> \n <p>总而言之，每个分片都是一个Lucene实例，当查询请求打到ES后，ES会把请求转发到每个shard上分别进行查询，最终进行汇总。</p> \n <p>这时候，shard越少，产生的额外开销越少</p> \n <h3><a id=\"_480\"></a>路由机制</h3> \n <p><strong>一条数据是如何落地到对应的shard上的？</strong></p> \n <p>当索引一个文档的时候，文档会被存储到一个主分片中。</p> \n <p>Elasticsearch 如何知道一个文档应该存放到哪个分片中呢？</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/57b06e193856e4479fd0249518f058af.png\" alt=\"img\"></p> \n <p>es的路由过程是根据下面这个算法决定的：</p> \n <pre><code>shard_num = hash(_routing) % num_primary_shards\n\n\n其中 _routing是一个可变值，默认是文档的 _id 的值  ，也可以设置成一个自定义的值。Elasticsearch文档的ID（类似于关系数据库中的自增ID），\n\n_routing 通过 hash 函数生成一个数字，然后这个数字再除以  num_of_primary_shards （主分片的数量）后得到余数 。\n\n这个分布在 0 到  number_of_primary_shards-1 之间的余数，就是我们所寻求的文档所在分片的位置。\n\n\n</code></pre> \n <p><strong>这就解释了为什么我们要在创建索引的时候就确定好主分片的数量</strong> <strong>并且永远不会改变这个数量</strong>：</p> \n <p>因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。</p> \n <p>假设你有一个100个分片的索引。当一个请求在集群上执行时会发生什么呢？</p> \n <pre><code>1. 这个搜索的请求会被发送到一个节点\n2. 接收到这个请求的节点，将这个查询广播到这个索引的每个分片上（可能是主分片，也可能是复本分片）\n3. 每个分片执行这个搜索查询并返回结果\n4. 结果在通道节点上合并、排序并返回给用户\n</code></pre> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/e3185a017d6eb1f69fd72faf013fcb57.png\" alt=\"img\"></p> \n <h2><a id=\"rediscluster_528\"></a>rediscluster的数据分片两大工作</h2> \n <h3><a id=\"__hash_532\"></a>虚拟槽分片 ( hash取模分片+范围分片的混血)</h3> \n <blockquote> \n  <p>Redis Cluster在设计中没有使用一致性哈希（Consistency Hashing），而是使用数据分片引入哈希槽（hash slot）来实现；</p> \n </blockquote> \n <p>虚拟槽分片是Redis Cluster采用的分片方式.</p> \n <p>在该分片方式中：</p> \n <ul>\n  <li>首先 预设虚拟槽，每个槽为一个hash值，每个node负责一定槽范围。</li>\n  <li>每一个值都是key的hash值取余，每个槽映射一个数据子集，一般比节点数大</li>\n </ul> \n <blockquote> \n  <p>Redis Cluster中预设虚拟槽的范围为0到16383</p> \n </blockquote> \n <p><img src=\"https://img-blog.csdnimg.cn/5d13b1192ef94ff18373014ad462339c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5p625p6E5biILeWwvOaBqQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <h4><a id=\"3Redis_549\"></a>3个节点的Redis集群虚拟槽分片结果：</h4> \n <pre><code>[root@localhost redis-cluster]# docker exec -it redis-cluster_redis1_1 redis-cli --cluster check 172.18.8.164:6001\n172.18.8.164:6001 (c4cfd72f...) -&gt; 0 keys | 5461 slots | 1 slaves.\n172.18.8.164:6002 (c15a7801...) -&gt; 0 keys | 5462 slots | 1 slaves.\n172.18.8.164:6003 (3fe7628d...) -&gt; 0 keys | 5461 slots | 1 slaves.\n[OK] 0 keys in 3 masters.\n0.00 keys per slot on average.\n&gt;&gt;&gt; Performing Cluster Check (using node 172.18.8.164:6001)\nM: c4cfd72f7cbc22cd81b701bd4376fabbe3d162bd 172.18.8.164:6001\n   slots:[0-5460] (5461 slots) master\n   1 additional replica(s)\nS: a212e28165b809b4c75f95ddc986033c599f3efb 172.18.8.164:6006\n   slots: (0 slots) slave\n   replicates 3fe7628d7bda14e4b383e9582b07f3bb7a74b469\nM: c15a7801623ee5ebe3cf952989dd5a157918af96 172.18.8.164:6002\n   slots:[5461-10922] (5462 slots) master\n   1 additional replica(s)\nS: 5e74257b26eb149f25c3d54aef86a4d2b10269ca 172.18.8.164:6004\n   slots: (0 slots) slave\n   replicates c4cfd72f7cbc22cd81b701bd4376fabbe3d162bd\nS: 8fb7f7f904ad1c960714d8ddb9ad9bca2b43be1c 172.18.8.164:6005\n   slots: (0 slots) slave\n   replicates c15a7801623ee5ebe3cf952989dd5a157918af96\nM: 3fe7628d7bda14e4b383e9582b07f3bb7a74b469 172.18.8.164:6003\n   slots:[10923-16383] (5461 slots) master\n   1 additional replica(s)\n[OK] All nodes agree about slots configuration.\n&gt;&gt;&gt; Check for open slots...\n&gt;&gt;&gt; Check slots coverage...\n[OK] All 16384 slots covered.\n</code></pre> \n <h3><a id=\"_589\"></a>虚拟槽分片的路由机制：</h3> \n <p>1.把16384槽按照节点数量进行平均分配，由节点进行管理<br> 2.对每个key按照CRC16规则进行hash运算<br> 3.把hash结果对16383进行取模<br> 4.把余数发送给Redis节点<br> 5.节点接收到数据，验证是否在自己管理的槽编号的范围</p> \n <ul>\n  <li>如果在自己管理的槽编号范围内，则把数据保存到数据槽中，然后返回执行结果</li>\n  <li>如果在自己管理的槽编号范围外，则会把数据发送给正确的节点，由正确的节点来把数据保存在对应的槽中</li>\n </ul> \n <blockquote> \n  <p>需要注意的是：Redis Cluster的节点之间会共享消息，每个节点都会知道是哪个节点负责哪个范围内的数据槽</p> \n </blockquote> \n <p>虚拟槽分布方式中，由于每个节点管理一部分数据槽，数据保存到数据槽中。</p> \n <p>当节点扩容或者缩容时，对数据槽进行重新分配迁移即可，数据不会丢失。</p> \n <h2><a id=\"shardingjdbc_610\"></a>shardingjdbc的数据分片两大工作</h2> \n <h3><a id=\"_614\"></a><strong>第一大工作：分片的拆分</strong></h3> \n <p><strong>表的拆分：</strong></p> \n <p>将一张大表 t_order ，拆分生成数个表结构完全一致的小表 t_order_0、t_order_1、···、t_order_n，</p> \n <p>每张小表，只存储大表中的一部分数据，</p> \n <h3><a id=\"user_630\"></a>例子：user表的数据分片</h3> \n <p><img src=\"https://img-blog.csdnimg.cn/f3c12ebf263a4d508e9c1039ac4c28f8.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5p625p6E5biILeWwvOaBqQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"order_634\"></a>例子：order表的数据分片</h3> \n <p><img src=\"https://img-blog.csdnimg.cn/ea4aa93c43f44119b7ce5808c19d33c8.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5p625p6E5biILeWwvOaBqQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"_644\"></a><strong>第二大工作：分片的路由</strong></h3> \n <p>当执行一条SQL时，会通过 路由策略 ， 将数据**route(路由)**到不同的分片内。</p> \n <ul>\n  <li> <p>数据源的路由</p> </li>\n  <li> <p>表的路由</p> </li>\n </ul> \n <p>面临的问题：</p> \n <ul>\n  <li>分片key的选择</li>\n  <li>分片策略的选择</li>\n  <li>分片算法的选择</li>\n </ul> \n <h2><a id=\"_672\"></a>核心概念</h2> \n <h3><a id=\"_676\"></a>分⽚键</h3> \n <p>⽤于分⽚的字段，是将数据库（表）⽔平拆分的关键字段。</p> \n <p>在对表中的数据进行分片时，首先要选出一个分片键（Shard Key），即用户可以通过这个字段进行数据的水平拆分。</p> \n <p>例：</p> \n <blockquote> \n  <p>将订单表中的订单主键的尾数取模分⽚，则订单主键为分⽚字段。</p> \n </blockquote> \n <h4><a id=\"_688\"></a>执行表的选择</h4> \n <p>我们将 t_order 表分片以后，当执行一条 SQL 时，通过对字段 order_id 取模的方式来决定要执行的表, 这条数据该在哪个数据库中的哪个表中执行，此时 order_id 字段就是分片健。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/724720e86bb34301b1962e483c4dea4f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5p625p6E5biILeWwvOaBqQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <h4><a id=\"_700\"></a>执行库的选择(数据源的选择)</h4> \n <p>这样以来同一个订单的相关数据就会存在同一个数据库表中，大幅提升数据检索的性能，</p> \n <h4><a id=\"_710\"></a>说明</h4> \n <ul>\n  <li> <p>除了使用单个字段作为分片件， sharding-jdbc 还支持根据多个字段作为分片健进行分片。</p> </li>\n  <li> <p>SQL 中如果⽆分⽚字段，将执⾏全路由，性能较差。</p> </li>\n </ul> \n <h3><a id=\"_722\"></a>数据节点</h3> \n <p>数据节点是分库分表中一个不可再分的最小数据单元（表），它由数据源名称和数据表组成，</p> \n <p>例如上图中 ds1.t_user_0 就表示一个数据节点。</p> \n <h3><a id=\"_732\"></a>逻辑表</h3> \n <p>逻辑表是指一组具有相同逻辑和数据结构表的总称。</p> \n <p>比如我们将订单表 t_order 拆分成 t_order_0 ··· t_order_9 等 10 张表。</p> \n <p>此时我们会发现分库分表以后数据库中已不在有 t_order 这张表，取而代之的是 t_order_n，但我们在代码中写 SQL 依然按 t_order 来写。</p> \n <p>此时 t_order 就是这些拆分表的逻辑表。</p> \n <p>例如上图中 t_user 就表示一个数据节点。</p> \n <h3><a id=\"_748\"></a>真实表（物理表）</h3> \n <p>真实表也就是上边提到的 t_order_n 数据库中真实存在的物理表。</p> \n <p>例如上图中 t_user _0就表示一个真实表。</p> \n <h2><a id=\"_758\"></a>分片策略</h2> \n <p>分片策略是一种抽象的概念，实际分片操作的是由分片算法和分片健来完成的。</p> \n <p>真正可⽤于分⽚操作的是分⽚键 + 分⽚算法，也就是分⽚策略。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/da66bcb5694e4420bff71afb1f97d4f2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5p625p6E5biILeWwvOaBqQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>为什么要这么设计，是出于分⽚算法的独⽴性，将其独⽴抽离。</p> \n <p>ShardingSphere-JDBC考虑更多的灵活性，把分片算法单独抽象出来，方便开发者扩展；</p> \n <h3><a id=\"_778\"></a>标准分片策略</h3> \n <p>标准分片策略适用于单分片键，此策略支持 PreciseShardingAlgorithm 和 RangeShardingAlgorithm 两个分片算法。</p> \n <p>其中 PreciseShardingAlgorithm 是必选的，用于处理 = 和 IN 的分片。</p> \n <p>RangeShardingAlgorithm 用于处理BETWEEN AND， &gt;， &lt;，&gt;=，&lt;= 条件分片，</p> \n <p>RangeShardingAlgorithm 是可选的， 如果不配置RangeShardingAlgorithm，SQL中的条件等将按照全库路由处理。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/e16866e452a24c28bfff227874b75616.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5p625p6E5biILeWwvOaBqQ==,size_18,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"_796\"></a>复合分片策略</h3> \n <p>复合分片策略对应 ComplexShardingStrategy。</p> \n <p>同样支持对 SQL语句中的 =，&gt;， &lt;， &gt;=， &lt;=，IN和 BETWEEN AND 的分片操作。</p> \n <p>不同的是它支持多分片键，具体分配片细节完全由应用开发者实现。</p> \n <p>ComplexShardingStrategy ⽀持多分⽚键，由于多分⽚键之间的关系复杂，因此并未进⾏过多的封装，而是直接将分⽚键值组合以及分⽚操作符透传⾄分⽚算法，完全由应⽤开发者实现，提供最⼤的灵活度。</p> \n <h3><a id=\"inline_810\"></a>表达式分片策略（inline内联分片策略）</h3> \n <p>行表达式分片策略，支持对 SQL语句中的 = 和 IN 的分片操作，但只支持单分片键。</p> \n <p>这种策略通常用于简单的分片，不需要自定义分片算法，可以直接在配置文件中接着写规则。</p> \n <p>t_order_$-&gt;{t_order_id % 4} 代表 t_order 对其字段 t_order_id取模，拆分成4张表，而表名分别是t_order_0 到 t_order_3。</p> \n <h3><a id=\"Hint__820\"></a>强制分片策略（Hint 暗示分片策略）</h3> \n <p>Hint 分片策略，通过指定分片健而非从 SQL 中提取分片健的方式进行分片的策略。</p> \n <p>对于分⽚值⾮ SQL 决定，不是来自于分片建，甚至连分片建都没有 ，而由其他外置条件决定的场景，可使⽤Hint 分片策略 。</p> \n <p>前面的分片策略都是解析 SQL 语句， 提取分片建和分片值，并根据设置的分片算法进行分片。</p> \n <p>Hint 分片算法 指定分⽚值而⾮从 SQL 中提取，而是手工设置的⽅式，进⾏分⽚的策略。</p> \n <p>例：内部系统，按照员⼯登录主键分库，而数据库中并⽆此字段。</p> \n <h3><a id=\"_834\"></a>不分⽚策略</h3> \n <p>对应 NoneShardingStrategy。不分⽚的策略。</p> \n <p>这种严格来说不算是一种分片策略了。</p> \n <p>只是ShardingSphere也提供了这么一个配置。</p> \n <h2><a id=\"_842\"></a>分片算法</h2> \n <p>上边我们提到可以用分片健取模的规则分片，但这只是比较简单的一种，</p> \n <p>在实际开发中我们还希望用 &gt;=、&lt;=、&gt;、&lt;、BETWEEN 和 IN 等条件作为分片规则，自定义分片逻辑，这时就需要用到分片策略与分片算法。</p> \n <p>从执行 SQL 的角度来看，分库分表可以看作是一种路由机制，把 SQL 语句路由到我们期望的数据库或数据表中并获取数据，分片算法可以理解成一种路由规则。</p> \n <p>咱们先捋一下它们之间的关系，分片策略只是抽象出的概念，它是由分片算法和分片健组合而成，分片算法做具体的数据分片逻辑。</p> \n <p>分库、分表的分片策略配置是相对独立的，可以各自使用不同的策略与算法，每种策略中可以是多个分片算法的组合，每个分片算法可以对多个分片健做逻辑判断。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/86b9cca7abe6ca63465345cb826838f4.png\" alt=\"img\"></p> \n <p>sharding-jdbc 提供了多种分片算法：</p> \n <p>提供了抽象分片算法类：<code>ShardingAlgorithm</code>，根据类型又分为：精确分片算法、区间分片算法、复合分片算法以及Hint分片算法；</p> \n <ul>\n  <li>精确分片算法：对应<code>PreciseShardingAlgorithm</code>类，主要用于处理 <code>=</code> 和 <code>IN</code>的分片；</li>\n  <li>区间分片算法：对应<code>RangeShardingAlgorithm</code>类，主要用于处理 <code>BETWEEN AND</code>, <code>&gt;</code>, <code>&lt;</code>, <code>&gt;=</code>, <code>&lt;=</code> 分片；</li>\n  <li>复合分片算法：对应<code>ComplexKeysShardingAlgorithm</code>类，用于处理使用多键作为分片键进行分片的场景；</li>\n  <li>Hint分片算法：对应<code>HintShardingAlgorithm</code>类，用于处理使用 <code>Hint</code> 行分片的场景；</li>\n </ul> \n <h4><a id=\"_PreciseShardingAlgorithm_869\"></a>精确分片算法 PreciseShardingAlgorithm</h4> \n <p>精确分片算法（PreciseShardingAlgorithm）用于单个字段作为分片键，SQL中有 = 与 IN 等条件的分片，</p> \n <p>需要配合 StandardShardingStrategy 使⽤。</p> \n <h4><a id=\"__RangeShardingAlgorithm_877\"></a>范围分片算法 RangeShardingAlgorithm</h4> \n <p>范围分片算法（RangeShardingAlgorithm）用于单个字段作为分片键，SQL中有 BETWEEN AND、&gt;、&lt;、&gt;=、&lt;= 等条件的分片，需要需要配合 StandardShardingStrategy 使⽤。</p> \n <h4><a id=\"__ComplexKeysShardingAlgorithm_885\"></a>复合分片算法 ComplexKeysShardingAlgorithm</h4> \n <p>对应 ComplexKeysShardingAlgorithm，⽤于处理使⽤ <strong>多键作为分⽚键</strong> 进⾏分⽚的场景，</p> \n <p><strong>（多个字段作为分片键）</strong>，同时获取到多个分片健的值，根据多个字段处理业务逻辑。</p> \n <p>包含多个分⽚键的逻辑较复杂，需要应⽤开发者⾃⾏处理其中的复杂度。</p> \n <p>需要配合 ComplexShardingStrategy 使⽤。</p> \n <p>需要在复合分片策略（ComplexShardingStrategy ）下使用。</p> \n <h4><a id=\"Hint___HintShardingAlgorithm_901\"></a>Hint 分片算法 HintShardingAlgorithm</h4> \n <p>Hint 分片算法（HintShardingAlgorithm）稍有不同</p> \n <p>前面的算法（如StandardShardingAlgorithm）都是解析 SQL 语句， 提取分片值，并根据设置的分片算法进行分片。</p> \n <p>Hint 分片算法 指定分⽚值而⾮从 SQL 中提取，而是手工设置的⽅式，进⾏分⽚的策略。</p> \n <p>对于分⽚值⾮ SQL 决定，不是来自于分片建，甚至连分片建都没有 ，而由其他外置条件决定的场景，可使⽤Hint 分片算法 。</p> \n <p>就需要通过 Java API 等方式 指定 分片值，这也叫<strong>强制路由</strong>、或者说 <strong>暗示路由</strong>。</p> \n <p>例： 内部系统，按照员⼯登录主键分库，而数据库中并⽆此字段。</p> \n <p>SQL Hint ⽀持通过 Java API 和 SQL 注释（待实现）两种⽅式使⽤。</p> \n <h2><a id=\"ShardingJDBC_929\"></a>ShardingJDBC的分片策略</h2> \n <p>整个ShardingJDBC 分库分表的核心就是在于**配置 分片策略+分片算法 **。</p> \n <p>我们的这些实战都是使用的inline分片算法，即提供一个分片键和一个分片表达式来制定分片算法。</p> \n <p>这种方式配置简单，功能灵活，是分库分表最佳的配置方式，并且对于绝大多数的分库分片场景来说，都已经非常好用了。</p> \n <p>但是，如果针对一些更为复杂的分片策略，例如多分片键、按范围分片等场景，inline分片算法就有点力不从心了。</p> \n <p>所以，我们还需要学习下ShardingSphere提供的其他几种分片策略。</p> \n <p>ShardingSphere目前提供了一共五种分片策略：</p> \n <ul>\n  <li> <p>NoneShardingStrategy 不分片</p> </li>\n  <li> <p>InlineShardingStrategy</p> </li>\n </ul> \n <h2><a id=\"InlineShardingStrategy_953\"></a>InlineShardingStrategy</h2> \n <p>最常用的分片方式</p> \n <h3><a id=\"_959\"></a>实现方式：</h3> \n <p>按照分片表达式来进行分片。</p> \n <h2><a id=\"JavaAPIInlineShardingStrategy__965\"></a>实战：JavaAPI使用InlineShardingStrategy 实战</h2> \n <h3><a id=\"Inline_971\"></a>Inline内联分片策略</h3> \n <p>分片策略基本和上面的分片算法对应，包括：标准分片策略、复合分片策略、Hint分片策略、内联分片策略、不分片策略；\\</p> \n <ul>\n  <li>内联分片策略：</li>\n </ul> \n <p>对应<code>InlineShardingStrategy</code>类，没有提供分片算法，路由规则通过表达式来实现；</p> \n <h3><a id=\"Inline_981\"></a>Inline内联分片配置类</h3> \n <p>在使用中我们并没有直接使用上面的分片策略类，ShardingSphere-JDBC分别提供了对应策略的配置类包括：</p> \n <ul>\n  <li><code>InlineShardingStrategyConfiguration</code></li>\n </ul> \n <h3><a id=\"Inline_991\"></a>Inline内联分片实战</h3> \n <p>有了以上相关基础概念，接下来针对每种分片策略做一个简单的实战，</p> \n <p>在实战前首先准备好库和表；</p> \n <blockquote> \n  <p>具体请参见视频，和配套源码</p> \n </blockquote> \n <h3><a id=\"_1001\"></a>准备真实数据源</h3> \n <p>分别准备两个库：<code>ds0</code>、<code>ds1</code>；然后每个库分别包含4个表</p> \n <pre><code class=\"prism language-sql\"><span class=\"token keyword\">CREATE</span> <span class=\"token keyword\">TABLE</span> <span class=\"token punctuation\">`</span>t_user_0<span class=\"token punctuation\">`</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">`</span>user_id<span class=\"token punctuation\">`</span> <span class=\"token keyword\">bigInt</span> <span class=\"token operator\">NOT</span> <span class=\"token boolean\">NULL</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">`</span>name<span class=\"token punctuation\">`</span> <span class=\"token keyword\">VARCHAR</span><span class=\"token punctuation\">(</span><span class=\"token number\">45</span><span class=\"token punctuation\">)</span> <span class=\"token boolean\">NULL</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">PRIMARY</span> <span class=\"token keyword\">KEY</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">`</span>user_id<span class=\"token punctuation\">`</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">CREATE</span> <span class=\"token keyword\">TABLE</span> <span class=\"token punctuation\">`</span>t_user_1<span class=\"token punctuation\">`</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">`</span>user_id<span class=\"token punctuation\">`</span> <span class=\"token keyword\">bigInt</span> <span class=\"token operator\">NOT</span> <span class=\"token boolean\">NULL</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">`</span>name<span class=\"token punctuation\">`</span> <span class=\"token keyword\">VARCHAR</span><span class=\"token punctuation\">(</span><span class=\"token number\">45</span><span class=\"token punctuation\">)</span> <span class=\"token boolean\">NULL</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">PRIMARY</span> <span class=\"token keyword\">KEY</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">`</span>user_id<span class=\"token punctuation\">`</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">CREATE</span> <span class=\"token keyword\">TABLE</span> <span class=\"token punctuation\">`</span>t_user_2<span class=\"token punctuation\">`</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">`</span>user_id<span class=\"token punctuation\">`</span> <span class=\"token keyword\">bigInt</span> <span class=\"token operator\">NOT</span> <span class=\"token boolean\">NULL</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">`</span>name<span class=\"token punctuation\">`</span> <span class=\"token keyword\">VARCHAR</span><span class=\"token punctuation\">(</span><span class=\"token number\">45</span><span class=\"token punctuation\">)</span> <span class=\"token boolean\">NULL</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">PRIMARY</span> <span class=\"token keyword\">KEY</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">`</span>user_id<span class=\"token punctuation\">`</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">CREATE</span> <span class=\"token keyword\">TABLE</span> <span class=\"token punctuation\">`</span>t_user_3<span class=\"token punctuation\">`</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">`</span>user_id<span class=\"token punctuation\">`</span> <span class=\"token keyword\">bigInt</span> <span class=\"token operator\">NOT</span> <span class=\"token boolean\">NULL</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">`</span>name<span class=\"token punctuation\">`</span> <span class=\"token keyword\">VARCHAR</span><span class=\"token punctuation\">(</span><span class=\"token number\">45</span><span class=\"token punctuation\">)</span> <span class=\"token boolean\">NULL</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">PRIMARY</span> <span class=\"token keyword\">KEY</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">`</span>user_id<span class=\"token punctuation\">`</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n\n</code></pre> \n <p>我们这里有两个数据源，这里都使用java代码的方式来配置：</p> \n <pre><code class=\"prism language-java\">  <span class=\"token annotation punctuation\">@Before</span>\n\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">buildShardingDataSource</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> SQLException <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token comment\">/* * 1. 数据源集合：dataSourceMap * 2. 分片规则：shardingRuleConfig * */</span>\n\n        DataSource druidDs1 <span class=\"token operator\">=</span> <span class=\"token function\">buildDruidDataSource</span><span class=\"token punctuation\">(</span>\n                <span class=\"token string\">\"jdbc:mysql://cdh1:3306/sharding_db1?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=true&amp;serverTimezone=UTC\"</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">\"root\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"123456\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        DataSource druidDs2 <span class=\"token operator\">=</span> <span class=\"token function\">buildDruidDataSource</span><span class=\"token punctuation\">(</span>\n                <span class=\"token string\">\"jdbc:mysql://cdh1:3306/sharding_db2?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=true&amp;serverTimezone=UTC\"</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">\"root\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"123456\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// 配置真实数据源</span>\n        Map<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>String<span class=\"token punctuation\">,</span> DataSource<span class=\"token punctuation\">&gt;</span></span> dataSourceMap <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">HashMap</span><span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>String<span class=\"token punctuation\">,</span> DataSource<span class=\"token punctuation\">&gt;</span></span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// 添加数据源.</span>\n        <span class=\"token comment\">// 两个数据源ds_0和ds_1</span>\n        dataSourceMap<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"ds0\"</span><span class=\"token punctuation\">,</span>druidDs1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        dataSourceMap<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"ds1\"</span><span class=\"token punctuation\">,</span> druidDs2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">/** * 需要构建表规则 * 1. 指定逻辑表. * 2. 配置实际节点》 * 3. 指定主键字段. * 4. 分库和分表的规则》 * */</span>\n        <span class=\"token comment\">// 配置分片规则</span>\n        ShardingRuleConfiguration shardingRuleConfig <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">ShardingRuleConfiguration</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">//消息表分片规则</span>\n        TableRuleConfiguration userShardingRuleConfig <span class=\"token operator\">=</span> <span class=\"token function\">userShardingRuleConfig</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        shardingRuleConfig<span class=\"token punctuation\">.</span><span class=\"token function\">getTableRuleConfigs</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">add</span><span class=\"token punctuation\">(</span>userShardingRuleConfig<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// 多数据源一定要指定默认数据源</span>\n        <span class=\"token comment\">// 只有一个数据源就不需要</span>\n        shardingRuleConfig<span class=\"token punctuation\">.</span><span class=\"token function\">setDefaultDataSourceName</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"ds0\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        Properties p <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Properties</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">//打印sql语句，生产环境关闭</span>\n        p<span class=\"token punctuation\">.</span><span class=\"token function\">setProperty</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"sql.show\"</span><span class=\"token punctuation\">,</span> Boolean<span class=\"token punctuation\">.</span>TRUE<span class=\"token punctuation\">.</span><span class=\"token function\">toString</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        dataSource<span class=\"token operator\">=</span> ShardingDataSourceFactory<span class=\"token punctuation\">.</span><span class=\"token function\">createDataSource</span><span class=\"token punctuation\">(</span>\n                dataSourceMap<span class=\"token punctuation\">,</span> shardingRuleConfig<span class=\"token punctuation\">,</span> p<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n    <span class=\"token punctuation\">}</span>\n</code></pre> \n <p>这里配置的两个数据源都是普通的数据源，最后会把dataSourceMap交给<code>ShardingDataSourceFactory</code>管理；</p> \n <h3><a id=\"_1071\"></a>表规则配置</h3> \n <p>表规则配置类<code>TableRuleConfiguration</code>，包含了五个要素：</p> \n <p>逻辑表、真实数据节点、数据库分片策略、数据表分片策略、分布式主键生成策略；</p> \n <pre><code class=\"prism language-java\">  <span class=\"token comment\">/** * 消息表的分片规则 */</span>\n    <span class=\"token keyword\">protected</span> TableRuleConfiguration <span class=\"token function\">userShardingRuleConfig</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        String logicTable <span class=\"token operator\">=</span> USER_LOGIC_TB<span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">//获取实际的 ActualDataNodes</span>\n        String actualDataNodes <span class=\"token operator\">=</span> <span class=\"token string\">\"ds$-&gt;{0..1}.t_user_$-&gt;{0..1}\"</span><span class=\"token punctuation\">;</span>\n\n        TableRuleConfiguration tableRuleConfig <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">TableRuleConfiguration</span><span class=\"token punctuation\">(</span>logicTable<span class=\"token punctuation\">,</span> actualDataNodes<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">//设置分表策略</span>\n        <span class=\"token comment\">// inline 模式</span>\n        ShardingStrategyConfiguration tableShardingStrategy <span class=\"token operator\">=</span>\n                <span class=\"token keyword\">new</span> <span class=\"token class-name\">InlineShardingStrategyConfiguration</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"user_id\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"t_user_$-&gt;{user_id % 2}\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token comment\">//自定义模式</span>\n<span class=\"token comment\">// TableShardingAlgorithm tableShardingAlgorithm = new TableShardingAlgorithm();</span>\n<span class=\"token comment\">// ShardingStrategyConfiguration tableShardingStrategy = new StandardShardingStrategyConfiguration(\"user_id\", tableShardingAlgorithm);</span>\n\n        tableRuleConfig<span class=\"token punctuation\">.</span><span class=\"token function\">setTableShardingStrategyConfig</span><span class=\"token punctuation\">(</span>tableShardingStrategy<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// 配置分库策略（Groovy表达式配置db规则）</span>\n        <span class=\"token comment\">// inline 模式</span>\n        ShardingStrategyConfiguration dsShardingStrategy <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">InlineShardingStrategyConfiguration</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"user_id\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"ds${user_id % 2}\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">//自定义模式</span>\n<span class=\"token comment\">// DsShardingAlgorithm dsShardingAlgorithm = new DsShardingAlgorithm();</span>\n<span class=\"token comment\">// ShardingStrategyConfiguration dsShardingStrategy = new StandardShardingStrategyConfiguration(\"user_id\", dsShardingAlgorithm);</span>\n        tableRuleConfig<span class=\"token punctuation\">.</span><span class=\"token function\">setDatabaseShardingStrategyConfig</span><span class=\"token punctuation\">(</span>dsShardingStrategy<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        tableRuleConfig<span class=\"token punctuation\">.</span><span class=\"token function\">setKeyGeneratorConfig</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">KeyGeneratorConfiguration</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"SNOWFLAKE\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"user_id\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">return</span> tableRuleConfig<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n</code></pre> \n <ul>\n  <li> <p>逻辑表：这里配置的逻辑表就是t_user，对应的物理表有t_user_0，t_user_1；</p> </li>\n  <li> <p>真实数据节点：这里使用行表达式进行配置的，简化了配置；上面的配置就相当于配置了：</p> <pre><code class=\"prism language-xml\">db0\n  ├── t_user_0 \n  └── t_user_1 \ndb1\n  ├── t_user_0 \n  └── t_user_1\n\n</code></pre> </li>\n  <li> <p>数据库分片策略：</p> <p>这里的库分片策略就是上面介绍的五种类型，</p> <p>这里使用的InlineShardingStrategy，需要设置 内联表达式，groovy表达式；</p> <pre><code class=\"prism language-java\">\n        <span class=\"token comment\">//设置分表策略</span>\n        <span class=\"token comment\">// inline 模式</span>\n        ShardingStrategyConfiguration tableShardingStrategy <span class=\"token operator\">=</span>\n                <span class=\"token keyword\">new</span> <span class=\"token class-name\">InlineShardingStrategyConfiguration</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"user_id\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"t_user_$-&gt;{user_id % 2}\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token comment\">//自定义模式</span>\n<span class=\"token comment\">// TableShardingAlgorithm tableShardingAlgorithm = new TableShardingAlgorithm();</span>\n<span class=\"token comment\">// ShardingStrategyConfiguration tableShardingStrategy = new StandardShardingStrategyConfiguration(\"user_id\", tableShardingAlgorithm);</span>\n\n        tableRuleConfig<span class=\"token punctuation\">.</span><span class=\"token function\">setTableShardingStrategyConfig</span><span class=\"token punctuation\">(</span>tableShardingStrategy<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre> <p>这里的shardingValue就是user_id对应的真实值，每次和2取余；availableTargetNames可选择就是{ds0，ds1}；看余数和哪个库能匹配上就表示路由到哪个库；</p> </li>\n  <li> <p>数据表分片策略：指定的**分片键(order_id)**和分库策略不一致，其他都一样；</p> </li>\n  <li> <p>分布式主键生成策略：ShardingSphere-JDBC提供了多种分布式主键生成策略，后面详细介绍，这里使用雪花算法；</p> </li>\n </ul> \n <h3><a id=\"groovy_1153\"></a>groovy语法说明</h3> \n <p>行表达式的使⽤⾮常直观，只需要在配置中使⽤ ${ expression } 或 $-&gt;{ expression } 标识 行表达式即可。</p> \n <p>⽬前⽀持数据节点和分⽚算法这两个部分的配置。</p> \n <p>行表达式的内容使⽤的是 Groovy 的语法，Groovy 能够⽀持的所有操作， 行表达式均能够⽀持。例如：<br> ${begin…end} 表⽰范围区间<br> ${[unit1, unit2, unit_x]} 表⽰枚举值</p> \n <p>行表达式中如果出现连续多个 ${ expression } 或 $-&gt;{ expression } 表达式，整个表达式最终的结果将会根据每个表达式的结果进笛卡尔组合。<br> 例如，以下⾏表达式： <span class=\"katex--inline\"><span class=\"katex\"><span class=\"katex-mathml\"> [ ′ o n l i n e ′ , ′ o f f l i n e ′ ] t a b l e {[\'online\', \'offline\']}_table </span><span class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height: 1.05159em; vertical-align: -0.2997em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen\"><span class=\"mopen\">[</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height: 0.751892em;\"><span class=\"\" style=\"top: -3.063em; margin-right: 0.05em;\"><span class=\"pstrut\" style=\"height: 2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mord mathdefault\">o</span><span class=\"mord mathdefault\">n</span><span class=\"mord mathdefault\" style=\"margin-right: 0.01968em;\">l</span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\">n</span><span class=\"mord\"><span class=\"mord mathdefault\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height: 0.751892em;\"><span class=\"\" style=\"top: -3.063em; margin-right: 0.05em;\"><span class=\"pstrut\" style=\"height: 2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mpunct\"><span class=\"mpunct\">,</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height: 0.751892em;\"><span class=\"\" style=\"top: -3.063em; margin-right: 0.05em;\"><span class=\"pstrut\" style=\"height: 2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right: 0.166667em;\"></span><span class=\"mord mathdefault\">o</span><span class=\"mord mathdefault\" style=\"margin-right: 0.10764em;\">f</span><span class=\"mord mathdefault\" style=\"margin-right: 0.10764em;\">f</span><span class=\"mord mathdefault\" style=\"margin-right: 0.01968em;\">l</span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\">n</span><span class=\"mord\"><span class=\"mord mathdefault\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height: 0.751892em;\"><span class=\"\" style=\"top: -3.063em; margin-right: 0.05em;\"><span class=\"pstrut\" style=\"height: 2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mclose\">]</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height: 0.130856em;\"><span class=\"\" style=\"top: -2.4003em; margin-right: 0.05em;\"><span class=\"pstrut\" style=\"height: 2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height: 0.2997em;\"><span class=\"\"></span></span></span></span></span></span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">b</span><span class=\"mord mathdefault\" style=\"margin-right: 0.01968em;\">l</span><span class=\"mord mathdefault\">e</span></span></span></span></span>{1…3}<br> 最终会解析为：<br> online_table1, online_table2, online_table3, offline_table1, offline_table2,offline_table3</p> \n <p>配置数据节点时对于均匀分布的数据节点，如果数据结构如下：</p> \n <pre><code>db0\n├── t_order0\n└── t_order1\ndb1\n├── t_order0\n└── t_order1\n</code></pre> \n <p>用行表达式可以简化为：<br> db<span class=\"katex--inline\"><span class=\"katex\"><span class=\"katex-mathml\"> 0..1. t o r d e r {0..1}.t_order </span><span class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height: 0.84444em; vertical-align: -0.15em;\"></span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">1</span></span><span class=\"mord\">.</span><span class=\"mord\"><span class=\"mord mathdefault\">t</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height: 0.151392em;\"><span class=\"\" style=\"top: -2.55em; margin-left: 0em; margin-right: 0.05em;\"><span class=\"pstrut\" style=\"height: 2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">o</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height: 0.15em;\"><span class=\"\"></span></span></span></span></span></span><span class=\"mord mathdefault\" style=\"margin-right: 0.02778em;\">r</span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">e</span><span class=\"mord mathdefault\" style=\"margin-right: 0.02778em;\">r</span></span></span></span></span>{0…1}<br> 或者<br> db<span class=\"katex--inline\"><span class=\"katex\"><span class=\"katex-mathml\"> − &gt; 0..1. t o r d e r -&gt;{0..1}.t_order </span><span class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height: 0.66666em; vertical-align: -0.08333em;\"></span><span class=\"mord\">−</span><span class=\"mspace\" style=\"margin-right: 0.277778em;\"></span><span class=\"mrel\">&gt;</span><span class=\"mspace\" style=\"margin-right: 0.277778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height: 0.84444em; vertical-align: -0.15em;\"></span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">1</span></span><span class=\"mord\">.</span><span class=\"mord\"><span class=\"mord mathdefault\">t</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height: 0.151392em;\"><span class=\"\" style=\"top: -2.55em; margin-left: 0em; margin-right: 0.05em;\"><span class=\"pstrut\" style=\"height: 2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">o</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height: 0.15em;\"><span class=\"\"></span></span></span></span></span></span><span class=\"mord mathdefault\" style=\"margin-right: 0.02778em;\">r</span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">e</span><span class=\"mord mathdefault\" style=\"margin-right: 0.02778em;\">r</span></span></span></span></span>-&gt;{0…1}<br> 对于⾃定义的数据节点，如果数据结构如下：</p> \n <pre><code>db0\n├── t_order0\n└── t_order1\ndb1\n├── t_order2\n├── t_order3\n└── t_order4\n</code></pre> \n <p>用行表达式可以简化为：<br> db0.t_order<span class=\"katex--inline\"><span class=\"katex\"><span class=\"katex-mathml\"> 0..1 , d b 1. t o r d e r {0..1},db1.t_order </span><span class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height: 0.88888em; vertical-align: -0.19444em;\"></span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">1</span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right: 0.166667em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">b</span><span class=\"mord\">1</span><span class=\"mord\">.</span><span class=\"mord\"><span class=\"mord mathdefault\">t</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height: 0.151392em;\"><span class=\"\" style=\"top: -2.55em; margin-left: 0em; margin-right: 0.05em;\"><span class=\"pstrut\" style=\"height: 2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">o</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height: 0.15em;\"><span class=\"\"></span></span></span></span></span></span><span class=\"mord mathdefault\" style=\"margin-right: 0.02778em;\">r</span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">e</span><span class=\"mord mathdefault\" style=\"margin-right: 0.02778em;\">r</span></span></span></span></span>{2…4}<br> 或者<br> db0.t_order<span class=\"katex--inline\"><span class=\"katex\"><span class=\"katex-mathml\"> − &gt; 0..1 , d b 1. t o r d e r -&gt;{0..1},db1.t_order </span><span class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height: 0.66666em; vertical-align: -0.08333em;\"></span><span class=\"mord\">−</span><span class=\"mspace\" style=\"margin-right: 0.277778em;\"></span><span class=\"mrel\">&gt;</span><span class=\"mspace\" style=\"margin-right: 0.277778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height: 0.88888em; vertical-align: -0.19444em;\"></span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">1</span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right: 0.166667em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">b</span><span class=\"mord\">1</span><span class=\"mord\">.</span><span class=\"mord\"><span class=\"mord mathdefault\">t</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height: 0.151392em;\"><span class=\"\" style=\"top: -2.55em; margin-left: 0em; margin-right: 0.05em;\"><span class=\"pstrut\" style=\"height: 2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">o</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height: 0.15em;\"><span class=\"\"></span></span></span></span></span></span><span class=\"mord mathdefault\" style=\"margin-right: 0.02778em;\">r</span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">e</span><span class=\"mord mathdefault\" style=\"margin-right: 0.02778em;\">r</span></span></span></span></span>-&gt;{2…4}</p> \n <h3><a id=\"_1206\"></a>配置分片规则</h3> \n <p>配置分片规则<code>ShardingRuleConfiguration</code>，包括多种配置规则：</p> \n <p>表规则配置、绑定表配置、广播表配置、默认数据源名称、默认数据库分片策略、默认表分片策略、默认主键生成策略、主从规则配置、加密规则配置；</p> \n <ul>\n  <li>表规则配置 <strong>tableRuleConfigs</strong>：也就是上面配置的库分片策略和表分片策略，也是最常用的配置；</li>\n  <li>绑定表配置 <strong>bindingTableGroups</strong>：指分⽚规则⼀致的主表和⼦表；绑定表之间的多表关联查询不会出现笛卡尔积关联，关联查询效率将⼤⼤提升；</li>\n  <li>广播表配置 <strong>broadcastTables</strong>：所有的分⽚数据源中都存在的表，表结构和表中的数据在每个数据库中均完全⼀致。适⽤于数据量不⼤且需要与海量数据的表进⾏关联查询的场景；</li>\n  <li>默认数据源名称 <strong>defaultDataSourceName</strong>：未配置分片的表将通过默认数据源定位；</li>\n  <li>默认数据库分片策略 defaultDatabaseShardingStrategyConfig：表规则配置可以设置数据库分片策略，如果没有配置可以在这里面配置默认的；</li>\n  <li>默认表分片策略 <strong>defaultTableShardingStrategyConfig</strong>：表规则配置可以设置表分片策略，如果没有配置可以在这里面配置默认的；</li>\n  <li>默认主键生成策略 <strong>defaultKeyGeneratorConfig</strong>：表规则配置可以设置主键生成策略，如果没有配置可以在这里面配置默认的；内置UUID、SNOWFLAKE生成器；</li>\n  <li>主从规则配置 <strong>masterSlaveRuleConfigs</strong>：用来实现读写分离的，可配置一个主表多个从表，读面对多个从库可以配置负载均衡策略；</li>\n  <li>加密规则配置 <strong>encryptRuleConfig</strong>：提供了对某些敏感数据进行加密的功能，提供了⼀套完整、安全、透明化、低改造成本的数据加密整合解决⽅案；</li>\n </ul> \n <h3><a id=\"_1222\"></a>实战：数据插入</h3> \n <p>以上准备好，就可以操作数据库了，这里执行插入操作：</p> \n <pre><code class=\"prism language-java\">\n    <span class=\"token comment\">/** * 新增测试. * */</span>\n    <span class=\"token annotation punctuation\">@Test</span>\n    <span class=\"token keyword\">public</span>  <span class=\"token keyword\">void</span> <span class=\"token function\">testInsertUser</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> SQLException <span class=\"token punctuation\">{\n    <!-- --></span>\n\n        <span class=\"token comment\">/* * 1. 需要到DataSource * 2. 通过DataSource获取Connection * 3. 定义一条SQL语句. * 4. 通过Connection获取到PreparedStament. * 5. 执行SQL语句. * 6. 关闭连接. */</span>\n\n\n        <span class=\"token comment\">// * 2. 通过DataSource获取Connection</span>\n        Connection connection <span class=\"token operator\">=</span> dataSource<span class=\"token punctuation\">.</span><span class=\"token function\">getConnection</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// * 3. 定义一条SQL语句.</span>\n        <span class=\"token comment\">// 注意：******* sql语句中 使用的表是 上面代码中定义的逻辑表 *******</span>\n        String sql <span class=\"token operator\">=</span> <span class=\"token string\">\"insert into t_user(name) values(\'name-0001\')\"</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// * 4. 通过Connection获取到PreparedStament.</span>\n        PreparedStatement preparedStatement <span class=\"token operator\">=</span> connection<span class=\"token punctuation\">.</span><span class=\"token function\">prepareStatement</span><span class=\"token punctuation\">(</span>sql<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// * 5. 执行SQL语句.</span>\n        preparedStatement<span class=\"token punctuation\">.</span><span class=\"token function\">execute</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n         sql <span class=\"token operator\">=</span> <span class=\"token string\">\"insert into t_user(name) values(\'name-0002\')\"</span><span class=\"token punctuation\">;</span>\n        preparedStatement <span class=\"token operator\">=</span> connection<span class=\"token punctuation\">.</span><span class=\"token function\">prepareStatement</span><span class=\"token punctuation\">(</span>sql<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        preparedStatement<span class=\"token punctuation\">.</span><span class=\"token function\">execute</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// * 6. 关闭连接.</span>\n        preparedStatement<span class=\"token punctuation\">.</span><span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        connection<span class=\"token punctuation\">.</span><span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n</code></pre> \n <p>通过以上配置的真实数据源、分片规则以及属性文件创建分片数据源<code>ShardingDataSource</code>；</p> \n <p>接下来就可以像使用单库单表一样操作分库分表了，sql中可以直接使用逻辑表，分片算法会根据具体的值就行路由处理；</p> \n <p>经过路由最终：奇数入ds1.t_user_1，偶数入ds0.t_user_0；</p> \n <h3><a id=\"_1275\"></a>实战：数据查询</h3> \n <p>以上准备好，就可以操作数据库了，这里执行查询操作：</p> \n <pre><code>  /**\n     * 新增测试.\n     *\n     */\n    @Test\n    public  void testSelectUser() throws SQLException {\n\n        /*\n         * 1. 需要到DataSource\n         * 2. 通过DataSource获取Connection\n         * 3. 定义一条SQL语句.\n         * 4. 通过Connection获取到PreparedStament.\n         *  5. 执行SQL语句.\n         *  6. 关闭连接.\n         */\n\n\n        // * 2. 通过DataSource获取Connection\n        Connection connection = dataSource.getConnection();\n        // * 3. 定义一条SQL语句.\n        // 注意：******* sql语句中 使用的表是 上面代码中定义的逻辑表 *******\n        String sql = \"select * from  t_user where user_id=10000\";\n\n        // * 4. 通过Connection获取到PreparedStament.\n        PreparedStatement preparedStatement = connection.prepareStatement(sql);\n\n        // * 5. 执行SQL语句.\n        ResultSet resultSet= preparedStatement.executeQuery();\n\n\n        // * 6. 关闭连接.\n        preparedStatement.close();\n        connection.close();\n    }\n\n</code></pre> \n <h2><a id=\"PropertiesInlineShardingStrategy__1319\"></a>实战：Properties配置InlineShardingStrategy 实战</h2> \n <p>通过 Properties 配置来使用 InlineShardingStrategy</p> \n <h3><a id=\"_1323\"></a>配置参数：</h3> \n <p>inline.shardingColumn 分片键；</p> \n <p>inline.algorithmExpression 分片表达式</p> \n <h3><a id=\"_1329\"></a>配置实例</h3> \n <pre><code>spring.shardingsphere.datasource.names=ds0,ds1\nspring.shardingsphere.datasource.ds0.type=com.alibaba.druid.pool.DruidDataSource\nspring.shardingsphere.datasource.ds0.driver-class-name=com.mysql.cj.jdbc.Driver\nspring.shardingsphere.datasource.ds0.filters=com.alibaba.druid.filter.stat.StatFilter,com.alibaba.druid.wall.WallFilter,com.alibaba.druid.filter.logging.Log4j2Filter\nspring.shardingsphere.datasource.ds0.url=jdbc:mysql://cdh1:3306/sharding_db1?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=true&amp;serverTimezone=UTC\nspring.shardingsphere.datasource.ds0.password=123456\nspring.shardingsphere.datasource.ds0.username=root\nspring.shardingsphere.datasource.ds0.maxActive=20\nspring.shardingsphere.datasource.ds0.initialSize=1\nspring.shardingsphere.datasource.ds0.maxWait=60000\nspring.shardingsphere.datasource.ds0.minIdle=1\nspring.shardingsphere.datasource.ds0.timeBetweenEvictionRunsMillis=60000\nspring.shardingsphere.datasource.ds0.minEvictableIdleTimeMillis=300000\nspring.shardingsphere.datasource.ds0.validationQuery=SELECT 1 FROM DUAL\nspring.shardingsphere.datasource.ds0.testWhileIdle=true\nspring.shardingsphere.datasource.ds0.testOnBorrow=false\nspring.shardingsphere.datasource.ds0.testOnReturn=false\nspring.shardingsphere.datasource.ds0.poolPreparedStatements=true\nspring.shardingsphere.datasource.ds0.maxOpenPreparedStatements=20\nspring.shardingsphere.datasource.ds0.connection-properties=druid.stat.merggSql=ture;druid.stat.slowSqlMillis=5000\nspring.shardingsphere.datasource.ds1.type=com.alibaba.druid.pool.DruidDataSource\nspring.shardingsphere.datasource.ds1.driver-class-name=com.mysql.cj.jdbc.Driver\nspring.shardingsphere.datasource.ds1.filters=com.alibaba.druid.filter.stat.StatFilter,com.alibaba.druid.wall.WallFilter,com.alibaba.druid.filter.logging.Log4j2Filter\nspring.shardingsphere.datasource.ds1.url=jdbc:mysql://cdh1:3306/sharding_db2?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=true&amp;serverTimezone=UTC\nspring.shardingsphere.datasource.ds1.password=123456\nspring.shardingsphere.datasource.ds1.username=root\nspring.shardingsphere.datasource.ds1.maxActive=20\nspring.shardingsphere.datasource.ds1.initialSize=1\nspring.shardingsphere.datasource.ds1.maxWait=60000\nspring.shardingsphere.datasource.ds1.minIdle=1\nspring.shardingsphere.datasource.ds1.timeBetweenEvictionRunsMillis=60000\nspring.shardingsphere.datasource.ds1.minEvictableIdleTimeMillis=300000\nspring.shardingsphere.datasource.ds1.validationQuery=SELECT 1 FROM DUAL\nspring.shardingsphere.datasource.ds1.testWhileIdle=true\nspring.shardingsphere.datasource.ds1.testOnBorrow=false\nspring.shardingsphere.datasource.ds1.testOnReturn=false\nspring.shardingsphere.datasource.ds1.poolPreparedStatements=true\nspring.shardingsphere.datasource.ds1.maxOpenPreparedStatements=20\nspring.shardingsphere.datasource.ds1.connection-properties=druid.stat.merggSql=ture;druid.stat.slowSqlMillis=5000\n\n\n\n\nspring.shardingsphere.sharding.tables.t_user.actual-data-nodes=ds$-&gt;{0..1}.t_user_$-&gt;{0..1}\nspring.shardingsphere.sharding.tables.t_user.table-strategy.inline.sharding-column=user_id\nspring.shardingsphere.sharding.tables.t_user.table-strategy.inline.algorithm-expression=t_user_$-&gt;{user_id % 2}\nspring.shardingsphere.sharding.tables.t_user.database-strategy.inline.sharding-column=user_id\nspring.shardingsphere.sharding.tables.t_user.database-strategy.inline.algorithm-expression=ds$-&gt;{user_id % 2}\nspring.shardingsphere.sharding.tables.t_user.key-generator.column=user_id\nspring.shardingsphere.sharding.tables.t_user.key-generator.type=SNOWFLAKE\nspring.shardingsphere.sharding.tables.t_user.key-generator.props.worker.id=123\n\nspring.shardingsphere.sharding.tables.t_order.actual-data-nodes=ds$-&gt;{0..1}.t_order_$-&gt;{0..1}\nspring.shardingsphere.sharding.tables.t_order.table-strategy.inline.sharding-column=user_id\nspring.shardingsphere.sharding.tables.t_order.table-strategy.inline.algorithm-expression=t_order_$-&gt;{user_id % 2}\nspring.shardingsphere.sharding.tables.t_order.database-strategy.inline.sharding-column=user_id\nspring.shardingsphere.sharding.tables.t_order.database-strategy.inline.algorithm-expression=ds$-&gt;{user_id % 2}\nspring.shardingsphere.sharding.tables.t_order.key-generator.column=order_id\nspring.shardingsphere.sharding.tables.t_order.key-generator.type=SNOWFLAKE\nspring.shardingsphere.sharding.tables.t_order.key-generator.props.worker.id=123\n\n\nspring.shardingsphere.sharding.binding-tables[0]=t_order,t_user\n\n\n# 配置公共表\nspring.shardingsphere.sharding.broadcast-tables=t_config\nspring.shardingsphere.sharding.tables.t_config.key-generator.column=id\nspring.shardingsphere.sharding.tables.t_config.key-generator.type=SNOWFLAKE\nspring.shardingsphere.sharding.tables.t_config.key-generator.props.worker.id=123\n\n</code></pre> \n <h3><a id=\"_1407\"></a>行表达式分片策略的测试用例</h3> \n <pre><code>\n    @Test\n    public void testAddSomeUser() {\n\n        for (int i = 0; i &lt; 10; i++) {\n            User dto = new User();\n\n            dto.setName(\"user_\" + i);\n\n            //增加用户\n            entityService.addUser(dto);\n        }\n\n\n    }\n\n    @Test\n    public void testSelectAllUser() {\n        //增加用户\n        List&lt;User&gt; all = entityService.selectAllUser();\n        System.out.println(all);\n\n    }\n\n\n    @Test\n    public void testSelectAll() {\n        entityService.selectAll();\n    }\n\n</code></pre> \n <h3><a id=\"_1444\"></a>行表达式分片策略的问题</h3> \n <p>行表达式分片策略（<code>InlineShardingStrategy</code>），在配置中使用 <code>Groovy</code> 表达式，提供对 SQL语句中的 <code>=</code> 和 <code>IN</code> 的分片操作支持，它只支持单分片健。</p> \n <p>行表达式分片策略适用于做简单的分片算法，无需自定义分片算法，省去了繁琐的代码开发，是几种分片策略中最为简单的。</p> \n <p>它的配置相当简洁，这种分片策略利用<code>inline.algorithm-expression</code>书写表达式。</p> \n <p>比如：<code>ds-$-&gt;{order_id % 2}</code> 表示对 <code>order_id</code> 做取模计算，<code>$</code> 是个通配符用来承接取模结果，最终计算出分库<code>ds-0</code> ··· <code>ds-n</code>，整体来说比较简单。</p> \n <pre><code>spring.shardingsphere.sharding.tables.t_order.actual-data-nodes=ds$-&gt;{0..1}.t_order_$-&gt;{0..1}\nspring.shardingsphere.sharding.tables.t_order.table-strategy.inline.sharding-column=user_id\nspring.shardingsphere.sharding.tables.t_order.table-strategy.inline.algorithm-expression=t_order_$-&gt;{user_id % 2}\n</code></pre> \n <p>优势：</p> \n <p>相当简洁</p> \n <p>行表达式分片策略的问题：</p> \n <blockquote> \n  <p>不能支持 范围分片</p> \n  <p>范围分片 用于处理含有 <code>BETWEEN AND</code> 、<code>&gt;</code>，<code>&gt;=</code>, <code>&lt;=</code>，<code>&lt;</code>的分片处理。</p> \n </blockquote> \n <p>具体演示，请参见视频</p> \n <h2><a id=\"_JavaAPIStandardShardingStrategy_1480\"></a>实战： JavaAPI使用StandardShardingStrategy</h2> \n <h3><a id=\"_1484\"></a>标准分片策略的使用场景</h3> \n <p><strong>使用场景</strong>：SQL 语句中有<code>&gt;</code>，<code>&gt;=</code>, <code>&lt;=</code>，<code>&lt;</code>，<code>=</code>，<code>IN</code> 和 <code>BETWEEN AND</code> 操作符，都可以应用此分片策略。</p> \n <p>标准分片策略（<code>StandardShardingStrategy</code>），它只支持对单个分片健（字段）为依据的分库分表，</p> \n <p>并提供了两种分片算法 <code>PreciseShardingAlgorithm</code>（精准分片）和 <code>RangeShardingAlgorithm</code>（范围分片）。</p> \n <p>其中，精准分片算法是必须实现的算法，用于 SQL 含有 <code>=</code> 和 <code>IN</code> 的分片处理；</p> \n <p>范围分片算法是非必选的，用于处理含有 <code>BETWEEN AND</code> 、<code>&gt;</code>，<code>&gt;=</code>, <code>&lt;=</code>，<code>&lt;</code>的分片处理。</p> \n <blockquote> \n  <p>一旦我们没配置范围分片算法，而 SQL 中又用到 <code>BETWEEN AND</code> 或者 <code>like</code>等，那么 SQL 将按全库、表路由的方式逐一执行，查询性能会很差需要特别注意。</p> \n </blockquote> \n <h3><a id=\"_1502\"></a>实战准备</h3> \n <p>有了以上相关基础概念，接下来针对每种分片策略做一个简单的实战，</p> \n <p>在实战前首先准备好库和表；</p> \n <blockquote> \n  <p>具体请参见视频，和配套源码</p> \n </blockquote> \n <p>精准分片用于处理含有= 、in的分片处理。</p> \n <p>范围分片 用于处理含有 <code>BETWEEN AND</code> 、<code>&gt;</code>，<code>&gt;=</code>, <code>&lt;=</code>，<code>&lt;</code>的分片处理。</p> \n <h3><a id=\"_1518\"></a>表规则配置</h3> \n <p>表规则配置类<code>TableRuleConfiguration</code>，包含了五个要素：</p> \n <p>逻辑表、真实数据节点、数据库分片策略、数据表分片策略、分布式主键生成策略；</p> \n <pre><code class=\"prism language-java\">\n  \n    <span class=\"token comment\">/** * 表的分片规则 */</span>\n    <span class=\"token keyword\">protected</span> TableRuleConfiguration <span class=\"token function\">userShardingRuleConfig</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        String logicTable <span class=\"token operator\">=</span> USER_LOGIC_TB<span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">//获取实际的 ActualDataNodes</span>\n        String actualDataNodes <span class=\"token operator\">=</span> <span class=\"token string\">\"ds$-&gt;{0..1}.t_user_$-&gt;{0..1}\"</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// 两个表达式的 笛卡尔积</span>\n<span class=\"token comment\">//ds0.t_user_0</span>\n<span class=\"token comment\">//ds1.t_user_0</span>\n<span class=\"token comment\">//ds0.t_user_1</span>\n<span class=\"token comment\">//ds1.t_user_1</span>\n\n        TableRuleConfiguration tableRuleConfig <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">TableRuleConfiguration</span><span class=\"token punctuation\">(</span>logicTable<span class=\"token punctuation\">,</span> actualDataNodes<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">//设置分表策略</span>\n        <span class=\"token comment\">// inline 模式</span>\n<span class=\"token comment\">// ShardingStrategyConfiguration tableShardingStrategy =</span>\n<span class=\"token comment\">// new InlineShardingStrategyConfiguration(\"user_id\", \"t_user_$-&gt;{user_id % 2}\");</span>\n        <span class=\"token comment\">//自定义模式</span>\n        TablePreciseShardingAlgorithm tablePreciseShardingAlgorithm <span class=\"token operator\">=</span>\n                <span class=\"token keyword\">new</span> <span class=\"token class-name\">TablePreciseShardingAlgorithm</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n     <span class=\"token comment\">/* RouteInfinityRangeShardingAlgorithm tableRangeShardingAlg = new RouteInfinityRangeShardingAlgorithm(); */</span>\n        RangeOrderShardingAlgorithm tableRangeShardingAlg <span class=\"token operator\">=</span>\n                <span class=\"token keyword\">new</span> <span class=\"token class-name\">RangeOrderShardingAlgorithm</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        PreciseOrderShardingAlgorithm preciseOrderShardingAlgorithm <span class=\"token operator\">=</span>\n                <span class=\"token keyword\">new</span> <span class=\"token class-name\">PreciseOrderShardingAlgorithm</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        ShardingStrategyConfiguration tableShardingStrategy <span class=\"token operator\">=</span>\n                <span class=\"token keyword\">new</span> <span class=\"token class-name\">StandardShardingStrategyConfiguration</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"user_id\"</span><span class=\"token punctuation\">,</span>\n                        preciseOrderShardingAlgorithm<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        tableRuleConfig<span class=\"token punctuation\">.</span><span class=\"token function\">setTableShardingStrategyConfig</span><span class=\"token punctuation\">(</span>tableShardingStrategy<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// 配置分库策略（Groovy表达式配置db规则）</span>\n        <span class=\"token comment\">// inline 模式</span>\n<span class=\"token comment\">// ShardingStrategyConfiguration dsShardingStrategy = new InlineShardingStrategyConfiguration(\"user_id\", \"ds${user_id % 2}\");</span>\n        <span class=\"token comment\">//自定义模式</span>\n        DsPreciseShardingAlgorithm dsPreciseShardingAlgorithm <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">DsPreciseShardingAlgorithm</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        RangeOrderShardingAlgorithm dsRangeShardingAlg <span class=\"token operator\">=</span>\n                <span class=\"token keyword\">new</span> <span class=\"token class-name\">RangeOrderShardingAlgorithm</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        ShardingStrategyConfiguration dsShardingStrategy <span class=\"token operator\">=</span>\n                <span class=\"token keyword\">new</span> <span class=\"token class-name\">StandardShardingStrategyConfiguration</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"user_id\"</span><span class=\"token punctuation\">,</span>\n                        preciseOrderShardingAlgorithm<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        tableRuleConfig<span class=\"token punctuation\">.</span><span class=\"token function\">setDatabaseShardingStrategyConfig</span><span class=\"token punctuation\">(</span>dsShardingStrategy<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        tableRuleConfig<span class=\"token punctuation\">.</span><span class=\"token function\">setKeyGeneratorConfig</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">KeyGeneratorConfiguration</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"SNOWFLAKE\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"user_id\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">return</span> tableRuleConfig<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n\n</code></pre> \n <h3><a id=\"_StandardShardingStrategyConfiguration_1590\"></a>数据库分片策略 StandardShardingStrategyConfiguration</h3> \n <pre><code class=\"prism language-java\">        ShardingStrategyConfiguration dsShardingStrategy <span class=\"token operator\">=</span>\n                <span class=\"token keyword\">new</span> <span class=\"token class-name\">StandardShardingStrategyConfiguration</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"user_id\"</span><span class=\"token punctuation\">,</span>\n                        dsPreciseShardingAlgorithm<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n</code></pre> \n <p>这里的shardingValue就是user_id对应的真实值，每次和2取余；availableTargetNames可选择就是{ds0，ds1}；看余数和哪个库能匹配上就表示路由到哪个库；</p> \n <ul>\n  <li> <p>数据表分片策略：指定的**分片键(order_id)**和分库策略不一致，其他都一样；</p> </li>\n  <li> <p>分布式主键生成策略：ShardingSphere-JDBC提供了多种分布式主键生成策略，后面详细介绍，这里使用雪花算法；</p> </li>\n </ul> \n <h3><a id=\"_1609\"></a>测试用例</h3> \n <p>以上准备好，就可以操作数据库了，这里执行插入操作：</p> \n <pre><code class=\"prism language-java\">  <span class=\"token annotation punctuation\">@Test</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">testSelectUserIn</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> SQLException <span class=\"token punctuation\">{\n    <!-- --></span>\n\n        <span class=\"token comment\">/* * 1. 需要到DataSource * 2. 通过DataSource获取Connection * 3. 定义一条SQL语句. * 4. 通过Connection获取到PreparedStament. * 5. 执行SQL语句. * 6. 关闭连接. */</span>\n\n\n        <span class=\"token comment\">// * 2. 通过DataSource获取Connection</span>\n        Connection connection <span class=\"token operator\">=</span> dataSource<span class=\"token punctuation\">.</span><span class=\"token function\">getConnection</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// * 3. 定义一条SQL语句.</span>\n        <span class=\"token comment\">// 注意：******* sql语句中 使用的表是 上面代码中定义的逻辑表 *******</span>\n        String sql <span class=\"token operator\">=</span> <span class=\"token string\">\"select * from t_user where user_id in (10,11,23)\"</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// * 4. 通过Connection获取到PreparedStament.</span>\n        PreparedStatement preparedStatement <span class=\"token operator\">=</span> connection<span class=\"token punctuation\">.</span><span class=\"token function\">prepareStatement</span><span class=\"token punctuation\">(</span>sql<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// * 5. 执行SQL语句.</span>\n        ResultSet resultSet <span class=\"token operator\">=</span> preparedStatement<span class=\"token punctuation\">.</span><span class=\"token function\">executeQuery</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n\n        <span class=\"token comment\">// * 6. 关闭连接.</span>\n        preparedStatement<span class=\"token punctuation\">.</span><span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        connection<span class=\"token punctuation\">.</span><span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n\n</code></pre> \n <p>通过以上配置的真实数据源、分片规则以及属性文件创建分片数据源<code>ShardingDataSource</code>；</p> \n <p>接下来就可以像使用单库单表一样操作分库分表了，sql中可以直接使用逻辑表，分片算法会根据具体的值就行路由处理；</p> \n <p>以上使用了最常见的精确分片算法，下面继续看一下其他几种分片算法；</p> \n <h2><a id=\"_JavaAPIRangeShardingAlgorithm1_1660\"></a>实战： JavaAPI使用RangeShardingAlgorithm实战1</h2> \n <h3><a id=\"_1664\"></a>分片算法与分片值</h3> \n <h4><a id=\"_1668\"></a>四大分片算法</h4> \n <ul>\n  <li>精确分片算法 PreciseShardingAlgorithm</li>\n </ul> \n <p>精确分片算法（PreciseShardingAlgorithm）用于单个字段作为分片键，SQL中有 = 与 IN 等条件的分片，</p> \n <p>需要配合 StandardShardingStrategy 使⽤。</p> \n <ul>\n  <li>范围分片算法 RangeShardingAlgorithm</li>\n </ul> \n <p>范围分片算法（RangeShardingAlgorithm）用于单个字段作为分片键，SQL中有 BETWEEN AND、&gt;、&lt;、&gt;=、&lt;= 等条件的分片，需要需要配合 StandardShardingStrategy 使⽤。</p> \n <ul>\n  <li>复合分片算法 ComplexKeysShardingAlgorithm</li>\n </ul> \n <p>对应 ComplexKeysShardingAlgorithm，⽤于处理使⽤ <strong>多键作为分⽚键</strong> 进⾏分⽚的场景，</p> \n <p><strong>（多个字段作为分片键）</strong>，同时获取到多个分片健的值，根据多个字段处理业务逻辑。</p> \n <p>包含多个分⽚键的逻辑较复杂，需要应⽤开发者⾃⾏处理其中的复杂度。</p> \n <p>需要配合 ComplexShardingStrategy 使⽤。</p> \n <p>需要在复合分片策略（ComplexShardingStrategy ）下使用。</p> \n <ul>\n  <li>Hint 分片算法 HintShardingAlgorithm</li>\n </ul> \n <p>Hint 分片算法（HintShardingAlgorithm）稍有不同</p> \n <p>前面的算法（如StandardShardingAlgorithm）都是解析 SQL 语句， 提取分片值，并根据设置的分片算法进行分片。</p> \n <p>Hint 分片算法 指定分⽚值而⾮从 SQL 中提取，而是手工设置的⽅式，进⾏分⽚的策略。</p> \n <p>对于分⽚值⾮ SQL 决定，不是来自于分片建，甚至连分片建都没有 ，而由其他外置条件决定的场景，可使⽤Hint 分片算法 。</p> \n <p>就需要通过 Java API 等方式 指定 分片值，这也叫<strong>强制路由</strong>、或者说 <strong>暗示路由</strong>。</p> \n <p>例： 内部系统，按照员⼯登录主键分库，而数据库中并⽆此字段。</p> \n <h4><a id=\"_1722\"></a>四大分片值</h4> \n <p>SQL Hint ⽀持通过 Java API 和 SQL 注释（待实现）两种⽅式使⽤。</p> \n <p>ShardingSphere-JDBC针对每种分片算法都提供了相应的<code>ShardingValue</code>，具体包括：</p> \n <ul>\n  <li>PreciseShardingValue</li>\n  <li>RangeShardingValue</li>\n  <li>ComplexKeysShardingValue</li>\n  <li>HintShardingValue</li>\n </ul> \n <h3><a id=\"_1733\"></a>范围分片算法</h3> \n <p>用在区间查询/范围查询的时候，比如下面的查询SQL：</p> \n <pre><code class=\"prism language-sql\"><span class=\"token keyword\">select</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">from</span>  t_user <span class=\"token keyword\">where</span> user_id <span class=\"token operator\">between</span> <span class=\"token number\">10</span> <span class=\"token operator\">and</span> <span class=\"token number\">20</span>\n\n</code></pre> \n <p>以上两个区间值10、20会直接保存到<code>RangeShardingValue</code>中，做库路由时，所以会访问两个库；</p> \n <p>参考的代码如下（以下代码，视频中有详细介绍）：</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">RangeOrderShardingAlgorithm</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">RangeShardingAlgorithm</span><span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>Integer<span class=\"token punctuation\">&gt;</span></span> <span class=\"token punctuation\">{\n    <!-- --></span>\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> Collection<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>String<span class=\"token punctuation\">&gt;</span></span> <span class=\"token function\">doSharding</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">final</span> Collection<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>String<span class=\"token punctuation\">&gt;</span></span> availableTargetNames<span class=\"token punctuation\">,</span> <span class=\"token keyword\">final</span> RangeShardingValue<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>Integer<span class=\"token punctuation\">&gt;</span></span> shardingValue<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        Collection<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>String<span class=\"token punctuation\">&gt;</span></span> result <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">HashSet</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">&gt;</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> shardingValue<span class=\"token punctuation\">.</span><span class=\"token function\">getValueRange</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">lowerEndpoint</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;=</span> shardingValue<span class=\"token punctuation\">.</span><span class=\"token function\">getValueRange</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">upperEndpoint</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>String each <span class=\"token operator\">:</span> availableTargetNames<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n                System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"shardingValue = \"</span> <span class=\"token operator\">+</span> shardingValue<span class=\"token punctuation\">.</span><span class=\"token function\">getValueRange</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token string\">\" target = \"</span> <span class=\"token operator\">+</span> each <span class=\"token operator\">+</span> <span class=\"token string\">\" shardingValue.getValue() % 2) = \"</span> <span class=\"token operator\">+</span> i <span class=\"token operator\">%</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>each<span class=\"token punctuation\">.</span><span class=\"token function\">endsWith</span><span class=\"token punctuation\">(</span>String<span class=\"token punctuation\">.</span><span class=\"token function\">valueOf</span><span class=\"token punctuation\">(</span>i <span class=\"token operator\">%</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n                    result<span class=\"token punctuation\">.</span><span class=\"token function\">add</span><span class=\"token punctuation\">(</span>each<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token punctuation\">}</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> result<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h3><a id=\"_1768\"></a>测试用例：</h3> \n <pre><code>  @Test\n    public void testSelectUserBetween() throws SQLException {\n\n        /*\n         * 1. 需要到DataSource\n         * 2. 通过DataSource获取Connection\n         * 3. 定义一条SQL语句.\n         * 4. 通过Connection获取到PreparedStament.\n         *  5. 执行SQL语句.\n         *  6. 关闭连接.\n         */\n\n\n        // * 2. 通过DataSource获取Connection\n        Connection connection = dataSource.getConnection();\n        // * 3. 定义一条SQL语句.\n        // 注意：******* sql语句中 使用的表是 上面代码中定义的逻辑表 *******\n        String sql = \"select * from  t_user where user_id between 10 and 20 \";\n\n        // * 4. 通过Connection获取到PreparedStament.\n        PreparedStatement preparedStatement = connection.prepareStatement(sql);\n\n        // * 5. 执行SQL语句.\n        ResultSet resultSet = preparedStatement.executeQuery();\n\n\n        // * 6. 关闭连接.\n        preparedStatement.close();\n        connection.close();\n    }\n\n</code></pre> \n <h2><a id=\"_JavaAPIRangeShardingAlgorithm2_1806\"></a>实战： JavaAPI使用RangeShardingAlgorithm实战2</h2> \n <h3><a id=\"range_unbounded_on_this_side_1812\"></a>异常：range unbounded on this side</h3> \n <p>用上面的算法，执行下面的测试用例，会抛出 异常：range unbounded on this side</p> \n <p>可以执行下面的用例，看看异常的效果</p> \n <pre><code>\n    @Test\n    public void testSelectUserBigThan() throws SQLException {\n\n        /*\n         * 1. 需要到DataSource\n         * 2. 通过DataSource获取Connection\n         * 3. 定义一条SQL语句.\n         * 4. 通过Connection获取到PreparedStament.\n         *  5. 执行SQL语句.\n         *  6. 关闭连接.\n         */\n\n\n        // * 2. 通过DataSource获取Connection\n        Connection connection = dataSource.getConnection();\n        // * 3. 定义一条SQL语句.\n        // 注意：******* sql语句中 使用的表是 上面代码中定义的逻辑表 *******\n        String sql = \"select * from  t_user where user_id &gt; 10000\";\n\n        // * 4. 通过Connection获取到PreparedStament.\n        PreparedStatement preparedStatement = connection.prepareStatement(sql);\n\n        // * 5. 执行SQL语句.\n        ResultSet resultSet = preparedStatement.executeQuery();\n\n\n        // * 6. 关闭连接.\n        preparedStatement.close();\n        connection.close();\n    }\n</code></pre> \n <h3><a id=\"_1856\"></a>异常的原因</h3> \n <p>以上两个区间值是没有边界的，<strong>执行获取上边界时</strong>，RangeShardingValue会抛出异常</p> \n <p>既然没有边界，直接做全路由</p> \n <h3><a id=\"_1864\"></a>对没有边界的范围分片进行路由</h3> \n <p>用在区间查询/范围查询的时候，比如下面的查询SQL：</p> \n <pre><code class=\"prism language-sql\"><span class=\"token keyword\">select</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">from</span>  t_user <span class=\"token keyword\">where</span> user_id <span class=\"token operator\">&gt;</span> <span class=\"token number\">10000</span>\n\n</code></pre> \n <p>参考的代码如下（以下代码，视频中有详细介绍）：</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">RouteInfinityRangeShardingAlgorithm</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">RangeShardingAlgorithm</span><span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>Integer<span class=\"token punctuation\">&gt;</span></span> <span class=\"token punctuation\">{\n    <!-- --></span>\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> Collection<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>String<span class=\"token punctuation\">&gt;</span></span> <span class=\"token function\">doSharding</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">final</span> Collection<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>String<span class=\"token punctuation\">&gt;</span></span> availableTargetNames<span class=\"token punctuation\">,</span> <span class=\"token keyword\">final</span> RangeShardingValue<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>Integer<span class=\"token punctuation\">&gt;</span></span> shardingValue<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n\n        Collection<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>String<span class=\"token punctuation\">&gt;</span></span> result <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">HashSet</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">&gt;</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        result<span class=\"token punctuation\">.</span><span class=\"token function\">addAll</span><span class=\"token punctuation\">(</span>availableTargetNames<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token keyword\">return</span> result<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"PropertiesStandardShardingStrategy___1896\"></a>Properties配置StandardShardingStrategy 实战</h2> \n <p>通过 Properties 配置来使用 StandardShardingStrategy</p> \n <h3><a id=\"_1900\"></a>配置参数：</h3> \n <ul>\n  <li> <p>standard.sharding-column 分片键；</p> </li>\n  <li> <p>standard.precise-algorithm-class-name 精确分片算法类名；</p> </li>\n  <li> <p>standard.range-algorithm-class-name 范围分片算法类名</p> </li>\n </ul> \n <h5><a id=\"standardprecisealgorithmclassname____1910\"></a>参数standard.precise-algorithm-class-name 说明：</h5> \n <p>standard.precise-algorithm-class-name 指向一个实现了PreciseShardingAlgorithm接口的java实现类，</p> \n <pre><code> io.shardingsphere.api.algorithm.sharding.standard.PreciseShardingAlgorithm\n</code></pre> \n <p><strong>此java实现类</strong>提供按照 <strong>= 或者 IN</strong> 逻辑的精确分片</p> \n <h5><a id=\"standardrangealgorithmclassname___1922\"></a>参数standard.range-algorithm-class-name 说明：</h5> \n <p>指向一个实现了 io.shardingsphere.api.algorithm.sharding.standard.RangeShardingAlgorithm接口的java类名，</p> \n <p><strong>此java实现类</strong>提供按照 Between 条件进行的范围分片。</p> \n <pre><code>示例： com.crazymaker.springcloud.message.core.PreciseShardingAlgorithm\n</code></pre> \n <h3><a id=\"_1932\"></a>参数补充说明：</h3> \n <p>StandardShardingStrategy的两大内嵌算法中：精确分片算法是必须提供的，而范围分片算法则是可选的。</p> \n <h3><a id=\"_1938\"></a>配置实例</h3> \n <pre><code>\nspring.shardingsphere.sharding.tables.t_order.actual-data-nodes=ds$-&gt;{0..1}.t_order_$-&gt;{0..1}\n#spring.shardingsphere.sharding.tables.t_order.table-strategy.inline.sharding-column=user_id\n#spring.shardingsphere.sharding.tables.t_order.table-strategy.inline.algorithm-expression=t_order_$-&gt;{user_id % 2}\nspring.shardingsphere.sharding.tables.t_order.table-strategy.standard.sharding-column=user_id\nspring.shardingsphere.sharding.tables.t_order.table-strategy.standard.precise-algorithm-class-name=com.crazymaker.springcloud.sharding.jdbc.demo.core.TablePreciseShardingAlgorithmDemo\nspring.shardingsphere.sharding.tables.t_order.key-generator.column=order_id\nspring.shardingsphere.sharding.tables.t_order.key-generator.type=SNOWFLAKE\nspring.shardingsphere.sharding.tables.t_order.key-generator.props.worker.id=123\nspring.shardingsphere.sharding.tables.t_order.database-strategy.standard.precise-algorithm-class-name=com.crazymaker.springcloud.sharding.jdbc.demo.core.DsPreciseShardingAlgorithmDemo\nspring.shardingsphere.sharding.tables.t_order.database-strategy.standard.sharding-column=user_id\n#spring.shardingsphere.sharding.tables.t_order.database-strategy.inline.sharding-column=user_id\n#spring.shardingsphere.sharding.tables.t_order.database-strategy.inline.algorithm-expression=ds$-&gt;{user_id % 2}\n\n</code></pre> \n <blockquote> \n  <p>就写这么多，更加详细的内容，请参见视频</p> \n </blockquote> \n <h2><a id=\"ComplexShardingStrategy_1963\"></a>ComplexShardingStrategy复合分片策略实战</h2> \n <h3><a id=\"___1967\"></a>内联分片、标准分片 策略的不足：</h3> \n <p>只有一个分片建</p> \n <p>问题： 多个分片键参与分片路由，咋整？</p> \n <h3><a id=\"ComplexSharding_1979\"></a>ComplexSharding分片策略</h3> \n <p>分片策略基本和上面的分片算法对应，包括：标准分片策略、复合分片策略、Hint分片策略、内联分片策略、不分片策略；</p> \n <ul>\n  <li> <p>标准分片策略：对应<code>StandardShardingStrategy</code>类，提供<code>PreciseShardingAlgorithm</code>和<code>RangeShardingAlgorithm</code>两个分片算法，<code>PreciseShardingAlgorithm</code>是必须的，<code>RangeShardingAlgorithm</code>可选的；</p> <pre><code class=\"prism language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">StandardShardingStrategy</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">ShardingStrategy</span> <span class=\"token punctuation\">{\n      <!-- --></span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> String shardingColumn<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> PreciseShardingAlgorithm preciseShardingAlgorithm<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> RangeShardingAlgorithm rangeShardingAlgorithm<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n</code></pre> </li>\n  <li> <p>复合分片策略：对应<code>ComplexShardingStrategy</code>类，提供<code>ComplexKeysShardingAlgorithm</code>分片算法；</p> <pre><code class=\"prism language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">ComplexShardingStrategy</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">ShardingStrategy</span> <span class=\"token punctuation\">{\n      <!-- --></span>\n    <span class=\"token annotation punctuation\">@Getter</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> Collection<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>String<span class=\"token punctuation\">&gt;</span></span> shardingColumns<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> ComplexKeysShardingAlgorithm shardingAlgorithm<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n</code></pre> <p>可以发现支持多个分片键；</p> </li>\n  <li> <p>Hint分片策略：对应<code>HintShardingStrategy</code>类，通过 Hint 指定分片值而非从 SQL 中提取分片值的方式进行分片的策略；提供<code>HintShardingAlgorithm</code>分片算法；</p> <pre><code class=\"prism language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">HintShardingStrategy</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">ShardingStrategy</span> <span class=\"token punctuation\">{\n      <!-- --></span>\n    <span class=\"token annotation punctuation\">@Getter</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> Collection<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>String<span class=\"token punctuation\">&gt;</span></span> shardingColumns<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> HintShardingAlgorithm shardingAlgorithm<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n</code></pre> </li>\n  <li> <p>内联分片策略：对应<code>InlineShardingStrategy</code>类，没有提供分片算法，路由规则通过表达式来实现；</p> </li>\n  <li> <p>不分片策略：对应<code>NoneShardingStrategy</code>类，不分片策略；</p> </li>\n </ul> \n <h3><a id=\"ComplexSharding_2022\"></a>ComplexSharding分片策略配置类</h3> \n <p>在使用中我们并没有直接使用上面的分片策略类，ShardingSphere-JDBC分别提供了对应策略的配置类包括：</p> \n <ul>\n  <li><code>StandardShardingStrategyConfiguration</code></li>\n  <li><code>ComplexShardingStrategyConfiguration</code></li>\n  <li><code>HintShardingStrategyConfiguration</code></li>\n  <li><code>InlineShardingStrategyConfiguration</code></li>\n  <li><code>NoneShardingStrategyConfiguration</code></li>\n </ul> \n <pre><code>/**\n * Complex sharding strategy configuration.\n */\n@Getter\npublic final class ComplexShardingStrategyConfiguration implements ShardingStrategyConfiguration {\n    \n    private final String shardingColumns;\n    \n    private final ComplexKeysShardingAlgorithm shardingAlgorithm;\n    \n    public ComplexShardingStrategyConfiguration(\n    \n    final String shardingColumns, \n    final ComplexKeysShardingAlgorithm shardingAlgorithm) {\n    \n        Preconditions.checkArgument(!Strings.isNullOrEmpty(shardingColumns), \"ShardingColumns is required.\");\n        Preconditions.checkNotNull(shardingAlgorithm, \"ShardingAlgorithm is required.\");\n        this.shardingColumns = shardingColumns;\n        this.shardingAlgorithm = shardingAlgorithm;\n    }\n}\n\n</code></pre> \n <h3><a id=\"ComplexSharding_2061\"></a>ComplexSharding分片算法</h3> \n <p>提供了抽象分片算法类：<code>ShardingAlgorithm</code>，根据类型又分为：精确分片算法、区间分片算法、复合分片算法以及Hint分片算法；</p> \n <ul>\n  <li>精确分片算法：对应<code>PreciseShardingAlgorithm</code>类，主要用于处理 <code>=</code> 和 <code>IN</code>的分片；</li>\n  <li>区间分片算法：对应<code>RangeShardingAlgorithm</code>类，主要用于处理 <code>BETWEEN AND</code>, <code>&gt;</code>, <code>&lt;</code>, <code>&gt;=</code>, <code>&lt;=</code> 分片；</li>\n  <li>复合分片算法：对应<code>ComplexKeysShardingAlgorithm</code>类，用于处理使用多键作为分片键进行分片的场景；</li>\n  <li>Hint分片算法：对应<code>HintShardingAlgorithm</code>类，用于处理使用 <code>Hint</code> 行分片的场景；</li>\n </ul> \n <p>以上所有的算法类都是接口类，具体实现交给开发者自己；</p> \n <h3><a id=\"ComplexSharding_2072\"></a>自定义ComplexSharding分片算法</h3> \n <p>问题： 多个分片键参与分片路由，咋整？</p> \n <p>user_id，和oder_id 参与分片</p> \n <p>分片算法如下：</p> \n <pre><code class=\"prism language-java\">\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">SimpleComplexKeySharding</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">ComplexKeysShardingAlgorithm</span><span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>Long<span class=\"token punctuation\">&gt;</span></span> <span class=\"token punctuation\">{\n    <!-- --></span>\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> Collection<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>String<span class=\"token punctuation\">&gt;</span></span> <span class=\"token function\">doSharding</span><span class=\"token punctuation\">(</span>Collection<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>String<span class=\"token punctuation\">&gt;</span></span> availableTargetNames<span class=\"token punctuation\">,</span>\n                                         ComplexKeysShardingValue<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>Long<span class=\"token punctuation\">&gt;</span></span> shardingValue<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        Map<span class=\"token operator\">&lt;</span>String<span class=\"token punctuation\">,</span> Collection<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>Long<span class=\"token punctuation\">&gt;</span></span><span class=\"token operator\">&gt;</span> map <span class=\"token operator\">=</span> shardingValue<span class=\"token punctuation\">.</span><span class=\"token function\">getColumnNameAndShardingValuesMap</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        Collection<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>Long<span class=\"token punctuation\">&gt;</span></span> userIds <span class=\"token operator\">=</span> map<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"user_id\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        Collection<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>Long<span class=\"token punctuation\">&gt;</span></span> orderIds <span class=\"token operator\">=</span> map<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"order_id\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        List<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>String<span class=\"token punctuation\">&gt;</span></span> result <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">ArrayList</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">&gt;</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// user_id，order_id分片键进行分表</span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>Long userId <span class=\"token operator\">:</span> userIds<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>Long orderId <span class=\"token operator\">:</span> orderIds<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n\n                Long innerShardingValue <span class=\"token operator\">=</span> userId <span class=\"token operator\">+</span> orderId<span class=\"token punctuation\">;</span>\n                Long suffix <span class=\"token operator\">=</span> innerShardingValue <span class=\"token operator\">%</span> <span class=\"token number\">2</span><span class=\"token punctuation\">;</span>\n\n\n                <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>String each <span class=\"token operator\">:</span> availableTargetNames<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n                    System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"innerShardingValue = \"</span> <span class=\"token operator\">+</span> innerShardingValue <span class=\"token operator\">+</span> <span class=\"token string\">\" target = \"</span> <span class=\"token operator\">+</span> each <span class=\"token operator\">+</span> <span class=\"token string\">\" innerShardingValue % 2 = \"</span> <span class=\"token operator\">+</span> suffix<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>each<span class=\"token punctuation\">.</span><span class=\"token function\">endsWith</span><span class=\"token punctuation\">(</span>suffix <span class=\"token operator\">+</span> <span class=\"token string\">\"\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n                        result<span class=\"token punctuation\">.</span><span class=\"token function\">add</span><span class=\"token punctuation\">(</span>each<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                    <span class=\"token punctuation\">}</span>\n                <span class=\"token punctuation\">}</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> result<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h3><a id=\"ComplexSharding_2116\"></a>通过代码使用ComplexSharding复合分片算法</h3> \n <p>可以同时使用多个分片键，比如可以同时使用user_id和order_id作为分片键；</p> \n <pre><code class=\"prism language-java\">orderTableRuleConfig<span class=\"token punctuation\">.</span><span class=\"token function\">setDatabaseShardingStrategyConfig</span><span class=\"token punctuation\">(</span>\n		<span class=\"token keyword\">new</span> <span class=\"token class-name\">ComplexShardingStrategyConfiguration</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"order_id,user_id\"</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">SimpleComplexKeySharding</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\norderTableRuleConfig<span class=\"token punctuation\">.</span><span class=\"token function\">setTableShardingStrategyConfig</span><span class=\"token punctuation\">(</span>\n		<span class=\"token keyword\">new</span> <span class=\"token class-name\">ComplexShardingStrategyConfiguration</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"order_id,user_id\"</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">SimpleComplexKeySharding</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n</code></pre> \n <p>如上在配置分库分表策略时，指定了两个分片键，用逗号隔开；</p> \n <h3><a id=\"_2132\"></a>使用属性进行配置</h3> \n <p>支持多分片键的复杂分片策略。</p> \n <p>配置参数：</p> \n <p>complex.sharding-columns 分片键(多个);</p> \n <p>complex.algorithm-class-name 分片算法实现类。</p> \n <h3><a id=\"_2144\"></a>配置参数：</h3> \n <p>shardingColumn指定多个分片列。</p> \n <p>algorithmClassName指向一个实现了org.apache.shardingsphere.api.sharding.complex.ComplexKeysShardingAlgorithm接口的java类名。提供按照多个分片列进行综合分片的算法。</p> \n <blockquote> \n  <p>具体的介绍，请参见视频</p> \n </blockquote> \n <h3><a id=\"_2156\"></a>测试用例与执行</h3> \n <p>参见视频</p> \n <h2><a id=\"HintShardingStrategy_2164\"></a>HintShardingStrategy强制（暗示）分片策略实战</h2> \n <p>问题： 在一些应用场景中，分片值并不存在于 SQL，而存在于外部业务逻辑，咋整？</p> \n <p>问题2：根据外部值分片，咋整？</p> \n <p>eg：</p> \n <p>我要根据 月份分片，或者根据 小时分片</p> \n <p>我要根据 心情 分片</p> \n <p><strong>简单来理解</strong></p> \n <p>这个分片策略，简单来理解就是说，他的分片键不再跟SQL语句相关联，而是用程序另行指定。</p> \n <p>对于一些复杂的情况，例如select count(*) from (select userid from t_user where userid in (1,3,5,7,9)) 这样的SQL语句，就没法通过SQL语句来指定一个分片键。</p> \n <p>暗示策略与前面的策略之不同：</p> \n <ul>\n  <li>前面的策略提取分片键列与值并进行分片是 Apache ShardingSphere 对 SQL 零侵入的实现方式。</li>\n </ul> \n <p>若 SQL 语句中没有分片条件，则无法进行分片，需要全路由。</p> \n <p>在一些应用场景中，分片条件并不存在于 SQL，而存在于外部业务逻辑。</p> \n <ul>\n  <li>暗示策略需要提供一种通过外部指定分片值的方式，在 Apache ShardingSphere 中叫做 Hint。</li>\n </ul> \n <p>暗示分片值算法如下：</p> \n <p>可以通过编程的方式向 <code>HintManager</code> 中添加分片值，该分片值仅在当前线程内生效；然后通过 hint暗示策略+hint暗示算法分片</p> \n <h3><a id=\"_2216\"></a>分片策略算法</h3> \n <p>ShardingSphere-JDBC在分片策略上分别引入了<strong>分片算法</strong>、<strong>分片策略</strong>两个概念，</p> \n <p>当然在分片的过程中<strong>分片键</strong>也是一个核心的概念；在此可以简单的理解<code>分片策略 = 分片算法 + 分片键</code>；</p> \n <p>至于为什么要这么设计，应该是ShardingSphere-JDBC考虑更多的灵活性，把分片算法单独抽象出来，方便开发者扩展；</p> \n <h3><a id=\"_2224\"></a>分片算法</h3> \n <p>提供了抽象分片算法类：<code>ShardingAlgorithm</code>，根据类型又分为：精确分片算法、区间分片算法、复合分片算法以及Hint分片算法；</p> \n <ul>\n  <li>精确分片算法：对应<code>PreciseShardingAlgorithm</code>类，主要用于处理 <code>=</code> 和 <code>IN</code>的分片；</li>\n  <li>区间分片算法：对应<code>RangeShardingAlgorithm</code>类，主要用于处理 <code>BETWEEN AND</code>, <code>&gt;</code>, <code>&lt;</code>, <code>&gt;=</code>, <code>&lt;=</code> 分片；</li>\n  <li>复合分片算法：对应<code>ComplexKeysShardingAlgorithm</code>类，用于处理使用多键作为分片键进行分片的场景；</li>\n  <li>Hint分片算法：对应<code>HintShardingAlgorithm</code>类，用于处理使用外部值分片的场景；</li>\n </ul> \n <p>以上所有的算法类都是接口类，具体实现交给开发者自己；</p> \n <h3><a id=\"_2235\"></a>分片策略</h3> \n <p>分片策略基本和上面的分片算法对应，包括：标准分片策略、复合分片策略、Hint分片策略、内联分片策略、不分片策略；</p> \n <ul>\n  <li> <p>Hint分片策略：对应<code>HintShardingStrategy</code>类，通过 Hint 指定分片值而非从 SQL 中提取分片值的方式进行分片的策略；提供<code>HintShardingAlgorithm</code>分片算法；</p> <pre><code class=\"prism language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">HintShardingStrategy</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">ShardingStrategy</span> <span class=\"token punctuation\">{\n      <!-- --></span>\n    <span class=\"token annotation punctuation\">@Getter</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> Collection<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>String<span class=\"token punctuation\">&gt;</span></span> shardingColumns<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> HintShardingAlgorithm shardingAlgorithm<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n</code></pre> </li>\n  <li> <p>内联分片策略：对应<code>InlineShardingStrategy</code>类，没有提供分片算法，路由规则通过表达式来实现；</p> </li>\n  <li> <p>不分片策略：对应<code>NoneShardingStrategy</code>类，不分片策略；</p> </li>\n </ul> \n <h3><a id=\"_2254\"></a>分片策略配置类</h3> \n <p>在使用中我们并没有直接使用上面的分片策略类，ShardingSphere-JDBC分别提供了对应策略的配置类包括：</p> \n <ul>\n  <li><code>StandardShardingStrategyConfiguration</code></li>\n  <li><code>ComplexShardingStrategyConfiguration</code></li>\n  <li><code>HintShardingStrategyConfiguration</code> 外部值分片</li>\n  <li><code>InlineShardingStrategyConfiguration</code></li>\n  <li><code>NoneShardingStrategyConfiguration</code></li>\n </ul> \n <h3><a id=\"HintShardingAlgorithm_2266\"></a>自定义HintShardingAlgorithm分片算法</h3> \n <p>问题：根据外部值分片，咋整？</p> \n <p>我要根据 月份分片，或者根据 小时分片</p> \n <p>我要根据 心情 分片</p> \n <p>分片算法如下：</p> \n <pre><code>\npublic class SimpleHintShardingAlgorithmDemo implements HintShardingAlgorithm&lt;Integer&gt; {\n\n    @Override\n    public Collection&lt;String&gt; doSharding(Collection&lt;String&gt; availableTargetNames,\n                                         HintShardingValue&lt;Integer&gt; hintShardingValue) {\n\n        Collection&lt;String&gt; result = new HashSet&lt;&gt;(2);\n        Collection&lt;Integer&gt; values = hintShardingValue.getValues();\n\n\n        for (String each : availableTargetNames) {\n\n            for (int shardingValue : values) {\n\n\n                System.out.println(\"shardingValue = \" + shardingValue + \" target = \" + each + \" shardingValue % 2 = \" + shardingValue % 2);\n                if (each.endsWith(String.valueOf(shardingValue % 2))) {\n                    result.add(each);\n                }\n\n            }\n        }\n        return result;\n    }\n\n	\n}\n\n</code></pre> \n <h3><a id=\"_2310\"></a>使用代码进行配置</h3> \n <pre><code>// 设置库表分片策略\norderTableRuleConfig.setDatabaseShardingStrategyConfig(new HintShardingStrategyConfiguration(new 		SimpleHintShardingAlgorithmDemo()));\norderTableRuleConfig.setTableShardingStrategyConfig(new HintShardingStrategyConfiguration(new SimpleHintShardingAlgorithmDemo()));\n\n</code></pre> \n <h3><a id=\"_2325\"></a>使用属性进行配置</h3> \n <ul>\n  <li> <p>配置参数：hint.algorithm-class-name 分片算法实现类。</p> </li>\n  <li> <p>实现方式：</p> <p>algorithmClassName指向一个实现了org.apache.shardingsphere.api.sharding.hint.HintShardingAlgorithm接口的java类名。 <code>示例：com.roy.shardingDemo.algorithm.MyHintShardingAlgorithm</code></p> <p>在这个算法类中，同样是需要分片键的。而分片键的指定是通过HintManager.addDatabaseShardingValue方法(分库)和HintManager.addTableShardingValue(分表)来指定。</p> <p>使用时要注意，这个分片键是线程隔离的，只在当前线程有效，所以通常建议使用之后立即关闭，或者用try资源方式打开。</p> </li>\n </ul> \n <h3><a id=\"HintManager_2345\"></a>在代码使用<code>HintManager</code>进行暗示</h3> \n <p>在一些应用场景中，分片条件并不存在于 SQL，而存在于外部业务逻辑；</p> \n <p>问题：根据外部值分片，咋整？</p> \n <p>我要根据 月份分片，或者根据 小时分片</p> \n <p>我要根据 心情 分片</p> \n <p>可以通过编程的方式向 <code>HintManager</code> 中添加分片值，该分片值仅在当前线程内生效；</p> \n <pre><code class=\"prism language-java\">\n    <span class=\"token annotation punctuation\">@Test</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">testAddSomeOrderByMonth</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> month <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span> month <span class=\"token operator\">&lt;=</span> <span class=\"token number\">12</span><span class=\"token punctuation\">;</span> month<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n            <span class=\"token keyword\">final</span> <span class=\"token keyword\">int</span> index <span class=\"token operator\">=</span> month<span class=\"token punctuation\">;</span>\n            <span class=\"token keyword\">new</span> <span class=\"token class-name\">Thread</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">Runnable</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n                <span class=\"token annotation punctuation\">@Override</span>\n                <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">run</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n                    System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"当前月份 = \"</span> <span class=\"token operator\">+</span> index<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                    HintManager hintManager <span class=\"token operator\">=</span> HintManager<span class=\"token punctuation\">.</span><span class=\"token function\">getInstance</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                    hintManager<span class=\"token punctuation\">.</span><span class=\"token function\">addTableShardingValue</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"t_order\"</span><span class=\"token punctuation\">,</span> index<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                    hintManager<span class=\"token punctuation\">.</span><span class=\"token function\">addDatabaseShardingValue</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"t_order\"</span><span class=\"token punctuation\">,</span> index<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n                    Order dto <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Order</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                    dto<span class=\"token punctuation\">.</span><span class=\"token function\">setUserId</span><span class=\"token punctuation\">(</span><span class=\"token number\">704733680467685377</span>L<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n                    <span class=\"token comment\">//增加订单</span>\n                    entityService<span class=\"token punctuation\">.</span><span class=\"token function\">addOrder</span><span class=\"token punctuation\">(</span>dto<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n\n                <span class=\"token punctuation\">}</span>\n            <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">start</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n\n</code></pre> \n <h3><a id=\"_2394\"></a>测试用例与执行</h3> \n <p>参见视频</p> \n <h3><a id=\"Hint_2398\"></a>Hint实现机制</h3> \n <p>Apache ShardingSphere 使用 <code>ThreadLocal</code> 管理分片键值。 可以通过编程的方式向 <code>HintManager</code> 中添加分片条件，该分片条件仅在当前线程内生效。</p> \n <p>除了通过编程的方式使用强制分片路由，Apache ShardingSphere 还可以通过 SQL 中的特殊注释的方式引用 Hint，使开发者可以采用更加透明的方式使用该功能。</p> \n <p>指定了强制分片路由的 SQL 将会无视原有的分片逻辑，直接路由至指定的真实数据节点。</p> \n <p><strong>切记：</strong></p> \n <p>涉及到<code>ThreadLocal</code> 线程局部变量的，执行完后用完记得清理哦。免得污染后面的执行，尤其在线程池的场景中。</p> \n <p>Session的使用，也是类似的。</p> \n <h3><a id=\"Hint_2416\"></a>Hint分片策略的优势和劣势</h3> \n <p><strong>场景优势：</strong></p> \n <p>可以程序指定分片值</p> \n <p><strong>性能优势：</strong></p> \n <p>Hint分片策略并没有完全按照SQL解析树来构建分片策略，是绕开了SQL解析的，</p> \n <p>所有对某些比较复杂的语句，Hint分片策略性能有可能会比较好，<strong>仅仅是可能，还需要是分析源码</strong>。</p> \n <p><strong>使用限制</strong></p> \n <p>Hint路由在使用时有非常多的限制：</p> \n <blockquote> \n  <pre><code class=\"prism language-sql\"><span class=\"token comment\">-- 不支持UNION</span>\n<span class=\"token keyword\">SELECT</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">FROM</span> t_order1 <span class=\"token keyword\">UNION</span> <span class=\"token keyword\">SELECT</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">FROM</span> t_order2\n<span class=\"token keyword\">INSERT</span> <span class=\"token keyword\">INTO</span> tbl_name <span class=\"token punctuation\">(</span>col1<span class=\"token punctuation\">,</span> col2<span class=\"token punctuation\">,</span> …<span class=\"token punctuation\">)</span> <span class=\"token keyword\">SELECT</span> col1<span class=\"token punctuation\">,</span> col2<span class=\"token punctuation\">,</span> … <span class=\"token keyword\">FROM</span> tbl_name <span class=\"token keyword\">WHERE</span> col3 <span class=\"token operator\">=</span> ?\n\n<span class=\"token comment\">-- 不支持多层子查询</span>\n<span class=\"token keyword\">SELECT</span> <span class=\"token function\">COUNT</span><span class=\"token punctuation\">(</span><span class=\"token operator\">*</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">FROM</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">SELECT</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">FROM</span> t_order o <span class=\"token keyword\">WHERE</span> o<span class=\"token punctuation\">.</span>id <span class=\"token operator\">IN</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">SELECT</span> id <span class=\"token keyword\">FROM</span> t_order <span class=\"token keyword\">WHERE</span> <span class=\"token keyword\">status</span> <span class=\"token operator\">=</span> ?<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">-- 不支持函数计算。ShardingSphere只能通过SQL字面提取用于分片的值</span>\n<span class=\"token keyword\">SELECT</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">FROM</span> t_order <span class=\"token keyword\">WHERE</span> to_date<span class=\"token punctuation\">(</span>create_time<span class=\"token punctuation\">,</span> <span class=\"token string\">\'yyyy-mm-dd\'</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token string\">\'2019-01-01\'</span><span class=\"token punctuation\">;</span>\n</code></pre> \n </blockquote> \n <p>从这里也能看出，即便有了ShardingSphere框架，分库分表后对于SQL语句的支持依然是非常脆弱的。</p> \n <h2><a id=\"NoneShardingStrategyConfiguration_2458\"></a>NoneShardingStrategyConfiguration不分片策略实战</h2> \n <p>不分片，怎么配置呢</p> \n <h3><a id=\"_2468\"></a>分片策略</h3> \n <p>分片策略基本和上面的分片算法对应，包括：标准分片策略、复合分片策略、Hint分片策略、内联分片策略、不分片策略；</p> \n <ul>\n  <li>不分片策略：对应<code>NoneShardingStrategy</code>类，不分片策略；</li>\n </ul> \n <h3><a id=\"_2476\"></a>分片策略配置类</h3> \n <p>在使用中我们并没有直接使用上面的分片策略类，ShardingSphere-JDBC分别提供了对应策略的配置类包括：</p> \n <ul>\n  <li>NoneShardingStrategyConfiguration</li>\n </ul> \n <h3><a id=\"_2486\"></a>使用代码进行配置</h3> \n <p>配置<code>NoneShardingStrategyConfiguration</code>即可：</p> \n <pre><code class=\"prism language-java\">orderTableRuleConfig<span class=\"token punctuation\">.</span><span class=\"token function\">setDatabaseShardingStrategyConfig</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">NoneShardingStrategyConfiguration</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\norderTableRuleConfig<span class=\"token punctuation\">.</span><span class=\"token function\">setTableShardingStrategyConfig</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">NoneShardingStrategyConfiguration</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n</code></pre> \n <h3><a id=\"_2498\"></a>使用属性进行配置</h3> \n <p>参见视频</p> \n <p>这样数据会插入每个库每张表，可以理解为<code>广播表</code></p> \n <h2><a id=\"_2510\"></a>实战：广播表原理与实操</h2> \n <p>什么是广播表：</p> \n <p>存在于所有的数据源中的表，表结构和表中的数据在每个数据库中均完全一致。</p> \n <p>一般是为字典表或者配置表 t_config，</p> \n <p>某个表一旦被配置为广播表，只要修改某个数据库的广播表，所有数据源中广播表的数据都会跟着同步。</p> \n <p><strong>存在这样的情况：表结构和表中的数据在每个数据库中完全一致，如字典表，那么这时候应该怎么办？广播表这时候就应运而生了。</strong></p> \n <blockquote> \n  <p>定义：指所有的分片数据源中都存在的表，表结构和表中的数据在每个数据库中完全一致。<br> 适用：数据量不大且需要与海量数据的表进行关联查询的场景，例如：字典表。</p> \n </blockquote> \n <p>广播表需要满足如下：<br> （1）在每个数据库表都存在该表以及表结构都一样。<br> （2）当保存的时候，每个数据库都会插入相同的数据。</p> \n <h3><a id=\"_2539\"></a>使用代码进行配置</h3> \n <p>配置<code>NoneShardingStrategyConfiguration</code>即可：</p> \n <pre><code class=\"prism language-java\">\n        <span class=\"token comment\">//广播表配置如下;</span>\n<span class=\"token comment\">// shardingRuleConfig.getBroadcastTables().add(\"t_config\");</span>\n\n\n</code></pre> \n <h3><a id=\"_2553\"></a>使用属性进行配置</h3> \n <pre><code>spring.shardingsphere.sharding.broadcast-tables=t_config\n\n</code></pre> \n <p>具体的演示，请参见视频</p> \n <h3><a id=\"_2564\"></a>广播表的效果</h3> \n <p>运行结果如下：</p> \n <p>添加记录时，在ds0和ds1都会保存1条相同的数据。<br> 当查询的时候，会随机的选择一个数据源进行查询。</p> \n <p><strong>添加</strong></p> \n <pre><code>\n[main] INFO  ShardingSphere-SQL - Logic SQL: insert into t_config (status, id) values (?, ?)\n[main] INFO  ShardingSphere-SQL - SQLStatement: InsertStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.InsertStatement@61be6051, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@13c18bba), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@13c18bba, columnNames=[status, id], insertValueContexts=[InsertValueContext(parametersCount=2, valueExpressions=[ParameterMarkerExpressionSegment(startIndex=42, stopIndex=42, parameterMarkerIndex=0), ParameterMarkerExpressionSegment(startIndex=45, stopIndex=45, parameterMarkerIndex=1)], parameters=[UN_KNOWN, 1])], generatedKeyContext=Optional.empty)\n[main] INFO  ShardingSphere-SQL - Actual SQL: ds0 ::: insert into t_config (status, id) values (?, ?) ::: [UN_KNOWN, 1]\n[main] INFO  ShardingSphere-SQL - Actual SQL: ds1 ::: insert into t_config (status, id) values (?, ?) ::: [UN_KNOWN, 1]\n\n</code></pre> \n <p><strong>查询</strong></p> \n <pre><code>[main] INFO  o.h.h.i.QueryTranslatorFactoryInitiator - HHH000397: Using ASTQueryTranslatorFactory\n[main] INFO  ShardingSphere-SQL - Logic SQL: select configenti0_.id as id1_0_, configenti0_.status as status2_0_ from t_config configenti0_ limit ?\n[main] INFO  ShardingSphere-SQL - SQLStatement: SelectStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@784212, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@5ac646b3), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@5ac646b3, projectionsContext=ProjectionsContext(startIndex=7, stopIndex=66, distinctRow=false, projections=[ColumnProjection(owner=configenti0_, name=id, alias=Optional[id1_0_]), ColumnProjection(owner=configenti0_, name=status, alias=Optional[status2_0_])]), groupByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@24b38e8f, orderByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@5cf072ea, paginationContext=org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@1edac3b4, containsSubquery=false)\n[main] INFO  ShardingSphere-SQL - Actual SQL: ds1 ::: select configenti0_.id as id1_0_, configenti0_.status as status2_0_ from t_config configenti0_ limit ? ::: [3]\n[ConfigBean(id=1, status=UN_KNOWN), ConfigBean(id=704836248892059648, status=UN_KNOWN0), ConfigBean(id=704836250150350849, status=UN_KNOWN1)]\n\n\n</code></pre> \n <h2><a id=\"_2602\"></a>实战：绑定表</h2> \n <p>绑定表：那些分片规则一致的主表和子表。</p> \n <p>比如：t_order 订单表和 t_order_item 订单服务项目表，都是按 order_id 字段分片，因此两张表互为绑定表关系。</p> \n <p>那绑定表存在的意义是啥呢？</p> \n <p>通常在我们的业务中都会使用 t_order 和 t_order_item 等表进行多表联合查询，但由于分库分表以后这些表被拆分成N多个子表。</p> \n <p>如果不配置绑定表关系，会出现笛卡尔积关联查询，将产生如下四条 SQL。</p> \n <h3><a id=\"_2620\"></a>没有绑定表的效果</h3> \n <pre><code>\n[main] INFO  ShardingSphere-SQL - Logic SQL: SELECT a.* FROM `t_order` a left join `t_user` b on a.user_id=b.user_id  where  a.user_id=?\n....\n[main] INFO  ShardingSphere-SQL - Actual SQL: ds1 ::: SELECT a.* FROM `t_order_1` a left join `t_user_1` b on a.user_id=b.user_id  where  a.user_id=? ::: [704733680467685377]\n[main] INFO  ShardingSphere-SQL - Actual SQL: ds1 ::: SELECT a.* FROM `t_order_1` a left join `t_user_0` b on a.user_id=b.user_id  where  a.user_id=? ::: [704733680467685377]\n[order_id: 704786564605521921, user_id: 704733680467685377, status: NotPayed, order_id: 704786564697796609, ....]\n</code></pre> \n <h3><a id=\"_2633\"></a>有绑定表的效果</h3> \n <pre><code>[main] INFO  ShardingSphere-SQL - Logic SQL: SELECT a.* FROM `t_order` a left join `t_user` b on a.user_id=b.user_id  where  a.user_id=?\n[main] INFO  ShardingSphere-SQL - SQLStatement: SelectStatementContext(super=CommonSQLStatementContext(sqlStatement=org.apache.shardingsphere.sql.parser.sql.statement.dml.SelectStatement@4247093b, tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@7074da1d), tablesContext=org.apache.shardingsphere.sql.parser.binder.segment.table.TablesContext@7074da1d, projectionsContext=ProjectionsContext(startIndex=7, stopIndex=9, distinctRow=false, projections=[ShorthandProjection(owner=Optional[a], actualColumns=[ColumnProjection(owner=a, name=order_id, alias=Optional.empty), ColumnProjection(owner=a, name=user_id, alias=Optional.empty), ColumnProjection(owner=a, name=status, alias=Optional.empty)])]), groupByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.groupby.GroupByContext@5bdb6ea8, orderByContext=org.apache.shardingsphere.sql.parser.binder.segment.select.orderby.OrderByContext@3e55eeb9, paginationContext=org.apache.shardingsphere.sql.parser.binder.segment.select.pagination.PaginationContext@44a13699, containsSubquery=false)\n[main] INFO  ShardingSphere-SQL - Actual SQL: ds1 ::: SELECT a.* FROM `t_order_1` a left join `t_user_1` b on a.user_id=b.user_id  where  a.user_id=? ::: [704733680467685377]\n[order_id: 704786564605521921, user_id: 704733680467685377, status: NotPayed, order_id: 704786564697796609, user_id: 704733680467685377, status: NotPayed, order_id: 704786564790071297, user_id: 704733680467685377, .....]\n\n</code></pre> \n <h2><a id=\"shardingjdbc_sql_2645\"></a>shardingjdbc 的sql执行流程</h2> \n <p>shardingjdbc 对原有的 <code>DataSource</code>、<code>Connection</code> 等接口扩展成 <code>ShardingDataSource</code>、<code>ShardingConnection</code>，</p> \n <p>而对外暴露的分片操作接口与 JDBC 规范中所提供的接口完全一致，只要你熟悉 JDBC 就可以轻松应用 Sharding-JDBC 来实现分库分表。</p> \n <p><strong><img src=\"https://img-blog.csdnimg.cn/img_convert/c1554a7ce715660c12df81bf7b0f1761.png\" alt=\"img\"></strong></p> \n <p>一张表经过分库分表后被拆分成多个子表，并分散到不同的数据库中，</p> \n <p>在不修改原业务 SQL 的前提下，<code>Sharding-JDBC</code> 就必须对 SQL进行一些改造才能正常执行。</p> \n <p>大致的执行流程：<code>SQL 解析</code> -&gt; <code>查询优化</code> -&gt; <code>SQL 路由</code> -&gt; <code>SQL 改写</code> -&gt; <code>SQL 执⾏</code> -&gt; <code>结果归并</code> 六步组成，一起瞅瞅每个步骤做了点什么。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/cf5ed7c00e9ed2d9be4aa1a5164b564b.png\" alt=\"img\"></p> \n <h3><a id=\"SQL_2665\"></a>SQL解析</h3> \n <p>接着语法解析会将拆分后的SQL转换为抽象语法树，通过对抽象语法树遍历，提炼出分片所需的上下文，</p> \n <p>上下文包含查询字段信息（<code>Field</code>）、表信息（<code>Table</code>）、查询条件（<code>Condition</code>）、排序信息（<code>Order By</code>）、分组信息（<code>Group By</code>）以及分页信息（<code>Limit</code>）等，并标记出 SQL中有可能需要改写的位置。</p> \n <p>例如，以下 SQL：</p> \n <pre><code>SELECT id, name FROM t_user WHERE status = \'ACTIVE\' AND age &gt; 18\n\n</code></pre> \n <h3><a id=\"SQL__2682\"></a><strong>SQL 解析引擎</strong></h3> \n <p>相对于其他编程语⾔，SQL 是⽐较简单的。不过，它依然是⼀⻔完善的编程语⾔，因此对 SQL 的语法进⾏解析，与解析其他编程语⾔（如：Java 语⾔、C 语⾔、Go 语⾔等）并⽆本质区别。</p> \n <p><strong>功能点</strong></p> \n <p>• 提供独立的 SQL 解析功能</p> \n <p>• 可以非常方便的对语法规则进行扩充和修改 (使用了 ANTLR)</p> \n <p>• 支持多种方言的 SQL 解析</p> \n <table>\n  <thead>\n   <tr>\n    <th>数据库</th>\n    <th>支持状态</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>MySQL</td>\n    <td>支持，完善</td>\n   </tr>\n   <tr>\n    <td>PostgreSQL</td>\n    <td>支持，完善</td>\n   </tr>\n   <tr>\n    <td>SQLServer</td>\n    <td>支持</td>\n   </tr>\n   <tr>\n    <td>Oracle</td>\n    <td>支持</td>\n   </tr>\n   <tr>\n    <td>SQL92</td>\n    <td>支持</td>\n   </tr>\n  </tbody>\n </table> \n <ul>\n  <li><strong>历史</strong></li>\n </ul> \n <p>SQL 解析作为分库分表类产品的核心，其性能和兼容性是最重要的衡量指标。ShardingSphere 的 SQL 解 析器经历了 3 代产品的更新迭代。</p> \n <p>第一代 SQL 解析器为了追求性能与快速实现，在 1.4.x 之前的版本使用 Druid 作为 SQL 解析器。经实际 测试，它的性能远超其它解析器。</p> \n <p>第二代 SQL 解析器从 1.5.x 版本开始，ShardingSphere 采用完全自研的 SQL 解析引擎。由于目的不同， ShardingSphere 并不需要将 SQL 转为一颗完全的抽象语法树，也无需通过访问器模式进行二次遍历。它 采用对 SQL 半理解的方式，仅提炼数据分片需要关注的上下文，因此 SQL 解析的性能和兼容性得到了进 一步的提高。</p> \n <p>第三代 SQL 解析器从 3.0.x 版本开始，尝试使用 ANTLR 作为 SQL 解析引擎的生成器，并采用 Visit 的方 式从 AST 中获取 SQL Statement。从 5.0.x 版本开始，解析引擎的架构已完成重构调整，同时通过将第一 次解析的得到的 AST 放入缓存，方便下次直接获取相同 SQL 的解析结果，来提高解析效率。</p> \n <p>因此官方建 议用戶采用 PreparedStatement 这种 SQL 预编译的方式来提升性能。</p> \n <h4><a id=\"_2723\"></a>抽象语法树</h4> \n <p>解析过程分为词法解析和语法解析。词法解析器⽤于将 SQL 拆解为不可再分的原⼦符号，称为 Token。并根据不同数据库⽅⾔所提供的字典，将其归类为关键字，表达式，字⾯量和操作符。再使⽤语法解析器将 SQL 转换为抽象语法树。</p> \n <h2><a id=\"shardingjdbc_SQL__2729\"></a>shardingjdbc 的SQL 路由原理</h2> \n <p>SQL 路由通过解析分片上下文，匹配到用户配置的分片策略，并生成路由路径。</p> \n <p>简单点理解就是可以根据我们配置的分片策略计算出 SQL该在哪个库的哪个表中执行，</p> \n <p>而SQL路由又根据有无分片健区分出 <code>分片路由</code> 和 <code>广播路由</code>。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/9df0e7bf185c7b50e00f32062a2b4339.png\" alt=\"img\"></p> \n <p>有分⽚键的路由叫分片路由，细分为直接路由、标准路由和笛卡尔积路由这3种类型。</p> \n <h3><a id=\"_2743\"></a>直接路由（暗示路由）</h3> \n <p>直接路由是通过使用 <code>HintAPI</code> 直接将 SQL路由到指定⾄库表的一种分⽚方式，而且直接路由可以⽤于分⽚键不在SQL中的场景，还可以执⾏包括⼦查询、⾃定义函数等复杂情况的任意SQL。</p> \n <p>比如根据 <code>t_order_id</code> 字段为条件查询订单，此时希望在不修改SQL的前提下，加上 <code>user_id</code>作为分片条件就可以使用直接路由。</p> \n <p>直接路由需要通过 Hint(使用 HintAPI 直接指定路由至库表)方式指定分片值，</p> \n <p>不需要提取分片键值，并且 是只分库不分表的前提下，则可以避免 SQL 解析。</p> \n <p>因此它的兼容性最好，可以执行包 括子查询、自定义函数等复杂情况的任意 SQL。直接路由还可以用于分片键不在 SQL 中的场景。例如，设 置用于数据库分片的值为 3</p> \n <pre><code class=\"prism language-css\">hintManager.<span class=\"token function\">setDatabaseShardingValue</span><span class=\"token punctuation\">(</span>3<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre> \n <p>假如路由算法为 value % 2，当一个逻辑库 t_order 对应 2 个真实库 t_order_0 和 t_order_1 时， 路由后 SQL 将在 t_order_1 上执行。</p> \n <h3><a id=\"_2767\"></a>标准路由</h3> \n <p>标准路由是最推荐也是最为常⽤的分⽚⽅式，它的适⽤范围是不包含关联查询或仅包含绑定表之间关联查询的SQL。</p> \n <ul>\n  <li> <p>当 SQL分片健的运算符为 <code>=</code> 时，路由结果将落⼊单库（表），路由策略返回的是单个的目标。</p> </li>\n  <li> <p>当分⽚运算符是<code>BETWEEN</code> 或<code>IN</code> 等范围时，路由结果则不⼀定落⼊唯⼀的库（表），因此⼀条逻辑SQL最终可能被拆分为多条⽤于执⾏的真实SQL。</p> </li>\n </ul> \n <p>如果按照 order_id 的奇数和偶数进行数据分片，一个单表查询的 SQL 如下:</p> \n <pre><code class=\"prism language-sql\"><span class=\"token keyword\">SELECT</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">FROM</span> t_order  <span class=\"token keyword\">where</span> t_order_id <span class=\"token operator\">in</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n</code></pre> \n <p>SQL路由处理后</p> \n <pre><code class=\"prism language-sql\"><span class=\"token keyword\">SELECT</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">FROM</span> t_order_0  <span class=\"token keyword\">where</span> t_order_id <span class=\"token operator\">in</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">SELECT</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">FROM</span> t_order_1  <span class=\"token keyword\">where</span> t_order_id <span class=\"token operator\">in</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n</code></pre> \n <p>绑定表的关联查询与单表查询复杂度和性能相当。</p> \n <p>举例说明，如果一个包含绑定表的关联查询的 SQL 如 下:</p> \n <pre><code class=\"prism language-csharp\"> SELECT <span class=\"token operator\">*</span> <span class=\"token class-name\">FROM</span> t_order o <span class=\"token class-name\">JOIN</span> t_order_item i <span class=\"token class-name\">ON</span> o<span class=\"token punctuation\">.</span>order_id<span class=\"token operator\">=</span>i<span class=\"token punctuation\">.</span>order_id <span class=\"token class-name\">WHERE</span> order_ id IN <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre> \n <p>那么路由的结果应为:</p> \n <pre><code class=\"prism language-csharp\">SELECT <span class=\"token operator\">*</span> <span class=\"token class-name\">FROM</span> t_order_0 o <span class=\"token class-name\">JOIN</span> t_order_item_0 i <span class=\"token class-name\">ON</span> o<span class=\"token punctuation\">.</span>order_id<span class=\"token operator\">=</span>i<span class=\"token punctuation\">.</span>order_id <span class=\"token class-name\">WHERE</span> order_id IN <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nSELECT <span class=\"token operator\">*</span> <span class=\"token class-name\">FROM</span> t_order_1 o <span class=\"token class-name\">JOIN</span> t_order_item_1 i <span class=\"token class-name\">ON</span> o<span class=\"token punctuation\">.</span>order_id<span class=\"token operator\">=</span>i<span class=\"token punctuation\">.</span>order_id <span class=\"token class-name\">WHERE</span> order_id IN <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre> \n <p>可以看到，SQL 拆分的数目与单表是一致的。</p> \n <h3><a id=\"_2817\"></a>笛卡尔积路由</h3> \n <p>笛卡尔路由是由非绑定表之间的关联查询产生的，查询性能较低尽量避免走此路由模式。</p> \n <p>笛卡尔路由是最复杂的情况，它无法根据绑定表的关系定位分片规则，因此非绑定表之间的关联查询需 要拆解为笛卡尔积组合执行。</p> \n <p>如果上个示例中的 SQL 并未配置绑定表关系，那么路由的结果应为:</p> \n <pre><code class=\"prism language-csharp\">SELECT <span class=\"token operator\">*</span> <span class=\"token class-name\">FROM</span> t_order_0 o <span class=\"token class-name\">JOIN</span> t_order_item_0 i <span class=\"token class-name\">ON</span> o<span class=\"token punctuation\">.</span>order_id<span class=\"token operator\">=</span>i<span class=\"token punctuation\">.</span>order_id <span class=\"token class-name\">WHERE</span> order_id IN <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nSELECT <span class=\"token operator\">*</span> <span class=\"token class-name\">FROM</span> t_order_0 o <span class=\"token class-name\">JOIN</span> t_order_item_1 i <span class=\"token class-name\">ON</span> o<span class=\"token punctuation\">.</span>order_id<span class=\"token operator\">=</span>i<span class=\"token punctuation\">.</span>order_id <span class=\"token class-name\">WHERE</span> order_id IN <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nSELECT <span class=\"token operator\">*</span> <span class=\"token class-name\">FROM</span> t_order_1 o <span class=\"token class-name\">JOIN</span> t_order_item_0 i <span class=\"token class-name\">ON</span> o<span class=\"token punctuation\">.</span>order_id<span class=\"token operator\">=</span>i<span class=\"token punctuation\">.</span>order_id <span class=\"token class-name\">WHERE</span> order_id IN <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nSELECT <span class=\"token operator\">*</span> <span class=\"token class-name\">FROM</span> t_order_1 o <span class=\"token class-name\">JOIN</span> t_order_item_1 i <span class=\"token class-name\">ON</span> o<span class=\"token punctuation\">.</span>order_id<span class=\"token operator\">=</span>i<span class=\"token punctuation\">.</span>order_id <span class=\"token class-name\">WHERE</span> order_id IN <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre> \n <p>笛卡尔路由查询性能较低，需谨慎使用。</p> \n <h3><a id=\"_2840\"></a>广播路由</h3> \n <p>无分⽚键的路由又叫做广播路由，可以划分为全库表路由、全库路由、 全实例路由、单播路由和阻断路由这 5种类型。</p> \n <p><strong>全库表路由</strong></p> \n <p>全库表路由针对的是数据库 <code>DQL</code>和 <code>DML</code>，以及 <code>DDL</code>等操作，</p> \n <p>当我们执行一条逻辑表 <code>t_order</code> SQL时，在所有分片库中对应的真实表 <code>t_order_0</code> ··· <code>t_order_n</code> 内逐一执行。</p> \n <p><strong>全库路由</strong></p> \n <p>全库路由主要是对数据库层面的操作，比如数据库 <code>SET</code> 类型的数据库管理命令，以及 TCL 这样的事务控制语句。</p> \n <p>对逻辑库设置 <code>autocommit</code> 属性后，所有对应的真实库中都执行该命令。</p> \n <pre><code class=\"prism language-sql\"><span class=\"token keyword\">SET</span> autocommit<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n</code></pre> \n <p><strong>全实例路由</strong></p> \n <p>全实例路由是针对数据库实例的 DCL 操作（设置或更改数据库用户或角色权限），比如：创建一个用户 order ，这个命令将在所有的真实库实例中执行，以此确保 order 用户可以正常访问每一个数据库实例。</p> \n <pre><code class=\"prism language-sql\"><span class=\"token keyword\">CREATE</span> <span class=\"token keyword\">USER</span> <span class=\"token keyword\">order</span><span class=\"token variable\">@127.0.0.1</span> identified <span class=\"token keyword\">BY</span> <span class=\"token string\">\'程序员内点事\'</span><span class=\"token punctuation\">;</span>\n</code></pre> \n <p><strong>单播路由</strong></p> \n <p>单播路由用来获取某一真实表信息，比如获得表的描述信息：</p> \n <pre><code class=\"prism language-sql\"><span class=\"token keyword\">DESCRIBE</span> t_order<span class=\"token punctuation\">;</span> \n</code></pre> \n <p><code>t_order</code> 的真实表是 <code>t_order_0</code> ···· <code>t_order_n</code>，他们的描述结构相完全同，我们只需在任意的真实表执行一次就可以。</p> \n <p><strong>阻断路由</strong></p> \n <p>⽤来屏蔽SQL对数据库的操作，例如：</p> \n <pre><code class=\"prism language-php\"><span class=\"token keyword\">USE</span> order_db<span class=\"token punctuation\">;</span>\n</code></pre> \n <p>这个命令不会在真实数据库中执⾏，因为 <code>ShardingSphere</code> 采⽤的是逻辑 Schema（数据库的组织和结构） ⽅式，所以无需将切换数据库的命令发送⾄真实数据库中。</p> \n <p><strong>SQL 改写</strong></p> \n <p>将基于逻辑表开发的SQL改写成可以在真实数据库中可以正确执行的语句。比如查询 <code>t_order</code> 订单表，我们实际开发中 SQL是按逻辑表 <code>t_order</code> 写的。</p> \n <pre><code class=\"prism language-sql\"><span class=\"token keyword\">SELECT</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">FROM</span> t_order\n</code></pre> \n <p>但分库分表以后真实数据库中 <code>t_order</code> 表就不存在了，而是被拆分成多个子表 <code>t_order_n</code> 分散在不同的数据库内，还按原SQL执行显然是行不通的，这时需要将分表配置中的逻辑表名称改写为路由之后所获取的真实表名称。</p> \n <pre><code class=\"prism language-sql\"><span class=\"token keyword\">SELECT</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">FROM</span> t_order_n\n</code></pre> \n <h3><a id=\"SQL_2902\"></a>SQL执行</h3> \n <p>将路由和改写后的真实 SQL 安全且高效发送到底层数据源执行。但这个过程并不是简单的将 SQL 通过JDBC 直接发送至数据源执行，而是平衡数据源连接创建以及内存占用所产生的消耗，它会自动化的平衡资源控制与执行效率。</p> \n <h3><a id=\"_2906\"></a>结果归并</h3> \n <p>将从各个数据节点获取的多数据结果集，合并成一个大的结果集并正确的返回至请求客户端，称为结果归并。</p> \n <p>而我们SQL中的排序、分组、分页和聚合等语法，均是在归并后的结果集上进行操作的。</p> \n <h2><a id=\"join_2918\"></a>问题：分库的join怎么解决</h2> \n <p><img src=\"https://img-blog.csdnimg.cn/724753f0873144a4a8abd80acdd2d20e.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"__join_2926\"></a>首先看是那种 join。</h3> \n <p>JOIN的含大致分为左连接，右连接，内连接，外连接，自然连接。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/4637cde2b42055b32ed6a34d4a05e34c.png\" alt=\"img\"></p> \n <h4><a id=\"_2936\"></a>笛卡尔积</h4> \n <p>JOIN首先要理解笛卡尔积。</p> \n <p>笛卡尔积就是将A表的每一条记录与B表的每一条记录强行拼在一起。所以，如果A表有n条记录，B表有m条记录，笛卡尔积产生的结果就会产生n*m条记录。</p> \n <h4><a id=\"INNER_JOIN_2942\"></a>内连接：INNER JOIN</h4> \n <p>内连接INNER JOIN是最常用的连接操作。从数学的角度讲就是求两个表的交集，从笛卡尔积的角度讲就是从笛卡尔积中挑出ON子句条件成立的记录。</p> \n <h4><a id=\"LEFT_JOIN_2946\"></a>左连接：LEFT JOIN</h4> \n <p>左连接LEFT JOIN的含义就是求两个表的交集外加左表剩下的数据。</p> \n <p>从笛卡尔积的角度讲，就是先从笛卡尔积中挑出ON子句条件成立的记录，然后加上左表中剩余的记录</p> \n <h4><a id=\"RIGHT_JOIN_2954\"></a>右连接：RIGHT JOIN</h4> \n <p>同理右连接RIGHT JOIN就是求两个表的交集外加右表剩下的数据。</p> \n <p>从笛卡尔积的角度描述，右连接就是从笛卡尔积中挑出ON子句条件成立的记录，然后加上右表中剩余的记录</p> \n <h4><a id=\"_2962\"></a>常用的是左外连接</h4> \n <pre><code>   /**\n     * 根据用户查询 order\n     *\n     * @return\n     */\n    @Query(nativeQuery = true,\n            value = \"SELECT a.* FROM `t_order` a left join `t_user` b on a.user_id=b.user_id  where  a.user_id=?1\")\n    List&lt;OrderEntity&gt; selectOrderOfUserId(long userId);\n    /**\n     * 根据用户查询 order\n     *\n     * @return\n     */\n    @Query(nativeQuery = true,\n            value = \"SELECT a.* FROM `t_order` a left join `t_user` b on a.user_id=b.user_id \")\n    List&lt;OrderEntity&gt; selectOrderOfUser();\n\n</code></pre> \n <h4><a id=\"join_2986\"></a>回答：分库的join怎么解决：</h4> \n <ul>\n  <li> <p>就是一般用左外连接，</p> </li>\n  <li> <p>两个表用相同的分片建，</p> </li>\n  <li> <p>并且进行表绑定，防止产生数据源实例内的笛卡尔积路由。</p> </li>\n  <li> <p>使得join的时候，一个分片内部的数据，在分片内部完成 join操作，再由shardingjdbc完成 结果的归并。</p> </li>\n  <li> <p>从而得到最终的结果。</p> </li>\n </ul> \n <h2><a id=\"_2997\"></a>连环问：分库分表后，模糊条件查询怎么处理？</h2> \n <p>上面提到的都是条件中有sharding column的SQL执行。</p> \n <p>但是，总有一些查询条件是不包含sharding column的，同时，我们也不可能为了这些请求量并不高的查询，无限制的冗余分库分表。</p> \n <p>那么这些查询条件中没有sharding column的SQL怎么处理？</p> \n <p>而在移动互联网时代，海量的用户每天产生海量的数量，这些海量数据远不是一张表能Hold住的。</p> \n <p>比如</p> \n <ul>\n  <li> <p>用户表：支付宝8亿，微信10亿。CITIC对公140万，对私8700万。</p> </li>\n  <li> <p>订单表：美团每天几千万，淘宝历史订单百亿、千亿。</p> </li>\n </ul> \n <p>目前绝大部分公司的核心数据都是：以RDBMS存储为主，NoSQL/NewSQL存储为辅！</p> \n <ul>\n  <li> <p>RDBMS互联网公司又以MySQL为主</p> </li>\n  <li> <p>NoSQL比较具有代表性的是MongoDB，es</p> </li>\n  <li> <p>NewSQL比较具有代表性的是TiDB。</p> </li>\n </ul> \n <p>但是，MySQL单表可以存储10亿级数据，具体的原因，前面视频已经具体分析</p> \n <p>但是，行业认可的，MySQL单表容量在1KW以下, 所以必然要分库分表</p> \n <p>回顾一下，sharding 核心的步骤是：</p> \n <blockquote> \n  <p>SQL解析，重写，路由，执行，结果归并。</p> \n </blockquote> \n <p>以sharding-jdbc为例，有多少个分库分表，就要并发路由到多少个分库分表中执行，然后对结果进行合并。</p> \n <p>更有甚者，尤其是有些模糊条件查询，或者上十个条件筛选。</p> \n <blockquote> \n  <p>这种条件查询相对于有sharding column的条件查询性能很明显会下降很多。</p> \n </blockquote> \n <p>多sharding column最好不要使用，建议采用 单sharding column + es + HBase的索引与存储隔离的架构。</p> \n <h3><a id=\"_3059\"></a>索引与存储隔离的架构</h3> \n <p>例如有sharding column的查询走分库分表，一些模糊查询，或者多个不固定条件筛选则走es，海量存储则交给HBase。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/8586d415dd7048aea0f5aca170da3fe6.png\" alt=\"在这里插入图片描述\"></p> \n <p><strong>HBase特点：</strong></p> \n <p>所有字段的全量数据保存到HBase中，Hadoop体系下的HBase存储能力是海量的，</p> \n <p>rowkey查询速度快，快如闪电(可以优化到50Wqps甚至更高)。</p> \n <p><strong>es特点：</strong></p> \n <p>es的多条件检索能力非常强大。可能参与条件检索的字段索引到ES中。</p> \n <p>这个方案把es和HBase的优点发挥的淋漓尽致，同时又规避了它们的缺点，可以说是一个扬长避免的最佳实践。</p> \n <p>这就是经典的ES+HBase组合方案，即索引与数据存储隔离的方案。</p> \n <p>它们之间的交互大概是这样的：</p> \n <ul>\n  <li> <p>先根据用户输入的条件去es查询获取符合过滤条件的rowkey值，</p> </li>\n  <li> <p>然后用rowkey值去HBase查询</p> </li>\n </ul> \n <p>交互图如下所示：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/b140b4f89ef54a269b61596a4e7962bf.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5p625p6E5biILeWwvOaBqQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>对于海量数据，且有一定的并发量的分库分表，绝不是引入某一个分库分表中间件就能解决问题，而是一项系统的工程。</p> \n <p>需要分析整个表相关的业务，让合适的中间件做它最擅长的事情。</p> \n <p>例如有sharding column的查询走分库分表，</p> \n <p>一些模糊查询，或者多个不固定条件筛选则走es，海量存储则交给HBase。</p> \n <h3><a id=\"biglog_3117\"></a>biglog同步保障数据一致性的架构</h3> \n <p>在很多业务情况下，我们都会在系统中加入redis缓存做查询优化， 使用es 做全文检索。</p> \n <p>如果数据库数据发生更新，这时候就需要在业务代码中写一段同步更新redis的代码。</p> \n <p>这种<strong>数据同步的代码跟业务代码糅合在一起会不太优雅</strong>，能不能把这些数据同步的代码抽出来形成一个独立的模块呢，答案是可以的。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/20210605204112427.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"_3135\"></a>数据的冷热分离</h3> \n <p>做了这么多事情后，后面还会有很多的工作要做，比如数据同步的一致性问题，</p> \n <p>还有运行一段时间后，某些表的数据量慢慢达到单表瓶颈，这时候还需要做冷数据迁移。</p> \n <h2><a id=\"_3153\"></a>问题：广播表是不是公共表</h2> \n <p><img src=\"https://img-blog.csdnimg.cn/af22edab59ff4c64b6532176554d9e2c.png\" alt=\"在这里插入图片描述\"></p> \n <p>可以这么理解。</p> \n <p>广播表，就是更新操作，覆盖所有分片， 查询操作，查一个分片即可。</p> \n <h2><a id=\"_3173\"></a>分布式主键</h2> \n <p>数据分⽚后，不同数据节点⽣成全局唯⼀主键是非常棘⼿的问题，</p> \n <p>同⼀个逻辑表（t_order）内的不同真实表（t_order_n）之间的⾃增键由于无法互相感知而产⽣重复主键。</p> \n <p>尽管可通过设置⾃增主键 初始值 和 步长 的⽅式避免 ID 碰撞，但这样会使维护成本加大，乏完整性和可扩展性。</p> \n <p>如果后去需要增加分片表的数量，要逐一修改分片表的步长，运维成本非常高，所以不建议这种方式。</p> \n <p>为了让上手更加简单，ApacheShardingSphere 内置了 UUID、SNOWFLAKE 两种分布式主键⽣成器，</p> \n <p>默认使⽤雪花算法（snowflake）⽣成 64bit 的⻓整型数据。</p> \n <p>不仅如此它还抽离出分布式主键⽣成器的接口，⽅便我们实现⾃定义的⾃增主键⽣成算法。</p> \n <h3><a id=\"_3193\"></a>实现动机</h3> \n <p>传统数据库软件开发中，主键⾃动⽣成技术是基本需求。而各个数据库对于该需求也提供了相应的⽀持，⽐如 MySQL 的⾃增键，Oracle 的⾃增序列等。</p> \n <p>数据分⽚后，不同数据节点⽣成全局唯⼀主键是⾮常棘⼿的问题。</p> \n <p>同⼀个逻辑表内的不同实际表之间的⾃增键由于⽆法互相感知而产⽣<strong>重复主键</strong>。</p> \n <p>虽然可通过约束⾃增主键初始值和步⻓的⽅式避免碰撞，但需引⼊额外的运维规则，使解决⽅案缺乏完整性和可扩展性。</p> \n <p>⽬前有许多第三⽅解决⽅案可以完美解决这个问题，如 UUID 等依靠特定算法⾃⽣成不重复键，或者通过引⼊主键⽣成服务等。</p> \n <p>为了⽅⽤⼾使⽤、满⾜不同⽤⼾不同使⽤场景的需求，Apache ShardingSphere不仅提供了内置的分布式主键⽣成器，</p> \n <p>例如 UUID 、SNOWFLAKE，</p> \n <p>还抽离出分布式主键⽣成器的接口，⽅便⽤⼾⾃⾏实现⾃定义的⾃增主键⽣成器。</p> \n <p>内置的主键⽣成器</p> \n <h2><a id=\"UUID_3217\"></a>UUID</h2> \n <p>采⽤ UUID.randomUUID() 的⽅式产⽣分布式主键。</p> \n <h3><a id=\"SNOWFLAKE_3223\"></a>SNOWFLAKE</h3> \n <p>在分⽚规则配置模块可配置每个表的主键⽣成策略，默认使⽤雪花算法（snowfl ake ）⽣成 64bit 的⻓整型数据。<br> 雪花算法是由 Twitter 公布的分布式主键⽣成算法，它能够保证不同进程主键的不重复性，以及相同进程主键的有序性。</p> \n <h4><a id=\"_3228\"></a>实现原理</h4> \n <p>在同⼀个进程中，它⾸先是通过时间位保证不重复，如果时间相同则是通过序列位保证。同时由于时间位是单调递增的，且各个服务器如果⼤体做了时间同步，那么⽣成的主键在分布式环境可以认为是总体有序的，这就保证了对索引字段的插⼊的⾼效性。</p> \n <p>例如 MySQL 的 Innodb 存储引擎的主键。<br> 使⽤雪花算法⽣成的主键，⼆进制表⽰形式包含 4 部分，从⾼位到低位分表为：</p> \n <ul>\n  <li>1bit 符号位、</li>\n  <li>41bit 时间戳位、</li>\n  <li>10bit ⼯作进程位以及</li>\n  <li>12bit 序列号位。</li>\n </ul> \n <h4><a id=\"1bit_3246\"></a>符号位（1bit）</h4> \n <p>预留的符号位，恒为零。</p> \n <h4><a id=\"41bit_3250\"></a>时间戳位（41bit）</h4> \n <p>41 位的时间戳可以容纳的毫秒数是 2 的 41 次幂，⼀年所使⽤的毫秒数是：365 * 24 * 60 * 60 *1000。</p> \n <p>通过计算可知：<br> Math.pow(2, 41) / (365 * 24 * 60 * 60 * 1000L);<br> 结果约等于 69.73 年。</p> \n <p>Apache ShardingSphere 的雪花算法的时间纪元从 2016 年 11 ⽉ 1 ⽇零点开始，可以使⽤到 2086 年，</p> \n <p>相信能满⾜绝⼤部分系统的要求。</p> \n <h4><a id=\"10bit_3264\"></a><strong>⼯作进程位（10bit）</strong></h4> \n <p>该标志在 Java 进程内是唯⼀的，如果是分布式应⽤部署应保证每个⼯作进程的 id 是不同的。该值默认为0，可通过属性设置。</p> \n <h4><a id=\"12bit_3268\"></a>序列号位（12bit）</h4> \n <p>该序列是⽤来在同⼀个毫秒内⽣成不同的 ID。</p> \n <p>如果在这个毫秒内⽣成的数量超过 4096 (2 的 12 次幂)，那么⽣成器会等待到下个毫秒继续⽣成。<br> 雪花算法主键的详细结构⻅下图。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/007b02a17dfd4e5da19dcaedd13e0cf1.png\" alt=\"在这里插入图片描述\"></p> \n <h4><a id=\"_3281\"></a>时钟回拨</h4> \n <p>服务器时钟回拨会导致产⽣重复序列，因此默认分布式主键⽣成器提供了⼀个最⼤容忍的时钟回拨毫秒数。</p> \n <p>如果时钟回拨的时间超过最⼤容忍的毫秒数阈值，则程序报错；</p> \n <p>如果在可容忍的范围内，默认分布式主键⽣成器会等待时钟同步到最后⼀次主键⽣成的时间后再继续⼯作。</p> \n <p>最⼤容忍的时钟回拨毫秒数的默认值为 0，可通过属性设置。</p> \n <h4><a id=\"_3293\"></a>步长不均衡</h4> \n <p>导致数据倾斜</p> \n <h2><a id=\"Shardingjdbc_SPI_3301\"></a>Shardingjdbc SPI与自定义主键</h2> \n <h3><a id=\"Java_SPI_3305\"></a>Java SPI是什么</h3> \n <p>SPI全称Service Provider Interface，是Java提供的一套用来被第三方实现或者扩展的API，它可以用来启用框架扩展和替换组件。</p> \n <p>系统设计的各个抽象，往往有很多不同的实现方案，</p> \n <p>在面向的对象的设计里，一般推荐模块之间基于接口编程，模块之间不对实现类进行硬编码。</p> \n <p>一旦代码里涉及具体的实现类，就违反了可拔插的原则，如果需要替换一种实现，就需要修改代码。</p> \n <p>为了实现在模块装配的时候能不在程序里动态指明，这就需要一种服务发现机制。</p> \n <p>Java SPI就是提供这样的一个机制：为某个接口寻找服务实现的机制。</p> \n <p>有点类似IOC的思想，就是将装配的控制权移到程序之外，在模块化设计中这个机制尤其重要。</p> \n <p>整体机制图如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/fd039534003a46b59b80189245ce6b70.png\" alt=\"在这里插入图片描述\"></p> \n <p><img src=\"https://img-blog.csdn.net/20171211145713130\" alt=\"这里写图片描述\"></p> \n <p>Java SPI 实际上是“<strong>基于接口的编程＋策略模式＋配置文件</strong>”组合实现的动态加载机制。所以SPI的核心思想就是<strong>解耦</strong>。</p> \n <h3><a id=\"Java_SPI_3343\"></a><strong>Java SPI的约定</strong></h3> \n <h3><a id=\"Java__SPI_3347\"></a>Java SPI使用场景</h3> \n <p>概括地说，适用于：<strong>调用者根据实际使用需要，启用、扩展、或者替换框架的实现策略</strong></p> \n <p>比较常见的例子：</p> \n <ul>\n  <li>数据库驱动加载接口实现类的加载<br> JDBC加载不同类型数据库的驱动</li>\n  <li>日志门面接口实现类加载<br> SLF4J加载不同提供商的日志实现类</li>\n  <li>Spring<br> Spring中大量使用了SPI,比如：对servlet3.0规范对ServletContainerInitializer的实现、自动类型转换Type Conversion SPI(Converter SPI、Formatter SPI)等</li>\n  <li>Dubbo<br> Dubbo中也大量使用SPI的方式实现框架的扩展, 不过它对Java提供的原生SPI做了封装，允许用户扩展实现Filter接口</li>\n </ul> \n <h3><a id=\"Java_SPI_3364\"></a>Java SPI使用约定</h3> \n <p>要使用Java SPI，需要遵循如下约定：</p> \n <ul>\n  <li>1、当服务提供者提供了接口的一种具体实现后，在jar包的META-INF/services目录下创建一个以“接口全限定名”为命名的文件，内容为实现类的全限定名；</li>\n  <li>2、接口实现类所在的jar包放在主程序的classpath中；</li>\n  <li>3、主程序通过java.util.ServiceLoder动态装载实现模块，它通过扫描META-INF/services目录下的配置文件找到实现类的全限定名，把类加载到JVM；</li>\n  <li>4、SPI的实现类必须携带一个不带参数的构造方法；</li>\n </ul> \n <h3><a id=\"JavaSPI_3375\"></a>JavaSPI实战</h3> \n <p>首先，我们需要定义一个接口，SPI Service 接口</p> \n <pre><code>package com.crazymaker.springcloud.sharding.jdbc.demo.generator;\n\npublic interface IdGenerator\n{\n\n    /**\n     * Next id long.\n     *\n     * @return the nextId\n     */\n    Long nextId();\n\n}\n\n</code></pre> \n <p>然后，定义两个实现类，也可以定义两个实现类</p> \n <pre><code>// 单机版 AtomicLong 类型的ID生成器\n@Data\npublic class AtomicLongShardingKeyGeneratorSPIDemo implements IdGenerator {\n\n    private AtomicLong atomicLong = new AtomicLong(0);\n\n    @Override\n    public Long nextId() {\n        return atomicLong.incrementAndGet();\n    }\n}\n\n</code></pre> \n <p>最后，要在ClassPath路径下配置添加一个文件：</p> \n <ul>\n  <li>文件名字是接口的全限定类名</li>\n  <li>内容是实现类的全限定类名</li>\n  <li>多个实现类用换行符分隔。</li>\n </ul> \n <p>SPI配置文件位置，文件路径如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/b2b5a113037941f597e1c76f0c994f5c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5p625p6E5biILeWwvOaBqQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>内容就是实现类的全限定类名：</p> \n <pre><code class=\"prism language-css\"> com.crazymaker.springcloud.sharding.jdbc.demo.generator.AtomicLongShardingKeyGeneratorSPIDemo\n</code></pre> \n <p><strong>测试</strong></p> \n <p>然后我们就可以通过<code>ServiceLoader.load或者Service.providers</code>方法拿到实现类的实例。</p> \n <ul>\n  <li><code>Service.providers</code>包位于<code>sun.misc.Service</code>，</li>\n  <li><code>ServiceLoader.load</code>包位于<code>java.util.ServiceLoader</code>。</li>\n </ul> \n <pre><code class=\"prism language-java\">\n    <span class=\"token annotation punctuation\">@Test</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">testGenIdByProvider</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        Iterator<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>IdGenerator<span class=\"token punctuation\">&gt;</span></span> providers <span class=\"token operator\">=</span> Service<span class=\"token punctuation\">.</span><span class=\"token function\">providers</span><span class=\"token punctuation\">(</span>IdGenerator<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>providers<span class=\"token punctuation\">.</span><span class=\"token function\">hasNext</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n            IdGenerator generator <span class=\"token operator\">=</span> providers<span class=\"token punctuation\">.</span><span class=\"token function\">next</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> <span class=\"token number\">100</span><span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n\n                Long id <span class=\"token operator\">=</span> generator<span class=\"token punctuation\">.</span><span class=\"token function\">nextId</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n                System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"id = \"</span> <span class=\"token operator\">+</span> id<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token annotation punctuation\">@Test</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">testGenIdByServiceLoader</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        ServiceLoader<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>IdGenerator<span class=\"token punctuation\">&gt;</span></span> serviceLoaders <span class=\"token operator\">=</span> ServiceLoader<span class=\"token punctuation\">.</span><span class=\"token function\">load</span><span class=\"token punctuation\">(</span>IdGenerator<span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n\n        Iterator<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>IdGenerator<span class=\"token punctuation\">&gt;</span></span> iterator <span class=\"token operator\">=</span> serviceLoaders<span class=\"token punctuation\">.</span><span class=\"token function\">iterator</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>iterator<span class=\"token punctuation\">.</span><span class=\"token function\">hasNext</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n            IdGenerator generator <span class=\"token operator\">=</span> iterator<span class=\"token punctuation\">.</span><span class=\"token function\">next</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> <span class=\"token number\">100</span><span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n\n                Long id <span class=\"token operator\">=</span> generator<span class=\"token punctuation\">.</span><span class=\"token function\">nextId</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n                System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"id = \"</span> <span class=\"token operator\">+</span> id<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n</code></pre> \n <p>两种方式的输出结果是一致的：</p> \n <h3><a id=\"_3504\"></a>可插拔架构</h3> \n <h4><a id=\"_3506\"></a>背景</h4> \n <p>在 Apache ShardingSphere 中，很多功能实现类的加载⽅式是通过 SPI（Service Provider Interface）注的⽅式完成的。SPI 是⼀种为了被第三⽅实现或扩展的 API，它可以⽤于实现框架扩展或组件替换。</p> \n <h4><a id=\"_3510\"></a>挑战</h4> \n <p>可插拔架构对程序架构设计的要求⾮常⾼，需要将各个模块相互独⽴，互不感知，并且通过⼀个可插拔内核，以叠加的⽅式将各种功能组合使⽤。设计⼀套将功能开发完全隔离的架构体系，既可以最⼤限度的将开源社区的活⼒激发出来，也能够保障项⽬的质量。<br> Apache ShardingSphere 5.x 版本开始致⼒于可插拔架构，项⽬的功能组件能够灵活的以可插拔的⽅式进⾏扩展。⽬前，数据分⽚、读写分离、数据加密、影⼦库压测等功能，以及对 MySQL、PostgreSQL、SQLServer、Oracle 等 SQL 与协议的⽀持，均通过插件的⽅式织⼊项⽬。Apache ShardingSphere ⽬前已提供数⼗个 SPI 作为系统的扩展点，而且仍在不断增加中。</p> \n <h4><a id=\"_3515\"></a>⽬标</h4> \n <p>让开发者能够像使⽤积木⼀样定制属于⾃⼰的独特系统，是 Apache ShardingSphere 可插拔架构的设计⽬标。</p> \n <p>Apache ShardingSphere 可插拔架构提供了数⼗个基于 SPI 的扩展点。对于开发者来说，可以⼗分⽅便的对功能进⾏定制化扩展。<br> 本章节将 Apache ShardingSphere 的 SPI 扩展点悉数列出。如⽆特殊需求，⽤⼾可以使⽤ Apache Shard-ingSphere 提供的内置实现；⾼级⽤⼾则可以参考各个功能模块的接口进⾏⾃定义实现。</p> \n <h3><a id=\"SPI_3524\"></a>基于类型的SPI机制</h3> \n <pre><code>package org.apache.shardingsphere.spi;\n\nimport java.util.Properties;\n\n/**\n * Base algorithm SPI.\n */\npublic interface TypeBasedSPI {\n    \n    /**\n     * Get algorithm type.\n     * \n     * @return type\n     */\n    String getType();\n    \n    /**\n     * Get properties.\n     * \n     * @return properties of algorithm\n     */\n    Properties getProperties();\n    \n    /**\n     * Set properties.\n     * \n     * @param properties properties of algorithm\n     */\n    void setProperties(Properties properties);\n}\n</code></pre> \n <h3><a id=\"_3563\"></a>分布式主键扩展点</h3> \n <p><img src=\"https://img-blog.csdnimg.cn/9f12d741b0114018924937f3e2bdee39.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"_3569\"></a>自定义主键实战</h3> \n <pre><code>package com.crazymaker.springcloud.sharding.jdbc.demo.generator;\n\nimport lombok.Data;\nimport org.apache.shardingsphere.spi.keygen.ShardingKeyGenerator;\n\nimport java.util.Properties;\nimport java.util.concurrent.atomic.AtomicLong;\n\n// 单机版 AtomicLong 类型的ID生成器\n@Data\npublic class AtomicLongShardingKeyGenerator implements ShardingKeyGenerator {\n\n    private AtomicLong atomicLong = new AtomicLong(0);\n    private Properties properties = new Properties();\n\n    @Override\n    public Comparable&lt;?&gt; generateKey() {\n        return atomicLong.incrementAndGet();\n    }\n\n    @Override\n    public String getType() {\n\n        //声明类型\n        return \"DemoAtomicLongID\";\n    }\n}\n\n</code></pre> \n <h3><a id=\"_3608\"></a>使用实例</h3> \n <pre><code>\n\n    @Test\n    public void testGenIdByShardingServiceLoader() {\n        ShardingKeyGeneratorServiceLoader serviceLoader = new ShardingKeyGeneratorServiceLoader();\n        ShardingKeyGenerator keyGenerator= serviceLoader.newService(\"DemoAtomicLongID\" ,new Properties());\n\n        for (int i = 0; i &lt; 100; i++) {\n\n            Long id = (Long) keyGenerator.generateKey();\n\n            System.out.println(\"id = \" + id);\n\n        }\n    }\n\n\n</code></pre> \n <h3><a id=\"_3634\"></a>演示和源码介绍:</h3> \n <p>请参见视频</p> \n <h2><a id=\"ShardingSphereSQL_3640\"></a>ShardingSphere的SQL使用限制</h2> \n <p>参见官网文档：</p> \n <p>https://shardingsphere.apache.org/document/current/cn/features/sharding/use-norms/sql/</p> \n <p>文档中</p> \n <p>详细列出了非常多ShardingSphere目前版本支持和不支持的SQL类型。</p> \n <p>这些需要关注。</p> \n <p><strong>支持的SQL</strong></p> \n <table>\n  <thead>\n   <tr>\n    <th align=\"left\">SQL</th>\n    <th align=\"left\">必要条件</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td align=\"left\">SELECT * FROM tbl_name</td>\n    <td align=\"left\"></td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT * FROM tbl_name WHERE (col1 = ? or col2 = ?) and col3 = ?</td>\n    <td align=\"left\"></td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT * FROM tbl_name WHERE col1 = ? ORDER BY col2 DESC LIMIT ?</td>\n    <td align=\"left\"></td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT COUNT(*), SUM(col1), MIN(col1), MAX(col1), AVG(col1) FROM tbl_name WHERE col1 = ?</td>\n    <td align=\"left\"></td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT COUNT(col1) FROM tbl_name WHERE col2 = ? GROUP BY col1 ORDER BY col3 DESC LIMIT ?, ?</td>\n    <td align=\"left\"></td>\n   </tr>\n   <tr>\n    <td align=\"left\">INSERT INTO tbl_name (col1, col2,…) VALUES (?, ?, ….)</td>\n    <td align=\"left\"></td>\n   </tr>\n   <tr>\n    <td align=\"left\">INSERT INTO tbl_name VALUES (?, ?,….)</td>\n    <td align=\"left\"></td>\n   </tr>\n   <tr>\n    <td align=\"left\">INSERT INTO tbl_name (col1, col2, …) VALUES (?, ?, ….), (?, ?, ….)</td>\n    <td align=\"left\"></td>\n   </tr>\n   <tr>\n    <td align=\"left\">INSERT INTO tbl_name (col1, col2, …) SELECT col1, col2, … FROM tbl_name WHERE col3 = ?</td>\n    <td align=\"left\">INSERT表和SELECT表必须为相同表或绑定表</td>\n   </tr>\n   <tr>\n    <td align=\"left\">REPLACE INTO tbl_name (col1, col2, …) SELECT col1, col2, … FROM tbl_name WHERE col3 = ?</td>\n    <td align=\"left\">REPLACE表和SELECT表必须为相同表或绑定表</td>\n   </tr>\n   <tr>\n    <td align=\"left\">UPDATE tbl_name SET col1 = ? WHERE col2 = ?</td>\n    <td align=\"left\"></td>\n   </tr>\n   <tr>\n    <td align=\"left\">DELETE FROM tbl_name WHERE col1 = ?</td>\n    <td align=\"left\"></td>\n   </tr>\n   <tr>\n    <td align=\"left\">CREATE TABLE tbl_name (col1 int, …)</td>\n    <td align=\"left\"></td>\n   </tr>\n   <tr>\n    <td align=\"left\">ALTER TABLE tbl_name ADD col1 varchar(10)</td>\n    <td align=\"left\"></td>\n   </tr>\n   <tr>\n    <td align=\"left\">DROP TABLE tbl_name</td>\n    <td align=\"left\"></td>\n   </tr>\n   <tr>\n    <td align=\"left\">TRUNCATE TABLE tbl_name</td>\n    <td align=\"left\"></td>\n   </tr>\n   <tr>\n    <td align=\"left\">CREATE INDEX idx_name ON tbl_name</td>\n    <td align=\"left\"></td>\n   </tr>\n   <tr>\n    <td align=\"left\">DROP INDEX idx_name ON tbl_name</td>\n    <td align=\"left\"></td>\n   </tr>\n   <tr>\n    <td align=\"left\">DROP INDEX idx_name</td>\n    <td align=\"left\"></td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT DISTINCT * FROM tbl_name WHERE col1 = ?</td>\n    <td align=\"left\"></td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT COUNT(DISTINCT col1) FROM tbl_name</td>\n    <td align=\"left\"></td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT subquery_alias.col1 FROM (select tbl_name.col1 from tbl_name where tbl_name.col2=?) subquery_alias</td>\n    <td align=\"left\"></td>\n   </tr>\n  </tbody>\n </table> \n <p><strong>不支持的SQL</strong></p> \n <table>\n  <thead>\n   <tr>\n    <th align=\"left\">SQL</th>\n    <th align=\"left\">不支持原因</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td align=\"left\">INSERT INTO tbl_name (col1, col2, …) VALUES(1+2, ?, …)</td>\n    <td align=\"left\">VALUES语句不支持运算表达式</td>\n   </tr>\n   <tr>\n    <td align=\"left\">INSERT INTO tbl_name (col1, col2, …) SELECT * FROM tbl_name WHERE col3 = ?</td>\n    <td align=\"left\">SELECT子句暂不支持使用*号简写及内置的分布式主键生成器</td>\n   </tr>\n   <tr>\n    <td align=\"left\">REPLACE INTO tbl_name (col1, col2, …) SELECT * FROM tbl_name WHERE col3 = ?</td>\n    <td align=\"left\">SELECT子句暂不支持使用*号简写及内置的分布式主键生成器</td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT * FROM tbl_name1 UNION SELECT * FROM tbl_name2</td>\n    <td align=\"left\">UNION</td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT * FROM tbl_name1 UNION ALL SELECT * FROM tbl_name2</td>\n    <td align=\"left\">UNION ALL</td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT SUM(DISTINCT col1), SUM(col1) FROM tbl_name</td>\n    <td align=\"left\">详见DISTINCT支持情况详细说明</td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT * FROM tbl_name WHERE to_date(create_time, ‘yyyy-mm-dd’) = ?</td>\n    <td align=\"left\">会导致全路由</td>\n   </tr>\n   <tr>\n    <td align=\"left\">(SELECT * FROM tbl_name)</td>\n    <td align=\"left\">暂不支持加括号的查询</td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT MAX(tbl_name.col1) FROM tbl_name</td>\n    <td align=\"left\">查询列是函数表达式时,查询列前不能使用表名;若查询表存在别名,则可使用表的别名</td>\n   </tr>\n  </tbody>\n </table> \n <p><strong>DISTINCT支持情况详细说明</strong></p> \n <p><strong>支持的SQL</strong></p> \n <table>\n  <thead>\n   <tr>\n    <th align=\"left\">SQL</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td align=\"left\">SELECT DISTINCT * FROM tbl_name WHERE col1 = ?</td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT DISTINCT col1 FROM tbl_name</td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT DISTINCT col1, col2, col3 FROM tbl_name</td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT DISTINCT col1 FROM tbl_name ORDER BY col1</td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT DISTINCT col1 FROM tbl_name ORDER BY col2</td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT DISTINCT(col1) FROM tbl_name</td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT AVG(DISTINCT col1) FROM tbl_name</td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT SUM(DISTINCT col1) FROM tbl_name</td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT COUNT(DISTINCT col1) FROM tbl_name</td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT COUNT(DISTINCT col1) FROM tbl_name GROUP BY col1</td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT COUNT(DISTINCT col1 + col2) FROM tbl_name</td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT COUNT(DISTINCT col1), SUM(DISTINCT col1) FROM tbl_name</td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT COUNT(DISTINCT col1), col1 FROM tbl_name GROUP BY col1</td>\n   </tr>\n   <tr>\n    <td align=\"left\">SELECT col1, COUNT(DISTINCT col1) FROM tbl_name GROUP BY col1</td>\n   </tr>\n  </tbody>\n </table> \n <p><strong>不支持的SQL</strong></p> \n <table>\n  <thead>\n   <tr>\n    <th align=\"left\">SQL</th>\n    <th align=\"left\">不支持原因</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td align=\"left\">SELECT SUM(DISTINCT tbl_name.col1), SUM(tbl_name.col1) FROM tbl_name</td>\n    <td align=\"left\">查询列是函数表达式时,查询列前不能使用表名;若查询表存在别名,则可使用表的别名</td>\n   </tr>\n  </tbody>\n </table> \n <h2><a id=\"ShardingJdbc_3744\"></a>ShardingJdbc数据分片开发总结</h2> \n <p>作为一个开发者，ShardingJdbc可以帮我们屏蔽底层的细节，</p> \n <p>让我们在面对分库分表的场景下，可以像使用单库单表一样简单；</p> \n <h3><a id=\"_3752\"></a>分片策略算法</h3> \n <p>ShardingSphere-JDBC在分片策略上分别引入了<strong>分片算法</strong>、<strong>分片策略</strong>两个概念，</p> \n <p>当然在分片的过程中<strong>分片键</strong>也是一个核心的概念；在此可以简单的理解<code>分片策略 = 分片算法 + 分片键</code>；</p> \n <p>至于为什么要这么设计，应该是ShardingSphere-JDBC考虑更多的灵活性，把分片算法单独抽象出来，方便开发者扩展；</p> \n <h4><a id=\"_3760\"></a>分片算法</h4> \n <p>提供了抽象分片算法类：<code>ShardingAlgorithm</code>，根据类型又分为：精确分片算法、区间分片算法、复合分片算法以及Hint分片算法；</p> \n <ul>\n  <li>精确分片算法：对应<code>PreciseShardingAlgorithm</code>类，主要用于处理 <code>=</code> 和 <code>IN</code>的分片；</li>\n  <li>区间分片算法：对应<code>RangeShardingAlgorithm</code>类，主要用于处理 <code>BETWEEN AND</code>, <code>&gt;</code>, <code>&lt;</code>, <code>&gt;=</code>, <code>&lt;=</code> 分片；</li>\n  <li>复合分片算法：对应<code>ComplexKeysShardingAlgorithm</code>类，用于处理使用多键作为分片键进行分片的场景；</li>\n  <li>Hint分片算法：对应<code>HintShardingAlgorithm</code>类，用于处理使用 <code>Hint</code> 行分片的场景；</li>\n </ul> \n <p>以上所有的算法类都是接口类，具体实现交给开发者自己；</p> \n <h4><a id=\"_3771\"></a>分片策略</h4> \n <p>分片策略基本和上面的分片算法对应，包括：标准分片策略、复合分片策略、Hint分片策略、内联分片策略、不分片策略；</p> \n <ul>\n  <li> <p>标准分片策略：对应<code>StandardShardingStrategy</code>类，提供<code>PreciseShardingAlgorithm</code>和<code>RangeShardingAlgorithm</code>两个分片算法，<code>PreciseShardingAlgorithm</code>是必须的，<code>RangeShardingAlgorithm</code>可选的；</p> <pre><code class=\"prism language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">StandardShardingStrategy</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">ShardingStrategy</span> <span class=\"token punctuation\">{\n      <!-- --></span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> String shardingColumn<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> PreciseShardingAlgorithm preciseShardingAlgorithm<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> RangeShardingAlgorithm rangeShardingAlgorithm<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n</code></pre> </li>\n  <li> <p>复合分片策略：对应<code>ComplexShardingStrategy</code>类，提供<code>ComplexKeysShardingAlgorithm</code>分片算法；</p> <pre><code class=\"prism language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">ComplexShardingStrategy</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">ShardingStrategy</span> <span class=\"token punctuation\">{\n      <!-- --></span>\n    <span class=\"token annotation punctuation\">@Getter</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> Collection<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>String<span class=\"token punctuation\">&gt;</span></span> shardingColumns<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> ComplexKeysShardingAlgorithm shardingAlgorithm<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n</code></pre> <p>可以发现支持多个分片键；</p> </li>\n  <li> <p>Hint分片策略：对应<code>HintShardingStrategy</code>类，通过 Hint 指定分片值而非从 SQL 中提取分片值的方式进行分片的策略；提供<code>HintShardingAlgorithm</code>分片算法；</p> <pre><code class=\"prism language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">HintShardingStrategy</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">ShardingStrategy</span> <span class=\"token punctuation\">{\n      <!-- --></span>\n    <span class=\"token annotation punctuation\">@Getter</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> Collection<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>String<span class=\"token punctuation\">&gt;</span></span> shardingColumns<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> HintShardingAlgorithm shardingAlgorithm<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n</code></pre> </li>\n  <li> <p>内联分片策略：对应<code>InlineShardingStrategy</code>类，没有提供分片算法，路由规则通过表达式来实现；</p> </li>\n  <li> <p>不分片策略：对应<code>NoneShardingStrategy</code>类，不分片策略；</p> </li>\n </ul> \n <h4><a id=\"_3814\"></a>分片策略配置类</h4> \n <p>在使用中我们并没有直接使用上面的分片策略类，ShardingSphere-JDBC分别提供了对应策略的配置类包括：</p> \n <ul>\n  <li><code>StandardShardingStrategyConfiguration</code></li>\n  <li><code>ComplexShardingStrategyConfiguration</code></li>\n  <li><code>HintShardingStrategyConfiguration</code></li>\n  <li><code>InlineShardingStrategyConfiguration</code></li>\n  <li><code>NoneShardingStrategyConfiguration</code></li>\n </ul> \n <h3><a id=\"_3824\"></a>实战步骤总结</h3> \n <p>有了以上相关基础概念，接下来针对每种分片策略做一个简单的实战，在实战前首先准备好库和表；</p> \n <h4><a id=\"_3828\"></a>准备</h4> \n <p>分别准备两个库：<code>ds0</code>、<code>ds1</code>；然后每个库分别包含两个表：<code>t_order0</code>，<code>t_order1</code>；</p> \n <pre><code class=\"prism language-sql\"><span class=\"token keyword\">CREATE</span> <span class=\"token keyword\">TABLE</span> <span class=\"token punctuation\">`</span>t_order0<span class=\"token punctuation\">`</span> <span class=\"token punctuation\">(</span>\n  <span class=\"token punctuation\">`</span>id<span class=\"token punctuation\">`</span> <span class=\"token keyword\">bigint</span><span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">NOT</span> <span class=\"token boolean\">NULL</span> <span class=\"token keyword\">AUTO_INCREMENT</span><span class=\"token punctuation\">,</span>\n  <span class=\"token punctuation\">`</span>user_id<span class=\"token punctuation\">`</span> <span class=\"token keyword\">bigint</span><span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">NOT</span> <span class=\"token boolean\">NULL</span><span class=\"token punctuation\">,</span>\n  <span class=\"token punctuation\">`</span>order_id<span class=\"token punctuation\">`</span> <span class=\"token keyword\">bigint</span><span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">NOT</span> <span class=\"token boolean\">NULL</span><span class=\"token punctuation\">,</span>\n  <span class=\"token keyword\">PRIMARY</span> <span class=\"token keyword\">KEY</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">`</span>id<span class=\"token punctuation\">`</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">)</span> <span class=\"token keyword\">ENGINE</span><span class=\"token operator\">=</span><span class=\"token keyword\">InnoDB</span> <span class=\"token keyword\">DEFAULT</span> <span class=\"token keyword\">CHARSET</span><span class=\"token operator\">=</span>utf8\n\n</code></pre> \n <h4><a id=\"_3842\"></a>准备真实数据源</h4> \n <p>我们这里有两个数据源，这里都使用java代码的方式来配置：</p> \n <pre><code class=\"prism language-java\">  <span class=\"token comment\">/** * 通过ShardingDataSourceFactory 构建分片数据源 * * @return * @throws SQLException */</span>\n    <span class=\"token annotation punctuation\">@Before</span>\n\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">buildShardingDataSource</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> SQLException <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token comment\">/* * 1. 数据源集合：dataSourceMap * 2. 分片规则：shardingRuleConfig * 3. 属性：properties * */</span>\n\n        DataSource druidDs1 <span class=\"token operator\">=</span> <span class=\"token function\">buildDruidDataSource</span><span class=\"token punctuation\">(</span>\n                <span class=\"token string\">\"jdbc:mysql://cdh1:3306/sharding_db1?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=true&amp;serverTimezone=UTC\"</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">\"root\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"123456\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        DataSource druidDs2 <span class=\"token operator\">=</span> <span class=\"token function\">buildDruidDataSource</span><span class=\"token punctuation\">(</span>\n                <span class=\"token string\">\"jdbc:mysql://cdh1:3306/sharding_db2?useUnicode=true&amp;characterEncoding=utf8&amp;allowMultiQueries=true&amp;useSSL=true&amp;serverTimezone=UTC\"</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">\"root\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"123456\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// 配置真实数据源</span>\n        Map<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>String<span class=\"token punctuation\">,</span> DataSource<span class=\"token punctuation\">&gt;</span></span> dataSourceMap <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">HashMap</span><span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>String<span class=\"token punctuation\">,</span> DataSource<span class=\"token punctuation\">&gt;</span></span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// 添加数据源.</span>\n        <span class=\"token comment\">// 两个数据源ds_0和ds_1</span>\n        dataSourceMap<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"ds0\"</span><span class=\"token punctuation\">,</span>druidDs1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        dataSourceMap<span class=\"token punctuation\">.</span><span class=\"token function\">put</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"ds1\"</span><span class=\"token punctuation\">,</span> druidDs2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">/** * 需要构建表规则 * 1. 指定逻辑表. * 2. 配置实际节点》 * 3. 指定主键字段. * 4. 分库和分表的规则》 * */</span>\n        <span class=\"token comment\">// 配置分片规则</span>\n        ShardingRuleConfiguration shardingRuleConfig <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">ShardingRuleConfiguration</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n\n        <span class=\"token comment\">//step2：分片规则</span>\n        TableRuleConfiguration userShardingRuleConfig <span class=\"token operator\">=</span> <span class=\"token function\">userShardingRuleConfig</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        shardingRuleConfig<span class=\"token punctuation\">.</span><span class=\"token function\">getTableRuleConfigs</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">add</span><span class=\"token punctuation\">(</span>userShardingRuleConfig<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n\n        <span class=\"token comment\">// 多数据源一定要指定默认数据源</span>\n        <span class=\"token comment\">// 只有一个数据源就不需要</span>\n        shardingRuleConfig<span class=\"token punctuation\">.</span><span class=\"token function\">setDefaultDataSourceName</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"ds0\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        Properties properties <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Properties</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">//打印sql语句，生产环境关闭</span>\n        properties<span class=\"token punctuation\">.</span><span class=\"token function\">setProperty</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"sql.show\"</span><span class=\"token punctuation\">,</span> Boolean<span class=\"token punctuation\">.</span>TRUE<span class=\"token punctuation\">.</span><span class=\"token function\">toString</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        dataSource<span class=\"token operator\">=</span> ShardingDataSourceFactory<span class=\"token punctuation\">.</span><span class=\"token function\">createDataSource</span><span class=\"token punctuation\">(</span>\n                dataSourceMap<span class=\"token punctuation\">,</span> shardingRuleConfig<span class=\"token punctuation\">,</span> properties<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n    <span class=\"token punctuation\">}</span>\n</code></pre> \n <p>这里配置的两个数据源都是普通的数据源，最后会把dataSourceMap交给<code>ShardingDataSourceFactory</code>管理；</p> \n <h4><a id=\"_3910\"></a>表规则配置</h4> \n <p>表规则配置类<code>TableRuleConfiguration</code>，包含了五个要素：逻辑表、真实数据节点、数据库分片策略、数据表分片策略、分布式主键生成策略；</p> \n <pre><code class=\"prism language-java\">    <span class=\"token comment\">/** * 表的分片规则 */</span>\n    <span class=\"token keyword\">protected</span> TableRuleConfiguration <span class=\"token function\">userShardingRuleConfig</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        String logicTable <span class=\"token operator\">=</span> USER_LOGIC_TB<span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">//获取实际的 ActualDataNodes</span>\n        String actualDataNodes <span class=\"token operator\">=</span> <span class=\"token string\">\"ds$-&gt;{0..1}.t_user_$-&gt;{0..1}\"</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// 两个表达式的 笛卡尔积</span>\n<span class=\"token comment\">//ds0.t_user_0</span>\n<span class=\"token comment\">//ds1.t_user_0</span>\n<span class=\"token comment\">//ds0.t_user_1</span>\n<span class=\"token comment\">//ds1.t_user_1</span>\n\n        TableRuleConfiguration tableRuleConfig <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">TableRuleConfiguration</span><span class=\"token punctuation\">(</span>logicTable<span class=\"token punctuation\">,</span> actualDataNodes<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">//设置分表策略</span>\n        <span class=\"token comment\">// inline 模式</span>\n<span class=\"token comment\">// ShardingStrategyConfiguration tableShardingStrategy =</span>\n<span class=\"token comment\">// new InlineShardingStrategyConfiguration(\"user_id\", \"t_user_$-&gt;{user_id % 2}\");</span>\n        <span class=\"token comment\">//自定义模式</span>\n        TablePreciseShardingAlgorithm tablePreciseShardingAlgorithm <span class=\"token operator\">=</span>\n                <span class=\"token keyword\">new</span> <span class=\"token class-name\">TablePreciseShardingAlgorithm</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        RouteInfinityRangeShardingAlgorithm routeInfinityRangeShardingAlgorithm <span class=\"token operator\">=</span>\n                <span class=\"token keyword\">new</span> <span class=\"token class-name\">RouteInfinityRangeShardingAlgorithm</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        RangeOrderShardingAlgorithm tableRangeShardingAlg <span class=\"token operator\">=</span>\n                <span class=\"token keyword\">new</span> <span class=\"token class-name\">RangeOrderShardingAlgorithm</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        PreciseOrderShardingAlgorithm preciseOrderShardingAlgorithm <span class=\"token operator\">=</span>\n                <span class=\"token keyword\">new</span> <span class=\"token class-name\">PreciseOrderShardingAlgorithm</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        ShardingStrategyConfiguration tableShardingStrategy <span class=\"token operator\">=</span>\n                <span class=\"token keyword\">new</span> <span class=\"token class-name\">StandardShardingStrategyConfiguration</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"user_id\"</span><span class=\"token punctuation\">,</span>\n                        preciseOrderShardingAlgorithm<span class=\"token punctuation\">,</span>\n                        routeInfinityRangeShardingAlgorithm<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        tableRuleConfig<span class=\"token punctuation\">.</span><span class=\"token function\">setTableShardingStrategyConfig</span><span class=\"token punctuation\">(</span>tableShardingStrategy<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// 配置分库策略（Groovy表达式配置db规则）</span>\n        <span class=\"token comment\">// inline 模式</span>\n<span class=\"token comment\">// ShardingStrategyConfiguration dsShardingStrategy = new InlineShardingStrategyConfiguration(\"user_id\", \"ds${user_id % 2}\");</span>\n        <span class=\"token comment\">//自定义模式</span>\n        DsPreciseShardingAlgorithm dsPreciseShardingAlgorithm <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">DsPreciseShardingAlgorithm</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        RangeOrderShardingAlgorithm dsRangeShardingAlg <span class=\"token operator\">=</span>\n                <span class=\"token keyword\">new</span> <span class=\"token class-name\">RangeOrderShardingAlgorithm</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        ShardingStrategyConfiguration dsShardingStrategy <span class=\"token operator\">=</span>\n                <span class=\"token keyword\">new</span> <span class=\"token class-name\">StandardShardingStrategyConfiguration</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"user_id\"</span><span class=\"token punctuation\">,</span>\n                        preciseOrderShardingAlgorithm<span class=\"token punctuation\">,</span>\n                        routeInfinityRangeShardingAlgorithm<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        tableRuleConfig<span class=\"token punctuation\">.</span><span class=\"token function\">setDatabaseShardingStrategyConfig</span><span class=\"token punctuation\">(</span>dsShardingStrategy<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        tableRuleConfig<span class=\"token punctuation\">.</span><span class=\"token function\">setKeyGeneratorConfig</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">KeyGeneratorConfiguration</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"SNOWFLAKE\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"user_id\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">return</span> tableRuleConfig<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n</code></pre> \n <ul>\n  <li> <p>逻辑表：这里配置的逻辑表就是t_user，对应的物理表有t_user_0，t_user_1；</p> </li>\n  <li> <p>真实数据节点：这里使用行表达式进行配置的，简化了配置；上面的配置就相当于配置了：</p> <pre><code class=\"prism language-xml\">db0\n  ├── t_user_0 \n  └── t_user_1 \ndb1\n  ├── t_user_0 \n  └── t_user_1\n\n</code></pre> </li>\n  <li> <p>数据库分片策略：这里的库分片策略就是上面介绍的五种类型，这里使用的<code>StandardShardingStrategyConfiguration</code>，需要指定<strong>分片键</strong>和<strong>分片算法</strong>，这里使用的是<strong>精确分片算法</strong>；</p> <pre><code class=\"prism language-java\">\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">PreciseOrderShardingAlgorithm</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">PreciseShardingAlgorithm</span><span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>Long<span class=\"token punctuation\">&gt;</span></span> <span class=\"token punctuation\">{\n      <!-- --></span>\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> String <span class=\"token function\">doSharding</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">final</span> Collection<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>String<span class=\"token punctuation\">&gt;</span></span> availableTargetNames<span class=\"token punctuation\">,</span>\n                             <span class=\"token keyword\">final</span> PreciseShardingValue<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>Long<span class=\"token punctuation\">&gt;</span></span> shardingValue<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n      <!-- --></span>\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>String each <span class=\"token operator\">:</span> availableTargetNames<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n      <!-- --></span>\n            System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"shardingValue = \"</span> <span class=\"token operator\">+</span> shardingValue<span class=\"token punctuation\">.</span><span class=\"token function\">getValue</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span> <span class=\"token string\">\" target = \"</span> <span class=\"token operator\">+</span> each <span class=\"token operator\">+</span> <span class=\"token string\">\" shardingValue.getValue() % 2) = \"</span> <span class=\"token operator\">+</span> shardingValue<span class=\"token punctuation\">.</span><span class=\"token function\">getValue</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">%</span> <span class=\"token number\">2</span>L<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>each<span class=\"token punctuation\">.</span><span class=\"token function\">endsWith</span><span class=\"token punctuation\">(</span>String<span class=\"token punctuation\">.</span><span class=\"token function\">valueOf</span><span class=\"token punctuation\">(</span>shardingValue<span class=\"token punctuation\">.</span><span class=\"token function\">getValue</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">%</span> <span class=\"token number\">2</span>L<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n      <!-- --></span>\n                <span class=\"token keyword\">return</span> each<span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> null<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n\n</code></pre> <p>这里的shardingValue就是user_id对应的真实值，每次和2取余；availableTargetNames可选择就是{ds0，ds1}；看余数和哪个库能匹配上就表示路由到哪个库；</p> </li>\n  <li> <p>数据表分片策略：指定的**分片键(order_id)**和分库策略不一致，其他都一样；</p> </li>\n  <li> <p>分布式主键生成策略：ShardingSphere-JDBC提供了多种分布式主键生成策略，后面详细介绍，这里使用雪花算法；</p> </li>\n </ul> \n <h4><a id=\"_4019\"></a>配置分片规则</h4> \n <p>配置分片规则<code>ShardingRuleConfiguration</code>，包括多种配置规则：表规则配置、绑定表配置、广播表配置、默认数据源名称、默认数据库分片策略、默认表分片策略、默认主键生成策略、主从规则配置、加密规则配置；</p> \n <ul>\n  <li>表规则配置 <strong>tableRuleConfigs</strong>：也就是上面配置的库分片策略和表分片策略，也是最常用的配置；</li>\n  <li>绑定表配置 <strong>bindingTableGroups</strong>：指分⽚规则⼀致的主表和⼦表；绑定表之间的多表关联查询不会出现笛卡尔积关联，关联查询效率将⼤⼤提升；</li>\n  <li>广播表配置 <strong>broadcastTables</strong>：所有的分⽚数据源中都存在的表，表结构和表中的数据在每个数据库中均完全⼀致。适⽤于数据量不⼤且需要与海量数据的表进⾏关联查询的场景；</li>\n  <li>默认数据源名称 <strong>defaultDataSourceName</strong>：未配置分片的表将通过默认数据源定位；</li>\n  <li>默认数据库分片策略 defaultDatabaseShardingStrategyConfig：表规则配置可以设置数据库分片策略，如果没有配置可以在这里面配置默认的；</li>\n  <li>默认表分片策略 <strong>defaultTableShardingStrategyConfig</strong>：表规则配置可以设置表分片策略，如果没有配置可以在这里面配置默认的；</li>\n  <li>默认主键生成策略 <strong>defaultKeyGeneratorConfig</strong>：表规则配置可以设置主键生成策略，如果没有配置可以在这里面配置默认的；内置UUID、SNOWFLAKE生成器；</li>\n  <li>主从规则配置 <strong>masterSlaveRuleConfigs</strong>：用来实现读写分离的，可配置一个主表多个从表，读面对多个从库可以配置负载均衡策略；</li>\n  <li>加密规则配置 <strong>encryptRuleConfig</strong>：提供了对某些敏感数据进行加密的功能，提供了⼀套完整、安全、透明化、低改造成本的数据加密整合解决⽅案；</li>\n </ul> \n <h4><a id=\"_4033\"></a>数据插入</h4> \n <p>以上准备好，就可以操作数据库了，这里执行插入操作：</p> \n <pre><code class=\"prism language-java\"> <span class=\"token comment\">/** * 新增测试. * */</span>\n    <span class=\"token annotation punctuation\">@Test</span>\n    <span class=\"token keyword\">public</span>  <span class=\"token keyword\">void</span> <span class=\"token function\">testInsertUser</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> SQLException <span class=\"token punctuation\">{\n    <!-- --></span>\n\n        <span class=\"token comment\">/* * 1. 需要到DataSource * 2. 通过DataSource获取Connection * 3. 定义一条SQL语句. * 4. 通过Connection获取到PreparedStament. * 5. 执行SQL语句. * 6. 关闭连接. */</span>\n\n\n        <span class=\"token comment\">// * 2. 通过DataSource获取Connection</span>\n        Connection connection <span class=\"token operator\">=</span> dataSource<span class=\"token punctuation\">.</span><span class=\"token function\">getConnection</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// * 3. 定义一条SQL语句.</span>\n        <span class=\"token comment\">// 注意：******* sql语句中 使用的表是 上面代码中定义的逻辑表 *******</span>\n        String sql <span class=\"token operator\">=</span> <span class=\"token string\">\"insert into t_user(name) values(\'name-0001\')\"</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// * 4. 通过Connection获取到PreparedStament.</span>\n        PreparedStatement preparedStatement <span class=\"token operator\">=</span> connection<span class=\"token punctuation\">.</span><span class=\"token function\">prepareStatement</span><span class=\"token punctuation\">(</span>sql<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// * 5. 执行SQL语句.</span>\n        preparedStatement<span class=\"token punctuation\">.</span><span class=\"token function\">execute</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n         sql <span class=\"token operator\">=</span> <span class=\"token string\">\"insert into t_user(name) values(\'name-0002\')\"</span><span class=\"token punctuation\">;</span>\n        preparedStatement <span class=\"token operator\">=</span> connection<span class=\"token punctuation\">.</span><span class=\"token function\">prepareStatement</span><span class=\"token punctuation\">(</span>sql<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        preparedStatement<span class=\"token punctuation\">.</span><span class=\"token function\">execute</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// * 6. 关闭连接.</span>\n        preparedStatement<span class=\"token punctuation\">.</span><span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        connection<span class=\"token punctuation\">.</span><span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n</code></pre> \n <p>通过以上配置的真实数据源、分片规则以及属性文件创建分片数据源<code>ShardingDataSource</code>；</p> \n <p>接下来就可以像使用单库单表一样操作分库分表了，sql中可以直接使用逻辑表，分片算法会根据具体的值就行路由处理；</p> \n <p>经过路由最终：奇数入ds1.t_user_1，偶数入ds0.t_user_0；</p> \n <h4><a id=\"_4084\"></a>分片算法</h4> \n <p>上面的介绍的精确分片算法中，通过<code>PreciseShardingValue</code>来获取当前分片键值，ShardingSphere-JDBC针对每种分片算法都提供了相应的<code>ShardingValue</code>，具体包括：</p> \n <ul>\n  <li>PreciseShardingValue</li>\n  <li>RangeShardingValue</li>\n  <li>ComplexKeysShardingValue</li>\n  <li>HintShardingValue</li>\n </ul> \n <h2><a id=\"_4103\"></a>读写分离</h2> \n <p>对于同一时刻有大量并发读操作和较少写操作类型的应用系统来说，将数据库拆分为主库和从库，主库负责处理事务性的增删改操作，从库负责处理查询操作，能够有效的避免由数据更新导致的行锁，使得整个系统的查询性能得到极大的改善。</p> \n <h3><a id=\"Mysql_4109\"></a>搭建的Mysql主从集群</h3> \n <p><strong>设置前注意下面几点：</strong><br> 1）要保证同步服务期间之间的网络联通。即能相互<code>ping</code>通，能使用对方授权信息连接到对方数据库（防火墙开放3306端口）。<br> 2）关闭selinux。<br> 3）同步前，双方数据库中需要同步的数据要保持一致。这样，同步环境实现后，再次更新的数据就会如期同步了。如果主库是新库，忽略此步。</p> \n <p><strong>创建目录</strong></p> \n <pre><code class=\"prism language-shell\"><span class=\"token function\">mkdir</span> -p /usr/local/docker/mysqlMS\n<span class=\"token function\">cd</span> /usr/local/docker/mysqlMS\n</code></pre> \n <p><strong>编写docker-compose.yml</strong></p> \n <pre><code class=\"prism language-sh\">version: \'3.8\'\nservices:\n  mysql-master:\n    container_name: mysql-master \n    image: mysql:5.7.31\n    restart: always\n    ports:\n      - 3340:3306 \n    privileged: true\n    volumes:\n      - $PWD/msql-master/volumes/log:/var/log/mysql  \n      - $PWD/msql-master/volumes/conf/my.cnf:/etc/mysql/my.cnf\n      - $PWD/msql-master/volumes/data:/var/lib/mysql\n    environment:\n      MYSQL_ROOT_PASSWORD: \"123456\"\n    command: [\n        \'--character-set-server=utf8mb4\',\n        \'--collation-server=utf8mb4_general_ci\',\n        \'--max_connections=3000\'\n    ]\n    networks:\n      - myweb\n      \n  mysql-slave:\n    container_name: mysql-slave \n    image: mysql:5.7.31\n    restart: always\n    ports:\n      - 3341:3306 \n    privileged: true\n    volumes:\n      - $PWD/msql-slave/volumes/log:/var/log/mysql  \n      - $PWD/msql-slave/volumes/conf/my.cnf:/etc/mysql/my.cnf\n      - $PWD/msql-slave/volumes/data:/var/lib/mysql\n    environment:\n      MYSQL_ROOT_PASSWORD: \"123456\"\n    command: [\n        \'--character-set-server=utf8mb4\',\n        \'--collation-server=utf8mb4_general_ci\',\n        \'--max_connections=3000\'\n    ]\n    networks:\n      - myweb    \n\nnetworks:\n\n  myweb:\n    driver: bridge\n</code></pre> \n <p><strong>创建配置文件夹</strong></p> \n <pre><code class=\"prism language-sh\">root@haima-PC:/usr/local/docker/mysqlMS# mkdir -p msql-master/volumes/conf\nroot@haima-PC:/usr/local/docker/mysqlMS# mkdir -p msql-slave/volumes/conf\nroot@haima-PC:/usr/local/docker/mysqlMS# tree\n.\n├── docker-compose.yml\n├── msql-master\n│   └── volumes\n│       └── conf\n└── msql-slave\n    └── volumes\n        └── conf\n\n6 directories, 1 file\n</code></pre> \n <p><strong>1. 主master配置文件my.cnf</strong></p> \n <pre><code>vim msql-master/volumes/conf/my.cnf\n[mysqld]\n# [必须]服务器唯一ID，默认是1，一般取IP最后一段\nserver-id=1\n\n# [必须]启用二进制日志\nlog-bin=mysql-bin \n\n# 复制过滤：也就是指定哪个数据库不用同步（mysql库一般不同步）\nbinlog-ignore-db=mysql\n\n# 设置需要同步的数据库 binlog_do_db = 数据库名； \n# 如果是多个同步库，就以此格式另写几行即可。\n# 如果不指明对某个具体库同步，表示同步所有库。除了binlog-ignore-db设置的忽略的库\n# binlog_do_db = test #需要同步test数据库。\n\n# 确保binlog日志写入后与硬盘同步\nsync_binlog = 1\n\n# 跳过所有的错误，继续执行复制操作\nslave-skip-errors = all       \n温馨提示：在主服务器上最重要的二进制日志设置是sync_binlog，这使得mysql在每次提交事务的时候把二进制日志的内容同步到磁盘上，即使服务器崩溃也会把事件写入日志中。\nsync_binlog这个参数是对于MySQL系统来说是至关重要的，他不仅影响到Binlog对MySQL所带来的性能损耗，而且还影响到MySQL中数据的完整性。对于``\"sync_binlog\"``参数的各种设置的说明如下：\nsync_binlog=0，当事务提交之后，MySQL不做fsync之类的磁盘同步指令刷新binlog_cache中的信息到磁盘，而让Filesystem自行决定什么时候来做同步，或者cache满了之后才同步到磁盘。\nsync_binlog=n，当每进行n次事务提交之后，MySQL将进行一次fsync之类的磁盘同步指令来将binlog_cache中的数据强制写入磁盘。\n  \n在MySQL中系统默认的设置是sync_binlog=0，也就是不做任何强制性的磁盘刷新指令，这时候的性能是最好的，但是风险也是最大的。因为一旦系统Crash，在binlog_cache中的所有binlog信息都会被丢失。而当设置为“1”的时候，是最安全但是性能损耗最大的设置。因为当设置为1的时候，即使系统Crash，也最多丢失binlog_cache中未完成的一个事务，对实际数据没有任何实质性影响。\n  \n从以往经验和相关测试来看，对于高并发事务的系统来说，“sync_binlog”设置为0和设置为1的系统写入性能差距可能高达5倍甚至更多。\n</code></pre> \n <p><strong>2. 从slave配置文件my.cnf</strong></p> \n <pre><code>vim msql-slave/volumes/conf/my.cnf\n[mysqld]\n# [必须]服务器唯一ID，默认是1，一般取IP最后一段  \nserver-id=2\n\n# 如果想实现 主-从（主）-从 这样的链条式结构，需要设置：\n# log-slave-updates      只有加上它，从前一台机器上同步过来的数据才能同步到下一台机器。\n\n# 设置需要同步的数据库，主服务器上不限定数据库，在从服务器上限定replicate-do-db = 数据库名；\n# 如果不指明同步哪些库，就去掉这行，表示所有库的同步（除了ignore忽略的库）。\n# replicate-do-db = test；\n\n# 不同步test数据库 可以写多个例如 binlog-ignore-db = mysql,information_schema \nreplicate-ignore-db=mysql  \n\n## 开启二进制日志功能，以备Slave作为其它Slave的Master时使用\nlog-bin=mysql-bin\nlog-bin-index=mysql-bin.index\n\n## relay_log配置中继日志\n#relay_log=edu-mysql-relay-bin  \n\n## 还可以设置一个log保存周期：\n#expire_logs_days=14\n\n# 跳过所有的错误，继续执行复制操作\nslave-skip-errors = all   \n</code></pre> \n <p><strong>启动服务</strong></p> \n <pre><code class=\"prism language-sh\">root@haima-PC:/usr/local/docker/mysqlMM# docker-compose up -d\nCreating network \"mysqlms_myweb\" with driver \"bridge\"\nCreating mysql-master ... done\nCreating mysql-slave  ... done\n</code></pre> \n <p><strong>查询服务ip地址</strong></p> \n <p>从上面的信息里获取服务创建的网络名称<code>mysqlms_myweb</code></p> \n <pre><code class=\"prism language-sh\">docker network inspect mysqlms_myweb\n</code></pre> \n <p>查到结果</p> \n <pre><code class=\"prism language-shell\">mysql-master ip为192.168.112.3\nmysql-slave ip为192.168.112.2\n</code></pre> \n <p><strong>进入主mysql服务</strong></p> \n <pre><code class=\"prism language-sh\">docker exec -it mysql-master bash\n\nmysql -uroot -p123456\n\n#查看server_id是否生效\nmysql&gt; show variables like \'%server_id%\';\n+----------------+-------+\n| Variable_name  | Value |\n+----------------+-------+\n| server_id      | 1     |\n| server_id_bits | 32    |\n+----------------+-------+\n\n#看master信息 File 和 Position 从服务上要用\nmysql&gt; show master status;\n+------------------+----------+--------------+------------------+-------------------+\n| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |\n+------------------+----------+--------------+------------------+-------------------+\n| mysql-bin.000005 |      154 |              | mysql            |                   |\n+------------------+----------+--------------+------------------+-------------------+\n1 row in set (0.00 sec)\n\n\n#开权限\nmysql&gt; grant replication slave,replication client on *.* to \'slave\'@\'%\' identified by \"123456\";\nmysql&gt; flush privileges;\n</code></pre> \n <hr> \n <p><strong>进入从slave服务</strong></p> \n <pre><code class=\"prism language-sh\">docker exec -it mysql-slave bash\n\nmysql -uroot -p123456\n\n#查看server_id是否生效\nmysql&gt; show variables like \'%server_id%\';\n+----------------+-------+\n| Variable_name  | Value |\n+----------------+-------+\n| server_id      | 2     |\n| server_id_bits | 32    |\n+----------------+-------+\n\n\n# 连接主mysql服务 master_log_file 和 master_log_pos的值要填写主master里查出来的值\n\nchange master to master_host=\'192.168.112.3\',master_user=\'slave\',master_password=\'123456\',master_port=3306,master_log_file=\'mysql-bin.000005\', master_log_pos=154,master_connect_retry=30;\n\n\n#启动slave\nmysql&gt; start slave;\n\nmysql&gt; show slave status \\G;\n*************************** 1. row ***************************\n               Slave_IO_State: Waiting for master to send event\n                  Master_Host: 192.168.112.3\n                  Master_User: slave\n                  Master_Port: 3306\n                Connect_Retry: 30\n              Master_Log_File: mysql-bin.000004\n          Read_Master_Log_Pos: 617\n               Relay_Log_File: 7fee2f1fd5d2-relay-bin.000002\n                Relay_Log_Pos: 783\n        Relay_Master_Log_File: mysql-bin.000004\n             Slave_IO_Running: Yes\n            Slave_SQL_Running: Yes\n              Replicate_Do_DB: \n          Replicate_Ignore_DB: \n           Replicate_Do_Table: \n       Replicate_Ignore_Table: \n      Replicate_Wild_Do_Table: \n  Replicate_Wild_Ignore_Table: \n                   Last_Errno: 0\n                   Last_Error: \n                 Skip_Counter: 0\n          Exec_Master_Log_Pos: 617\n              Relay_Log_Space: 997\n              Until_Condition: None\n               Until_Log_File: \n                Until_Log_Pos: 0\n           Master_SSL_Allowed: No\n           Master_SSL_CA_File: \n           Master_SSL_CA_Path: \n              Master_SSL_Cert: \n            Master_SSL_Cipher: \n               Master_SSL_Key: \n        Seconds_Behind_Master: 0\nMaster_SSL_Verify_Server_Cert: No\n                Last_IO_Errno: 0\n                Last_IO_Error: \n               Last_SQL_Errno: 0\n               Last_SQL_Error: \n  Replicate_Ignore_Server_Ids: \n             Master_Server_Id: 1\n                  Master_UUID: 8f6e9f5a-61f4-11eb-ac84-0242c0a86002\n             Master_Info_File: /var/lib/mysql/master.info\n                    SQL_Delay: 0\n          SQL_Remaining_Delay: NULL\n      Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates\n           Master_Retry_Count: 86400\n                  Master_Bind: \n      Last_IO_Error_Timestamp: \n     Last_SQL_Error_Timestamp: \n               Master_SSL_Crl: \n           Master_SSL_Crlpath: \n           Retrieved_Gtid_Set: \n            Executed_Gtid_Set: \n                Auto_Position: 0\n         Replicate_Rewrite_DB: \n                 Channel_Name: \n           Master_TLS_Version: \n1 row in set (0.01 sec)\n</code></pre> \n <p>连接主mysql参数说明：</p> \n <pre><code class=\"prism language-sh\">**master_port**：Master的端口号，指的是容器的端口号\n\n**master_user**：用于数据同步的用户\n\n**master_password**：用于同步的用户的密码\n\n**master_log_file**：指定 Slave 从哪个日志文件开始复制数据，即上文中提到的 File 字段的值\n\n**master_log_pos**：从哪个 Position 开始读，即上文中提到的 Position 字段的值\n\n**master_connect_retry**：如果连接失败，重试的时间间隔，单位是秒，默认是60秒\n</code></pre> \n <p>上面看到，有两个Yes，说明已经成功了</p> \n <pre><code class=\"prism language-yaml\">        <span class=\"token key atrule\">Relay_Master_Log_File</span><span class=\"token punctuation\">:</span> mysql<span class=\"token punctuation\">-</span>bin.000004\n             <span class=\"token key atrule\">Slave_IO_Running</span><span class=\"token punctuation\">:</span> Yes\n            <span class=\"token key atrule\">Slave_SQL_Running</span><span class=\"token punctuation\">:</span> Yes\n</code></pre> \n <p><strong>设置从服务器slave为只读模式</strong></p> \n <p>在从服务器slave上操作</p> \n <pre><code class=\"prism language-sh\">SHOW VARIABLES LIKE \'%read_only%\'; #查看只读状态\n\nSET GLOBAL super_read_only=1; #super权限的用户只读状态 1.只读 0：可写\nSET GLOBAL read_only=1; #普通权限用户读状态 1.只读 0：可写\n</code></pre> \n <p>到此已经设置成功了，下面就可以测试一下，已经可以主从同步了</p> \n <p>从服务器上的常用操作</p> \n <pre><code class=\"prism language-sql\">stop slave<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">start</span> slave<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">show</span> slave <span class=\"token keyword\">status</span><span class=\"token punctuation\">;</span>\n</code></pre> \n <h3><a id=\"_4449\"></a>数据源准备</h3> \n <h4><a id=\"cdh1_4451\"></a>在cdh1节点的主库创建表</h4> \n <p><a href=\"https://img-blog.csdnimg.cn/20210101220214565.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70\"><img src=\"https://img-blog.csdnimg.cn/20210101220214565.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></a></p> \n <p>脚本如下：</p> \n <pre><code>SET NAMES utf8mb4;\nSET FOREIGN_KEY_CHECKS = 0;\n\n-- ----------------------------\n-- Table structure for t_user_0\n-- ----------------------------\nDROP TABLE IF EXISTS `t_user_0`;\nCREATE TABLE `t_user_0`  (\n  `id` bigint(20) NULL DEFAULT NULL,\n  `name` varchar(40) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL\n) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;\n\nDROP TABLE IF EXISTS `t_user_1`;\nCREATE TABLE `t_user_1`  (\n  `id` bigint(20) NULL DEFAULT NULL,\n  `name` varchar(40) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL\n) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;\n\nSET FOREIGN_KEY_CHECKS = 1;\n</code></pre> \n <h4><a id=\"cdh2_4481\"></a>确保cdh2节点的从库也有以上两个表：</h4> \n <p><a href=\"https://img-blog.csdnimg.cn/20210101220505503.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70\"><img src=\"https://img-blog.csdnimg.cn/20210101220505503.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></a></p> \n <blockquote> \n  <p>注意：主库创建的表，会自动复制到从库</p> \n </blockquote> \n <h3><a id=\"binlog_4495\"></a>binlog（归档日志）</h3> \n <p>MySQL整体来看就有两块：</p> \n <ul>\n  <li> <p>一块是Server层，主要做的是MySQL功能层面的事情；比如 binlog是 Server层也有自己的日志</p> </li>\n  <li> <p>还有一块是引擎层，负责存储相关的具体事宜。比如，redo log是InnoDB引擎特有的日志，</p> </li>\n </ul> \n <p>binlog记录了对MySQL数据库执行更改的所有操作，不包括SELECT和SHOW这类操作，主要作用是用于数据库的主从复制及数据的增量恢复</p> \n <p>使用mysqldump备份时，只是对一段时间的数据进行全备，但是如果备份后突然发现数据库服务器故障，这个时候就要用到binlog的日志了</p> \n <p>binlog格式有三种：STATEMENT，ROW，MIXED</p> \n <ul>\n  <li>STATEMENT模式：binlog里面记录的就是SQL语句的原文。优点是并不需要记录每一行的数据变化，减少了binlog日志量，节约IO，提高性能。缺点是在某些情况下会导致master-slave中的数据不一致</li>\n  <li>ROW模式：不记录每条SQL语句的上下文信息，仅需记录哪条数据被修改了，修改成什么样了，解决了STATEMENT模式下出现master-slave中的数据不一致。缺点是会产生大量的日志，尤其是alter table的时候会让日志暴涨</li>\n  <li>MIXED模式：以上两种模式的混合使用，一般的复制使用STATEMENT模式保存binlog，对于STATEMENT模式无法复制的操作使用ROW模式保存binlog，MySQL会根据执行的SQL语句选择日志保存方式</li>\n </ul> \n <h3><a id=\"redo_log_4515\"></a><strong>redo log（重做日志）</strong></h3> \n <p>MySQL里常说的WAL技术，全称是Write Ahead Log，即当事务提交时，先写redo log，再修改页。</p> \n <p>也就是说，当有一条记录需要更新的时候，InnoDB会先把记录写到redo log里面，并更新Buffer Pool的page，这个时候更新操作就算完成了</p> \n <p>Buffer Pool是物理页的缓存，对InnoDB的任何修改操作都会首先在Buffer Pool的page上进行，然后这样的页将被标记为脏页并被放到专门的Flush List上，后续将由专门的刷脏线程阶段性的将这些页面写入磁盘</p> \n <p>InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB，循环使用，从头开始写，写到末尾就又回到开头循环写（顺序写，节省了随机写磁盘的IO消耗）</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/7224acb71a77c3f5d97f316dcf60b59d.png\" alt=\"7224acb71a77c3f5d97f316dcf60b59d.png\"></p> \n <p>Write Pos是当前记录的位置，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。</p> \n <p>Check Point是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件</p> \n <p>Write Pos和Check Point之间空着的部分，可以用来记录新的操作。如果Write Pos追上Check Point，这时候不能再执行新的更新，需要停下来擦掉一些记录，把Check Point推进一下</p> \n <p>当数据库发生宕机时，数据库不需要重做所有的日志，因为Check Point之前的页都已经刷新回磁盘，只需对Check Point后的redo log进行恢复，从而缩短了恢复的时间</p> \n <p>当缓冲池不够用时，根据LRU算法会溢出最近最少使用的页，若此页为脏页，那么需要强制执行Check Point，将脏页刷新回磁盘。</p> \n <p>InnoDB首先将redo log放入到redo log buffer，然后按一定频率将其刷新到redo log file</p> \n <p>下列三种情况下会将redo log buffer刷新到redo log file：</p> \n <ul>\n  <li> <p>Master Thread每一秒将redo log buffer刷新到redo log file</p> </li>\n  <li> <p>每个事务提交时会将redo log buffer刷新到redo log file</p> </li>\n  <li> <p>当redo log缓冲池剩余空间小于1/2时，会将redo log buffer刷新到redo log file</p> </li>\n </ul> \n <h3><a id=\"_4556\"></a><strong>两阶段提交</strong></h3> \n <p>将redo log的写入拆成了两个步骤：prepare和commit，这就是两阶段提交</p> \n <pre><code class=\"prism language-go\">create table <span class=\"token function\">T</span><span class=\"token punctuation\">(</span>ID <span class=\"token builtin\">int</span> primary key<span class=\"token punctuation\">,</span> c <span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nupdate T set c<span class=\"token operator\">=</span>c<span class=\"token operator\">+</span><span class=\"token number\">1</span> where ID<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">;</span>\n</code></pre> \n <p>执行器和InnoDB引擎在执行这个update语句时的内部流程：</p> \n <ul>\n  <li>执行器先找到引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据也本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回</li>\n  <li>执行器拿到引擎给的行数据，把这个值加上1，得到新的一行数据，再调用引擎接口写入这行新数据</li>\n  <li>引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务</li>\n  <li>执行器生成这个操作的binlog，并把binlog写入磁盘</li>\n  <li>执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交状态，更新完成</li>\n </ul> \n <p>update语句的执行流程图如下，图中浅色框表示在InnoDB内部执行的，深色框表示是在执行器中执行的</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/04c58afebecb9f83ffc8a6982e55bd5f.png\" alt=\"04c58afebecb9f83ffc8a6982e55bd5f.png\"></p> \n <h3><a id=\"redo_logbinlog_4583\"></a><strong>redo log和binlog日志的不同</strong></h3> \n <ul>\n  <li>redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用</li>\n  <li>redo log是物理日志，记录的是在某个数据上做了什么修改；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如给ID=2这一行的c字段加1</li>\n  <li>redo log是循环写的，空间固定会用完；binlog是可以追加写入的，binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志</li>\n </ul> \n <h3><a id=\"binlog_4593\"></a>binlog主从复制原理</h3> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/f752c82faa35276f40ebc9e882f10aeb.png\" alt=\"f752c82faa35276f40ebc9e882f10aeb.png\"></p> \n <p>从库B和主库A之间维持了一个长连接。主库A内部有一个线程，专门用于服务从库B的这个长连接。一个事务日志同步的完整过程如下：</p> \n <ul>\n  <li>在从库B上通过change master命令，设置主库A的IP、端口、用户名、密码，以及要从哪个位置开始请求binlog，这个位置包含文件名和日志偏移量</li>\n  <li>在从库B上执行start slave命令，这时从库会启动两个线程，就是图中的I/O线程和SQL线程。其中I/O线程负责与主库建立连接</li>\n  <li>主库A校验完用户名、密码后，开始按照从库B传过来的位置，从本地读取binlog，发给B</li>\n  <li>从库B拿到binlog后，写到本地文件，称为中继日志</li>\n  <li>SQL线程读取中继日志，解析出日志里的命令，并执行</li>\n </ul> \n <p>由于多线程复制方案的引入，SQL线程演化成了多个线程</p> \n <p>主从复制不是完全实时地进行同步，而是异步实时。这中间存在主从服务之间的执行延时，如果主服务器的压力很大，则可能导致主从服务器延时较大。</p> \n <h3><a id=\"ShardingJDBC_4613\"></a>Sharding-JDBC实现读写分离</h3> \n <p>使用Sharding-JDBC配置读写分离，优点在于数据源完全有Sharding托管，写操作自动执行master库，读操作自动执行slave库。不需要程序员在程序中关注这个实现了。</p> \n <pre><code>spring.main.allow-bean-definition-overriding=true\nspring.shardingsphere.datasource.names=master,slave\nspring.shardingsphere.datasource.master.type=com.alibaba.druid.pool.DruidDataSource\nspring.shardingsphere.datasource.master.driver-class-name=com.mysql.cj.jdbc.Driver\nspring.shardingsphere.datasource.master.url=jdbc:mysql://localhost:3306/db_master?characterEncoding=utf-8\nspring.shardingsphere.datasource.master.username=\nspring.shardingsphere.datasource.master.password=\nspring.shardingsphere.datasource.slave.type=com.alibaba.druid.pool.DruidDataSource\nspring.shardingsphere.datasource.slave.driver-class-name=com.mysql.cj.jdbc.Driver\nspring.shardingsphere.datasource.slave.url=jdbc:mysql://localhost:3306/db_slave?characterEncoding=utf-8\nspring.shardingsphere.datasource.slave.username=\nspring.shardingsphere.datasource.slave.password=\nspring.shardingsphere.masterslave.load-balance-algorithm-type=round_robin\nspring.shardingsphere.masterslave.name=dataSource\nspring.shardingsphere.masterslave.master-data-source-name=master\nspring.shardingsphere.masterslave.slave-data-source-names=slave\nspring.shardingsphere.props.sql.show=true\n\n</code></pre> \n <p>参数解读：</p> \n <p>load-balance-algorithm-type 用于配置从库负载均衡算法类型，可选值：ROUND_ROBIN(轮询)，RANDOM（随机）</p> \n <p>props.sql.show=true 在执行SQL时，会打印SQL，并显示执行库的名称</p> \n <h3><a id=\"Java_API_4650\"></a>Java API主从配置</h3> \n <p>分别给ds0和ds1准备从库：ds01和ds11，分别配置主从同步；读写分离配置如下：</p> \n <pre><code class=\"prism language-java\">		\nList<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>String<span class=\"token punctuation\">&gt;</span></span> slaveDataSourceNames1 <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">ArrayList</span><span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>String<span class=\"token punctuation\">&gt;</span></span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nslaveDataSourceNames1<span class=\"token punctuation\">.</span><span class=\"token function\">add</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"ds11\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nMasterSlaveRuleConfiguration masterSlaveRuleConfiguration1 <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">MasterSlaveRuleConfiguration</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"ds1\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"ds1\"</span><span class=\"token punctuation\">,</span>\n				slaveDataSourceNames1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nshardingRuleConfig<span class=\"token punctuation\">.</span><span class=\"token function\">getMasterSlaveRuleConfigs</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">add</span><span class=\"token punctuation\">(</span>masterSlaveRuleConfiguration1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n</code></pre> \n <p>这样在执行查询操作的时候会自动路由到从库，实现读写分离；</p> \n <h3><a id=\"MasterSlaveRuleConfiguration_4666\"></a>MasterSlaveRuleConfiguration</h3> \n <p>在上面章节介绍分片规则的时候，其中有说到主从规则配置，其目的就是用来实现读写分离的，核心配置类：<code>MasterSlaveRuleConfiguration</code>：</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">MasterSlaveRuleConfiguration</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">RuleConfiguration</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> String name<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> String masterDataSourceName<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> List<span class=\"token generics function\"><span class=\"token punctuation\">&lt;</span>String<span class=\"token punctuation\">&gt;</span></span> slaveDataSourceNames<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> LoadBalanceStrategyConfiguration loadBalanceStrategyConfiguration<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n</code></pre> \n <ul>\n  <li>name：配置名称，当前使用的4.1.0版本，这里必须是主库的名称；</li>\n  <li>masterDataSourceName：主库数据源名称；</li>\n  <li>slaveDataSourceNames：从库数据源列表，可以配置一主多从；</li>\n  <li>LoadBalanceStrategyConfiguration：面对多个从库，读取的时候会通过负载算法进行选择；</li>\n </ul> \n <p>主从负载算法类：<code>MasterSlaveLoadBalanceAlgorithm</code>，实现类包括：随机和循环；</p> \n <ul>\n  <li>ROUND_ROBIN：实现类<code>RoundRobinMasterSlaveLoadBalanceAlgorithm</code></li>\n  <li>RANDOM：实现类<code>RandomMasterSlaveLoadBalanceAlgorithm</code></li>\n </ul> \n <h3><a id=\"%E3%80%80_4694\"></a>问题：　读写分离架构中经常出现，那就是读延迟的问题如何解决？</h3> \n <p>刚插入一条数据，然后马上就要去读取，这个时候有可能会读取不到？归根到底是因为主节点写入完之后数据是要复制给从节点的，读不到的原因是复制的时间比较长，也就是说数据还没复制到从节点，你就已经去从节点读取了，肯定读不到。mysql5.7 的主从复制是多线程了，意味着速度会变快，但是不一定能保证百分百马上读取到，这个问题我们可以有两种方式解决：</p> \n <p>（1）业务层面妥协，是否操作完之后马上要进行读取</p> \n <p>（2）对于操作完马上要读出来的，且业务上不能妥协的，我们可以对于这类的读取直接走主库，当然Sharding-JDBC也是考虑到这个问题的存在，所以给我们提供了一个功能，可以让用户在使用的时候指定要不要走主库进行读取。在读取前使用下面的方式进行设置就可以了：</p> \n <pre><code>    public List&lt;UserInfo&gt; getList() {\n        // 强制路由主库\n        HintManager.getInstance().setMasterRouteOnly();\n        return this.list();\n    }\n</code></pre> \n <h3><a id=\"Mysql_4714\"></a>问题：Mysql主从环境部署一段时间后，发现主从不同步时，如何进行数据同步至一致？</h3> \n <p>规避性答法：dba解决</p> \n <h2><a id=\"_4724\"></a>分布式事务</h2> \n <p>ShardingSphere-JDBC使用分布式事务和使用本地事务没什么区别，提供了透明化的分布式事务；</p> \n <p>支持的事务类型包括：本地事务、XA事务和柔性事务，默认是本地事务；</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">enum</span> TransactionType <span class=\"token punctuation\">{\n    <!-- --></span>\n    LOCAL<span class=\"token punctuation\">,</span> XA<span class=\"token punctuation\">,</span> BASE\n<span class=\"token punctuation\">}</span>\n\n</code></pre> \n <h3><a id=\"_4737\"></a>依赖</h3> \n <p>根据具体使用XA事务还是柔性事务，需要引入不同的模块；</p> \n <pre><code class=\"prism language-xml\"><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>dependency</span><span class=\"token punctuation\">&gt;</span></span>\n	<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>groupId</span><span class=\"token punctuation\">&gt;</span></span>org.apache.shardingsphere<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>groupId</span><span class=\"token punctuation\">&gt;</span></span>\n	<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>artifactId</span><span class=\"token punctuation\">&gt;</span></span>sharding-transaction-xa-core<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>artifactId</span><span class=\"token punctuation\">&gt;</span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>dependency</span><span class=\"token punctuation\">&gt;</span></span>\n\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>dependency</span><span class=\"token punctuation\">&gt;</span></span>\n	<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>groupId</span><span class=\"token punctuation\">&gt;</span></span>org.apache.shardingsphere<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>groupId</span><span class=\"token punctuation\">&gt;</span></span>\n	<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>artifactId</span><span class=\"token punctuation\">&gt;</span></span>shardingsphere-transaction-base-seata-at<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>artifactId</span><span class=\"token punctuation\">&gt;</span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>dependency</span><span class=\"token punctuation\">&gt;</span></span>\n\n</code></pre> \n <h3><a id=\"_4754\"></a>实现</h3> \n <p>ShardingSphere-JDBC提供了分布式事务管理器<code>ShardingTransactionManager</code>，实现包括：</p> \n <ul>\n  <li>XAShardingTransactionManager：基于 XA 的分布式事务管理器；</li>\n  <li>SeataATShardingTransactionManager：基于 Seata 的分布式事务管理器；</li>\n </ul> \n <p>XA 的分布式事务管理器具体实现包括：Atomikos、Narayana、Bitronix；默认是Atomikos；</p> \n <h3><a id=\"_4763\"></a>实战</h3> \n <p>默认的事务类型是TransactionType.LOCAL，ShardingSphere-JDBC天生面向多数据源，本地模式其实是循环提交每个数据源的事务，不能保证数据的一致性，所以需要使用分布式事务，具体使用也很简单：</p> \n <pre><code class=\"prism language-java\"><span class=\"token comment\">//改变事务类型为XA</span>\nTransactionTypeHolder<span class=\"token punctuation\">.</span><span class=\"token function\">set</span><span class=\"token punctuation\">(</span>TransactionType<span class=\"token punctuation\">.</span>XA<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nDataSource dataSource <span class=\"token operator\">=</span> ShardingDataSourceFactory<span class=\"token punctuation\">.</span><span class=\"token function\">createDataSource</span><span class=\"token punctuation\">(</span>dataSourceMap<span class=\"token punctuation\">,</span> shardingRuleConfig<span class=\"token punctuation\">,</span>\n				<span class=\"token keyword\">new</span> <span class=\"token class-name\">Properties</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nConnection conn <span class=\"token operator\">=</span> dataSource<span class=\"token punctuation\">.</span><span class=\"token function\">getConnection</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">try</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n	<span class=\"token comment\">//关闭自动提交</span>\n	conn<span class=\"token punctuation\">.</span><span class=\"token function\">setAutoCommit</span><span class=\"token punctuation\">(</span><span class=\"token boolean\">false</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n			\n	String sql <span class=\"token operator\">=</span> <span class=\"token string\">\"insert into t_order (user_id,order_id) values (?,?)\"</span><span class=\"token punctuation\">;</span>\n	PreparedStatement preparedStatement <span class=\"token operator\">=</span> conn<span class=\"token punctuation\">.</span><span class=\"token function\">prepareStatement</span><span class=\"token punctuation\">(</span>sql<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n	<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;=</span> <span class=\"token number\">5</span><span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n		preparedStatement<span class=\"token punctuation\">.</span><span class=\"token function\">setInt</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> i <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n		preparedStatement<span class=\"token punctuation\">.</span><span class=\"token function\">setInt</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> i <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n		preparedStatement<span class=\"token punctuation\">.</span><span class=\"token function\">executeUpdate</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n	<span class=\"token punctuation\">}</span>\n	<span class=\"token comment\">//事务提交</span>\n	conn<span class=\"token punctuation\">.</span><span class=\"token function\">commit</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">Exception</span> e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n	e<span class=\"token punctuation\">.</span><span class=\"token function\">printStackTrace</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n	<span class=\"token comment\">//事务回滚</span>\n	conn<span class=\"token punctuation\">.</span><span class=\"token function\">rollback</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n</code></pre> \n <p>可以发现使用起来还是很简单的，ShardingSphere-JDBC会根据当前的事务类型，在提交的时候判断是走本地事务提交，还是使用分布式事务管理器<code>ShardingTransactionManager</code>进行提交；</p> \n <h2><a id=\"SnowFlake_4800\"></a>SnowFlake时钟回拨问题</h2> \n <p>SnowFlake很好，分布式、去中心化、无第三方依赖。</p> \n <p>但它并不是完美的，由于SnowFlake强依赖时间戳，所以时间的变动会造成SnowFlake的算法产生错误。</p> \n <p><strong>时钟回拨</strong>:最常见的问题就是时钟回拨导致的ID重复问题，在SnowFlake算法中并没有什么有效的解法，仅是抛出异常。时钟回拨涉及两种情况①实例停机→时钟回拨→实例重启→计算ID ②实例运行中→时钟回拨→计算ID</p> \n <p><strong>手动配置</strong>:另一个就是workerId（机器ID）是需要部署时手动配置，而workerId又不能重复。几台实例还好，一旦实例达到一定量级，管理workerId将是一个复杂的操作。</p> \n <h3><a id=\"ntp_4810\"></a>ntp导致的时钟回拨</h3> \n <p>我们的服务器时间校准一般是通过ntp进程去校准的。但由于校准这个动作，会导致时钟跳跃变化的现象。<br> 而这种情况里面，往往回拨最能引起我们的困扰,回拨如下所示:</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/6256494d0ad2d38a303d2bb19a2fd791.png\" alt=\"img\"></p> \n <h3><a id=\"_4819\"></a>时钟回拨改进避免</h3> \n <p>ID生成器一旦不可用，可能造成所有数据库相关新增业务都不可用，影响太大。所以时钟回拨的问题必须解决。</p> \n <p>造成时钟回拨的原因多种多样，可能是闰秒回拨，可能是NTP同步，还可能是服务器时间手动调整。总之就是时间回到了过去。针对回退时间的多少可以进行不同的策略改进。</p> \n <p>一般有以下几种方案：</p> \n <ol>\n  <li>少量服务器部署ID生成器实例，关闭NTP服务器，严格管理服务器。这种方案不需要从代码层面解决，完全人治。</li>\n  <li>针对回退时间断的情况，如闰秒回拨仅回拨了1s，可以在代码层面通过判断暂停一定时间内的ID生成器使用。虽然少了几秒钟可用时间，但时钟正常后，业务即可恢复正常。</li>\n </ol> \n <pre><code class=\"prism language-csharp\"><span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>refusedSeconds <span class=\"token operator\">&lt;=</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token keyword\">try</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token comment\">//时间偏差大小小于5ms，则等待两倍时间</span>\n		<span class=\"token function\">wait</span><span class=\"token punctuation\">(</span>refusedSeconds <span class=\"token operator\">&lt;</span><span class=\"token operator\">&lt;</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span class=\"token comment\">//wait</span>\n	<span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">InterruptedException</span> e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n		e<span class=\"token punctuation\">.</span><span class=\"token function\">printStackTrace</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n	<span class=\"token punctuation\">}</span>\n    currentSecond <span class=\"token operator\">=</span> <span class=\"token function\">getCurrentSecond</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span class=\"token keyword\">else</span> <span class=\"token punctuation\">{\n    <!-- --></span><span class=\"token comment\">//时钟回拨较大</span>\n    <span class=\"token comment\">//用其他策略修复时钟问题</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>实例启动后，改用内存生成时间。</p> \n <p>该方案为baidu开源的UidGenerator使用的方案，由于实例启动后，时间不再从服务器获取，所以不管服务器时钟如何回拨，都影响不了SnowFlake的执行。</p> \n <p>如下代码中lastSecond变量是一个AtomicLong类型，用以代替系统时间</p> \n <pre><code class=\"prism language-kotlin\"> List<span class=\"token operator\">&lt;</span>Long<span class=\"token operator\">&gt;</span> uidList <span class=\"token operator\">=</span> uidProvider<span class=\"token punctuation\">.</span><span class=\"token function\">provide</span><span class=\"token punctuation\">(</span>lastSecond<span class=\"token punctuation\">.</span><span class=\"token function\">incrementAndGet</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre> \n <p>以上2和3都是解决时钟<code>实例运行中→时钟回拨→计算ID</code>的情况。</p> \n <p>而<code>实例停机→时钟回拨→实例重启→计算ID</code>的情况，可以通过实例启动的时候，采用未使用过的workerId来完成。</p> \n <p>只要workerId和此前生成ID的workerId不一致，即便时间戳有误，所生成的ID也不会重复。</p> \n <p>UidGenerator采取的就是这种方案，但这种方案又必须依赖一个存储中心，不管是redis、mysql、zookeeper都可以，但必须存储着此前使用过的workerId，不能重复。</p> \n <p>尤其是在分布式部署Id生成器的情况下，更要注意用一个存储中心解决此问题。</p> \n <blockquote> \n  <p>UidGenerator代码可上Githubhttps://github.com/zer0Black/uid-generator查看</p> \n </blockquote> \n <h2><a id=\"_4872\"></a>说明：本文未完待续，后续在博客园会更新</h2> \n <h2><a id=\"_4878\"></a>参考文档：</h2> \n <p>https://www.jianshu.com/p/d3c1ee5237e5</p> \n <p>https://www.cnblogs.com/zer0black/p/12323541.html?ivk_sa=1024320u</p> \n <p>https://shardingsphere.apache.org/document/current/cn/features/sharding/use-norms/sql/</p> \n <p>https://blog.csdn.net/free_ant/article/details/111461606</p> \n <p>https://www.jianshu.com/p/46b42f7f593c</p> \n <p>https://blog.csdn.net/yangguosb/article/details/78772730</p> \n <p>https://blog.csdn.net/youanyyou/article/details/121005680</p> \n <p>https://www.cnblogs.com/huanshilang/p/12055296.html</p> \n <p>https://www.cnblogs.com/haima/p/14341903.html</p> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 25159);
INSERT INTO `crawlerblog` VALUES (123124019, 'clickhouse 超底层原理 + 高可用实操 （史上最全）', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <p>文章很长，建议收藏起来慢慢读！ <a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\"><strong>总目录 博客园版</strong></a> 为大家准备了更多的好文章！！！！</p> \n <h2><a id=\"Java____httpswwwcnblogscomcrazymakercirclep13917138html_2\"></a>推荐：尼恩Java面试宝典（持续更新 + 史上最全 + 面试必备）<a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\">具体详情，请点击此链接</a></h2> \n <p>尼恩Java面试宝典，<strong>34个最新pdf</strong>，含<strong>2000多页</strong>，<strong>不断更新、持续迭代</strong> <a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\">具体详情，请点击此链接</a></p> \n <p><img src=\"https://img-blog.csdnimg.cn/729b33f6bc37429385edbef85fd805c3.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h2><a id=\"_7\"></a>本文背景</h2> \n <p>这段时间给大家 做简历指导，发现大家都缺少优质实操项目，所以打算介绍一个《100W级别qps日志平台实操》，基于clickhouse+netty，于是，就写了此文</p> \n <p>此文设计到<strong>大量的底层原理，和高并发的实操知识，建议大家慢慢读</strong>，</p> \n <p>并且强烈建议大，<strong>对着此文，实操一下</strong>。</p> \n <h2><a id=\"MPP_17\"></a>MPP数据库简介</h2> \n <h3><a id=\"OLTPOLAP_19\"></a><strong>什么是OLTP与OLAP？</strong></h3> \n <h4><a id=\"OLTPOnLine_Transaction_Processing____21\"></a>OLTP(OnLine Transaction Processing ) 联机事务处理 系统</h4> \n <p>例如mysql。</p> \n <p>擅长事务处理，在数据操作中保持着很强的一致性和原子性 ，能够很好的支持频繁的数据插入和修改 ，但是，一旦数据量过大，OLTP便力不从心了。</p> \n <h4><a id=\"OLAPOnLine_Analytical_Processing__27\"></a>OLAP(On-Line Analytical Processing)联机分析处理 系统</h4> \n <p>例如clickhouse，greenplum，Doris。</p> \n <p>不特别关心对数据进行输入、修改等事务性处理，而是关心对已有 的大量数据进行多维度的、复杂的分析的一类数据系统 。</p> \n <h4><a id=\"ClickHouse__35\"></a>ClickHouse 简介</h4> \n <p>ClickHouse的全称是Click Stream，Data WareHouse。</p> \n <p>ClickHouse 是俄罗斯的 Yandex （俄罗斯第一大搜索引擎） 于 2016 年开源的用于<strong>在线分析处理查询</strong>（OLAP :Online Analytical Processing）<strong>MPP架构</strong>的<strong>列式存储数据库</strong>（DBMS：Database Management System），能够使用 SQL 查询实时生成分析数据报告。</p> \n <p>ClickHouse 使用 C++ 语言编写，主要用于在线分析处理查询（OLAP），能够使用 SQL 查询实时生成分析数据报<br> 告。</p> \n <p>clickhouse可以做用户行为分析，流批一体</p> \n <p>clickhouse没有走hadoop生态，采用 Local attached storage 作为存储</p> \n <p>令人惊喜的是，ClickHouse 的性能大幅超越了很多商业 MPP 数据库软件，比如 Vertica,InfiniDB.</p> \n <p>相比传统的数据库软件，ClickHouse 要快 100-1000X:</p> \n <p>100Million 数据集:</p> \n <p>ClickHouse 比 Vertica 约快 5 倍，比 Hive 快 279 倍，比 My SQL 快 801 倍</p> \n <p>1Billion 数据集:</p> \n <p>ClickHouse 比 Vertica 约快 5 倍，MySQL 和 Hive 已经无法完成任务了</p> \n <h4><a id=\"Greenplum_62\"></a>Greenplum简介</h4> \n <p>Greenplum是一家总部位于美国加利福尼亚州，为全球大型企业用户提供新型企业级数据仓库(EDW)、企业级数据云(EDC)和商务智能(BI)提供解决方案和咨询服务的公司，</p> \n <p>在全球已有：[纳斯达克，[纽约证券交易所，Skype. FOX，T-Mobile;</p> \n <p>中国已有：中信实业银行，东方航空公司，阿里巴巴，华泰保险，中国远洋，李宁公司等大型企业用户选择Greenplum的产品。</p> \n <p><em>Greenplum</em>的架构采用了<strong>MPP</strong>(大规模并行处理)。</p> \n <p>Greenplum名字来源</p> \n <p><em>Greenplum</em>的大中华区总裁Stanley Chen告诉我们：“<em>Greenplum</em>这个名字是一个7岁小女孩无意中脱口而出的。”起初几个创始人在斟酌公司名字的时候都很没头绪，于是他们去问了朋友的孩子，一个年仅7岁的可爱小姑娘告诉他们叫“<em>Apple</em>”，但是爸爸告诉她，这个名字已经被别人用了，还有其他的么?很快孩子便随口说了“<em>Greenplum</em>”，于是“<em>Greenplum</em>”公司的名字就这样诞生了。**</p> \n <h4><a id=\"Doris_78\"></a>Doris简介</h4> \n <p>Doris由百度大数据部研发 ，之前叫百度 Palo，2018年贡献到 Apache 社区后，更名为 doris</p> \n <p>Doris是一个MPP的OLAP系统，以较低的成本提供在大数据集上的高性能分析和报表查询功能。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/957ad5f21c482139bb4ddb3c27412873.png\" alt=\"图片\"></p> \n <h4><a id=\"StoneDB_90\"></a>StoneDB介绍</h4> \n <blockquote> \n  <p>此处的介绍，目的是 推广国产软件， 国产软件，不容易呀</p> \n </blockquote> \n <p>StoneDB是国内首款基于MySQL的实时HTAP数据库产品， 由杭州石原子科技有限公司自主设计、研发的 基于 MySQL 内核打造的开源 HTAP（Hybrid Transactional and Analytical Processing）融合型数据库产品，可实现与 MySQL 的无缝切换。StoneDB 具备高性能、实时分析等特点，为用户提供一站式HTAP解决方案。StoneDB是一款兼容 MySQL的 HTAP 数据库，可以实现从MySQL到StonDB的无缝切换。</p> \n <p>StoneDB 是基于 MySQL 内核打造的开源 HTAP (Hybrid Transactional and Analytical Processing) 融合型数据库，可实现与 MySQL 的无缝切换。StoneDB 具备超高性能、实时分析等特点，为用户提供一站式 HTAP 解决方案。</p> \n <p>StoneDB 包含 100% 兼容 MySQL 5.6、5.7 协议，以及 MySQL 生态等重要特性，支持 MySQL 常用的功能及语法，支持 MySQL 生态中的系统工具和客户端，如 Navicat、Workbench、mysqldump、mydumper。由于 100% 兼容 MySQL，因此 StoneDB 的所有工作负载都可以继续使用 MySQL 数据库体系运行。</p> \n <p>StoneDB 专门针对 OLAP 应用程序进行了设计和优化，支持百亿数据场景下进行高性能、多维度字段组合的复杂查询。</p> \n <p>StoneDB 采用基于知识网格技术和列式存储引擎，该存储引擎为海量数据背景下 OLAP 应用而设计，通过列式存储数据、知识网格过滤、高效数据压缩等技术，为应用系统提供低成本和高性能的数据查询支持。</p> \n <h3><a id=\"MPP__104\"></a>什么是MPP 系统</h3> \n <p><strong>什么是 大规模并行处理 MPP架构？（Massively Parallel Processing）</strong></p> \n <p>MPP架构是将任务并行的分散到多个服务器和节点上，在每个节点上计算完成后，将各自部分的结果汇总在一起得到最终的结果。</p> \n <p>采用MPP架构的数据库称为MPP数据库。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/35d963632f61dd0c9da46bd8585f7703.jpeg\" alt=\"img\"></p> \n <p>在 MPP 系统中，每个 单节点也可以运行自己的操作系统、数据库等。</p> \n <p>换言之，每个节点内的 CPU 不能访问另一个节点的内存。</p> \n <p>节点之间的信息交互是通过节点互联网络实现的，这个过程一般称为<strong>数据重分配</strong>(<em>Data Redistribution</em>) 。</p> \n <p>与传统的单体架构 明显不同，MPP系统因为 要在不同处理单元之间传送信息，</p> \n <ul>\n  <li>当数据规模很小的时候，MPP的效率要比单体架构要差一点，</li>\n  <li>但是当数据规模上来之后，MPP的效率要比 单体架构 好。</li>\n </ul> \n <p>这就是看通信时间占用计算时间的比例而定，如果通信时间比较多，那MPP系统就不占优势了，相反，如果通信时间比较少，那MPP系统可以充分发挥资源的优势，达到高效率。</p> \n <h3><a id=\"MPP_133\"></a>为什么需要MPP数据库？</h3> \n <h4><a id=\"_135\"></a><strong>海量数据的分析需求</strong></h4> \n <p>传统数据库无法支持大规模集群与PB级别数据量</p> \n <p>单台机器性能受限、成本高昂，扩展性受限</p> \n <h4><a id=\"_141\"></a><strong>支持复杂的结构化查询（这里是重点）</strong></h4> \n <p>复杂查询经常使用多表联结、全表扫描等，牵涉的数据量往往十分庞大；</p> \n <p>支持复杂sql查询和支持大数据规模；</p> \n <h4><a id=\"Hadoop_147\"></a>Hadoop技术的先天不足</h4> \n <p>Hive等sql-on-hadoop性能太慢，分析场景不一样，SQL兼容性与支持不足</p> \n <h4><a id=\"MPP_151\"></a>MPP数据库应用领域</h4> \n <p><strong>大数据分析</strong>：</p> \n <p>MPP数据库做大数据计算或分析平台非常适合，例如:数据仓库系统、历史数据管理系统、数据集市等。</p> \n <p>MPP数据库有很强的并行数据计算能力和海量数据存储能力，、</p> \n <p>所以，**报表统计分析、**运维统计数据，快速生成报表展示都可以使用mpp数据库。</p> \n <p>符合几个条件：不需要更新数据，不需要频繁重复离线计算，不需要并发大。</p> \n <p>有上百亿以上离线数据，不更新，结构化，需要各种复杂分析的sql语句，那就可以选择他。</p> \n <p>几秒、几十秒立即返回你想要的分析结果。</p> \n <p>例如sum，count，group by，order，好几层查询嵌套，在几百亿数据里分分钟出结果</p> \n <p>这类的数据库：，clickhouse，greenplum，Doris</p> \n <p>MPP数据库不擅长高频的小规模数据插入、修改、删除，每次事务处理的数据量不大。</p> \n <p>这类数据衡量指标是TPS，适用的系统是OLTP数据库。</p> \n <h2><a id=\"Clickhouse_177\"></a>Clickhouse特性</h2> \n <p>Clickhouse是一个列式数据库管理系统，在OLAP领域像一匹黑马一样，以其超高的性能受到业界的青睐。</p> \n <h3><a id=\"Clickhouse_181\"></a>Clickhouse的优势特性：</h3> \n <h4><a id=\"_185\"></a>数据分区与线程级并行</h4> \n <p>ClickHouse支持PARTITION BY子句，在建表时可以指定按照任意合法表达式进行数据分区操作，</p> \n <p>比如通过toYYYYMM()将数据按月进行分区、toMonday()将数据按照周几进行分区。</p> \n <p>分区条件查询，只能读取包含适当分区数据块，而不扫描过多的数据。</p> \n <p>灵活的使用，可以大大提升查询的性能。</p> \n <p>ClickHouse 将数据划分为多个 partition，每个 partition 再进一步划分为多个 index granularity(索引粒度)，</p> \n <p>然后通过多个 CPU核心分别处理其中的一部分来实现并行数据处理。</p> \n <p>在这种设计下，单条 Query 就能利用整机所有 CPU。</p> \n <p>极致的并行处理能力，极大的降低了查询延时。</p> \n <p>所以，ClickHouse 即使对于大量数据的查询也能够化整为零平行处理。</p> \n <p>但是有一个弊端就是对于单条查询使用多 cpu，就不利于同时并发多条查询。所以对于高 qps 的查询业务，ClickHouse 并不是强项。</p> \n <h4><a id=\"_213\"></a>采用列式存储，数据类型一致，压缩性能更高</h4> \n <p>在一些列式数据库管理系统中(例如InfiniDB CE和MonetDB) 并没有使用数据压缩。&gt;</p> \n <blockquote> \n  <p>InfiniDB Community Edition（社区版）提供一个可伸缩的分析型数据库引擎，主要为数据仓库、商业智能、以及对实时性要求不严格的应用而开发。基于MySQL搭建。包括对查询、事务处理以及大数据量加载的支持。</p> \n  <p>MonetDB是一个开源的面向列的数据库管理系统。MonetDB被设计用来为较大规模数据（如几百万行和数百列的数据库表）提供高性能查询的支持。</p> \n </blockquote> \n <p>但是, 若想达到比较优异的性能，数据压缩确实起到了至关重要的作用。</p> \n <p>提供 LZ4、ZSTD 两种数据压缩格式</p> \n <h4><a id=\"IO_225\"></a>硬件利用率高，连续IO，提高了磁盘驱动器的效率</h4> \n <p>许多的列式数据库(如 SAP HANA, Google PowerDrill)只能在内存中工作，这种方式会造成比实际更多的设备预算。</p> \n <p>ClickHouse被设计用于工作在传统磁盘上的系统，它提供每GB更低的存储成本，但如果有可以使用SSD和内存，它也会合理的利用这些资源</p> \n <h4><a id=\"SIMDCPU_231\"></a>向量化引擎与SIMD提高了CPU利用率，多核多节点并行化大查询</h4> \n <p>为了高效的使用CPU，数据不仅仅按列存储，同时还按向量(列的一部分)进行处理，这样可以更加高效地使用CPU</p> \n <p>ClickHouse会使用服务器上一切可用的资源，从而以最自然的方式并行处理大型查询</p> \n <h4><a id=\"SQL_237\"></a>支持SQL</h4> \n <p>ClickHouse支持基于SQL的声明式查询语言，该语言大部分情况下是与SQL标准兼容的。几乎覆盖了标准SQL的大部分语法，包括DDL和DML，以及配套的各种函数，用户管理及权限管理，数据的备份与恢复<br> 支持的查询包括 GROUP BY，ORDER BY，IN，JOIN以及非相关子查询。<br> 绝大部分查询基本和常用的mysql一样，可以省去大部分同学的学习成本。不仅如此提供了强大的函数支查询能力，更丰富的存储格式，例如array多维数组、json、tuple、set等。</p> \n <h4><a id=\"_245\"></a>支持近似计算</h4> \n <p>ClickHouse提供各种各样在允许牺牲数据精度的情况下对查询进行加速的方法：</p> \n <blockquote> \n  <ol>\n   <li> <p>用于近似计算的各类聚合函数，如：distinct values, medians, quantiles</p> </li>\n   <li> <p>基于数据的部分样本进行近似查询。这时，仅会从磁盘检索少部分比例的数据。</p> </li>\n   <li> <p>不使用全部的聚合条件，通过随机选择有限个数据聚合条件进行聚合。这在数据聚合条件满足某些分布条件下，在提供相当准确的聚合结果的同时降低了计算资源的使用。</p> </li>\n  </ol> \n </blockquote> \n <h4><a id=\"_259\"></a>索引</h4> \n <ul>\n  <li>主键索引</li>\n </ul> \n <p>ClickHouse支持主键索引，它将每列数据按照index granularity（默认8192行）进行划分，会为每个数据片段创建一个索引文件，索引文件包含每个索引行（『标记』）的主键值。</p> \n <p>索引行号定义为 n * index_granularity 。当数据被插入到表中时，会分成数据片段并按主键的字典序排序。例如，主键是 (CounterID, Date) 时，片段中数据按 CounterID 排序，具有相同 CounterID 的部分按 Date 排序。</p> \n <p>但是值得注意的是：ClickHouse 不要求主键惟一。</p> \n <p>所以，你可以插入多条具有相同主键的行。</p> \n <p>要想实现去重效果，需要结合具体的表引擎ReplacingMergeTree、CollapsingMergeTree、VersionedCollapsingMergeTree实现。</p> \n <ul>\n  <li> <h5><a id=\"_275\"></a>稀疏索引</h5> </li>\n </ul> \n <p>ClickHouse支持对任意列创建任意数量的稀疏索引。其中被索引的value可以是任意的合法SQL Expression，并不仅仅局限于对column value本身进行索引。之所以叫稀疏索引，是因为它本质上是对一个完整index granularity（默认8192行）的统计信息，并不会具体记录每一行在文件中的位置。</p> \n <h4><a id=\"_281\"></a>支持近似计算</h4> \n <p>ClickHouse提供各种各样在允许牺牲数据精度的情况下对查询进行加速的方法：</p> \n <blockquote> \n  <ol>\n   <li>用于近似计算的各类聚合函数，如：distinct values, medians, quantiles</li>\n   <li>基于数据的部分样本进行近似查询。这时，仅会从磁盘检索少部分比例的数据。</li>\n   <li>不使用全部的聚合条件，通过随机选择有限个数据聚合条件进行聚合。这在数据聚合条件满足某些分布条件下，在提供相当准确的聚合结果的同时降低了计算资源的使用。</li>\n  </ol> \n </blockquote> \n <h4><a id=\"_289\"></a>丰富的表引擎</h4> \n <p>ClickHouse和MySQL类似，把表级的存储引擎插件化，根据表的不同需求可以设定不同的存储引擎。</p> \n <p>目前包括合并树，日志，接口和其他四大类20多种引擎。</p> \n <p>clickhouse 不仅拥有自己强大的MergeTree家族的多种本地引擎外，还提供了丰富的外部引擎供我们选择，包括但不限于：kafka、HDFS、Mysql。<br> 但是使用外部引擎的时，性能自然会不如本地存储。</p> \n <pre><code class=\"prism language-undefined\">MergeTree引擎家族中很有很多优秀的引擎\n比如：\n    适合人物画像的AggregatingMergeTree引擎\n    可自定义去重的SummingMergeTree引擎\n    折叠树CollapsingMergeTree\n    用于Graphite监控的GraphiteMergeTree引擎\n    。。。\n这些都具有数据副本的能力  Replicated*\n官方推荐的适合大多数场景的依然是MergeTree引擎，其家族中其他引擎大多也是在其基础上做的封装。\n</code></pre> \n <blockquote> \n  <p>除此之外，还有分布式的表引擎Distributed。 Distributed是一种逻辑表引擎，并不存储数据。</p> \n  <p>创建该表引擎时，会指向已配置的分片集，要查询的时候，它会向每个分片发起查询并最终汇总集合然后返回。<br> 这里配置分片集可超灵活的配置，不用的时候可以删除。以后会单独来介绍该引擎的使用。</p> \n </blockquote> \n <h4><a id=\"shardreplica_321\"></a>基于shard+replica实现的线性扩展和高可靠</h4> \n <h4><a id=\"clickhouse_325\"></a>clickhouse高吞吐写入能力</h4> \n <p>ClickHouse 采用类 LSM Tree的结构，数据写入后定期在后台 Compaction。</p> \n <p>通过类 LSM tree的结构，ClickHouse 在数据导入时全部是顺序 append 写，写入后数据段不可更改，</p> \n <p>在后台compaction 时也是多个段 merge sort 后顺序写回磁盘。</p> \n <p>顺序写的特性，充分利用了磁盘的吞吐能力，即便在 HDD 上也有着优异的写入性能。</p> \n <p>官方公开 benchmark 测试显示能够达到 50MB-200MB/s 的写入吞吐能力，按照每行100Byte 估算，大约相当于 50W-200W 条/s 的写入速度。</p> \n <h2><a id=\"LSMLog_Structured_Merge_Tree_339\"></a>LSM结构（Log Structured Merge Tree）解读</h2> \n <p>1996年，一篇名为 Thelog-structured merge-tree（LSM-tree）的论文创造性地提出了日志结构合并树（ Log-Structured Merge-Tree）的概念，该方法既吸收了日志结构方法的优点，又通过将数据文件预排序克服了日志结构方法随机读性能较差的问题。</p> \n <p>尽管当时 LSM-tree新颖且优势鲜明，但它真正声名鹊起却是在 10年之后的 2006年，</p> \n <p>2006年，Google 发表了 BigTable 的论文。这篇论文提到 BigTable 单机上所使用的数据结构就是 LSM。</p> \n <p>那年谷歌的一篇使用了 LSM-tree技术的论文 Bigtable: A Distributed Storage System for Structured Data横空出世，在分布式数据处理领域掀起了一阵旋风，</p> \n <p>随后两个声名赫赫的大数据开源组件（ 2007年的 HBase与 2008年的 Cassandra，目前两者同为 Apache顶级项目）直接在其思想基础上破茧而出，彻底改变了大数据基础组件的格局，同时也极大地推广了 LSM-tree技术。</p> \n <p>目前，LSM 被很多存储产品作为存储结构，比如 Apache HBase, Apache Cassandra, MongoDB 的 Wired Tiger 存储引擎, LevelDB 存储引擎, RocksDB 存储引擎等。</p> \n <p>简单地说，LSM 的设计目标是提供比传统的 B+ 树更好的写性能。</p> \n <p>LSM 通过将磁盘的随机写转化为顺序写来提高写性能 ，而付出的代价就是牺牲部分读性能、写放大（B+树同样有写放大的问题）。</p> \n <p>LSM-tree最大的特点是同时使用了两部分类树的数据结构来存储数据，并同时提供查询。</p> \n <p>其中一部分数据结构（ C0树）存在于内存缓存（通常叫作 memtable）中，负责接受新的数据插入更新以及读请求，并直接在内存中对数据进行排序；</p> \n <p>另一部分数据结构（ C1树）存在于硬盘上 (这部分通常叫作 sstable)，它们是由存在于内存缓存中的 C0树冲写到磁盘而成的，主要负责提供读操作，特点是有序且不可被更改。</p> \n <p>LSM 相比 B+ 树能提高写性能的本质原因是：</p> \n <blockquote> \n  <p>外存——无论磁盘还是 SSD，其随机读写都要慢于顺序读写。</p> \n </blockquote> \n <h3><a id=\"hashB_379\"></a>hash表和B+树</h3> \n <p>在了解LSM树之前，我们需要对hash表和B+树有所了解。</p> \n <p>hash表就不用说了，通过key值经过hash算法，直接定位到数据存储地址，然后取出value值。时间复杂度O（1），找数据和存数据就需要那么一下子，就给找到了</p> \n <p>hash存储方式支持增、删、改以及随机读取操作，但不支持顺序扫描，对应的存储系统为key-value存储系统。对于key-value的插入以及查询，哈希表的复杂度都是O(1)，明显比树的操作O(n)快,如果不需要有序的遍历数据，哈希表就是最佳选择</p> \n <p>B+树我们常用的数据库Mysql的底层数据结构，例如我们的索引就是B+树结构。</p> \n <p>B+树是一种专门针对磁盘存储而优化的N叉排序树，以树节点为单位存储在磁盘中，从根开始查找所需数据所在的节点编号和磁盘位置，将起加载到内存中然后继续查找，直到找到所需的数据。</p> \n <p>B+树既有排序树的优点，能够很快沿着树枝找打目标节点，又能防止树的高度过高，大大减少磁盘IO次数。还能进行快速全表扫描遍历。</p> \n <p>B+ 树的三个特点：</p> \n <ol>\n  <li>节点的子树数和关键字数相同</li>\n  <li>非叶子节点仅用作索引，它的关键字和子节点有重复元素</li>\n  <li>叶子节点形成有序链表，包含了全部数据，同时符合左小右大的顺序<br> <img src=\"https://img-blog.csdnimg.cn/20190504012504539.png\" alt=\"在这里插入图片描述\"></li>\n </ol> \n <p>B+树改进了B树, 让内结点只作索引使用, 去掉了其中指向data record的指针, 使得每个结点中能够存放更多的key, 因此能有更大的出度.</p> \n <blockquote> \n  <p>这有什么用? 这样就意味着存放同样多的key, 树的层高能进一步被压缩, 使得检索的时间更短。</p> \n </blockquote> \n <h4><a id=\"BB_410\"></a><strong>B树和B+树的对比介绍</strong></h4> \n <p>首先从二叉树说起，</p> \n <p>因为 二叉树 会产生退化现象，提出了平衡二叉树，</p> \n <p>在平衡二叉树基础上， 再提出怎样让每一层放的节点多一些，来减少遍历高度，引申出m叉树，</p> \n <p>m叉搜索树同样会有退化现象，引出m叉平衡树，也就是B树，这时候每个节点既放了key也放了value，</p> \n <p>怎样使每个节点放尽可能多的key值，以减少遍历高度呢（访问磁盘次数），</p> \n <p>可以将每个节点只放key值，将value值放在叶子结点，在叶子结点的value值增加指向相邻节点指针，这就是优化后的B+树。所有叶子节点形成有序链表，便于<strong>范围查询</strong>，不用每次要检索树。</p> \n <p>目前数据库多采用两级索引的B+树，树的层次最多三层，因此可能需要5次磁盘访问才能更新一条记录（三次磁盘访问获得数据索引以及行id，然后再进行一次数据文件读操作及一次数据文件写操作）</p> \n <p><strong>B~树(平衡多路二叉树)</strong></p> \n <p><strong>B<sub>树，又叫平衡多路查找树。一棵m阶的B</sub>树 (m叉树)的特性如下：</strong></p> \n <ol>\n  <li> <p>树中每个结点至多有m个孩子；</p> </li>\n  <li> <p>除根结点和叶子结点外，其它每个结点至少有[m/2]个孩子；</p> </li>\n  <li> <p>若根结点不是叶子结点，则至少有2个孩子；</p> </li>\n  <li> <p>所有叶子结点都出现在同一层，叶子结点不包含任何关键字信息(可以看做是外部接点或查询失败的接点，实际上这些结点不存在，指向这些结点的指针都为null)；</p> </li>\n  <li> <p>每个非终端结点中包含有n个关键字信息： (n，A0，K1，A1，K2，A2，…，Kn，An)。其中，</p> </li>\n </ol> \n <p>a) Ki (i=1…n)为关键字，且关键字按顺序排序Ki &lt; K(i-1)。</p> \n <p>b) Ai为指向子树根的接点，且指针A(i-1)指向子树种所有结点的关键字均小于Ki，但都大于K(i-1)。</p> \n <p>c) 关键字的个数n必须满足： [m/2]-1 &lt;= n &lt;= m-1</p> \n <p><img src=\"https://img-blog.csdnimg.cn/72119aefa4774660b7c60839625679d6.png\" alt=\"在这里插入图片描述\"></p> \n <p><strong>B+树</strong></p> \n <p><strong>B+树：是应文件系统所需而产生的一种B~树的变形树。</strong></p> \n <p>一棵m阶的B+树和m阶的B-树的差异在于：</p> \n <ol>\n  <li> <p>有n棵子树的结点中含有n个关键字； (B~树是n棵子树有n+1个关键字)</p> </li>\n  <li> <p>所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大的顺序链接。 (B~树的叶子节点并没有包括全部需要查找的信息)</p> </li>\n  <li> <p>所有的非终端结点可以看成是索引部分，结点中仅含有其子树根结点中最大（或最小）关键字。 (B~树的非终节点也包含需要查找的有效信息)</p> </li>\n </ol> \n <p><img src=\"https://img-blog.csdnimg.cn/7dff74ce4b174ee7983bf38f7f734fb2.png\" alt=\"在这里插入图片描述\"></p> \n <p><strong>a、B+树的磁盘读写代价更低</strong><br> 我们都知道磁盘时可以块存储的，也就是同一个磁道上同一盘块中的所有数据都可以一次全部读取。</p> \n <p><strong>而B+树的内部结点并没有指向关键字具体信息的指针</strong>(比如文件内容的具体地址 ， 比如说不包含B~树结点中的FileHardAddress[filenum]部分） 。</p> \n <p>因此其内部结点相对B~树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。</p> \n <p>这样，一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了。</p> \n <p>举个例子，假设磁盘中的一个盘块容纳16bytes，而一个关键字2bytes，一个关键字具体信息指针2bytes。一棵9阶B<sub>树(一个结点最多8个关键字)的内部结点需要2个盘快。而B+树内部结点只需要1个盘快。当需要把内部结点读入内存中的时候，B</sub>树就比B+数多一次盘块查找时间(在磁盘中就是盘片旋转的时间)。</p> \n <p><strong>b、B+树的查询效率更加稳定。</strong></p> \n <p>由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。</p> \n <p>所以任何关键字的查找必须走一条从根结点到叶子结点的路。</p> \n <p>所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。</p> \n <h3><a id=\"LSM_481\"></a>什么是LSM树</h3> \n <p>LSM树，即日志结构合并树(Log-Structured Merge-Tree)。</p> \n <p>其实它并不属于一个具体的数据结构，它更多是一种数据结构的设计思想。</p> \n <p>大多NoSQL数据库核心思想都是基于LSM来做的，只是具体的实现不同。</p> \n <h3><a id=\"LSM_489\"></a>LSM树诞生背景</h3> \n <p>传统关系型数据库使用btree或一些变体作为存储结构，能高效进行查找。</p> \n <p>但保存在磁盘中时它也有一个明显的缺陷，那就是逻辑上相离很近但物理却可能相隔很远，这就可能造成大量的磁盘随机读写。</p> \n <p>随机读写比顺序读写慢很多，为了提升IO性能，我们需要一种能将随机操作变为顺序操作的机制，于是便有了LSM树。</p> \n <p>为啥 随机读写比顺序读写慢很多呢？</p> \n <p>磁盘读写时涉及到磁盘上数据查找，地址一般由柱面号、盘面号和块号三者构成。</p> \n <p>也就是说：</p> \n <p>step1：移动臂先根据柱面号移动到指定柱面，</p> \n <p>step2： 然后根据 盘面号 确定盘面</p> \n <p>step3：最后 块号 确定磁道，最后将指定的磁道段移动到磁头下，便可开始读写。</p> \n <p>整个过程主要有三部分时间消耗，查找时间(seek time) +等待时间(latency time)+传输时间(transmission time) 。分别表示<strong>定位柱面的耗时</strong>、将块号指定 <strong>磁道段 移到磁头</strong>的耗时、将<strong>数据传到内存</strong>的耗时。</p> \n <p>整个磁盘IO最耗时的地方在查找时间，所以减少查找时间能大幅提升性能。</p> \n <h3><a id=\"LSM_513\"></a>LSM树原理</h3> \n <p>LSM树能让我们进行顺序写磁盘，从而大幅提升写操作，作为代价的是牺牲了一些读性能。</p> \n <p>LSM树由两个或以上的存储结构组成，</p> \n <p>最简单的两个存储结构：</p> \n <ul>\n  <li> <p>一个存储结构常驻内存中，称为C0 tree，具体可以是任何方便健值查找的数据结构，比如红黑树、map之类，甚至可以是跳表。</p> </li>\n  <li> <p>另外一个存储结构常驻在硬盘中，称为C1 tree，具体结构类似B树。</p> </li>\n </ul> \n <p>C1所有节点都是100%满的，节点的大小为磁盘块大小。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/d8c1c85017314912b2337e6a347312bc.png\" alt=\"在这里插入图片描述\"></p> \n <h4><a id=\"SSTable_531\"></a>SSTable的定义</h4> \n <p>要解释这个术语的真正含义，最好的方法就是从它的出处找答案，所以重新翻开BigTable的论文。</p> \n <p>在这篇论文中，最初对SSTable是这么描述的（第三页末和第四页初）：</p> \n <blockquote> \n  <p>SSTable</p> \n  <p>The Google <strong>SSTable</strong> file format is used internally to store Bigtable data.</p> \n  <p>An <strong>SSTable</strong> provides a <strong>persistent, ordered immutable map from keys to values, where both keys and values are arbitrary byte strings.</strong> Operations are provided to look up the value associated with a specified key, and to iterate over all key/value pairs in a specified key range. Internally, each SSTable contains a sequence of blocks (typically each block is 64KB in size, but this is configurable). A block index (stored at the end of the SSTable) is used to locate blocks; the index is loaded into memory when the SSTable is opened. A lookup can be performed with a single disk seek: we first find the appropriate block by performing a binary search in the in-memory index, and then reading the appropriate block from disk. Optionally, an SSTable can be completely mapped into memory, which allows us to perform lookups and scans without touching disk.</p> \n </blockquote> \n <p>简单的非直译：<br> SSTable是Bigtable内部用于数据的文件格式，它的格式为文件本身就是一个排序的、不可变的、持久的Key/Value对Map，其中Key和value都可以是任意的byte字符串。</p> \n <p>使用Key来查找Value，或通过给定Key范围遍历所有的Key/Value对。</p> \n <p>每个SSTable包含一系列的Block（一般Block大小为64KB，但是它是可配置的），在SSTable的末尾是Block索引，用于定位Block，<strong>这些索引在SSTable打开时被加载到内存中</strong>，在查找时首先从内存中的索引二分查找找到Block，然后一次磁盘寻道即可读取到相应的Block。还有一种方案是将这个SSTable加载到内存中，从而在查找和扫描中不需要读取磁盘。</p> \n <h4><a id=\"HBaseSSTable_552\"></a>HBase中的SSTable</h4> \n <p>这个貌似就是HFile第一个版本的格式么，贴张图感受一下：<br> <img src=\"https://imgconvert.csdnimg.cn/aHR0cDovL3d3dy5ibG9namF2YS5uZXQvaW1hZ2VzL2Jsb2dqYXZhX25ldC9kbGV2aW4vaW1hZ2UwMDgwLmpwZw?x-oss-process=image/format,png\" alt=\"img\"><br> 在HBase使用过程中，对这个版本的HFile遇到以下一些问题（参考<a href=\"http://hbase.apache.org/book.html#_hfile_format_2\">这里</a>）：</p> \n <ol>\n  <li>解析时内存使用量比较高。</li>\n  <li>Bloom Filter和Block索引会变的很大，而影响启动性能。具体的，Bloom Filter可以增长到100MB每个HFile，而Block索引可以增长到300MB，如果一个HRegionServer中有20个HRegion，则他们分别能增长到2GB和6GB的大小。HRegion需要在打开时，需要加载所有的Block索引到内存中，因而影响启动性能；而在第一次Request时，需要将整个Bloom Filter加载到内存中，再开始查找，因而Bloom Filter太大会影响第一次请求的延迟。<br> 而HFile在版本2中对这些问题做了一些优化，具体会在HFile解析时详细说明。</li>\n </ol> \n <h4><a id=\"LevelDB_SSTable_564\"></a>LevelDB 中的SSTable</h4> \n <p>先看看SSTable文件的结构</p> \n <p><img src=\"https://img-blog.csdn.net/20180205150843550\" alt=\"img\"></p> \n <p>整体上看 SSTable文件分为数据区与索引区，</p> \n <p>尾部的footer指出了meta index block与data index block的偏移与大小，</p> \n <p>index block指出了各data block的偏移与大小，metaindex block指出了filter block的偏移与大小。</p> \n <p>1）data block：存储key-value记录，分为Data、type、CRC三部分<br> 2）filter block：默认没有使用，用于快速从data block 判断key-value是否存在<br> 3）metaindex block ：记录filter block的相关信息<br> 4）Index block：描述一个data block，存储着对应data block的最大Key值，以及data block在文件中的偏移量和大小<br> 5）footer：索引的索引，记录metaindex block和Index block在SSTable中的偏移量了和大小</p> \n <p>下面再具体看看各个部分物理结构</p> \n <p>1、block<br> sstable中data block 、metaindex block、index block都用这种block这种结构。</p> \n <p>对于data block,当block大小（record、restarts数组、以及num_restarts）超过4k时，就切换一个新的block继续往SSTable写数据，</p> \n <p>而metaindex block、index block就只有一个block，所以上图看起来data block有多个。<br> <img src=\"https://img-blog.csdn.net/20180205160118846\" alt=\"这里写图片描述\"></p> \n <p>block主要由数据区record和restarts组成。 为什么是这种结构？</p> \n <p>data block主要是存储数据，block内给一定数量（默认16）key-value分组，</p> \n <p>每组又用restarts数组记录起始位置，因此可以根据restarts读取每组起始位置key-value，</p> \n <p>由于<strong>block内的数据是从小到大有序存储的</strong>，所以可以通过restarts数组，获取每组起始key-value,比较起始key key(n)与查找的key大小，如果key(n)&gt;key，那么key一定在序号&gt;=n组之后，否则在 &lt; n组之前。</p> \n <p>因此可以通过二分查找思想通过restarts获取起始key，来定位key的位置，避免线性查找低效。</p> \n <p>因此，restarts的思想就是：<strong>提高block内key-value查找效率</strong>，直接定位key所在group。</p> \n <p>下面再来看看record结构。</p> \n <p>record相对有意思，不是简单的用key-length | key-data | value-length|value-data存储。</p> \n <p><img src=\"https://img-blog.csdn.net/20180205164204612\" alt=\"这里写图片描述\"></p> \n <p>data block中的key是有序存储的，相邻的key之间可能有重复，因此存储时采用前缀压缩，后一个key只存储与前一个key不同的部分。</p> \n <p>重启点指出的位置即每组起始位置的key不按前缀压缩，而是完整存储该key。</p> \n <p>type是表示数据是否压缩，以怎样的方式压缩，crc32是该block校验码。</p> \n <p>2、index block</p> \n <p>index block 的结构也是block 结构，是data block的索引，记录每个data block 最大key 和 起始位置以及大小。</p> \n <p>具体的存储方式是以每个data block最大key 为key,以data block 起始位置和大小为value。因此可以根据每个</p> \n <p>block的最大key与查询key比较，直接定位查询key所在的位置。</p> \n <p>这是理论上key的存储方式，但是在sstable二次压缩的过程对key做了一个优化，它并不保存最大key，而是保存一个能分隔两个data block的最短Key，如：假定data block1的最大一个key为“abcdefg”，data block2最大key为“abzxcv”，则index可以记录data block1的索引key为“abd”；这样的分割串可以有很多，只要保证data block1中的所有Key都小于等于此索引，data block2中的所有Key都大于此索引即可。</p> \n <p>这种优化缩减了索引长度，查询时可以有效减小比较次数。<br> 　因此，index block的思想是提高SSTable内key-value查找效率，直接定位key所在block。</p> \n <p>3、metaindex_block<br> 也是block结构。就只有一条记录，其key是filter. + filter_policy的name，value是filter大小和起始位置。</p> \n <p>4、filter block<br> filter block就是一个bloom filter,关于bloom filter原理概念可以百度。<br> 每个bloom filter是对data block 的key 经过hash num 次形成的字节数组,多少个data block对应多少个bloom filter。<br> bloom filter实质就是一个bit 数组，对block 内key hash,将相应的位置设为1，这种设计关键在于能提高不存在的key判断效率，通过filter 计算，如果不存在，就不用通过data block内的restarts方式读取文件查找key是否存在，但是如果filter判断存在，还需通过restarts方式确定。</p> \n <p>5、footer<br> footer位于SSTable文件尾部，占用空间固定为48个字节。其末尾8个字节是一个magic_number。metaindex_block_handle与index_block_handle物理上占用了40个字节，metaindex_block_handle和index_block_handle是BlockHandle数据类型， 这种结构用于记录metaindex block 和index block的起始位置和大小。<br> <img src=\"https://img-blog.csdn.net/20180205175817071\" alt=\"这里写图片描述\"></p> \n <p>对于BlockHandle ，其实可以看作文件内容指针实现方式,BlockHandle记录数据位置及大小，与c/c++指针 思想类似，通过地址和大小可以读取数据。</p> \n <p>BlockHandle格式</p> \n <pre><code>varint64 offset | varint64 size_\n</code></pre> \n <p>采用变长存储，所以实际上存储可能连32字节都不到，剩余填充0。</p> \n <p>总结：</p> \n <blockquote> \n  <p>SSTable其实就是通过二次索引，先读取footer，</p> \n  <p>根据footer中index_block_handler记录的index_block起始位置和大小，读取index block，</p> \n  <p>通过index block 查询key所在data block，再在data block内部通过restarts 进一步确定key所在group。</p> \n </blockquote> \n <p>下面是完整的SSTable结构图</p> \n <p><img src=\"https://img-blog.csdn.net/20180205183459194\" alt=\"这里写图片描述\"></p> \n <h3><a id=\"LSM_672\"></a>LSM插入步骤</h3> \n <p>插入一条新纪录时，首先在日志文件中插入操作日志，以便后面恢复使用，日志是以append形式插入，所以速度非常快；</p> \n <p>将新纪录的索引插入到C0中，这里在内存中完成，不涉及磁盘IO操作；</p> \n <p>当C0大小达到某一阈值时或者每隔一段时间，将C0中记录滚动合并到磁盘C1中；</p> \n <p>对于多个存储结构的情况，当C1体量越来越大就向C2合并，以此类推，一直往上合并Ck。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/5afd0495051c42449f0b33d29128ceb0.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"LSM_684\"></a>LSM合并步骤</h3> \n <p>合并过程中会使用两个块：emptying block 和 filling block。</p> \n <ol>\n  <li>从C1中读取未合并叶子节点，放置内存中的emptying block中。</li>\n  <li>从小到大找C0中的节点，与emptying block进行<strong>合并排序</strong>，合并结果保存到filling block中，并将C0对应的节点删除。</li>\n  <li>不断执行第2步操作，合并排序结果不断填入filling block中，当其满了则将其追加到磁盘的新位置上，注意是追加而不是改变原来的节点。合并期间如故宫emptying block使用完了则再从C1中读取未合并的叶子节点。</li>\n  <li>C0和C1所有叶子节点都按以上合并完成后，即完成一次合并。</li>\n </ol> \n <h3><a id=\"LSM_695\"></a>LSM插入案例</h3> \n <p>向LSM树中插入 <code>A E L R U</code> ，首先会插入到内存中的C0树上，</p> \n <p>这里使用AVL树，插入“A”，</p> \n <p>当然，得先WAL， 预先写入日志，向磁盘日志文件追加记录，然后再插入C0，</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/10db0e22d5976705fd9237a0f3634dab.jpeg\" alt=\"img\"></p> \n <p>插入“E”，同样先追加日志再写内存，</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/1af0459e9d827b123dc09ca1d0acc81d.jpeg\" alt=\"img\"></p> \n <p>继续插入“L”，旋转后如下，</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/dd3493b45844d9b8817b6e7c0d1e6eba.jpeg\" alt=\"img\"></p> \n <p>插入“R”“U”，旋转后最终如下。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/0bc514b7b4b494b17e36fca5368518d4.jpeg\" alt=\"img\"></p> \n <p>假设此时触发合并，</p> \n <p>则因为C1还没有树，所以emptying block为空，直接从C0树中依次找最小的节点。</p> \n <p>filling block长度为4，这里假设磁盘块大小为4。</p> \n <p>开始找最小的节点，并放到filling block中，</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/0b704a70beb994b2e7e4b9d0adbe8795.jpeg\" alt=\"img\"></p> \n <p>继续找第二个节点，</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/bf9eef74282e3faf51eae8b6dc85ba74.jpeg\" alt=\"img\"></p> \n <p>以此类推，填满filling block，</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/afb625953ce5e7be31564b2c93def5be.jpeg\" alt=\"img\"></p> \n <p>开始写入磁盘，C1树，</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/f40e01a2e21b16aca0feedc143808ae9.jpeg\" alt=\"img\"></p> \n <p>继续插入 <code>B F N T</code> ，先分别写日志，然后插入到内存的C0树中，</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/7b994e6feaec75399997ea116121e86b.jpeg\" alt=\"img\"></p> \n <p>假如此时进行合并，先加载C1的最左边叶子节点到emptying block，</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/fef36245ec909a69cb4e2a3cbfad9c58.jpeg\" alt=\"img\"></p> \n <p>接着对C0树的节点和emptying block进行合并排序，首先是“A”进入filling block，</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/a1db6ff722860a30332ce8d538c09453.jpeg\" alt=\"img\"></p> \n <p>然后是“B”，</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/3f5faef2c3bcf4193e52ee0d61065da0.jpeg\" alt=\"img\"></p> \n <p>合并排序最终结果为，</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/a7a8e285d7f384f8a38c60de23487fa9.jpeg\" alt=\"img\"></p> \n <p>将filling block追加到磁盘的新位置，将原来的节点删除掉，</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/fa16349f4e708a311e90b4c196fc7eea.jpeg\" alt=\"img\"></p> \n <p>继续合并排序，再次填满filling block，</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/4d0ba1366d5b0956de465890c95ffda5.jpeg\" alt=\"img\"></p> \n <p>将filling block追加到磁盘的新位置，上一层的节点也要以磁盘块（或多个磁盘块）大小写入，尽量避开随机写。另外由于合并过程可能会导致上层节点的更新，可以暂时保存在内存，后面在适当时机写入。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/9f73c99e333c9738c5917ae4187dd85e.jpeg\" alt=\"img\"></p> \n <h3><a id=\"LSM_783\"></a>LSM查找操作</h3> \n <p>查找总体思想是先找内存的C0树，找不到则找磁盘的C1树，然后是C2树，以此类推。</p> \n <p>假如要找“B”，先找C0树，没找到。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/dd0e8d96e63d7bcc9848edb7a00f3009.jpeg\" alt=\"img\"></p> \n <p>接着找C1树，从根节点开始，</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/b6d0d7d75a51bb1bc963b62f85c79213.jpeg\" alt=\"img\"></p> \n <p>找到“B”。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/764581793582c78dc1448582cf436a40.jpeg\" alt=\"img\"></p> \n <h3><a id=\"LSM_803\"></a>LSM删除操作</h3> \n <p>删除操作为了能快速执行，主要是通过标记来实现，在内存中将要删除的记录标记一下，后面异步执行合并时将相应记录删除。</p> \n <p>比如要删除“U”，假设标为#的表示删除，则C0树的“U”节点变为，</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/0f04c1a76f05d8f95c8006d028c36f7b.jpeg\" alt=\"img\"></p> \n <p>而如果C0树不存在的记录，</p> \n <p>则在C0树中生成一个节点，并标为#，查找时就能再内存中得知该记录已被删除，无需去磁盘找了。</p> \n <p>比如要删除“B”，那么没有必要去磁盘执行删除操作，直接在C0树中插入一个“B”节点，并标为#。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/9aca1045771d3d7705d73ab43354c84f.jpeg\" alt=\"img\"></p> \n <h3><a id=\"LSM_828\"></a>LSM树的特点：用牺牲读性能，来换取写性能</h3> \n <h4><a id=\"_830\"></a>优化写性能</h4> \n <p>如果我们对写性能特别敏感，我们最好怎么做？</p> \n <p>—— Append Only：所有写操作都是将数据添加到文件末尾。这样做的写性能是最好的，大约等于磁盘的理论速度（200 ~ 300 MB/s）。</p> \n <p>但是 Append Only 的方式带来的问题是：</p> \n <ul>\n  <li>读操作不方便。</li>\n  <li>很难支持范围操作。</li>\n  <li>需要垃圾回收（合并过期数据）。</li>\n </ul> \n <p>所以， 纯粹的 Append Only 方式只能适用于一些简单的场景：</p> \n <ul>\n  <li>数据库的 WAL（预写日志）。</li>\n  <li>能知道明确的 offset，比如 Bitcask。</li>\n </ul> \n <h4><a id=\"_847\"></a>如果要优化读性能</h4> \n <p>如果我们对读性能特别敏感，一般我们有两种方式：</p> \n <ul>\n  <li>有序存储，比如 B+ 树，SkipList 等。</li>\n  <li>Hash 存储 —— 不支持范围操作，适用范围有限。</li>\n </ul> \n <h4><a id=\"_854\"></a>读写性能的权衡</h4> \n <p>如何获得（接近） Append Only 的写性能，而又能拥有不错的读性能呢？</p> \n <p>以 LevelDB 为代表的 LSM 存储引擎给出了一个参考答案。</p> \n <blockquote> \n  <p>注意，LevelDB 实现的是优化后的 LSM，原始的 LSM 可以参考论文。</p> \n </blockquote> \n <p>以 LevelDB 例子, LevelDB 的写操作主要由两步组成：</p> \n <ul>\n  <li>写日志并持久化（Append Only）。</li>\n  <li>Apply 到内存中的 memtable（SkipList）。</li>\n </ul> \n <p>所以，LevelDB 的写速度非常快。</p> \n <p>memtable 写“满”后，会转换为 immutable memtable，</p> \n <p>然后被后台线程 compaction 成按 Key 有序存储的 sst 文件（顺序写）。</p> \n <p>由于 sst 文件会有多个，所以 LevelDB 的读操作可能会有多次磁盘 IO（LevelDB 通过 table cache、block cache 和 bloom filter 等优化措施来减少读操作的磁盘 IO 次数）。</p> \n <h4><a id=\"_LSM__NO_SQL_875\"></a>基于 LSM 数据结构的 NO SQL的适用场景：</h4> \n <ul>\n  <li>写请求多。</li>\n  <li>写性能要求高:（高吞吐+低延迟）。</li>\n </ul> \n <p>LSM-tree的另一大特点是除了使用两部分类树的数据结构外，还会使用日志文件（通常叫作 commit log）来为数据恢复做保障。</p> \n <p>这三类数据结构的协作顺序一般是：所有的新插入与更新操作都首先被记录到 commit log中——该操作叫作 WAL（Write Ahead Log），然后再写到 memtable，最后当达到一定条件时数据会从 memtable冲写到 sstable，并抛弃相关的 log数据； memtable与 sstable可同时供查询；当 memtable出问题时，可从 commit log与 sstable中将 memtable的数据恢复。</p> \n <p>理论上，可以是内存中树的一部分和磁盘中第一层树做合并，对于磁盘中的树直接做update操作有可能会破坏物理block的连续性，但是实际应用中，一般LSM树有多层，当磁盘中的小树合并成一个大树的时候，可以重新排好顺序，使得block连续，优化读性能。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/20190504005457504.jpg\" alt=\"在这里插入图片描述\"></p> \n <p>LSM树的特点：<strong>用读性能来换取写性能</strong>，将对数据的修改增量保持在内存中，达到指定的大小限制后将这些修改操作批量写入磁盘</p> \n <p>LSM树的核心思想：放弃部分读性能，提高写性能</p> \n <p>代表数据库：nessDB、LevelDB、HBase等非关系型数据库</p> \n <p>我们可以参考 HBase的架构来体会其架构中基于 LSM-tree的部分特点。</p> \n <p>按照 WAL的原则，数据首先会写到 HBase的 HLog(相当于 commit log)里，然后再写到 MemStore（相当于 memtable）里，最后会冲写到磁盘 StoreFile（相当于 sstable）中。</p> \n <p>这样 HBase的 HRegionServer就通过 LSM-tree实现了数据文件的生成。</p> \n <p>HBase LSM-tree架构示意图如下图。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/9011d89d69d14b2ad3dafb5e53a172e5.jpeg\" alt=\"img\"></p> \n <p>LSM-tree的这种结构非常有利于数据的快速写入（理论上可以接近磁盘顺序写速度），</p> \n <p>但是，LSM-tree不利于读——因为理论上读的时候可能需要同时从 memtable和所有硬盘上的 sstable中查询数据，这样显然会对性能造成较大的影响。</p> \n <p>为了解决这个问题， LSM-tree采取了以下主要的相关措施。</p> \n <ul>\n  <li>定期将硬盘上小的 sstable合并（通常叫作 Merge或 Compaction操作）成大的 sstable，以减少 sstable的数量。而且，平时的数据更新删除操作并不会更新原有的数据文件，只会将更新删除操作加到当前的数据文件末端，只有在 sstable合并的时候才会真正将重复的操作或更新去重、合并。</li>\n  <li>对每个 sstable使用布隆过滤器（ Bloom Filter），以加速对数据在该 sstable的存在性进行判定，从而减少数据的总查询时间。</li>\n </ul> \n <p>LSM树和B+树的差异主要在于读性能和写性能进行权衡，在牺牲的读性能的同时，寻找其余补救方案。</p> \n <p>B+树存储引擎，不仅支持单条记录的增、删、读、改操作，还支持顺序扫描（B+树的叶子节点之间的指针），对应的存储系统就是关系数据库。但随着写入操作增多，为了维护B+树结构，节点分裂，读磁盘的随机读写概率会变大，读性能会逐渐减弱。</p> \n <p>LSM树（Log-Structured MergeTree）存储引擎和B+树存储引擎一样，同样支持增、删、读、改、顺序扫描操作。而且通过批量存储技术规避磁盘随机写入问题。</p> \n <p>当然凡事有利有弊，LSM树和B+树相比，LSM树牺牲了部分读性能，用来大幅提高写性能。</p> \n <h2><a id=\"vectorization_930\"></a><strong>什么是vectorization？</strong></h2> \n <p>向量化计算(vectorization)，也叫vectorized operation，也叫array programming，</p> \n <p>说的是一个事情：将多次for循环计算变成一次计算。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/2854bbcd5ee61fec3e9f7f4b9c099b9e.jpeg\" alt=\"img\"></p> \n <p>上图中，左侧为vectorization，右侧为寻常的For loop计算。</p> \n <p>vectorization 将多次for循环计算变成一次计算,</p> \n <p>vectorization 完全仰仗于CPU的SIMD指令集，</p> \n <p>SIMD指令可以在一条cpu指令上处理2、4、8或者更多份的数据。</p> \n <p>在Intel处理器上，这个称之为SSE, 以及后来的AVX，在Arm处理上，这个称之为NEON。</p> \n <p>因此简单来说，</p> \n <p>for循环计算是将一个loop——处理一个array（N个数据）的时候，每次处理1个数据，共处理N次，</p> \n <p>向量化计算就 转化为vectorization——处理一个array的时候每次同时处理8个数据，共处理N/8次。</p> \n <h3><a id=\"vectorization_956\"></a><strong>vectorization如何让速度更快？</strong></h3> \n <p>介绍SSE 指令集 / AVX指令集之前，先要引入一个向量的概念。所谓向量，</p> \n <p>就是多个标量的组合，通常意味着SIMD(单指令多数据)，就是一个指令同时对多个数据进行处理，达到很大的吞吐量。</p> \n <p>早在1996年，Intel就在X86架构上应用了MMX(多媒体扩展)指令集，那时候还仅仅是64位向量。</p> \n <p>到了1999年，SSE(流式SIMD扩展)指令集出现了，这时候的向量提升到了128位。</p> \n <h4><a id=\"SIMD_968\"></a>SIMD</h4> \n <p>SIMD（Single Instruction Multiple Data，单指令多数据流），是一种实现空间上的并行性的技术。</p> \n <p>这种技术使用一个控制器控制多个处理单元，同时对一组数据中的每一个数据执行相同的操作。</p> \n <p>在 SIMD 指令执行期间，任意时刻都只有一个进程在运行，即 SIMD 没有并发性，仅仅只是同时进行计算。</p> \n <p>在 Intel 的 x86 微架构处理器中，SIMD 指令集有 MMX、SSE、SSE2、SSE3、SSSE3、SSE4.1、SSE4.2、AVX、AVX2、AVX512。</p> \n <p>我们以x86指令集为例，</p> \n <p>1997年，x86扩展出了MMX指令集，伴随着80-bit的vector寄存器，首开向量化计算的先河。</p> \n <p>之后，x86又扩展出了SSE指令集 (有好几个版本, 从SSE1到SEE4.2)，伴随着128-bit寄存器。</p> \n <p>而在2011年，Intel发布了Sandy Bridge架构——扩展出了AVX指令集(256-bit寄存器)。</p> \n <p>在2016年，第一个带有AVX-512寄存器的CPU发布了(512-bit寄存器，可以同时处理16个32-bit的float数)。</p> \n <p>SSE和AVX各有16个寄存器。</p> \n <p>SSE的16个寄存器为XMM0-XMM15，AVX的16个寄存器为YMM0-YMM15。</p> \n <p>XMM 寄存器 registers 每个为128 bits，</p> \n <p>YMM寄存器 registers 每个为256bit</p> \n <p>AVX-512 寄存器 registers 每个为512bit。</p> \n <h4><a id=\"AVX_998\"></a>AVX</h4> \n <p>AVX 是 SSE 架构的延伸，将 SSE 的 XMM 128bit 寄存器升级成了 YMM 256bit 寄存器，同时浮点运算命令扩展至 256 位，运算效率提升了一倍。</p> \n <p>另外，AVX 还添加了三操作数指令，以减少在编码时先复制再运算的动作。</p> \n <p>AVX2 将大多数整数运算命令扩展至 256 位，同时支持 FMA（Fused Multiply-Accumulate，融合乘法累加）运算，可以在提高运算效率的同时减少运算时的精度损失。</p> \n <p>AVX512 将 AVX 指令进一步扩展至 512 位。</p> \n <p>AVX指令介绍, 参考该网站：<a href=\"https://www.codeproject.com/Articles/874396/Crunching-Numbers-with-AVX-and-AVX\">Crunching Numbers with AVX and AVX2 - CodeProject</a></p> \n <p>SSE有3个数据类型：__m128 , __m128d 和 <strong>m128i，分别代表Float、double (d) 和integer (i)。</strong></p> \n <p>AVX有3个数据类型： m256 , m256d 和 m256i，分别代表Float、double (d) 和 integer (i)。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/5de7bf7552df0cda6042c417fd885e9a.jpeg\" alt=\"img\"></p> \n <h3><a id=\"SSE_1024\"></a>SSE指令的数据类型</h3> \n <pre><code>SSE指令有3种数据类型，分别为:\n\n__m256、__m256i、__m256d。\n\n每一种类型都以\"__\"+\"m\"+“vector的位长度”构成。\n</code></pre> \n <h4><a id=\"__m256_1032\"></a>__m256</h4> \n <p>包含8个float类型数据的向量</p> \n <h4><a id=\"__m256i_1036\"></a>__m256i</h4> \n <p>包含若干个整型数据的向量，如char、short、int、unsigned long long等。</p> \n <p>例如256位的vector可以32个char、16个short、8个int，这些整型既可以是有符号的也可以是无符号的。</p> \n <h4><a id=\"__m256d_1042\"></a>__m256d</h4> \n <p>包含4个double类型数据的向量。</p> \n <h3><a id=\"_1046\"></a>指令</h3> \n <h4><a id=\"SSE_1048\"></a>SSE指令命名约定</h4> \n <pre><code>_mm256_&lt;name&gt;_&lt;data_type&gt;\n\n&lt;name&gt;：描述了内联函数的算术操作。\n&lt;data_type&gt;：标识函数主要参数的数据类型\n</code></pre> \n <h4><a id=\"_1055\"></a>从内存中加载数据</h4> \n <h5><a id=\"_m256i__mm256_loadu_si256___m256i_const__mem_addr_1057\"></a>指令：_m256i _mm256_loadu_si256 (__m256i const * mem_addr)</h5> \n <p>从内存中读入一个256位的整型数据放到dst中（32字节地址无需对齐）。</p> \n <pre><code>dst[255:0] := MEM[mem_addr+255:mem_addr]\ndst[MAX:256] := 0\n\n</code></pre> \n <h5><a id=\"_m256i__mm256_load_si256___m256i_const__mem_addr_1067\"></a>指令：_m256i _mm256_load_si256 (__m256i const * mem_addr)：</h5> \n <p>从内存中读入一个256位的整型数据放到dst中（32字节地址必需对齐）。</p> \n <pre><code>dst[255:0] := MEM[mem_addr+255:mem_addr]\ndst[MAX:256] := 0\n</code></pre> \n <h5><a id=\"_m256__mm256_load_ps_float_const__mem_addr_1076\"></a>指令：_m256 _mm256_load_ps (float const * mem_addr)：</h5> \n <p>从内存中读入8个float型数据放入dst（32字节地址必需对齐）。</p> \n <pre><code>dst[255:0] := MEM[mem_addr+255:mem_addr]\ndst[MAX:256] := 0\n</code></pre> \n <h5><a id=\"_m128__mm_maskload_ps_float_const__mem_addr_m128i_mask__1084\"></a>指令：_m128 _mm_maskload_ps (float const * mem_addr, m128i mask) ：</h5> \n <p>从内存中读入128位（4个float），根据mask的真假赋值。</p> \n <pre><code>FOR j := 0 to 3\n    i := j*32\n    IF mask[i+31]\n        dst[i+31:i] := MEM[mem_addr+i+31:mem_addr+i]\n    ELSE\n        dst[i+31:i] := 0\n    FI\nENDFOR\ndst[MAX:128] := 0\n</code></pre> \n <h5><a id=\"_m256__mm256_maskload_ps_float_const__mem_addr_m256i_mask_1098\"></a>指令：_m256 _mm256_maskload_ps (float const * mem_addr, m256i mask)：</h5> \n <p>根据掩码载入8个float数据</p> \n <pre><code>FOR j := 0 to 7\n	i := j*32\n	IF mask[i+31]\n		dst[i+31:i] := MEM[mem_addr+i+31:mem_addr+i]\n	ELSE\n		dst[i+31:i] := 0\n	FI\nENDFOR\ndst[MAX:256] := 0\n</code></pre> \n <h5><a id=\"_m256__mm256_add_ps___m256_a___m256_b_1115\"></a>指令：_m256 _mm256_add_ps (__m256 a, __m256 b)：</h5> \n <p>将 a+b 操作按32位float进行处理，其中32位不能有溢出。</p> \n <pre><code class=\"prism language-cpp\">FOR j <span class=\"token operator\">:</span><span class=\"token operator\">=</span> <span class=\"token number\">0</span> to <span class=\"token number\">7</span>\n	i <span class=\"token operator\">:</span><span class=\"token operator\">=</span> j<span class=\"token operator\">*</span><span class=\"token number\">32</span>\n	dst<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">31</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">:</span><span class=\"token operator\">=</span> a<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">31</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> b<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">31</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span>\nENDFOR\ndst<span class=\"token punctuation\">[</span>MAX<span class=\"token operator\">:</span><span class=\"token number\">256</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">:</span><span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n</code></pre> \n <h5><a id=\"_m256i__mm256_add_epi8___m256i_a___m256i_b_1127\"></a>指令：_m256i _mm256_add_epi8 (__m256i a, __m256i b)：</h5> \n <p>将 a+b 操作按8位整型进行处理，其中8位不能有溢出。</p> \n <pre><code class=\"prism language-cpp\">FOR j <span class=\"token operator\">:</span><span class=\"token operator\">=</span> <span class=\"token number\">0</span> to <span class=\"token number\">31</span>\n	i <span class=\"token operator\">:</span><span class=\"token operator\">=</span> j<span class=\"token operator\">*</span><span class=\"token number\">8</span>\n	dst<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">7</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">:</span><span class=\"token operator\">=</span> a<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">7</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> b<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">7</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span>\nENDFOR\ndst<span class=\"token punctuation\">[</span>MAX<span class=\"token operator\">:</span><span class=\"token number\">256</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">:</span><span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n</code></pre> \n <h5><a id=\"_m256i__mm256_adds_epi8___m256i_a___m256i_b_1138\"></a>指令：_m256i _mm256_adds_epi8 (__m256i a, __m256i b)：</h5> \n <p>将 a+b 操作按8位整型进行处理，考虑饱和问题。</p> \n <pre><code class=\"prism language-cpp\">FOR j <span class=\"token operator\">:</span><span class=\"token operator\">=</span> <span class=\"token number\">0</span> to <span class=\"token number\">31</span>	i <span class=\"token operator\">:</span><span class=\"token operator\">=</span> j<span class=\"token operator\">*</span><span class=\"token number\">8</span>	dst<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">7</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">:</span><span class=\"token operator\">=</span> <span class=\"token function\">Saturate8</span><span class=\"token punctuation\">(</span> a<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">7</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> b<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">7</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span> <span class=\"token punctuation\">)</span>ENDFORdst<span class=\"token punctuation\">[</span>MAX<span class=\"token operator\">:</span><span class=\"token number\">256</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">:</span><span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n</code></pre> \n <h5><a id=\"_m256i__mm256_adds_epu8___m256i_a___m256i_b_1146\"></a>指令：_m256i _mm256_adds_epu8 (__m256i a, __m256i b)：</h5> \n <p>将 a+b 操作按8位无符号整型进行处理，考虑饱和问题。</p> \n <pre><code class=\"prism language-cpp\">FOR j <span class=\"token operator\">:</span><span class=\"token operator\">=</span> <span class=\"token number\">0</span> to <span class=\"token number\">31</span>\n	i <span class=\"token operator\">:</span><span class=\"token operator\">=</span> j<span class=\"token operator\">*</span><span class=\"token number\">8</span>\n	dst<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">7</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">:</span><span class=\"token operator\">=</span> <span class=\"token function\">SaturateU8</span><span class=\"token punctuation\">(</span> a<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">7</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> b<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">7</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span> <span class=\"token punctuation\">)</span>\nENDFOR\ndst<span class=\"token punctuation\">[</span>MAX<span class=\"token operator\">:</span><span class=\"token number\">256</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">:</span><span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n</code></pre> \n <h5><a id=\"_mm256_fmadd_ps___m256_a___m256_b___m256_c_1158\"></a>指令：_mm256_fmadd_ps (__m256 a, __m256 b, __m256 c)</h5> \n <p>​ 将a*b+c操作按32位float型进行。不要溢出。</p> \n <pre><code class=\"prism language-cpp\">FOR j <span class=\"token operator\">:</span><span class=\"token operator\">=</span> <span class=\"token number\">0</span> to <span class=\"token number\">7</span>\n	i <span class=\"token operator\">:</span><span class=\"token operator\">=</span> j<span class=\"token operator\">*</span><span class=\"token number\">32</span>\n	dst<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">31</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">:</span><span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">31</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> b<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">31</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> c<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">31</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span>\nENDFOR\ndst<span class=\"token punctuation\">[</span>MAX<span class=\"token operator\">:</span><span class=\"token number\">256</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">:</span><span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n</code></pre> \n <h5><a id=\"_m256__mm256_fnmadd_ps___m256_a___m256_b___m256_c_1170\"></a>指令：_m256 _mm256_fnmadd_ps (__m256 a, __m256 b, __m256 c)</h5> \n <p>将 -(a*b)+c 操作按32位float型进行。不要溢出。</p> \n <pre><code class=\"prism language-cpp\">FOR j <span class=\"token operator\">:</span><span class=\"token operator\">=</span> <span class=\"token number\">0</span> to <span class=\"token number\">7</span>\n	i <span class=\"token operator\">:</span><span class=\"token operator\">=</span> j<span class=\"token operator\">*</span><span class=\"token number\">32</span>\n	dst<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">31</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">:</span><span class=\"token operator\">=</span> <span class=\"token operator\">-</span><span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">31</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> b<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">31</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> c<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">31</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span>\nENDFOR	\ndst<span class=\"token punctuation\">[</span>MAX<span class=\"token operator\">:</span><span class=\"token number\">256</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">:</span><span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n</code></pre> \n <h5><a id=\"_m256__mm256_fmaddsub_ps___m256_a___m256_b___m256_c_1182\"></a>指令：_m256 _mm256_fmaddsub_ps (__m256 a, __m256 b, __m256 c)</h5> \n <p>将a*b+c操作按32位float型进行，偶数做减法，奇数做加法。</p> \n <pre><code class=\"prism language-cpp\">FOR j <span class=\"token operator\">:</span><span class=\"token operator\">=</span> <span class=\"token number\">0</span> to <span class=\"token number\">7</span>\n	i <span class=\"token operator\">:</span><span class=\"token operator\">=</span> j<span class=\"token operator\">*</span><span class=\"token number\">32</span>\n	<span class=\"token function\">IF</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>j <span class=\"token operator\">&amp;</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> \n		dst<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">31</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">:</span><span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">31</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> b<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">31</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> c<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">31</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span>\n	ELSE\n		dst<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">31</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">:</span><span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>a<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">31</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> b<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">31</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> c<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">31</span><span class=\"token operator\">:</span>i<span class=\"token punctuation\">]</span>\n	FI\nENDFOR\ndst<span class=\"token punctuation\">[</span>MAX<span class=\"token operator\">:</span><span class=\"token number\">256</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">:</span><span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n</code></pre> \n <h3><a id=\"AVX_mm256_fmadd_ps_1198\"></a>AVX指令_mm256_fmadd_ps使用案例</h3> \n <p>下面一小段C++程序来展示一下AVX带来的计算速度：</p> \n <pre><code class=\"prism language-cpp\"><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;immintrin.h&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;iostream&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;chrono&gt;</span></span>\n<span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;ctime&gt;</span> </span>\n\n<span class=\"token keyword\">const</span> <span class=\"token keyword\">int</span> N <span class=\"token operator\">=</span> <span class=\"token number\">8</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> <span class=\"token keyword\">int</span> loop_num <span class=\"token operator\">=</span> <span class=\"token number\">100000000</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">float</span> gemfield_i<span class=\"token punctuation\">[</span><span class=\"token number\">8</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">{\n    <!-- --></span><span class=\"token number\">1.1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2.2</span><span class=\"token punctuation\">,</span><span class=\"token number\">3.3</span><span class=\"token punctuation\">,</span><span class=\"token number\">4.4</span><span class=\"token punctuation\">,</span><span class=\"token number\">5.5</span><span class=\"token punctuation\">,</span><span class=\"token number\">6.6</span><span class=\"token punctuation\">,</span><span class=\"token number\">7.7</span><span class=\"token punctuation\">,</span><span class=\"token number\">8.8</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">float</span> gemfield_m<span class=\"token punctuation\">[</span><span class=\"token number\">8</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">{\n    <!-- --></span><span class=\"token number\">2.2</span><span class=\"token punctuation\">,</span><span class=\"token number\">3.3</span><span class=\"token punctuation\">,</span><span class=\"token number\">4.4</span><span class=\"token punctuation\">,</span><span class=\"token number\">5.5</span><span class=\"token punctuation\">,</span><span class=\"token number\">6.6</span><span class=\"token punctuation\">,</span><span class=\"token number\">7.7</span><span class=\"token punctuation\">,</span><span class=\"token number\">8.8</span><span class=\"token punctuation\">,</span><span class=\"token number\">9.9</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">float</span> gemfield_a<span class=\"token punctuation\">[</span><span class=\"token number\">8</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">{\n    <!-- --></span><span class=\"token number\">11.1</span><span class=\"token punctuation\">,</span><span class=\"token number\">12.2</span><span class=\"token punctuation\">,</span><span class=\"token number\">13.3</span><span class=\"token punctuation\">,</span><span class=\"token number\">14.4</span><span class=\"token punctuation\">,</span><span class=\"token number\">15.5</span><span class=\"token punctuation\">,</span><span class=\"token number\">16.6</span><span class=\"token punctuation\">,</span><span class=\"token number\">17.7</span><span class=\"token punctuation\">,</span><span class=\"token number\">18.8</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">float</span> gemfield_o<span class=\"token punctuation\">[</span><span class=\"token number\">8</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">{\n    <!-- --></span><span class=\"token number\">0</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span>\n\n__m256 gemfield_v_i <span class=\"token operator\">=</span> <span class=\"token function\">_mm256_set_ps</span><span class=\"token punctuation\">(</span><span class=\"token number\">8.8</span><span class=\"token punctuation\">,</span><span class=\"token number\">7.7</span><span class=\"token punctuation\">,</span><span class=\"token number\">6.6</span><span class=\"token punctuation\">,</span><span class=\"token number\">5.5</span><span class=\"token punctuation\">,</span><span class=\"token number\">4.4</span><span class=\"token punctuation\">,</span><span class=\"token number\">3.3</span><span class=\"token punctuation\">,</span><span class=\"token number\">2.2</span><span class=\"token punctuation\">,</span><span class=\"token number\">1.1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n__m256 gemfield_v_m <span class=\"token operator\">=</span> <span class=\"token function\">_mm256_set_ps</span><span class=\"token punctuation\">(</span><span class=\"token number\">9.9</span><span class=\"token punctuation\">,</span><span class=\"token number\">8.8</span><span class=\"token punctuation\">,</span><span class=\"token number\">7.7</span><span class=\"token punctuation\">,</span><span class=\"token number\">6.6</span><span class=\"token punctuation\">,</span><span class=\"token number\">5.5</span><span class=\"token punctuation\">,</span><span class=\"token number\">4.4</span><span class=\"token punctuation\">,</span><span class=\"token number\">3.3</span><span class=\"token punctuation\">,</span><span class=\"token number\">2.2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n__m256 gemfield_v_a <span class=\"token operator\">=</span> <span class=\"token function\">_mm256_set_ps</span><span class=\"token punctuation\">(</span><span class=\"token number\">18.8</span><span class=\"token punctuation\">,</span><span class=\"token number\">17.7</span><span class=\"token punctuation\">,</span><span class=\"token number\">16.6</span><span class=\"token punctuation\">,</span><span class=\"token number\">15.5</span><span class=\"token punctuation\">,</span><span class=\"token number\">14.4</span><span class=\"token punctuation\">,</span><span class=\"token number\">13.3</span><span class=\"token punctuation\">,</span><span class=\"token number\">12.2</span><span class=\"token punctuation\">,</span><span class=\"token number\">11.1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n__m256 gemfield_v_o <span class=\"token operator\">=</span> <span class=\"token function\">_mm256_set_ps</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n\n<span class=\"token keyword\">void</span> <span class=\"token function\">syszuxMulAndAddV</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token keyword\">auto</span> start <span class=\"token operator\">=</span> std<span class=\"token double-colon punctuation\">::</span>chrono<span class=\"token double-colon punctuation\">::</span>system_clock<span class=\"token double-colon punctuation\">::</span><span class=\"token function\">now</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">for</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> j<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">;</span> j<span class=\"token operator\">&lt;</span>loop_num<span class=\"token punctuation\">;</span> j<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{\n    <!-- --></span>\n        gemfield_v_o <span class=\"token operator\">+=</span> <span class=\"token function\">_mm256_fmadd_ps</span><span class=\"token punctuation\">(</span>gemfield_v_i<span class=\"token punctuation\">,</span> gemfield_v_m<span class=\"token punctuation\">,</span> gemfield_v_a<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token keyword\">auto</span> end <span class=\"token operator\">=</span> std<span class=\"token double-colon punctuation\">::</span>chrono<span class=\"token double-colon punctuation\">::</span>system_clock<span class=\"token double-colon punctuation\">::</span><span class=\"token function\">now</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    std<span class=\"token double-colon punctuation\">::</span>chrono<span class=\"token double-colon punctuation\">::</span>duration<span class=\"token operator\">&lt;</span><span class=\"token keyword\">double</span><span class=\"token operator\">&gt;</span> elapsed_seconds <span class=\"token operator\">=</span> end<span class=\"token operator\">-</span>start<span class=\"token punctuation\">;</span>\n    std<span class=\"token double-colon punctuation\">::</span>cout <span class=\"token operator\">&lt;&lt;</span> <span class=\"token string\">\"resultV: \"</span><span class=\"token punctuation\">;</span>\n    <span class=\"token comment\">// float* f = (float*)&amp;gemfield_v_o;</span>\n    <span class=\"token keyword\">for</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i<span class=\"token operator\">&lt;</span>N<span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{\n    <!-- --></span>\n        std<span class=\"token double-colon punctuation\">::</span>cout<span class=\"token operator\">&lt;&lt;</span>gemfield_v_o<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token operator\">&lt;&lt;</span><span class=\"token string\">\" \"</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    std<span class=\"token double-colon punctuation\">::</span>cout<span class=\"token operator\">&lt;&lt;</span> <span class=\"token string\">\"\\nelapsed time: \"</span> <span class=\"token operator\">&lt;&lt;</span> elapsed_seconds<span class=\"token punctuation\">.</span><span class=\"token function\">count</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;&lt;</span> <span class=\"token string\">\"s\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">void</span> <span class=\"token function\">syszuxMulAndAdd</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token keyword\">auto</span> start <span class=\"token operator\">=</span> std<span class=\"token double-colon punctuation\">::</span>chrono<span class=\"token double-colon punctuation\">::</span>system_clock<span class=\"token double-colon punctuation\">::</span><span class=\"token function\">now</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">for</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> j<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">;</span> j<span class=\"token operator\">&lt;</span>loop_num<span class=\"token punctuation\">;</span> j<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token keyword\">for</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i<span class=\"token operator\">&lt;</span>N<span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{\n    <!-- --></span>\n            gemfield_o<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">+=</span> gemfield_i<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> gemfield_m<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> gemfield_a<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token keyword\">auto</span> end <span class=\"token operator\">=</span> std<span class=\"token double-colon punctuation\">::</span>chrono<span class=\"token double-colon punctuation\">::</span>system_clock<span class=\"token double-colon punctuation\">::</span><span class=\"token function\">now</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    std<span class=\"token double-colon punctuation\">::</span>chrono<span class=\"token double-colon punctuation\">::</span>duration<span class=\"token operator\">&lt;</span><span class=\"token keyword\">double</span><span class=\"token operator\">&gt;</span> elapsed_seconds <span class=\"token operator\">=</span> end<span class=\"token operator\">-</span>start<span class=\"token punctuation\">;</span>\n    std<span class=\"token double-colon punctuation\">::</span>cout <span class=\"token operator\">&lt;&lt;</span> <span class=\"token string\">\"result: \"</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">for</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i<span class=\"token operator\">&lt;</span><span class=\"token number\">8</span><span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{\n    <!-- --></span>\n        std<span class=\"token double-colon punctuation\">::</span>cout<span class=\"token operator\">&lt;&lt;</span>gemfield_o<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token operator\">&lt;&lt;</span><span class=\"token string\">\" \"</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    std<span class=\"token double-colon punctuation\">::</span>cout<span class=\"token operator\">&lt;&lt;</span> <span class=\"token string\">\"\\nelapsed time: \"</span> <span class=\"token operator\">&lt;&lt;</span> elapsed_seconds<span class=\"token punctuation\">.</span><span class=\"token function\">count</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;&lt;</span> <span class=\"token string\">\"s\\n\"</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">int</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token function\">syszuxMulAndAdd</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token function\">syszuxMulAndAddV</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">return</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>编译并运行：</p> \n <pre><code class=\"prism language-console\">#compile civilnet.cpp\ngemfield@ThinkPad-X1C:~$ g++ -march=skylake-avx512 civilnet.cpp -o civilnet\n\n#run civilnet\ngemfield@ThinkPad-X1C:~$ ./civilnet\nresult: 2.68435e+08 5.36871e+08 5.36871e+08 1.07374e+09 1.07374e+09 2.14748e+09 2.14748e+09 2.14748e+09 \nelapsed time: 2.39723s\nresultV: 2.68435e+08 5.36871e+08 5.36871e+08 1.07374e+09 1.07374e+09 2.14748e+09 2.14748e+09 2.14748e+09 \nelapsed time: 0.325577s\n</code></pre> \n <h3><a id=\"_1275\"></a>速度比对</h3> \n <p>for loop计算消耗了2.39723秒，</p> \n <p>而vectorization计算消耗了0.325577s，</p> \n <p>可以看到AVX的计算速度远超for loop，因为AVX使用了下面这样的并行方式：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/49fe846d96ec4520b7bf5892e405dda4.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"vectorizationCPU_1289\"></a>除了vectorization，还有什么可以让CPU计算速度更快？</h3> \n <p>如今的CPU并不是大多数程序员所想象的那个黑盒子——按照PC寄存器指向的地址load指令一条一条的执行，这样的CPU在486之后就灭绝了。</p> \n <p>现代CPU（Intel Core2后，AMDBulldozer后）的管线宽度为4个uops，一个时钟周期内最多可以执行4条指令（如果同时有loads、stores和single-uop的ALU指令）。</p> \n <p>因此，vectorization并不是CPU唯一一种并行计算的方式 。</p> \n <h4><a id=\"_1297\"></a>指令层面同样有并行机制</h4> \n <p>在指令与指令层面同样有并行机制，可以让一个单独的CPU core在同一时间内执行多条CPU指令。</p> \n <p>当排队中的多条CPU指令包含了loads、stores、ALU，多数现代的CPU可以在一个时钟周期内同时执行4条指令。平均下来，CPU在每个时钟周期内同时执行2条指令甚至更好——这仰仗于程序如何更好的优化。</p> \n <h4><a id=\"_1305\"></a>多核的并行机制</h4> \n <p>比如，一个 cpu型号为“Core™ i9-9820X CPU”，cpu核为10个，使用超线程技术将CPU核扩展为20个逻辑核/线程数：</p> \n <pre><code class=\"prism language-console\">gemfield@AI3:~$ cat /proc/cpuinfo | grep -i \"processor\"\nprocessor       : 0\nprocessor       : 1\nprocessor       : 2\nprocessor       : 3\nprocessor       : 4\nprocessor       : 5\nprocessor       : 6\nprocessor       : 7\nprocessor       : 8\nprocessor       : 9\nprocessor       : 10\nprocessor       : 11\nprocessor       : 12\nprocessor       : 13\nprocessor       : 14\nprocessor       : 15\nprocessor       : 16\nprocessor       : 17\nprocessor       : 18\nprocessor       : 19\n\ngemfield@AI3:~$ cat /proc/cpuinfo | grep -i \"processor\" | wc -l\n20\n</code></pre> \n <p>在这台机器上，我们可以同时运行20个线程（因为20个核是由HT扩展出来的，真正能同时运行的线程数量位于10个到20个之间）。</p> \n <p>只不过20个超线程对计算密集型的加速并非20倍（也即并非超线程数），而是10倍（也即cpu核数），</p> \n <p>因此，假如一个CPU拥有20个逻辑核、10个CPU核，每个核的每个时钟周期平均执行2个vector计算，每个vector计算可以同时操作8个float数。</p> \n <p>因此，至少在理论上，这个的机器可以在一个时钟周期内执行10 * 2 * 8 = 160个操作（当前，不同的指令有不同的吞吐量）。</p> \n <h4><a id=\"_1344\"></a>系统维度的的并行机制</h4> \n <p>接下来，应用层的程序员还会熟悉这一点：多线程——在多个处理器核上同时运行多个指令序列。</p> \n <p>这是 微观层面的cpu的时间片 调度方案。</p> \n <h2><a id=\"ClickHouse_1352\"></a>ClickHouse中的列式存储</h2> \n <p>clickhouse就是列式储存</p> \n <h3><a id=\"_1356\"></a>从数据存储讲起</h3> \n <p>我们最先接触的数据库系统，大部分都是行存储系统。</p> \n <p>大学的时候学数据库，老师让我们将数据库想象成一张表格，每条数据记录就是一行数据，每行数据包含若干列。</p> \n <p>所以我们对大部分数据存储的思维也就是一个复杂一点的表格管理系统。</p> \n <p>我们在一行一行地写入数据，然后按查询条件查询过滤出我们想要的行记录。</p> \n <p>大部分传统的关系型数据库，都是面向行来组织数据的。</p> \n <p>如 Mysql，Postgresql。近几年，也越来越多传统数据库加入了列存储的能力。虽然列存储的技术在十几年前就已经出现，却从来没有像现在这样成为一种流行的存储组织方式。</p> \n <p>行存储和列存储，是数据库底层组织数据的方式。（和文档型、K-V 型，时序型等概念不在一个层次）</p> \n <h3><a id=\"_1372\"></a>列式存储与行式存储</h3> \n <p>首先先来看看，行式存储是怎么样的，下面那张表<br> <img src=\"https://img-blog.csdnimg.cn/19196ef0da8c4ba8a77cea202e79d31f.png\" alt=\"在这里插入图片描述\"></p> \n <p>当我们是行式存储的时候，数据是一行一行的存储的，如下图<br> <img src=\"https://img-blog.csdnimg.cn/69322544a5cf4dfaaa6c1221de3925f8.png\" alt=\"在这里插入图片描述\"></p> \n <p>但是当我们是列式存储的时候就不一样了，是一列一列存储的，如下图<br> <img src=\"https://img-blog.csdnimg.cn/fefb1df0e96447f492b163dff67482dc.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"RowStore__ColumnStore_1387\"></a>Row-Store与 Column-Store对比</h3> \n <p>而clickhouse就是列式储存，但是行式存储跟列式存储有什么区别吗，或者说双方的优缺点是什么？</p> \n <p>行式存储的优缺点：</p> \n <ul>\n  <li>优点： \n   <ul>\n    <li>数据都被保存到一起</li>\n    <li>添加，修改，删除操作相对比较容易</li>\n   </ul> </li>\n  <li>缺点： \n   <ul>\n    <li>当你只是想要查询一条记录中的几列的时候，会把一条记录所有列的数据搜索出来，导致搜索太慢</li>\n   </ul> </li>\n  <li>应用场景： \n   <ul>\n    <li>适合随机的增删改查操作</li>\n    <li>需要在行中选取所有属性的查询操作</li>\n    <li>需要频繁插入或更新的操作，其操作与索引和行的大小更为相关</li>\n   </ul> </li>\n </ul> \n <p>列式存储的优缺点：</p> \n <ul>\n  <li>优点： \n   <ul>\n    <li>查询时，只有涉及到的列会被读取，所以查询速度会相对较快</li>\n    <li>投影很高效</li>\n    <li>任何列都可以作为索引</li>\n   </ul> </li>\n  <li>缺点： \n   <ul>\n    <li>选择完成时，被选择的列要重新组装</li>\n    <li>添加，修改，删除操作相对比较麻烦</li>\n   </ul> </li>\n  <li>应用场景： \n   <ul>\n    <li>查询需要大量行但是少数几个列</li>\n    <li>用于存储海量数据，并且修改操作不多的场景</li>\n   </ul> </li>\n </ul> \n <table>\n  <thead>\n   <tr>\n    <th align=\"left\">Row-Store</th>\n    <th align=\"left\">Column-Store</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td align=\"left\">因为按一行一行写和读取数据，因此读取数据时往往需要读取那些不必要的列</td>\n    <td align=\"left\">可以只读取必要的列</td>\n   </tr>\n   <tr>\n    <td align=\"left\">易于按记录读写数据</td>\n    <td align=\"left\">对一个一个记录的数据写入和读取都较慢</td>\n   </tr>\n   <tr>\n    <td align=\"left\">适合 OLTP 系统</td>\n    <td align=\"left\">适合 OLAP 系统</td>\n   </tr>\n   <tr>\n    <td align=\"left\">不利于大数据集的聚合统计操作</td>\n    <td align=\"left\">利于大数据集的数据聚合操作</td>\n   </tr>\n   <tr>\n    <td align=\"left\">不利于压缩数据</td>\n    <td align=\"left\">利于压缩数据</td>\n   </tr>\n  </tbody>\n </table> \n <h3><a id=\"_1424\"></a>列存储优势</h3> \n <p>基于列模式的存储，天然就会具备以下几个优点：</p> \n <ul>\n  <li> <p>自动索引</p> <p>因为基于列存储，所以每一列本身就相当于索引。所以在做一些需要索引的操作时，就不需要额外的数据结构来为此列创建合适的索引。</p> </li>\n  <li> <p>利于数据压缩</p> <p>利于压缩有两个原因。一来你会发现大部分列数据基数其实是重复的，这就可以做数据压缩。列式存储具有数据压缩特性，数据压缩比率是由压缩算法、列的数据类型、数据重复度等决定的。如果列有唯一约束，那么列中每行的数据都是唯一的，数据压缩比率就低。在InnoDB和StoneDB下，分别向具有唯一值的列插入6000万条数据，InnoDB表大小16G多，StoneDB表大小5G多，压缩比率为3:1多，而一般情况下是可以达到10:1以上的。</p> </li>\n </ul> \n <p>Apache Druid 底层数据存储就是基于列模式，另外 HBase 是一个比较有代表性的列存储模式数据库。</p> \n <h2><a id=\"ClickHouse_1439\"></a>ClickHouse的安装和使用</h2> \n <h3><a id=\"_1441\"></a>环境准备</h3> \n <p>从事服务器开发工作的都会遇到，linux下open_file的值默认是1024；max user processes（用户的线程数）的值默认是4096，在实际用于中，这两个值严重不足，常常需要调整这两个值。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/261fda1935d2401697cb944054050906.png\" alt=\"在这里插入图片描述\"></p> \n <blockquote> \n  <p>具体的参数介绍，请参见视频</p> \n </blockquote> \n <p>Clickhouse stack有一个单节点的Clickhouse服务容器和一个TabixUI作为Clickhouse的客户端。</p> \n <p>Clickhouse官方暂时没有图形化界面操作，只支持命令行下操作很不方便，不过官网提到了几个第三方的图形化界面，包括Tabix。</p> \n <p>官网：https://tabix.io/ Tabix是一个第三方的开源Clickhouse图形化界面，免费而且是基于浏览器访问。</p> \n <p>注，ClickHouse需要使用的端口包括用于HTTP通信的8123端口和用于主机间通信的9000端口。</p> \n <h3><a id=\"SSE42_1461\"></a>SSE4.2验证</h3> \n <p>验证是否支持SSE 4.2指令集,因为向量化执行需要用到这项特性</p> \n <pre><code class=\"prism language-shell\"><span class=\"token punctuation\">[</span>root@cdh1 clickhouse-alone<span class=\"token punctuation\">]</span><span class=\"token comment\"># grep -q sse4_2 /proc/cpuinfo &amp;&amp; echo \"SSE 4.2 supported\" || echo \"SSE 4.2 not supported\"</span>\nSSE <span class=\"token number\">4.2</span> supported\n\n</code></pre> \n <p>如果不支持SSE指令集，则不能直接使用先前下载的预编译安装包，需要通过源<br> 码编译特定的版本进行安装</p> \n <p>Docker默认是不开启 IPv6 支持的，但是我们某些业务往往又需要 IPv6 的支持，特别是 IPv6 普及大势所趋，本文主要介绍的是如何开启 Docker 桥接网络 IPv6 支持</p> \n <p>编辑 Docker 配置文件<code> /etc/docker/daemon.json</code>，如果该文件不存在，请手动建立。配置文件内容如下，如果你已有的配置文件缺少相应的配置项，添加上即可，没有必要完全覆盖内容。</p> \n <p>cat &gt;/etc/docker/daemon.json &lt;&lt;EOF<br> {\n  <!-- --><br> “registry-mirrors”:[“https://almtd3fa.mirror.aliyuncs.com”]<br> }<br> EOF</p> \n <p>vi /etc/docker/daemon.json</p> \n <pre><code class=\"prism language-go\"><span class=\"token punctuation\">{\n    <!-- --></span>\n  <span class=\"token string\">\"experimental\"</span><span class=\"token punctuation\">:</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span>\n  <span class=\"token string\">\"ipv6\"</span><span class=\"token punctuation\">:</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span>\n  <span class=\"token string\">\"ip6tables\"</span><span class=\"token punctuation\">:</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span>\n  <span class=\"token string\">\"fixed-cidr-v6\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"2607:f0d0:1002:51::/66\"</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>ipv6设置为true，启用对ipv6的支持。<br> ip6tables,启用ip6tables，docker会在ip6tables中配置docker网络相关的规则链。<br> experimental,启用实验特性，ip6tables是docker的一个实验功能，所以需要设为true。</p> \n <p>fixed-cidr-v6,配置ipv6子网。</p> \n <p>添加之后</p> \n <pre><code>[root@cdh1 udemy-single-test]# cat /etc/docker/daemon.json\n\n{\n\n  \"registry-mirrors\":[\"https://almtd3fa.mirror.aliyuncs.com\"],\n  \"experimental\": true,\n  \"ipv6\": true,\n  \"ip6tables\": true,\n  \"fixed-cidr-v6\": \"2607:f0d0:1002:51::/66\"\n}\n\n</code></pre> \n <p>这里<code>ip6tables</code>是指由 Docker 自动配置 IPv6 的防火墙规则，如果你希望自己手动配置，请改为 false 或者移除此项，否则容器将无法连接 IPv6 网络；<code>fixed-cidr-v6</code> 则是我们划分的子网段的第一个，这里仅作示例请读者根据实际情况修改。</p> \n <p>完成配置后请使用 systemctl restart docker 重启docker服务生效。完成此步后 Docker 算是完成对于 IPv6 的支持了</p> \n <h3><a id=\"ClickHouse_1531\"></a>ClickHouse的安装</h3> \n <p>部署代码如下：</p> \n <pre><code class=\"prism language-text\">version: \'3.5\'\n\nservices:\n  clickhouse-alone:\n    container_name: clickhouse-alone\n    image: yandex/clickhouse-server:20.4\n    volumes:\n      - ./data:/var/lib/clickhouse/\n      - ./config.xml:/etc/clickhouse-server/config.xml\n      - ./users.xml:/etc/clickhouse-server/users.xml\n    ports:\n      - \"8123:8123\"\n      - \"9000:9000\"\n      - \"9009:9009\"\n      - \"9004:9004\"\n    ulimits:\n      nproc: 65535\n      nofile:\n        soft: 262144\n        hard: 262144\n    healthcheck:\n      test: [\"CMD\", \"wget\", \"--spider\", \"-q\", \"localhost:8123/ping\"]\n      interval: 30s\n      timeout: 5s\n      retries: 3\n    deploy:\n      resources:\n        limits:\n          cpus: \'4\'\n          memory: 4096M\n        reservations:\n          memory: 4096M\n    networks:\n     ha-network-overlay:\n       aliases:\n        - clickhouse-alone\n  web-client:\n    container_name: web-client\n    image: spoonest/clickhouse-tabix-web-client\n    environment:\n      - CH_NAME=dev\n      - CH_HOST=127.0.0.1:8123\n      - CH_LOGIN=default\n    ports:\n      - \"18080:80\"\n    depends_on:\n      - clickhouse-alone\n    deploy:\n      resources:\n        limits:\n          cpus: \'0.1\'\n          memory: 128M\n        reservations:\n          memory: 128M\n    networks:\n     ha-network-overlay:\n       aliases:\n        - web-client\nnetworks:\n ha-network-overlay:\n  name: ha-network-overlay\n  driver: bridge\n</code></pre> \n <blockquote> \n  <p>具体的安装过程，请参见视频</p> \n </blockquote> \n <pre><code>[root@cdh1 clickhouse-alone]#  tail -f /home/docker-compose/clickhouse/clickhouse-alone/log/clickhouse-server.err.log\n2022.09.21 19:51:31.083714 [ 1 ] {} &lt;Warning&gt; Access(disk): File /var/lib/clickhouse/access/users.list doesn\'t exist\n2022.09.21 19:51:31.083739 [ 1 ] {} &lt;Warning&gt; Access(disk): Recovering lists in directory /var/lib/clickhouse/access/\n^C\n[root@cdh1 clickhouse-alone]#  tail -f /home/docker-compose/clickhouse/clickhouse-alone/log/clickhouse-server.log\n\n</code></pre> \n <h3><a id=\"ClickHouse_1619\"></a>连接ClickHouse</h3> \n <p>ClickHouse提供了两个种接口：</p> \n <ul>\n  <li>HTTP 易于直接使用。</li>\n  <li>本机TCP 开销较小。</li>\n </ul> \n <p>建议使用适当的工具或库来连接，Yandex官方支持以下方式：</p> \n <ul>\n  <li>命令行客户端</li>\n  <li>JDBC驱动程序</li>\n  <li>ODBC驱动程序</li>\n  <li>C ++客户端库</li>\n </ul> \n <p>非官方的第三方库工具：</p> \n <p>这个就太多了，支持Java、Python、PHP、Go、C等各种语言的客户端库</p> \n <p><strong>0 三个默认的端口：</strong></p> \n <p>首先看下ClickHouse配置文件，默认对外开放以下端口：</p> \n <pre><code>  &lt;http_port&gt;8123&lt;/http_port&gt;\n\n  &lt;tcp_port&gt;9000&lt;/tcp_port&gt;\n\n  &lt;mysql_port&gt;9004&lt;/mysql_port&gt;\n</code></pre> \n <h4><a id=\"clickhouseclient_1661\"></a>clickhouse-client</h4> \n <pre><code>docker exec -it clickhouse-alone clickhouse-client  --host 127.0.0.1 --port 9000 --database default --user clickhouse  --password=\'123456\'\n\n</code></pre> \n <p><img src=\"https://img-blog.csdnimg.cn/b6f526df751f4e479f8756d652781fc5.png\" alt=\"在这里插入图片描述\"></p> \n <h4><a id=\"DBeaver_1670\"></a>DBeaver</h4> \n <p>免费和开源的 DBeaver ，支持几乎所有的数据库，这当然也包括ch，而且是Yandex官方推荐哦。</p> \n <p>https://dbeaver.io/download/</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/f618d595339467e6a28e7f3faaf45352.png\" alt=\"img\"></p> \n <p>创建连接，可以在分析数据库中找到ch</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/8dcbfae6dc160a8cbda61822749cf4f4.png\" alt=\"img\"></p> \n <p>配置好JCDB方式的连接</p> \n <p><img src=\"https://img-blog.csdnimg.cn/ddc126e3aee645cf84e212bf8a8f15dc.png\" alt=\"在这里插入图片描述\"></p> \n <p>查看数据库对象和数据没有任何问题。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/9c9a80ad15fdbe441ed2cadb88545054.png\" alt=\"img\"></p> \n <h4><a id=\"Tabix_1700\"></a>Tabix</h4> \n <p>Tabix 也是ch官方推荐的数据库管理工具，他的好处是单独部署一套web服务，用户通过浏览器就可以连接ch数据库，无需额外安装任何客户端，支持SQL语法。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/460ee565e593acfa280a78a5c576b208.png\" alt=\"img\"></p> \n <p>安装很简单：</p> \n <p>https://tabix.io/doc/Install/</p> \n <p>连接CH，注意用http端口 8123</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/ea6a3cd2b0f69edd23f4bbced05833f1.png\" alt=\"img\"></p> \n <p>这种性冷淡风格，很好。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/fef20eb8810ca55da3d0e0747413c4e1.png\" alt=\"img\"></p> \n <h3><a id=\"_1730\"></a>配置文件介绍</h3> \n <p>为了降低修改配置的带来的风险和便于维护管理，我们将默认的配置文件做了如下拆解。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/adab14091ea8e0ff5d4df4f0d1fbab9b.png\" alt=\"img\"></p> \n <h4><a id=\"usersxml_1740\"></a>users.xml</h4> \n <p>users.xml默认的users.xml，可分为三个部分用户设置</p> \n <p>users：主要配置用户信息如账号、密码、访问ip等及对应的权限映射配额设置</p> \n <p>quotas：用于追踪和限制用户一段时间内的资源使用参数权限</p> \n <p>profiles：读写权限、内存、线程等大多数参数配置为了统一管理权限</p> \n <p>我们在users.xml预定义了对应权限及资源的quotas及profiles，例如default_profile、readwrite_profile、readonly_profile等,新增用户无需单独配置quotas及profiles,直接关联预定义好的配置即可</p> \n <h4><a id=\"usersdxxxxml_1752\"></a>users.d/xxx.xml</h4> \n <p>按不同的用户属性设置user配置，</p> \n <p>每一个xml对应一组用户,每个用户关联users.xml中的不同权限quotas及profiles</p> \n <h4><a id=\"users_copyxxxxml_1758\"></a>users_copy/xxx.xml</h4> \n <p>每次有变更用户操作时备份指定属性的xml，方便回滚</p> \n <h4><a id=\"metrikaxml_1762\"></a>metrika.xml</h4> \n <p>默认情况下包含集群的配置、zookeeper的配置、macros的配置,</p> \n <p>当有集群节点变动时，通常需要将修改后的配置文件同步整个集群,而macros 是每个服务器独有的配置,</p> \n <p>metrika.xml 一般建议进行拆解，如果不拆解很容易造成配置覆盖,引起macros混乱丢失数据,所以我们在metrika.xml 中只保留每台服务器<strong>通用的配置信息</strong>,而将独立的配置拆解出去</p> \n <h4><a id=\"confdxxxxml_1770\"></a>conf.d/xxx.xml</h4> \n <p>保存每台服务器独立的配置,如macros.xml</p> \n <h4><a id=\"config_copyxxxxml_1774\"></a>config_copy/xxx.xml</h4> \n <p>存放每次修改主配置时的备份文件，方便回滚</p> \n <h3><a id=\"CH_1781\"></a>CH的数据类型</h3> \n <ol>\n  <li>整形：固定长度的整形，包括有符号整型或无符号整型 \n   <ul>\n    <li>整型范围（-2n-1~2n-1-1）： \n     <ul>\n      <li>Int8 - [-128 : 127]</li>\n      <li>Int16 - [-32768 : 32767]</li>\n      <li>Int32 - [-2147483648 : 2147483647]</li>\n      <li>Int64 - [-9223372036854775808 : 9223372036854775807]</li>\n     </ul> </li>\n    <li>无符号整型范围（0~2n-1）： \n     <ul>\n      <li>UInt8 - [0 : 255]</li>\n      <li>UInt16 - [0 : 65535]</li>\n      <li>UInt32 - [0 : 4294967295]</li>\n      <li>UInt64 - [0 : 18446744073709551615]</li>\n     </ul> </li>\n   </ul> </li>\n  <li>浮点型:一般数据值比较小，不涉及大量的统计计算，精度要求不高的时候。比如保存商品的重量 \n   <ul>\n    <li>Float32 - float</li>\n    <li>Float64 – double</li>\n   </ul> </li>\n  <li>布尔型：没有单独的类型来存储布尔值。可以使用 UInt8 类型，取值限制为 0 或 1。</li>\n  <li>Decimal 型：有符号的浮点数，可在加、减和乘法运算过程中保持精度。对于除法，最低有效数字会被丢弃（不舍入）。 \n   <ul>\n    <li>使用场景： 一般金额字段、汇率、利率等字段为了保证小数点精度，都使用 Decimal 进行存储。</li>\n    <li>Decimal32(s)，相当于 Decimal(9-s,s)，有效位数为 1~9</li>\n    <li>Decimal64(s)，相当于 Decimal(18-s,s)，有效位数为 1~18</li>\n    <li>Decimal128(s)，相当于 Decimal(38-s,s)，有效位数为 1~38</li>\n   </ul> </li>\n  <li>字符串 \n   <ul>\n    <li>String：字符串可以任意长度的。它可以包含任意的字节集，包含空字节。</li>\n    <li>FixedString(N)：固定长度 N 的字符串，N 必须是严格的正自然数。当服务端读取长度小于 N 的字符串时候，通过在字符串末尾添加空字节来达到 N 字节长度。 当服务端读取长度大于 N 的字符串时候，将返回错误消息。与 String 相比，极少会使用 FixedString，因为使用起来不是很方便。</li>\n    <li>使用场景：名称、文字描述、字符型编码。 固定长度的可以保存一些定长的内容，比如一些编码，性别等但是考虑到一定的变化风险，带来收益不够明显，所以定长字符串使用意义有限。</li>\n   </ul> </li>\n  <li>枚举类型 \n   <ul>\n    <li>包括 Enum8 和 Enum16 类型。Enum 保存 ‘string’= integer 的对应关系 \n     <ul>\n      <li>Enum8 用 ‘String’= Int8 对描述。</li>\n      <li>Enum16 用 ‘String’= Int16 对描述。</li>\n     </ul> </li>\n   </ul> </li>\n  <li>时间类型 \n   <ul>\n    <li>Date 接受年-月-日的字符串比如 ‘2019-12-16’</li>\n    <li>Datetime 接受年-月-日 时:分:秒的字符串比如 ‘2019-12-16 20:50:10’</li>\n    <li>Datetime64 接受年-月-日 时:分:秒.亚秒的字符串比如‘2019-12-16 20:50:10.66’</li>\n   </ul> </li>\n </ol> \n <h2><a id=\"CH_1816\"></a>CH表引擎</h2> \n <p>表引擎是Clickhouse 的一大特色。可以说，表引擎决定了如何存储表的数据。包括：</p> \n <ul>\n  <li> <p>数据的存储方式和位置，写到哪里以及从哪里读取数据。</p> </li>\n  <li> <p>支持哪些查询以及如何支持。</p> </li>\n  <li> <p>并发数据访问。</p> </li>\n  <li> <p>索引的使用（如果存在）。</p> </li>\n  <li> <p>是否可以执行多线程请求。</p> </li>\n  <li> <p>数据复制参数。</p> </li>\n  <li> <p>表引擎的使用方式就是必须显式在创建表时定义该表使用的引擎，以及引擎使用的相关参数。</p> </li>\n </ul> \n <h3><a id=\"TinyLog_1828\"></a>TinyLog</h3> \n <p>以列文件的形式保存在磁盘上，不支持索引，没有并发控制。</p> \n <p>一般保存少量数据的小表，生产环境上作用有限。可以用于平时练习测试使用。</p> \n <h3><a id=\"Memory_1834\"></a>Memory</h3> \n <p>内存引擎，数据以未压缩的原始形式直接保存在内存当中，服务器重启数据就会消失。</p> \n <p>读写操作不会相互阻塞，不支持索引。简单查询下有非常非常高的性能表现。</p> \n <p>一般用到它的地方不多，除了用来测试，就是在需要非常高的性能，同时数据量又不太大的场景</p> \n <h3><a id=\"MergeTree_1842\"></a>MergeTree</h3> \n <p>clickhouse中最强大的表引擎当属MergeTree引擎及该系列中的其他引擎，支持索引和分区，</p> \n <p><strong>MergeTree 地位可以相当于innodb之于Mysql。</strong></p> \n <p>而且基于MergeTree，还衍生除了很多小弟，也是非常有特色的引擎。</p> \n <pre><code>create table t_order_mt(\n id UInt32,\n sku_id String,\n total_amount Decimal(16,2),\n create_time Datetime\n) engine =MergeTree\n partition by toYYYYMMDD(create_time)\n primary key (id)\n order by (id,sku_id);\n</code></pre> \n <h3><a id=\"ReplacingMergeTree_1864\"></a>ReplacingMergeTree</h3> \n <p>ReplacingMergeTree 是 MergeTree 的一个变种，</p> \n <p>它存储特性完全继承 MergeTree，只是多了一个去重的功能。</p> \n <p>尽管 MergeTree 可以设置主键，但是 primary key 其实没有唯一约束的功能。如果你想处理掉重复的数据，可以借助这个 ReplacingMergeTree。</p> \n <p><strong>去重的时机：</strong></p> \n <p>数据的去重只会在合并的过程中出现。</p> \n <p>合并会在未知的时间在后台进行，所以你无法预测先作出计划。有一些数据可能仍未被处理。</p> \n <p><strong>去重的范围：</strong></p> \n <p>如果表经过了分区，去重只会在分区内部进行去重，不能执行跨分区的去重。所以ReplacingMergeTree只适用于在后台清楚重复的数据以节省空间，但是它不保证没有重复的数据出现</p> \n <p><strong>结论：</strong></p> \n <ul>\n  <li>实际上是使用 order by 字段作为唯一键</li>\n  <li>去重不能跨分区</li>\n  <li>只有同一批插入（新版本）或合并分区时才会进行去重</li>\n  <li>认定重复的数据保留，版本字段值最大的</li>\n  <li>如果版本字段相同则按插入顺序保留最后一笔</li>\n </ul> \n <h3><a id=\"SummingMergeTree_1890\"></a>SummingMergeTree</h3> \n <p>对于不查询明细，只关心以维度进行汇总聚合结果的场景。</p> \n <p>如果只使用普通的MergeTree的话，无论是存储空间的开销，还是查询时临时聚合的开销都比较大。</p> \n <p>ClickHouse 为了这种场景，提供了一种能够“预聚合”的引擎 SummingMergeTree</p> \n <p>案例演示：<br> <img src=\"https://img-blog.csdnimg.cn/f90ed4ae58dd41f19392603f3a6083fd.png\" alt=\"在这里插入图片描述\"><br> <img src=\"https://img-blog.csdnimg.cn/e438d4c07704438d90e74bece21f2ffd.png\" alt=\"在这里插入图片描述\"></p> \n <p>结论：</p> \n <ul>\n  <li>以 SummingMergeTree（）中指定的列作为汇总数据列</li>\n  <li>可以填写多列必须数字列，如果不填，以所有非维度列且为数字列的字段为汇总数据列</li>\n  <li>以 order by 的列为准，作为维度列</li>\n  <li>其他的列按插入顺序保留第一行</li>\n  <li>不在一个分区的数据不会被聚合</li>\n  <li>只有在同一批次插入(新版本)或分片合并时才会进行聚合</li>\n </ul> \n <h2><a id=\"CH_1911\"></a>CH的基本操作</h2> \n <h3><a id=\"DDL_1913\"></a>DDL建表</h3> \n <pre><code class=\"prism language-sql\"><span class=\"token keyword\">create</span> <span class=\"token keyword\">table</span> t_order_mt<span class=\"token punctuation\">(</span>\n id UInt32<span class=\"token punctuation\">,</span>\n sku_id String<span class=\"token punctuation\">,</span>\n total_amount <span class=\"token keyword\">Decimal</span><span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n create_time <span class=\"token keyword\">Datetime</span>\n<span class=\"token punctuation\">)</span> <span class=\"token keyword\">engine</span> <span class=\"token operator\">=</span>MergeTree\n <span class=\"token keyword\">partition</span> <span class=\"token keyword\">by</span> toYYYYMMDD<span class=\"token punctuation\">(</span>create_time<span class=\"token punctuation\">)</span>\n <span class=\"token keyword\">primary</span> <span class=\"token keyword\">key</span> <span class=\"token punctuation\">(</span>id<span class=\"token punctuation\">)</span>\n <span class=\"token keyword\">order</span> <span class=\"token keyword\">by</span> <span class=\"token punctuation\">(</span>id<span class=\"token punctuation\">,</span>sku_id<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n</code></pre> \n <ul>\n  <li> <p>partition by 表示的是分区，上述sql所用的就是说根据创建时间进行分区</p> </li>\n  <li> <p>primary key 代表的是主键，特点如下：</p> \n   <ul>\n    <li>并不会唯一</li>\n    <li>索引</li>\n   </ul> </li>\n  <li> <p>order by 代表的是根据那两个字段进行排序</p> </li>\n </ul> \n <p><img src=\"https://img-blog.csdnimg.cn/4886dd3c97ca4b728f5ad30ec3364189.png\" alt=\"在这里插入图片描述\"></p> \n <p>尝试插入数据</p> \n <pre><code class=\"prism language-sql\"><span class=\"token keyword\">insert</span> <span class=\"token keyword\">into</span> t_order_mt <span class=\"token keyword\">values</span>\n<span class=\"token punctuation\">(</span><span class=\"token number\">101</span><span class=\"token punctuation\">,</span><span class=\"token string\">\'sku_001\'</span><span class=\"token punctuation\">,</span><span class=\"token number\">1000.00</span><span class=\"token punctuation\">,</span><span class=\"token string\">\'2020-06-01 12:00:00\'</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">(</span><span class=\"token number\">102</span><span class=\"token punctuation\">,</span><span class=\"token string\">\'sku_002\'</span><span class=\"token punctuation\">,</span><span class=\"token number\">2000.00</span><span class=\"token punctuation\">,</span><span class=\"token string\">\'2020-06-01 11:00:00\'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">(</span><span class=\"token number\">102</span><span class=\"token punctuation\">,</span><span class=\"token string\">\'sku_004\'</span><span class=\"token punctuation\">,</span><span class=\"token number\">2500.00</span><span class=\"token punctuation\">,</span><span class=\"token string\">\'2020-06-01 12:00:00\'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">(</span><span class=\"token number\">102</span><span class=\"token punctuation\">,</span><span class=\"token string\">\'sku_002\'</span><span class=\"token punctuation\">,</span><span class=\"token number\">2000.00</span><span class=\"token punctuation\">,</span><span class=\"token string\">\'2020-06-01 13:00:00\'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">(</span><span class=\"token number\">102</span><span class=\"token punctuation\">,</span><span class=\"token string\">\'sku_002\'</span><span class=\"token punctuation\">,</span><span class=\"token number\">12000.00</span><span class=\"token punctuation\">,</span><span class=\"token string\">\'2020-06-01 13:00:00\'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">(</span><span class=\"token number\">102</span><span class=\"token punctuation\">,</span><span class=\"token string\">\'sku_002\'</span><span class=\"token punctuation\">,</span><span class=\"token number\">600.00</span><span class=\"token punctuation\">,</span><span class=\"token string\">\'2020-06-02 12:00:00\'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n</code></pre> \n <p><img src=\"https://img-blog.csdnimg.cn/fb8de01761e64847bb3e75afb7852fc8.png\" alt=\"在这里插入图片描述\"></p> \n <p><img src=\"https://img-blog.csdnimg.cn/36c640f4ce3844ba93203cb14b6ef982.png\" alt=\"在这里插入图片描述\"></p> \n <p>通过命令执行 ： SELECT * FROM t_order_mt tom</p> \n <p><img src=\"https://img-blog.csdnimg.cn/d1bb6f2d22c54305813057856506a71d.png\" alt=\"在这里插入图片描述\"></p> \n <p>发现结果分为两部分， 是因为建表的时候，根据 create_time进行了分区</p> \n <blockquote> \n  <p>以上实操过程， 尼恩会在视频中，做详细解读</p> \n </blockquote> \n <h4><a id=\"partition_by__1970\"></a>partition by 分区（可选）</h4> \n <p>作用：降低扫描的范围，优化查询速度</p> \n <p><strong>分区目录：</strong></p> \n <p>MergeTree是以列文件 + 索引文件 + 表定义文件组成的，但是如果设定了分区，那么这些文件就会保存到不同的分区目录中。</p> \n <p><strong>并行：</strong></p> \n <p>分区后，面对涉及跨分区的查询统计，Clickhouse会以分区为单位并行处理。</p> \n <p><strong>数据写入与分区合并：</strong></p> \n <p>任何一个批次的数据写入都会产生一个临时分区，不会纳入任何一个已有的分区。</p> \n <p>写入后的某个时刻，clickhouse会自动执行合并操作，把临时分区的数据，合并到已有分区中。</p> \n <p><strong>分区文件目录：</strong></p> \n <ul>\n  <li>bin文件：数据文件</li>\n  <li>mrk文件：标记文件 \n   <ul>\n    <li>标记文件在idx索引文件和bin数据文件之间起了桥梁作用</li>\n    <li>以mrk2结尾的文件，表示该表启用了自适应索引间隔</li>\n   </ul> </li>\n  <li>primary.idx文件：主键索引文件，用于加快查询效率</li>\n  <li>minmax_create_time.idx：分区键的最大最小值</li>\n  <li>checksums.txt：校验文件，用于校验各个文件的正确性。存放各个文件的size以及hash值</li>\n </ul> \n <p><strong>分区id生成规则：</strong></p> \n <ul>\n  <li> <p>未定义分区键：没有定义partition by， 默认生成一个目录名为all的数据分区，所有数据均存放在all目录下。</p> </li>\n  <li> <p>整型分区键：分区键为整型，那么直接用该整型值的字符串形式做为分区ID</p> </li>\n  <li> <p>日期类分区键：分区键为日期类型，或者可以转化为日期类型。</p> </li>\n  <li> <p>其他类型分区键：String，Float类型等，通过128位的Hash算法取其Hash值作为分区ID</p> </li>\n  <li> <p>MinBlockNum：最小分区块编号，自增类型，从1开始向上递增。</p> </li>\n  <li> <p>MaxBlockNum：最大分区块编号，新创建的分区MinBlockNum等于MaxBlockNum的编号</p> </li>\n </ul> \n <h4><a id=\"primary_key__2008\"></a>primary key 主键(可选)</h4> \n <p>clickhouse中的主键只提供了数据的一级索引，但是却不是唯一约束。</p> \n <p>这就意味着是可以存在相同primary key的数据的。</p> \n <p>主键的设定主要依据: 是查询语句中的where条件</p> \n <p>根据条件通过对主键进行某种形式的二分查找，能够定位到对应的索引粒度（index granularity），避免了全表扫描</p> \n <p>index granularity：索引粒度，指在稀疏索引中两个相邻索引对应数据的间隔。</p> \n <p>Clickhouse中的MergeTree默认是8192.</p> \n <p>官方不建议修改这个值，除非该列存在大量重复值。</p> \n <p><strong>稀疏索引：</strong></p> \n <p>是可以用很少的索引数据，定位更多的数据，代价就是只能定位到索引粒度的第一行，然后再进行进行一点扫描。<br> <img src=\"https://img-blog.csdnimg.cn/2cd0fd5a835c4eea984520e17a827179.png\" alt=\"在这里插入图片描述\"></p> \n <h4><a id=\"order_by_2029\"></a>order by（必选）</h4> \n <p>order by 设定了分区内的数据按照哪些字段顺序进行有序保存。</p> \n <p>order by 是 MergeTree 中唯一一个必填项，甚至比 primary key 还重要，因为当用户不设置主键的情况，很多处理会依照 order by 的字段进行处理（比如后面会讲的去重和汇总）。</p> \n <p><strong>要求：</strong></p> \n <p>主键必须是 order by 字段的前缀字段。</p> \n <p>比如 order by 字段是 (id,sku_id) , 那么主键必须是 id 或者(id,sku_id)</p> \n <h4><a id=\"TTL_2041\"></a>数据TTL</h4> \n <p>TTL 即 Time To Live，MergeTree 提供了可以管理数据表或者列的生命周期的功能。<br> <img src=\"https://img-blog.csdnimg.cn/d6b9f64670fc49669a9ab8e0dd21d115.png\" alt=\"在这里插入图片描述\"><br> <img src=\"https://img-blog.csdnimg.cn/118d8494060841a28216d7099991c83f.png\" alt=\"在这里插入图片描述\"></p> \n <h2><a id=\"SQL_2049\"></a>SQL操作</h2> \n <h3><a id=\"Insert_2051\"></a>Insert</h3> \n <p>在表内插入一条数据：</p> \n <pre><code>insert into [table_name] values(…),(….)\n</code></pre> \n <p>在表内插入一个表的数据：</p> \n <pre><code>insert into [table_name] select a,b,c from [table_name_2]\n</code></pre> \n <h3><a id=\"Update__Delete_2065\"></a>Update 和 Delete</h3> \n <p>ClickHouse 提供了 Delete 和 Update 的能力，这类操作被称为 Mutation 查询，它可以看做 Alter 的一种。</p> \n <p>虽然可以实现修改和删除，但是和一般的 OLTP 数据库不一样，Mutation 语句是一种很“重”的操作，而且不支持事务。</p> \n <p>“重”的原因主要是：</p> \n <blockquote> \n  <p>每次修改或者删除都会导致放弃目标数据的原有分区，重建新分区。</p> \n </blockquote> \n <p>所以尽量做批量的变更，不要进行频繁小数据的操作。</p> \n <p>删除操作：</p> \n <pre><code>alter table t_order_smt delete where sku_id =‘sku_001’;\n</code></pre> \n <p>修改操作：</p> \n <pre><code>alter table t_order_smt update total_amount=toDecimal32(2000.00,2) where id =102;\n</code></pre> \n <p>由于操作比较“重”，所以 Mutation 语句分两步执行，</p> \n <ul>\n  <li>同步执行的部分其实只是进行新增数据新增分区和并把旧分区打上逻辑上的失效标记。</li>\n  <li>直到触发分区合并的时候，才会删除旧数据释放磁盘空间，一般不会开放这样的功能给用户，由管理员完成。</li>\n </ul> \n <h3><a id=\"_2093\"></a>查询操作</h3> \n <p>ClickHouse 基本上与标准 SQL 差别不大：</p> \n <ul>\n  <li> <p>支持子查询</p> </li>\n  <li> <p>支持 CTE(Common Table Expression 公用表表达式 with 子句)</p> </li>\n  <li> <p>支持各种 JOIN，但是 JOIN 操作无法使用缓存，所以即使是两次相同的 JOIN 语句，ClickHouse 也会视为两条新 SQL</p> </li>\n  <li> <p>GROUP BY</p> </li>\n </ul> \n <p><img src=\"https://img-blog.csdnimg.cn/37a528e92d484995ac02406bafd2db72.png\" alt=\"在这里插入图片描述\"></p> \n <ul>\n  <li> <p>GROUP BY 操作增加了 with rollup\\with cube\\with total 用来计算小计和总计。</p> </li>\n  <li> <p>GROUP BY with rollup：从右至左去掉维度进行小计</p> <p><img src=\"https://img-blog.csdnimg.cn/0de88c7281024750bb6f8b1dd7b5a814.png\" alt=\"在这里插入图片描述\"></p> </li>\n  <li> <p>GROUP BY with cube : 从右至左去掉维度进行小计，再从左至右去掉维度进行小计</p> <p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-gmJvnMuB-1663815310200)(C:\\Users\\nien\\AppData\\Roaming\\Typora\\typora-user-images\\1663815123052.png)]</p> </li>\n  <li> <p>GROUP BY with totals: 只计算合计</p> <p><img src=\"https://img-blog.csdnimg.cn/ecd07ddbca614f78be3006c35a9e08ac.png\" alt=\"在这里插入图片描述\"></p> </li>\n </ul> \n <h3><a id=\"alter__2125\"></a>alter 操作</h3> \n <ul>\n  <li>新增字段：alter table tableName add column newcolname String after col1;</li>\n  <li>修改字段类型：alter table tableName modify column newcolname String;</li>\n  <li>删除字段：alter table tableName drop column newcolname;</li>\n </ul> \n <blockquote> \n  <p>以上实操过程， 尼恩会在视频中，做详细解读</p> \n </blockquote> \n <h2><a id=\"CH_2135\"></a>CH高可用分片集群的多种架构</h2> \n <h3><a id=\"_2139\"></a>高可用集群的目标</h3> \n <p><strong>高可用的目标是 4个9，甚至5个9</strong></p> \n <p>系统可用性(Availability)是信息工业界用来衡量一个信息系统提供持续服务的能力，它表示的是在给定时间区间内系统或者系统某一能力在特定环境中能够正常工作的概率。</p> \n <p>简单地说， 可用性是平均故障间隔时间(MTBF)除以平均故障间隔时间(MTBF)和平均故障修复时间(MTTR)之和所得的结果， 即：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/bd1fd60467d9841ccb86f3b4b6bd046e.png\" alt=\"bd1fd60467d9841ccb86f3b4b6bd046e.png\"></p> \n <p>通常业界习惯用N个9来表征系统可用性，表示系统可以正常使用时间与总时间(1年)之比，比如：</p> \n <ul>\n  <li>99.9%代表3个9的可用性，意味着全年不可用时间在8.76小时以内，表示该系统在连续运行1年时间里最多可能的业务中断时间是8.76小时；</li>\n  <li>99.99%代表4个9的可用性，意味着全年不可用时间在52.6分钟以内,表示该系统在连续运行1年时间里最多可能的业务中断时间是52.6分钟；</li>\n  <li>99.999%代表5个9的可用性，意味着全年不可用时间必须保证在5.26分钟以内，缺少故障自动恢复机制的系统将很难达到5个9的高可用性。</li>\n </ul> \n <p>那么X个9里的X只代表数字3<sub>5，为什么没有1</sub>2，也没有大于6的呢？</p> \n <p>我们接着往下计算：</p> \n <pre><code>1个9：(1-90%)*365=36.5天 \n\n*2个9：(1-99%)*365=3.65天 \n\n6个9：(1-99.9999%)*365*24*60*60=31秒\n</code></pre> \n <p>可以看到1个9和、2个9分别表示一年时间内业务可能中断的时间是36.5天、3.65天，这种级别的可靠性或许还不配使用“可靠性”这个词；</p> \n <p>而6个9则表示一年内业务中断时间最多是31秒，那么这个级别的可靠性并非实现不了，而是要做到从“5个9” 到“6个9”的可靠性提升的话，后者需要付出比前者几倍的成本。</p> \n <h3><a id=\"1_Distributed__2179\"></a>高可用表引擎1： Distributed 分布式表</h3> \n <p>分布式引擎本身不存储数据, 但可以在多个服务器上进行分布式查询。</p> \n <blockquote> \n  <p>Distributed 分布式引擎可以理解为ES集群中的 ClientNode</p> \n </blockquote> \n <p>读是自动并行的。读取时，远程服务器表的索引（如果有的话）会被使用。</p> \n <p>我们可以引申理解它就相当于关系型数据库中的视图概念。</p> \n <blockquote> \n  <p>示例：ENGINE = Distributed(&lt;集群名称&gt;, &lt;库名&gt;, &lt;表名&gt;[, sharding_key])</p> \n </blockquote> \n <p>与分布式表对应的是本地表，</p> \n <p>也就是上面的&lt;表名&gt;参数，查询分布式表的时候，ClickHouse会自动查询所有分片，然后将结果汇总后返回</p> \n <h4><a id=\"_2195\"></a>向分布式表插入数据</h4> \n <p>ClickHouse会根据分片权重将数据分散插入到各个分片中</p> \n <p>默认情况下，每个分片中所有副本都会写入数据</p> \n <p>或者通过参数internal_replication配置每个分片只写入其中一个副本，使用复制表(ReplicateMergeTree)管理数据的副本</p> \n <h4><a id=\"2_ReplicatedMergeTree__2203\"></a>高可用相关的表引擎2： ReplicatedMergeTree 复制表</h4> \n <blockquote> \n  <p>ReplicatedMergeTree<br> ReplicatedSummingMergeTree<br> ReplicatedReplacingMergeTree<br> ReplicatedAggregatingMergeTree<br> ReplicatedCollapsingMergeTree<br> ReplicatedVersionedCollapsingMergetree<br> ReplicatedGraphiteMergeTree</p> \n </blockquote> \n <blockquote> \n  <p>注意：只有MergeTree系列引擎支持Replicated前缀</p> \n </blockquote> \n <ul>\n  <li> <p>副本是表级别的，不是整个服务器级的。所以，服务器里可以同时有复制表和非复制表</p> </li>\n  <li> <p>副本不依赖分片。每个分片有它自己的独立副本</p> </li>\n  <li> <p>数据副本使用到Zookeeper，需要在metrika.xml中配置zk的集群信息</p> </li>\n  <li> <p>SELECT 查询并不需要借助 ZooKeeper ，副本并不影响 SELECT 的性能，查询复制表与非复制表速度是一样的</p> </li>\n  <li> <p>默认情况下，INSERT 语句仅等待一个副本写入成功后返回。</p> <p>如果数据只成功写入一个副本后该副本所在的服务器不再存在，则存储的数据会丢失。</p> <p>要启用数据写入多个副本才确认返回，使用 insert_quorum选项</p> </li>\n  <li> <p>数据块会去重。</p> <p>对于被多次写的相同数据块（大小相同且具有相同顺序的相同行的数据块），该块仅会写入一次</p> </li>\n </ul> \n <blockquote> \n  <p>示例：</p> \n  <p>ENGINE = ReplicatedMergeTree(‘/clickhouse/tables/{layer}-{shard}/table_name’, ‘{replica}’)</p> \n </blockquote> \n <p>大括号中的参数是metrika.xml中macros配置的，</p> \n <p>每个节点读取自己的配置信息，统一了建表语句</p> \n <p>第一个参数用于zk中的目录结构，用了layer-shard名称分层</p> \n <p>第二个参数是副本名，用于标识同一个表分片的不同副本，同个分片中不同副本的副本名称要唯一</p> \n <h3><a id=\"CH1MergeTree___Distributed_2251\"></a>CH高可用方案1：MergeTree 本地表 + Distributed分布式表</h3> \n <p>每个分片中只有一个副本，数据存储在 本地表(MergeTree)，</p> \n <p>查询分布式表，引擎自动向所有分片查询数据并计算后返回</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/b08c7451fc2f137dcf10fd384b4d9585.jpeg\" alt=\"img\"></p> \n <p><strong>优势</strong></p> \n <p>架构简单，单机和分布式都可以用</p> \n <p><strong>劣势</strong></p> \n <p>单点问题，数据丢失风险大</p> \n <h3><a id=\"CH2MergeTree___Distributed_____2273\"></a>CH高可用方案2：MergeTree 本地表 + Distributed 分布式 + 多副本</h3> \n <p>在方案一的基础上为每个节点增加副本</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/d8b3ac7d50f548a5eea15873511f7684.jpeg\" alt=\"img\"></p> \n <p><strong>优势</strong></p> \n <p>在1.0的基础上，数据安全有了保障，任何一个实例或者服务器挂掉了，不影响集群查询服务</p> \n <p><strong>劣势</strong></p> \n <p>如果某个节点挂了，恢复以后可以将丢失的增量数据补全，</p> \n <p>但是如果硬盘彻底损坏，存量数据基本无法恢复，</p> \n <p>且这种方案不能用<strong>两个节点互为主备</strong>，会造成数据错乱</p> \n <h3><a id=\"CH3ReplicatedMergeTree__Distributed___2297\"></a>CH高可用方案3：ReplicatedMergeTree + Distributed + 多副本</h3> \n <p>把2.0方案中的数据表引擎替换成 ReplicatedMergeTree，并设置分布式写入时, 只写入分片的一个节点：</p> \n <blockquote> \n  <p>internal_replication 设置为true</p> \n </blockquote> \n <p>实现同一个分片中，写入一个节点的数据后，自动同步到其他的副本中</p> \n <p>下图实现的是一个节点启动多个ClickHouse实例</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/c91c5c97259bbe7277c1c2aea44ef464.jpeg\" alt=\"img\"></p> \n <p><strong>优势</strong></p> \n <p>由 ReplicatedMergeTree 表引擎管理数据副本(依赖Zookeeper)，无须担心节点挂掉后数据的同步和丢失问题</p> \n <p><strong>劣势</strong></p> \n <p>集群配置比较复杂， <code>macros</code>配置分片和副本需要仔细</p> \n <p><code>metrika.xml</code>配置</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/12a0c9a2882d1b0ea8ce8e6d8dbbc084.jpeg\" alt=\"img\"></p> \n <h5><a id=\"_2331\"></a>节点扩展</h5> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/122b0c4dce241d016a1fb8e4c91f70b6.jpeg\" alt=\"img\"></p> \n <p>在ClickHouse集群中使用复制表引擎 ReplicatedMergeTree 建立本地表，</p> \n <p>插入的数据会在ClickHouse的副本间进行自动复制，实现数据的高可用效果</p> \n <h2><a id=\"CH_2347\"></a>实操：CH分布式集群方案</h2> \n <h3><a id=\"_2351\"></a>高可用集群的架构方案</h3> \n <p>首先来看下本节内容大致的架构：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/729ab2d0ca2cb775e0abea7371dcf771.png\" alt=\"img\"></p> \n <p>如上图，整个集群一共 4 个节点，分为两个分片，每个分片一个副本。</p> \n <p>除了在每个节点创建 ReplicatedMergeTree 表，还会创建 Distributed 引擎的总表，</p> \n <p>Distributed 引擎的总表是 各个节点上的本地表的总代理，写入、查询、分发等操作都经过分布式总表路由。</p> \n <h3><a id=\"ClickHouse_2365\"></a>ClickHouse的集群层级</h3> \n <p>ClickHouse的集群层级，对应metrika.xml配置中的<code>macros</code>节点：</p> \n <blockquote> \n  <p><strong>集群</strong>《layer》 =&gt; <strong>分片</strong>《shard》 =&gt; <strong>副本</strong>《replica》 (每个ClickHouse实例都可以看做一个副本)</p> \n </blockquote> \n <table>\n  <thead>\n   <tr>\n    <th>Cluster</th>\n    <th>一个集群可以包括若干个Cluster</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>Shard</td>\n    <td>一个Cluster可以包括若干个Shard</td>\n   </tr>\n   <tr>\n    <td></td>\n    <td>一个Shard又可以包含若干个Replicate</td>\n   </tr>\n   <tr>\n    <td></td>\n    <td>一个Replicate就是一个特定的节点实例</td>\n   </tr>\n  </tbody>\n </table> \n <p>ClickHouse集群信息基于手工编写配置文件<code>metrika.xml</code>，默认加载/etc/metrika.xml，</p> \n <p>为了方便管理我们在主配置文件中引用<code>/etc/clickhouse-server/metrika.xml</code>，</p> \n <p>集群搭建完毕后可查询系统表<code>system.clusters</code>，查看集群配置信息</p> \n <p>metrika.xml 配置如下：</p> \n <h3><a id=\"metrikaxml_2391\"></a>增加集群配置文件:metrika.xml文件</h3> \n <p>创建metrika.xml文件<br> 在/etc/clickhouse-server/config.d/目录下创建metrika.xml</p> \n <p>加入如下内容：</p> \n <pre><code class=\"prism language-javascript\"><span class=\"token operator\">&lt;</span>yandex<span class=\"token operator\">&gt;</span>\n	<span class=\"token operator\">&lt;</span>clickhouse_remote_servers<span class=\"token operator\">&gt;</span>\n	 <span class=\"token operator\">&lt;</span><span class=\"token operator\">!</span><span class=\"token operator\">--</span> 自定义的集群名称 <span class=\"token operator\">--</span><span class=\"token operator\">&gt;</span>\n	 <span class=\"token operator\">&lt;</span><span class=\"token operator\">!</span><span class=\"token operator\">--</span> <span class=\"token number\">2</span>分片<span class=\"token number\">1</span>副本 <span class=\"token operator\">--</span><span class=\"token operator\">&gt;</span>\n	 <span class=\"token operator\">&lt;</span><span class=\"token operator\">!</span><span class=\"token operator\">--</span> 数据分片<span class=\"token number\">1</span> <span class=\"token operator\">--</span><span class=\"token operator\">&gt;</span>\n		<span class=\"token operator\">&lt;</span>cluster_1<span class=\"token operator\">&gt;</span>\n		<span class=\"token operator\">&lt;</span><span class=\"token operator\">!</span><span class=\"token operator\">--</span> 分片信息 <span class=\"token operator\">--</span><span class=\"token operator\">&gt;</span>\n			<span class=\"token operator\">&lt;</span>shard<span class=\"token operator\">&gt;</span>\n				<span class=\"token operator\">&lt;</span>weight<span class=\"token operator\">&gt;</span><span class=\"token number\">1</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>weight<span class=\"token operator\">&gt;</span> \n				<span class=\"token operator\">&lt;</span><span class=\"token operator\">!</span><span class=\"token operator\">--</span> 分布式表写入数据是否只写入到一个副本，配合复制表引擎使用，默认<span class=\"token boolean\">false</span> <span class=\"token operator\">--</span><span class=\"token operator\">&gt;</span>\n				<span class=\"token operator\">&lt;</span>internal_replication<span class=\"token operator\">&gt;</span><span class=\"token boolean\">true</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>internal_replication<span class=\"token operator\">&gt;</span>\n				 <span class=\"token operator\">&lt;</span><span class=\"token operator\">!</span><span class=\"token operator\">--</span> 分片副本信息，这里指定的用户名密码只能是明文，如果需要密文密码需要将配置指向users<span class=\"token punctuation\">.</span>xml中的profile中 <span class=\"token operator\">--</span><span class=\"token operator\">&gt;</span>\n				<span class=\"token operator\">&lt;</span>replica<span class=\"token operator\">&gt;</span>\n					<span class=\"token operator\">&lt;</span>host<span class=\"token operator\">&gt;</span>clickhouse<span class=\"token operator\">-</span><span class=\"token number\">01</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>host<span class=\"token operator\">&gt;</span>\n					<span class=\"token operator\">&lt;</span>port<span class=\"token operator\">&gt;</span><span class=\"token number\">9000</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>port<span class=\"token operator\">&gt;</span>\n					<span class=\"token operator\">&lt;</span><span class=\"token operator\">!</span><span class=\"token operator\">--</span>  <span class=\"token operator\">&lt;</span>user<span class=\"token operator\">&gt;</span>xxx<span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>user<span class=\"token operator\">&gt;</span>\n                     <span class=\"token operator\">&lt;</span>password<span class=\"token operator\">&gt;</span>xxx<span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>password<span class=\"token operator\">&gt;</span>  <span class=\"token operator\">--</span><span class=\"token operator\">&gt;</span>\n				<span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>replica<span class=\"token operator\">&gt;</span>\n				<span class=\"token operator\">&lt;</span>replica<span class=\"token operator\">&gt;</span>\n					<span class=\"token operator\">&lt;</span>host<span class=\"token operator\">&gt;</span>clickhouse<span class=\"token operator\">-</span><span class=\"token number\">03</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>host<span class=\"token operator\">&gt;</span>\n					<span class=\"token operator\">&lt;</span>port<span class=\"token operator\">&gt;</span><span class=\"token number\">9000</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>port<span class=\"token operator\">&gt;</span>\n				<span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>replica<span class=\"token operator\">&gt;</span>\n			<span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>shard<span class=\"token operator\">&gt;</span>\n			<span class=\"token operator\">&lt;</span>shard<span class=\"token operator\">&gt;</span>\n				<span class=\"token operator\">&lt;</span>weight<span class=\"token operator\">&gt;</span><span class=\"token number\">1</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>weight<span class=\"token operator\">&gt;</span>\n				<span class=\"token operator\">&lt;</span>internal_replication<span class=\"token operator\">&gt;</span><span class=\"token boolean\">true</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>internal_replication<span class=\"token operator\">&gt;</span>\n				<span class=\"token operator\">&lt;</span>replica<span class=\"token operator\">&gt;</span>\n					<span class=\"token operator\">&lt;</span>host<span class=\"token operator\">&gt;</span>clickhouse<span class=\"token operator\">-</span><span class=\"token number\">02</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>host<span class=\"token operator\">&gt;</span>\n					<span class=\"token operator\">&lt;</span>port<span class=\"token operator\">&gt;</span><span class=\"token number\">9000</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>port<span class=\"token operator\">&gt;</span>\n				<span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>replica<span class=\"token operator\">&gt;</span>\n				<span class=\"token operator\">&lt;</span>replica<span class=\"token operator\">&gt;</span>\n					<span class=\"token operator\">&lt;</span>host<span class=\"token operator\">&gt;</span>clickhouse<span class=\"token operator\">-</span><span class=\"token number\">04</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>host<span class=\"token operator\">&gt;</span>\n					<span class=\"token operator\">&lt;</span>port<span class=\"token operator\">&gt;</span><span class=\"token number\">9000</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>port<span class=\"token operator\">&gt;</span>\n				<span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>replica<span class=\"token operator\">&gt;</span>\n			<span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>shard<span class=\"token operator\">&gt;</span>\n		<span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>cluster_1<span class=\"token operator\">&gt;</span>\n	<span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>clickhouse_remote_servers<span class=\"token operator\">&gt;</span>\n        <span class=\"token operator\">&lt;</span>zookeeper<span class=\"token operator\">-</span>servers<span class=\"token operator\">&gt;</span>\n            <span class=\"token operator\">&lt;</span>node index<span class=\"token operator\">=</span><span class=\"token string\">\"1\"</span><span class=\"token operator\">&gt;</span>\n                <span class=\"token operator\">&lt;</span>host<span class=\"token operator\">&gt;</span>clickhouse<span class=\"token operator\">-</span>zookeeper<span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>host<span class=\"token operator\">&gt;</span>\n                <span class=\"token operator\">&lt;</span>port<span class=\"token operator\">&gt;</span><span class=\"token number\">2181</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>port<span class=\"token operator\">&gt;</span>\n            <span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>node<span class=\"token operator\">&gt;</span>\n        <span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>zookeeper<span class=\"token operator\">-</span>servers<span class=\"token operator\">&gt;</span>\n        <span class=\"token operator\">&lt;</span>networks<span class=\"token operator\">&gt;</span>\n            <span class=\"token operator\">&lt;</span>ip<span class=\"token operator\">&gt;</span><span class=\"token operator\">:</span><span class=\"token operator\">:</span><span class=\"token operator\">/</span><span class=\"token number\">0</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>ip<span class=\"token operator\">&gt;</span>\n        <span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>networks<span class=\"token operator\">&gt;</span>\n        <span class=\"token operator\">&lt;</span>clickhouse_compression<span class=\"token operator\">&gt;</span>\n            <span class=\"token operator\">&lt;</span><span class=\"token keyword\">case</span><span class=\"token operator\">&gt;</span>\n                <span class=\"token operator\">&lt;</span>min_part_size<span class=\"token operator\">&gt;</span><span class=\"token number\">10000000000</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>min_part_size<span class=\"token operator\">&gt;</span>\n                <span class=\"token operator\">&lt;</span>min_part_size_ratio<span class=\"token operator\">&gt;</span><span class=\"token number\">0.01</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>min_part_size_ratio<span class=\"token operator\">&gt;</span>\n                <span class=\"token operator\">&lt;</span>method<span class=\"token operator\">&gt;</span>lz4<span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>method<span class=\"token operator\">&gt;</span>\n            <span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span><span class=\"token keyword\">case</span><span class=\"token operator\">&gt;</span>\n        <span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>clickhouse_compression<span class=\"token operator\">&gt;</span>\n<span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>yandex<span class=\"token operator\">&gt;</span>\n\n\n</code></pre> \n <blockquote> \n  <p>注意修改 zk 以及各个节点的信息。</p> \n </blockquote> \n <p>分发到其他节点，同时修改macros标签里面的值为对应的服务器</p> \n <blockquote> \n  <p>以上配置实操过程， 尼恩会在视频中，做详细解读</p> \n </blockquote> \n <h3><a id=\"metrikaxml_2465\"></a>引入metrika.xml</h3> \n <p>配置完metrika.xml后，我们需要将metrika.xml引入配置中。在config.xml引入metrika.xml, config.xml就是clickhouse的全局配置。</p> \n <p>路径默认是:/etc/clickhouse-server/config.xml</p> \n <p>在该配置文件中添加以下配置:</p> \n <pre><code class=\"prism language-xml\"><span class=\"token comment\">&lt;!--引入metrika.xml--&gt;</span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>include_from</span><span class=\"token punctuation\">&gt;</span></span>/etc/clickhouse-server/config.d/metrika.xml<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>include_from</span><span class=\"token punctuation\">&gt;</span></span>\n\n</code></pre> \n <h3><a id=\"macrosxml_2481\"></a>macros.xml宏设置</h3> \n <p>每个实例都有自己的宏设置，如服务器1:</p> \n <pre><code>&lt;yandex&gt;\n    &lt;macros&gt;\n        &lt;replica&gt;clickhouse-01&lt;/replica&gt;\n        &lt;shard&gt;01&lt;/shard&gt;\n        &lt;layer&gt;01&lt;/layer&gt;\n    &lt;/macros&gt;\n&lt;/yandex&gt;\n</code></pre> \n <p>确保宏设置等于metrika.xml中的远程服务器设置</p> \n <h3><a id=\"_2501\"></a>启动集群</h3> \n <pre><code>docker-compose up -d\n</code></pre> \n <blockquote> \n  <p>关于集群的启动/设置/架构，请参加尼恩的视频</p> \n </blockquote> \n <h3><a id=\"_2513\"></a>启动检查</h3> \n <p>1、查询当前的集群信息</p> \n <pre><code class=\"prism language-csharp\"><span class=\"token keyword\">select</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">from</span> system<span class=\"token punctuation\">.</span>clusters<span class=\"token punctuation\">;</span>\n</code></pre> \n <p><img src=\"https://img-blog.csdnimg.cn/461147ae38eb4e8ab78968022e70069b.png\" alt=\"在这里插入图片描述\"></p> \n <p>2、查询zookeeper信息</p> \n <p>在ClickHouse系统表中，提供了一张Zookeeper代理表，</p> \n <p>我们可以使用SQL轻松访问Zookeeper内的数据，不用再像以前一样使用客户端登录进去查看。</p> \n <pre><code>#查询Zookeeper根目录\nselect * from system.zookeeper where path = \'/\'\n</code></pre> \n <p><img src=\"https://img-blog.csdnimg.cn/47dd36863c5a403db74cd17466de3e3c.png\" alt=\"在这里插入图片描述\"></p> \n <pre><code>\n\n#查询ClickHouse目录\nselect * from system.zookeeper where path = \'/clickhouse\'\n</code></pre> \n <p><img src=\"https://img-blog.csdnimg.cn/e9960998180f438c99a2e5adbd548ca7.png\" alt=\"在这里插入图片描述\"></p> \n <p>生产环境建议配置上Kerberos安全认证。</p> \n <blockquote> \n  <p>以上具体的实操过程， 尼恩会在视频中，做详细解读</p> \n </blockquote> \n <h2><a id=\"_2563\"></a>集群数据写入</h2> \n <h3><a id=\"_2567\"></a><strong>创建本地表</strong></h3> \n <p>现在我们有了群集和副本设置。接下来，需要在每个服务器中创建ReplicatedMergeTree表作为本地表。</p> \n <pre><code>\nCREATE TABLE ttt (id Int32) ENGINE = ReplicatedMergeTree(\'/clickhouse/tables/{layer}-{shard}/ttt\', \'{replica}\') PARTITION BY id ORDER BY id\n</code></pre> \n <p>先解释一下 ReplicatedMergeTree 引擎用法：</p> \n <pre><code class=\"prism language-javascript\"><span class=\"token constant\">ENGINE</span> <span class=\"token operator\">=</span> <span class=\"token function\">ReplicatedMergeTree</span><span class=\"token punctuation\">(</span><span class=\"token string\">\'zk_path\'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\'replica_name\'</span><span class=\"token punctuation\">)</span>\n</code></pre> \n <p><strong>zk_path ：</strong></p> \n <p>用于指定在 zk 中创建数据表的路径，一般 zk_path 建议配置成如下形式：</p> \n <pre><code class=\"prism language-javascript\"><span class=\"token operator\">/</span>clickhouse<span class=\"token operator\">/</span><span class=\"token punctuation\">{\n    <!-- --></span>cluster<span class=\"token punctuation\">}</span><span class=\"token operator\">/</span><span class=\"token punctuation\">{\n    <!-- --></span>shard<span class=\"token punctuation\">}</span><span class=\"token operator\">/</span><span class=\"token punctuation\">{\n    <!-- --></span>table_name<span class=\"token punctuation\">}</span>\n</code></pre> \n <ul>\n  <li>{cluster} 表示集群名；</li>\n  <li>{shard} 表示分片编号；</li>\n  <li>{table_name} 表示数据表的名称。</li>\n </ul> \n <blockquote> \n  <p>需要注意的是： zk_path 的定义，同一分片不同副本，需要定义相同的路径。</p> \n </blockquote> \n <p><strong>replica_name</strong></p> \n <p>replica_name 用于设置副本名称</p> \n <blockquote> \n  <p>需要注意的是： 同一分片不同副本，需要定义不同的名称；</p> \n </blockquote> \n <p>上面两句话如果感觉有点绕，可以对比下面这 4 个节点的本地表建表语句，应该就可以理解啦。</p> \n <p>在 clickhouse-01上：</p> \n <pre><code class=\"prism language-javascript\"><span class=\"token constant\">CREATE</span> <span class=\"token constant\">DATABASE</span> likecolumn<span class=\"token punctuation\">;</span> \n\n<span class=\"token constant\">CREATE</span> <span class=\"token constant\">TABLE</span> likecolumn<span class=\"token punctuation\">.</span><span class=\"token function\">table_test</span> <span class=\"token punctuation\">(</span>label_id UInt32<span class=\"token punctuation\">,</span> label_name String<span class=\"token punctuation\">,</span> insert_time Date<span class=\"token punctuation\">)</span> <span class=\"token constant\">ENGINE</span> <span class=\"token operator\">=</span> <span class=\"token function\">ReplicatedMergeTree</span><span class=\"token punctuation\">(</span><span class=\"token string\">\'/clickhouse/cluster_1/01/table_test\'</span><span class=\"token punctuation\">,</span><span class=\"token string\">\'replica01\'</span><span class=\"token punctuation\">,</span>insert_time<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>label_id<span class=\"token punctuation\">,</span> insert_time<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8192</span><span class=\"token punctuation\">)</span>\n</code></pre> \n <p><img src=\"https://img-blog.csdnimg.cn/8bf3f50dc8f04862bbdd00130b66db7d.png\" alt=\"在这里插入图片描述\"></p> \n <p>在 clickhouse-03上：</p> \n <pre><code class=\"prism language-javascript\"><span class=\"token constant\">CREATE</span> <span class=\"token constant\">DATABASE</span> likecolumn<span class=\"token punctuation\">;</span> \n\n<span class=\"token constant\">CREATE</span> <span class=\"token constant\">TABLE</span> likecolumn<span class=\"token punctuation\">.</span><span class=\"token function\">table_test</span> <span class=\"token punctuation\">(</span>label_id UInt32<span class=\"token punctuation\">,</span> label_name String<span class=\"token punctuation\">,</span> insert_time Date<span class=\"token punctuation\">)</span> <span class=\"token constant\">ENGINE</span> <span class=\"token operator\">=</span> \n<span class=\"token function\">ReplicatedMergeTree</span><span class=\"token punctuation\">(</span><span class=\"token string\">\'/clickhouse/cluster_1/01/table_test\'</span><span class=\"token punctuation\">,</span><span class=\"token string\">\'replica02\'</span><span class=\"token punctuation\">,</span>insert_time<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>label_id<span class=\"token punctuation\">,</span> insert_time<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8192</span><span class=\"token punctuation\">)</span>\n</code></pre> \n <p><img src=\"https://img-blog.csdnimg.cn/7b80de73a56c4e48a2522f22a3f2fb69.png\" alt=\"在这里插入图片描述\"></p> \n <p>在clickhouse-02上：</p> \n <pre><code class=\"prism language-javascript\"><span class=\"token constant\">CREATE</span> <span class=\"token constant\">DATABASE</span> likecolumn<span class=\"token punctuation\">;</span>\n\n<span class=\"token constant\">CREATE</span> <span class=\"token constant\">TABLE</span> likecolumn<span class=\"token punctuation\">.</span><span class=\"token function\">table_test</span> <span class=\"token punctuation\">(</span> label_id UInt32<span class=\"token punctuation\">,</span> label_name String<span class=\"token punctuation\">,</span> insert_time Date<span class=\"token punctuation\">)</span> <span class=\"token constant\">ENGINE</span> <span class=\"token operator\">=</span> <span class=\"token function\">ReplicatedMergeTree</span><span class=\"token punctuation\">(</span><span class=\"token string\">\'/clickhouse/cluster_1/02/table_test\'</span><span class=\"token punctuation\">,</span><span class=\"token string\">\'replica01\'</span><span class=\"token punctuation\">,</span>insert_time<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>label_id<span class=\"token punctuation\">,</span> insert_time<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8192</span><span class=\"token punctuation\">)</span>\n</code></pre> \n <p><img src=\"https://img-blog.csdnimg.cn/28ce38c108834666a3e7ca5935a8cbbb.png\" alt=\"在这里插入图片描述\"></p> \n <p>在clickhouse-04上：</p> \n <pre><code class=\"prism language-javascript\"><span class=\"token constant\">CREATE</span> <span class=\"token constant\">DATABASE</span> likecolumn<span class=\"token punctuation\">;</span>\n\n<span class=\"token constant\">CREATE</span> <span class=\"token constant\">TABLE</span> likecolumn<span class=\"token punctuation\">.</span><span class=\"token function\">table_test</span> <span class=\"token punctuation\">(</span> label_id UInt32<span class=\"token punctuation\">,</span> label_name String<span class=\"token punctuation\">,</span> insert_time Date<span class=\"token punctuation\">)</span> <span class=\"token constant\">ENGINE</span> <span class=\"token operator\">=</span> <span class=\"token function\">ReplicatedMergeTree</span><span class=\"token punctuation\">(</span><span class=\"token string\">\'/clickhouse/cluster_1/02/table_test\'</span><span class=\"token punctuation\">,</span><span class=\"token string\">\'replica02\'</span><span class=\"token punctuation\">,</span>insert_time<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>label_id<span class=\"token punctuation\">,</span> insert_time<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8192</span><span class=\"token punctuation\">)</span>\n</code></pre> \n <h3><a id=\"_2653\"></a>创建分布式总表</h3> \n <p>任选一个集群内的节点创建分布式总表：</p> \n <pre><code class=\"prism language-javascript\"><span class=\"token constant\">CREATE</span> <span class=\"token constant\">TABLE</span> likecolumn<span class=\"token punctuation\">.</span>table_test_all <span class=\"token constant\">AS</span> likecolumn<span class=\"token punctuation\">.</span>table_test <span class=\"token constant\">ENGINE</span> <span class=\"token operator\">=</span> <span class=\"token function\">Distributed</span><span class=\"token punctuation\">(</span>cluster_1<span class=\"token punctuation\">,</span> likecolumn<span class=\"token punctuation\">,</span> table_test<span class=\"token punctuation\">,</span> <span class=\"token function\">rand</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n</code></pre> \n <p><img src=\"https://img-blog.csdnimg.cn/c88830f73198428781c0f30696a22d89.png\" alt=\"在这里插入图片描述\"></p> \n <p>这里解释一下 Distributed 引擎用法： ENGINE = Distributed(cluster, database, table, sharding_key)</p> \n <ul>\n  <li>cluster：集群名</li>\n  <li>database 和 table：库表名</li>\n  <li>sharding_key：分片键，选填。</li>\n </ul> \n <h3><a id=\"_2673\"></a>高可靠写入数据</h3> \n <p>在创建了分布式总表的节点写入数据：</p> \n <pre><code class=\"prism language-javascript\">insert into likecolumn<span class=\"token punctuation\">.</span>table_test_all <span class=\"token function\">values</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token string\">\'111\'</span><span class=\"token punctuation\">,</span><span class=\"token string\">\'2020-11-17\'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\ninsert into likecolumn<span class=\"token punctuation\">.</span>table_test_all <span class=\"token function\">values</span> <span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token string\">\'111\'</span><span class=\"token punctuation\">,</span><span class=\"token string\">\'2019-11-18\'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\ninsert into likecolumn<span class=\"token punctuation\">.</span>table_test_all <span class=\"token function\">values</span> <span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token string\">\'111\'</span><span class=\"token punctuation\">,</span><span class=\"token string\">\'2020-11-19\'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\ninsert into likecolumn<span class=\"token punctuation\">.</span>table_test_all <span class=\"token function\">values</span> <span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span><span class=\"token string\">\'111\'</span><span class=\"token punctuation\">,</span><span class=\"token string\">\'2020-11-20\'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre> \n <p><img src=\"https://img-blog.csdnimg.cn/8f646e54be244f5d96926568c524dd54.png\" alt=\"在这里插入图片描述\"></p> \n <p><img src=\"https://img-blog.csdnimg.cn/17ad1fe9bc6f4508886cef3357bd7608.png\" alt=\"在这里插入图片描述\"></p> \n <p>查询总表数据</p> \n <pre><code class=\"prism language-javascript\">select <span class=\"token operator\">*</span> from likecolumn<span class=\"token punctuation\">.</span>table_test_all <span class=\"token punctuation\">;</span>\n</code></pre> \n <p><img src=\"https://img-blog.csdnimg.cn/298942af16004efe8a94d15fc1ca996f.png\" alt=\"在这里插入图片描述\"></p> \n <p>查询各个分片本地表的数据。</p> \n <pre><code>select * from likecolumn.table_test ;\n</code></pre> \n <p>04节点</p> \n <p><img src=\"https://img-blog.csdnimg.cn/e077694b47c24f4daa0b9c15f3461d93.png\" alt=\"在这里插入图片描述\"></p> \n <p>02节点</p> \n <p><img src=\"https://img-blog.csdnimg.cn/90f88d137ac94b77a6fc437e5eca4d57.png\" alt=\"在这里插入图片描述\"></p> \n <p>01节点</p> \n <p><img src=\"https://img-blog.csdnimg.cn/a90290279ef24b2b8d25b34c0f1f925b.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"_2722\"></a>高可用测试</h3> \n <p>停掉 192.168.150.123 的 ClickHouse 服务：</p> \n <pre><code class=\"prism language-javascript\">docker<span class=\"token operator\">-</span>compose stop clickhouse<span class=\"token operator\">-</span><span class=\"token number\">01</span>\ndocker<span class=\"token operator\">-</span>compose start clickhouse<span class=\"token operator\">-</span><span class=\"token number\">01</span>\n</code></pre> \n <p><img src=\"https://img-blog.csdnimg.cn/40764efc658341ff8f8589a44e67e539.png\" alt=\"在这里插入图片描述\"></p> \n <pre><code>insert into likecolumn.table_test_all values (5,\'111\',\'2020-11-20\');\nselect * from likecolumn.table_test_all ;\n</code></pre> \n <p>发现整个集群仍然可以正常写入和查询：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/a26dd4b72ba8479ca6d30dd4cd568aef.png\" alt=\"在这里插入图片描述\"></p> \n <blockquote> \n  <p>以上具体的实操过程， 尼恩会在视频中，做详细解读</p> \n </blockquote> \n <h2><a id=\"ZookeeperClickHouse_2750\"></a>Zookeeper在ClickHouse中的作用</h2> \n <p>Zookeeper作为一个分布式一致性存储服务，提供了丰富的读写接口和watch机制，</p> \n <p>分布式应用基于Zookeeper可以解决很多常见问题，例如心跳管理、主备切换、分布式锁等</p> \n <p><strong>ClickHouse中依赖Zookeeper解决哪些问题？</strong></p> \n <p>（1）分布式DDL执行。</p> \n <p>如：ClickHouse中DDL执行默认不是分布式的，</p> \n <p>用户需要在DDL语句中加上on Cluster XXX的申明才能触发这个功能</p> \n <p>（2）ReplicatedMergeTree表主备节点之间的状态同步</p> \n <p><strong>ClickHouse分布式DDL和其他完全分布式化的数据库有什么不同？</strong></p> \n <p><strong>ClickHouse分布式DDL：</strong></p> \n <p>（1）ClickHouse对库、表的管理都是在存储<strong>节点级别独立</strong>的，集群中各节点之间的<strong>库、表元数据信息</strong>没有一致性约束</p> \n <p><strong>原因是：由ClickHouse的架构特色决定的</strong></p> \n <ul>\n  <li> <p>彻底Share Nothing，各节点之间完全没有相互依赖</p> </li>\n  <li> <p>节点完全对等，集群中的节点角色统一</p> <p>ClickHouse没有传统MPP数据库中的前端节点、Worker节点、元数据节点等概念</p> </li>\n  <li> <p>ClickHouse的这种架构特色决定它可以敏捷化、小规模部署，集群可以任意进行分裂、合并。前提要求是感知数据在集群节点上的分布</p> </li>\n </ul> \n <p>（2）用户可以直接连接任意一个节点进行请求，当用户发送DDL命令时，默认只会在当前连接的节点执行命令</p> \n <p>思考：<strong>现实中如果用户有一个100台机器的集群，为了创建一个分布式存储的表难道用户需要依次连接每台机器发送DDL命令吗？</strong></p> \n <p>这个问题会导致：多个DDL之间的冲突问题无法解决</p> \n <p>举例：用户A和用户B同时创建同名表但是表字段又不一致，这肯定会让系统陷入一个诡异的不一致状态</p> \n <table>\n  <thead>\n   <tr>\n    <th>Cluster</th>\n    <th>一个集群可以包括若干个Cluster</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>Shard</td>\n    <td>一个Cluster可以包括若干个Shard</td>\n   </tr>\n   <tr>\n    <td></td>\n    <td>一个Shard又可以包含若干个Replicate</td>\n   </tr>\n   <tr>\n    <td></td>\n    <td>一个Replicate就是一个特定的节点实例</td>\n   </tr>\n  </tbody>\n </table> \n <p><strong>实现过程</strong></p> \n <p>**思路：**用户可以通过ClickHouse启动的config.xml来配置这套节点规划逻辑</p> \n <p>**如何配置：**用户可以把一个集群规划成若干个Cluster，每个Cluster可自定义Shard数量，每个Shard又可以自定义副本数量</p> \n <p>**说明：**单个存储节点内部不同Cluster之间的表都是相互可见的</p> \n <h3><a id=\"MPPClickhouseMPP_2810\"></a>传统的MPP数据库与Clickhouse的MPP数据库的区别？</h3> \n <table>\n  <thead>\n   <tr>\n    <th></th>\n    <th></th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>传统的MPP数据库</td>\n    <td>没有表级别的自定义副本数能力，只能做全库的副本数配置</td>\n   </tr>\n   <tr>\n    <td>Clickhouse的MPP数据库</td>\n    <td>（1）ClickHouse能做到表的Replicate数量自定义技术核心</td>\n   </tr>\n   <tr>\n    <td></td>\n    <td>（2）是它把主备同步逻辑放到了具体的表引擎中实现，而不是在节点级别做数据复制</td>\n   </tr>\n  </tbody>\n </table> \n <p>注意：当前只有ReplicatedMergeTree表引擎可以自动做主备状态同步，其他表引擎没有状态同步机制</p> \n <h3><a id=\"Cluster_2820\"></a>如果用户需要在多副本Cluster下创建其他表引擎，如何做？</h3> \n <p>需要在写入链路上配置多写逻辑</p> \n <h3><a id=\"ReplicatedMergeTree_2826\"></a>ReplicatedMergeTree表引擎的同步包括哪些？</h3> \n <ul>\n  <li> <p>写入同步、</p> </li>\n  <li> <p>异步Merge同步、</p> </li>\n  <li> <p>异步Mutation同步等；</p> </li>\n </ul> \n <p>注意：它所有的同步逻辑都是强依赖Zookeeper</p> \n <h3><a id=\"DDL_2838\"></a>分布式DDL执行链路</h3> \n <p><strong>哪些操作是可以走分布式DDL执行链路？</strong></p> \n <table>\n  <thead>\n   <tr>\n    <th></th>\n    <th></th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>ASTCreateQuery</td>\n    <td>包括常见的建库、建表、建视图，还有ClickHouse独有的Attach Table（可以从存储文件中直接加载一个之前卸载的数据表）</td>\n   </tr>\n   <tr>\n    <td>ASTAlterQuery：</td>\n    <td>包括ATTACH_PARTITION、FETCH_PARTITION、FREEZE_PARTITION、FREEZE_ALL等操作（对表的数据分区粒度进行操作）</td>\n   </tr>\n   <tr>\n    <td>ASTDropQuery：</td>\n    <td>其中包含了三种不同的删除操作（Drop / Truncate / Detach），Detach Table和Attach Table对应，它是表的卸载动作，把表的存储目录整个移到专门的detach文件夹下</td>\n   </tr>\n   <tr>\n    <td>ASTOptimizeQuery：</td>\n    <td>这是MergeTree表引擎特有的操作命令，它可以手动触发MergeTree表的合并动作，并可以强制数据分区下的所有Data Part合并成一个</td>\n   </tr>\n   <tr>\n    <td>ASTRenameQuery</td>\n    <td>修改表名，可更改到不同库下</td>\n   </tr>\n   <tr>\n    <td></td>\n    <td></td>\n   </tr>\n   <tr>\n    <td>ASTKillQueryQuery：</td>\n    <td>可以Kill正在运行的Query，也可以Kill之前发送的Mutation命令</td>\n   </tr>\n   <tr>\n    <td></td>\n    <td></td>\n   </tr>\n  </tbody>\n </table> \n <h2><a id=\"ESCK_2855\"></a>ES和CK的查询对比</h2> \n <p>Elasticsearch 是一个实时的分布式搜索分析引擎，它的底层是构建在 Lucene 之上的。简单来说是通过扩展 Lucene 的搜索能力，使其具有分布式的功能。</p> \n <p>ES 通常会和其它两个开源组件 Logstash（日志采集）和 Kibana（仪表盘）一起提供端到端的日志/搜索分析的功能，常常被简称为 ELK。</p> \n <p>Clickhouse 是俄罗斯搜索巨头 Yandex 开发的面向列式存储的关系型数据库。ClickHouse 是过去两年中 OLAP 领域中最热门的，并于 2016 年开源。</p> \n <p>ES 是最为流行的大数据日志和搜索解决方案，但是近几年来，它的江湖地位受到了一些挑战，许多公司已经开始把自己的日志解决方案从 ES 迁移到了 Clickhouse，这里就包括：携程，快手等公司。</p> \n <h3><a id=\"_2867\"></a>架构和设计的对比</h3> \n <p>ES 的底层是 Lucence，主要是要解决搜索的问题。搜索是大数据领域要解决的一个常见的问题，就是在海量的数据量要如何按照条件找到需要的数据。搜索的核心技术是倒排索引和布隆过滤器。</p> \n <p>ES 通过分布式技术，利用分片与副本机制，直接解决了集群下搜索性能与高可用的问题。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/7185bdbb2a094745821b44144bdb68b7.png\" alt=\"在这里插入图片描述\"></p> \n <p>ElasticSearch 是为分布式设计的，有很好的扩展性，在一个典型的分布式配置中，每一个节点（node）可以配制成不同的角色。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/97205efb880f46d58eb44f2690b8f695.png\" alt=\"在这里插入图片描述\"></p> \n <p><strong>如上图所示：</strong></p> \n <p>**Client Node，**负责 API 和数据的访问的节点，不存储／处理数据。**Data Node，**负责数据的存储和索引。**Master Node，**管理节点，负责 Cluster 中的节点的协调，不存储数据。ClickHouse 是基于 MPP 架构的分布式 ROLAP（关系 OLAP）分析引擎。每个节点都有同等的责任，并负责部分数据处理（不共享任何内容）。</p> \n <p>ClickHouse 是一个真正的列式数据库管理系统（DBMS)。</p> \n <p>在 ClickHouse 中，数据始终是按列存储的，包括矢量（向量或列块）执行的过程。</p> \n <p>让查询变得更快，最简单且有效的方法是减少数据扫描范围，和减少数据传输时的大小，而列式存储和数据压缩就可以帮助实现上述两点。</p> \n <p>Clickhouse 同时使用了日志合并树，稀疏索引和 CPU 功能（如 SIMD 单指令多数据）充分发挥了硬件优势，可实现高效的计算。</p> \n <p>Clickhouse 使用 Zookeeper 进行分布式节点之间的协调。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/64550b7f6679cdb49027b4309e80d41d.jpeg\" alt=\"img\"></p> \n <p>为了支持搜索，Clickhouse 同样支持布隆过滤器。</p> \n <h3><a id=\"_2902\"></a>对比的环境</h3> \n <p>ES stack<br> ES stack有一个单节点的Elastic的容器和一个Kibana容器组成，Elastic是被测目标之一，Kibana作为验证和辅助工具。部署代码如下：</p> \n <pre><code class=\"prism language-text\">version: \'3.7\'\n\nservices:\n  elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:7.4.0\n    container_name: elasticsearch\n    environment:\n      - xpack.security.enabled=false\n      - discovery.type=single-node\n    ulimits:\n      memlock:\n        soft: -1\n        hard: -1\n      nofile:\n        soft: 65536\n        hard: 65536\n    cap_add:\n      - IPC_LOCK\n    volumes:\n      - elasticsearch-data:/usr/share/elasticsearch/data\n    ports:\n      - 9200:9200\n      - 9300:9300\n    deploy:\n      resources:\n        limits:\n          cpus: \'4\'\n          memory: 4096M\n        reservations:\n          memory: 4096M\n\n  kibana:\n    container_name: kibana\n    image: docker.elastic.co/kibana/kibana:7.4.0\n    environment:\n      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200\n    ports:\n      - 5601:5601\n    depends_on:\n      - elasticsearch\n\nvolumes:\n  elasticsearch-data:\n    driver: local\n</code></pre> \n <p>Clickhouse stack<br> Clickhouse stack有一个单节点的Clickhouse服务容器和一个TabixUI作为Clickhouse的客户端。部署代码如下：</p> \n <pre><code class=\"prism language-text\">version: \"3.7\"\nservices:\n  clickhouse:\n    container_name: clickhouse\n    image: yandex/clickhouse-server\n    volumes:\n      - ./data/config:/var/lib/clickhouse\n    ports:\n      - \"8123:8123\"\n      - \"9000:9000\"\n      - \"9009:9009\"\n      - \"9004:9004\"\n    ulimits:\n      nproc: 65535\n      nofile:\n        soft: 262144\n        hard: 262144\n    healthcheck:\n      test: [\"CMD\", \"wget\", \"--spider\", \"-q\", \"localhost:8123/ping\"]\n      interval: 30s\n      timeout: 5s\n      retries: 3\n    deploy:\n      resources:\n        limits:\n          cpus: \'4\'\n          memory: 4096M\n        reservations:\n          memory: 4096M\n  \n  tabixui:\n    container_name: tabixui\n    image: spoonest/clickhouse-tabix-web-client\n    environment:\n      - CH_NAME=dev\n      - CH_HOST=127.0.0.1:8123\n      - CH_LOGIN=default\n    ports:\n      - \"18080:80\"\n    depends_on:\n      - clickhouse\n    deploy:\n      resources:\n        limits:\n          cpus: \'0.1\'\n          memory: 128M\n        reservations:\n          memory: 128M\n</code></pre> \n <ul>\n  <li>数据导入 stack<br> 数据导入部分使用了Vector.dev开发的vector，该工具和fluentd类似，都可以实现数据管道式的灵活的数据导入。</li>\n  <li>测试控制 stack<br> 测试控制我使用了Jupyter，使用了ES和Clickhouse的Python SDK来进行查询的测试。</li>\n </ul> \n <p>用Docker compose启动ES和Clickhouse的stack后，我们需要导入数据，我们利用Vector的generator功能，生成syslog，并同时导入ES和Clickhouse，在这之前，我们需要在Clickhouse上创建表。ES的索引没有固定模式，所以不需要事先创建索引。</p> \n <p>创建表的代码如下：</p> \n <pre><code class=\"prism language-text\">CREATE TABLE default.syslog(\n    application String,\n    hostname String,\n    message String,\n    mid String,\n    pid String,\n    priority Int16,\n    raw String,\n    timestamp DateTime(\'UTC\'),\n    version Int16\n) ENGINE = MergeTree()\n    PARTITION BY toYYYYMMDD(timestamp)\n    ORDER BY timestamp\n    TTL timestamp + toIntervalMonth(1);\n</code></pre> \n <h3><a id=\"_3034\"></a>查询来做一个对比</h3> \n <p>ES使用自己的查询语言来进行查询，Clickhouse支持SQL，我简单测试了一些常见的查询，并对它们的功能做一些比较。</p> \n <ul>\n  <li>返回所有的记录</li>\n </ul> \n <pre><code class=\"prism language-text\"># ES\n{\n  \"query\":{\n    \"match_all\":{}\n  }\n}\n\n# Clickhouse \n\"SELECT * FROM syslog\"\n</code></pre> \n <ul>\n  <li>匹配单个字段</li>\n </ul> \n <pre><code class=\"prism language-text\"># ES\n{\n  \"query\":{\n    \"match\":{\n      \"hostname\":\"for.org\"\n    }\n  }\n}\n\n# Clickhouse \n\"SELECT * FROM syslog WHERE hostname=\'for.org\'\"\n</code></pre> \n <ul>\n  <li>匹配多个字段</li>\n </ul> \n <pre><code class=\"prism language-text\"># ES\n{\n  \"query\":{\n    \"multi_match\":{\n      \"query\":\"up.com ahmadajmi\",\n        \"fields\":[\n          \"hostname\",\n          \"application\"\n        ]\n    }\n  }\n}\n\n# Clickhouse、\n\"SELECT * FROM syslog WHERE hostname=\'for.org\' OR application=\'ahmadajmi\'\"\n</code></pre> \n <ul>\n  <li>单词查找，查找包含特定单词的字段</li>\n </ul> \n <pre><code class=\"prism language-text\"># ES\n{\n  \"query\":{\n    \"term\":{\n      \"message\":\"pretty\"\n    }\n  }\n}\n\n# Clickhouse\n\"SELECT * FROM syslog WHERE lowerUTF8(raw) LIKE \'%pretty%\'\"\n</code></pre> \n <ul>\n  <li>范围查询， 查找版本大于2的记录</li>\n </ul> \n <pre><code class=\"prism language-text\"># ES\n{\n  \"query\":{\n    \"range\":{\n      \"version\":{\n        \"gte\":2\n      }\n    }\n  }\n}\n\n# Clickhouse\n\"SELECT * FROM syslog WHERE version &gt;= 2\"\n</code></pre> \n <h3><a id=\"_3122\"></a>查找到存在某字段的记录</h3> \n <p>ES是文档类型的数据库，每一个文档的模式不固定，所以会存在某字段不存在的情况；</p> \n <p>而Clickhouse对应为字段为空值</p> \n <pre><code class=\"prism language-text\"># ES\n{\n  \"query\":{\n    \"exists\":{\n      \"field\":\"application\"\n    }\n  }\n}\n\n# Clickhouse\n\"SELECT * FROM syslog WHERE application is not NULL\"\n</code></pre> \n <h3><a id=\"_3142\"></a>正则表达式查询</h3> \n <p>正则表达式查询，查询匹配某个正则表达式的数据</p> \n <pre><code class=\"prism language-text\"># ES\n{\n  \"query\":{\n    \"regexp\":{\n      \"hostname\":{\n        \"value\":\"up.*\",\n          \"flags\":\"ALL\",\n            \"max_determinized_states\":10000,\n              \"rewrite\":\"constant_score\"\n      }\n    }\n  }\n}\n\n# Clickhouse\n\"SELECT * FROM syslog WHERE match(hostname, \'up.*\')\"\n</code></pre> \n <h3><a id=\"_3165\"></a>聚合计数</h3> \n <p>统计某个字段出现的次数</p> \n <pre><code class=\"prism language-text\"># ES\n{\n  \"aggs\":{\n    \"version_count\":{\n      \"value_count\":{\n        \"field\":\"version\"\n      }\n    }\n  }\n}\n\n# Clickhouse\n\"SELECT count(version) FROM syslog\"\n</code></pre> \n <p>聚合不重复的值，查找所有不重复的字段的个数</p> \n <pre><code class=\"prism language-text\"># ES\n{\n  \"aggs\":{\n    \"my-agg-name\":{\n      \"cardinality\":{\n        \"field\":\"priority\"\n      }\n    }\n  }\n}\n\n# Clickhouse\n\"SELECT count(distinct(priority)) FROM syslog \"\n</code></pre> \n <h2><a id=\"ReplicatedMergeTree_3205\"></a>ReplicatedMergeTree引擎</h2> \n <p>ReplicatedMergeTree是MergeTree的派生引擎，它在MergeTree的基础上加入了<strong>分布式协同</strong>的能力，只有使用了ReplicatedMergeTree 复制表系列引擎，才能应用副本的能力。</p> \n <p>或者用一种更为直接的方式理解，即<strong>使用ReplicatedMergeTree的数据表就是副本</strong>。</p> \n <h3><a id=\"ReplicatedMergeTreeMergeTree_3211\"></a>ReplicatedMergeTree与MergeTree的逻辑关系</h3> \n <p>ReplicatedMergeTree与MergeTree的逻辑关系, 如下图所示：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/94d42de4f1cbdec309fc0f26ef4d0ce3.png\" alt=\"img\"></p> \n <p>在MergeTree中，一个数据分区由开始创建到全部完成，会历经两类存储区域。</p> \n <ul>\n  <li> <p><strong>内存</strong>：</p> <p>数据首先会被写入内存缓冲区。</p> </li>\n  <li> <p><strong>本地磁盘</strong>：</p> <p>数据接着会被写入tmp临时目录分区，待全部完成后，再将临时目录重命名为正式分区。</p> </li>\n </ul> \n <p><strong>ReplicatedMergeTree如何做到数据复制的呢？</strong></p> \n <p>ReplicatedMergeTree在上述MergeTree基础之上增加了ZooKeeper的部分，</p> \n <p>它会进一步在ZooKeeper内创建一系列的监听节点，并以此实现多个实例之间的通信。</p> \n <p>在整个通信过程中，ZooKeeper并不会涉及表数据的传输。</p> \n <h3><a id=\"ReplicatedMergeTree_3239\"></a>ReplicatedMergeTree特点</h3> \n <p>作为数据副本的主要实现载体，ReplicatedMergeTree在设计上有一些显著特点。</p> \n <ul>\n  <li> <p><strong>依赖ZooKeeper</strong>：在执行<code>INSERT</code>和<code>ALTER</code>查询的时候，ReplicatedMergeTree需要借助ZooKeeper的分布式协同能力，以实现多个副本之间的同步。</p> <p>但是在查询副本的时候，并不需要使用ZooKeeper。</p> </li>\n  <li> <p><strong>表级别的副本</strong>：</p> <p>副本是在表级别定义的，</p> <p>所以每张表的副本配置都可以按照它的实际需求进行个性化定义，包括副本的数量，以及副本在集群内的分布位置等。</p> </li>\n  <li> <p><strong>多主架构（Multi Master）</strong>：</p> <p>可以在任意一个副本上执行<code>INSERT</code>和<code>ALTER</code>查询，它们的效果是相同的。</p> <p>这些操作会借助ZooKeeper的协同能力被分发至每个副本以本地形式执行。</p> </li>\n  <li> <p><strong>Block数据块</strong>：</p> <p>在执行INSERT命令写入数据时，会依据 max_insert_block_size的大小（默认1048576行）将数据切分成若干个Block数据块。</p> <p>所以Block数据块是数据写入的基本单元，并且具有写入的原子性和唯一性。</p> </li>\n  <li> <p><strong>原子性</strong>：</p> <p>在数据写入时，一个Block块内的数据要么全部写入成功，要么全部失败。</p> </li>\n  <li> <p><strong>唯一性</strong>：</p> <p>在写入一个Block数据块的时候，会按照当前Block数据块的数据顺序、数据行和数据大小等指标，计算Hash信息摘要并记录在案。在此之后，如果某个待写入的Block数据块与先前已被写入的Block数据块拥有相同的Hash摘要（Block数据块内数据顺序、数据大小和数据行均相同），则该Block数据块会被忽略。</p> </li>\n </ul> \n <h3><a id=\"ZooKeeper_3275\"></a>ZooKeeper内的节点结构</h3> \n <p>ReplicatedMergeTree需要依靠ZooKeeper的事件监听机制以实现各个副本之间的协同。</p> \n <p>所以，在每张ReplicatedMergeTree表的创建过程中，它会以zk_path为根路径，在ZooKeeper中为这张表创建一组监听节点。</p> \n <p>按照作用的不同，监听节点可以大致分成如下几类：</p> \n <ul>\n  <li> <p>元数据</p> \n   <ul>\n    <li><strong>/metadata</strong>：保存元数据信息，包括主键、分区键、采样表达式等。</li>\n    <li><strong>/columns</strong>：保存列字段信息，包括列名称和数据类型。</li>\n    <li><strong>/replicas</strong>：保存副本名称，对应设置参数中的<code>replica_name</code>。</li>\n   </ul> </li>\n  <li> <p>判断标识</p> \n   <ul>\n    <li><strong>/leader_election</strong>：用于主副本的选举工作，主副本会主导<code>MERGE</code>和<code>MUTATION</code>操作（<code>ALTER DELETE</code>和<code>ALTER UPDATE</code>）。这些任务在主副本完成之后再借助ZooKeeper将消息事件分发至其他副本。</li>\n    <li><strong>/blocks</strong>：记录Block数据块的Hash信息摘要，以及对应的<code>partition_id</code>。通过Hash摘要能够判断Block数据块是否重复；通过<code>partition_id</code>，则能够找到需要同步的数据分区。</li>\n    <li><strong>/block_numbers</strong>：按照分区的写入顺序，以相同的顺序记录<code>partition_id</code>。各个副本在本地进行<code>MERGE</code>时，都会依照相同的<code>block_numbers</code>顺序进行。</li>\n    <li><strong>/quorum</strong>：记录<code>quorum</code>的数量，当至少有<code>quorum</code>数量的副本写入成功后，整个写操作才算成功。<code>quorum</code>的数量由<code>insert_quorum</code>参数控制，默认值为0。</li>\n   </ul> </li>\n  <li> <p>操作日志</p> \n   <ul>\n    <li> <p><strong>/log</strong>：常规操作日志节点（<code>INSERT</code>、<code>MERGE</code>和<code>DROP PARTITION</code>），它是整个工作机制中最为重要的一环，保存了副本需要执行的任务指令。log使用了ZooKeeper的持久顺序型节点，每条指令的名称以log-为前缀递增，例如log-0000000000、log-0000000001等。每一个副本实例都会监听/log节点，当有新的指令加入时，它们会把指令加入副本各自的任务队列，并执行任务。</p> </li>\n    <li> <p><strong>/mutations</strong>：MUTATION操作日志节点，作用与log日志类似，当执行<code>ALERT DELETE</code>和<code>ALERT UPDATE</code>查询时，操作指令会被添加到这个节点。mutations同样使用了ZooKeeper的持久顺序型节点，但是它的命名没有前缀，每条指令直接以递增数字的形式保存，例如0000000000、0000000001等。</p> </li>\n    <li> <p>/replicas/{replica_name}/</p> <p>*：每个副本各自的节点下的一组监听节点，用于指导副本在本地执行具体的任务指令，其中较为重要的节点有如下几个：</p> \n     <ul>\n      <li><strong>/queue</strong>：任务队列节点，用于执行具体的操作任务。当副本从/log或/mutations节点监听到操作指令时，会将执行任务添加至该节点下，并基于队列执行。</li>\n      <li><strong>/log_pointer</strong>：log日志指针节点，记录了最后一次执行的log日志下标信息。</li>\n      <li><strong>/mutation_pointer</strong>：mutations日志指针节点，记录了最后一次执行的mutations日志名称。</li>\n     </ul> </li>\n   </ul> </li>\n </ul> \n <h3><a id=\"Entry_3312\"></a>Entry日志对象的数据结构</h3> \n <p>ReplicatedMergeTree在ZooKeeper中有两组非常重要的父节点，那就<code>/log</code>和<code>/mutations</code>。它们的作用犹如一座通信塔，是分发操作指令的信息通道，而发送指令的方式，则是为这些父节点添加子节点。</p> \n <p>所有的副本实例，都会监听父节点的变化，当有子节点被添加时，它们能实时感知。这些被添加的子节点在ClickHouse中被统一抽象为Entry对象，而具体实现则由LogEntry和MutationEntry对象承载，分别对应<code>/log</code>和<code>/mutations</code>节点</p> \n <ul>\n  <li>LogEntry \n   <ul>\n    <li><strong>source replica</strong>：发送这条Log指令的副本来源，对应replica_name。</li>\n    <li><strong>type</strong>：操作指令类型，主要有<code>get</code>、<code>merge</code>和<code>mutate</code>三种，分别对应从远程副本下载分区、合并分区和<code>MUTATION</code>操作。</li>\n    <li><strong>block_id</strong>：当前分区的BlockID，对应/blocks路径下子节点的名称。</li>\n    <li><strong>partition_name</strong>：当前分区目录的名称。</li>\n   </ul> </li>\n  <li>MutationEntry \n   <ul>\n    <li><strong>source replica</strong>：发送这条<code>MUTATION</code>指令的副本来源，对应replica_name。</li>\n    <li><strong>commands</strong>：操作指令，主要有<code>ALTER DELETE</code>和<code>ALTER UPDATE</code>。</li>\n    <li><strong>mutation_id</strong>：MUTATION操作的版本号。</li>\n    <li><strong>partition_id</strong>：当前分区目录的ID。</li>\n   </ul> </li>\n </ul> \n <h2><a id=\"_3331\"></a>副本协同的核心流程</h2> \n <p>副本协同的核心流程主要有<code>INSERT</code>、<code>MERGE</code>、<code>MUTATION</code>和<code>ALTER</code>四种，分别对应了数据写入、分区合并、数据修改和元数据修改。<code>INSERT</code>和<code>ALTER</code>是分布式执行的，借助ZooKeeper的事件通知机制，多个副本之间会自动进行有效协同，但是它们不会使用ZooKeeper存储任何分区数据。而其他操作并不支持分布式执行，包括<code>SELECT</code>、<code>CREATE</code>、<code>DROP</code>、<code>RENAME</code>和<code>ATTACH</code>。</p> \n <p>在下列例子中，使用ReplicatedMergeTree实现一张拥有1分片、1副本的数据表来分别执行<code>INSERT</code>、<code>MERGE</code>、<code>MUTATION</code>和<code>ALTER</code>操作，演示执行流程。</p> \n <h3><a id=\"INSERT_3339\"></a>INSERT协同的核心流程</h3> \n <p>当需要在ReplicatedMergeTree中执行<code>INSERT</code>查询以写入数据时，即会进入<code>INSERT</code>核心流程，它的核心流程如下图所示</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/ab28f5792a6d730b73a1ac659f25e712.png\" alt=\"img\"></p> \n <p>INSERT的核心执行流程</p> \n <ol>\n  <li><strong>向副本A写入数据</strong></li>\n  <li><strong>由副本A推送Log日志</strong></li>\n  <li><strong>各个副本拉取Log日志</strong></li>\n  <li>各个副本向远端副本发起下载请求 \n   <ul>\n    <li>选择一个远端的其他副本作为数据的下载来源。远端副本的选择算法大致是这样的： \n     <ul>\n      <li>从<code>/replicas</code>节点拿到所有的副本节点。</li>\n      <li>遍历这些副本，选取其中一个。选取的副本需要拥有最大的<code>log_pointer</code>下标，并且<code>/queue</code>子节点数量最少。<code>log_pointer</code>下标最大，意味着该副本执行的日志最多，数据应该更加完整；而<code>/queue</code>最小，则意味着该副本目前的任务执行负担较小。</li>\n     </ul> </li>\n   </ul> </li>\n  <li><strong>远端副本响应其它副本的数据下载</strong></li>\n  <li><strong>各个副本下载数据并完成本地写入</strong></li>\n </ol> \n <p>在<code>INSERT</code>的写入过程中，ZooKeeper不会进行任何实质性的数据传输。本着谁执行谁负责的原则，在这个案例中由CH5首先在本地写入了分区数据。之后，也由这个副本负责发送Log日志，通知其他副本下载数据。如果设置了<code>insert_quorum</code>并且<code>insert_quorum&gt;=2</code>，则还会由该副本监控完成写入的副本数量。其他副本在接收到Log日志之后，会选择一个最合适的远端副本，点对点地下载分区数据。</p> \n <h3><a id=\"MERGE_3363\"></a>MERGE协同的核心流程</h3> \n <p>当ReplicatedMergeTree触发分区合并动作时，即会进入这个部分的流程，它的核心流程如下图所示</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/7a342f28a953b2a63663285bc9e37b7e.png\" alt=\"img\"></p> \n <p>MERGE的核心执行流程</p> \n <p>无论MERGE操作从哪个副本发起，其合并计划都会交由主副本来制定。</p> \n <ol>\n  <li><strong>创建远程连接，尝试与主副本通信</strong></li>\n  <li><strong>主副本接收通信</strong></li>\n  <li><strong>由主副本制定MERGE计划并推送Log日志</strong></li>\n  <li><strong>各个副本分别拉取Log日志</strong></li>\n  <li><strong>各个副本分别在本地执行MERGE</strong></li>\n </ol> \n <p>可以看到，在<code>MERGE</code>的合并过程中，ZooKeeper也不会进行任何实质性的数据传输，所有的合并操作，最终都是由各个副本在本地完成的。而无论合并动作在哪个副本被触发，都会首先被转交至主副本，再由主副本负责合并计划的制定、消息日志的推送以及对日志接收情况的监控。</p> \n <h3><a id=\"MUTATION_3385\"></a>MUTATION协同的核心流程</h3> \n <p>当对ReplicatedMergeTree执行<code>ALTER DELETE</code>或者<code>ALTER UPDATE</code>操作的时候（ClickHouse把<code>DELETE</code>和<code>UPDATE</code>操作也加入到了<code>ALTER TABLE</code>的范畴中，它并不支持裸的<code>DELETE</code>或者<code>UPDATE</code>操作），即会进入<code>MUTATION</code>部分的逻辑</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/ae92d8442dd7d702e6145c9e242aceb3.png\" alt=\"img\"></p> \n <p>MUTATION的核心执行流程</p> \n <p>与<code>MERGE</code>类似，无论<code>MUTATION</code>操作从哪个副本发起，首先都会由主副本进行响应。</p> \n <ol>\n  <li><strong>推送MUTATION日志</strong></li>\n  <li><strong>所有副本实例各自监听MUTATION日志</strong></li>\n  <li><strong>由主副本实例响应MUTATION日志并推送Log日志</strong></li>\n  <li><strong>各个副本实例分别拉取Log日志</strong></li>\n  <li><strong>各个副本实例分别在本地执行MUTATION</strong></li>\n </ol> \n <p>在<code>MUTATION</code>的整个执行过程中，ZooKeeper同样不会进行任何实质性的数据传输。所有的<code>MUTATION</code>操作，最终都是由各个副本在本地完成的。而<code>MUTATION</code>操作是经过<code>/mutations</code>节点实现分发的。CH6负责了消息的推送。但是无论<code>MUTATION</code>动作从哪个副本被触发，之后都会被转交至主副本，再由主副本负责推送Log日志，以通知各个副本执行最终的<code>MUTATION</code>逻辑。同时也由主副本对日志接收的情况实行监控。</p> \n <h3><a id=\"ALTER_3407\"></a>ALTER协同的核心流程</h3> \n <p>当对ReplicatedMergeTree执行<code>ALTER</code>操作进行元数据修改的时候，即会进入<code>ALTER</code>部分的逻辑，例如增加、删除表字段等，核心流程如下图</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/ec98dbdd7e3f3cbf2f53cfe76010ad79.png\" alt=\"img\"></p> \n <p>ALTER的核心执行流程</p> \n <p><code>ALTER</code>的流程与前几个相比简单很多，其执行过程中并不会涉及/log日志的分发，整个流程大致分成3个步骤</p> \n <ol>\n  <li><strong>修改共享元数据</strong></li>\n  <li><strong>监听共享元数据变更并各自执行本地修改</strong></li>\n  <li><strong>确认所有副本完成修改</strong></li>\n </ol> \n <p>在<code>ALTER</code>整个的执行过程中，ZooKeeper不会进行任何实质性的数据传输。所有的ALTER操作，最终都是由各个副本在本地完成的。本着谁执行谁负责的原则，在这个案例中由CH6负责对共享元数据的修改以及对各个副本修改进度的监控。</p> \n <h2><a id=\"clickhouse_3431\"></a>clickhouse的优越的性能</h2> \n <ul>\n  <li> <p>与一些同类型产品对比</p> <p><img src=\"https://img-blog.csdnimg.cn/img_convert/1d7621dc07ffbf349e3fa926d2018ec8.png\" alt=\"img\"></p> <p>官网截图</p> </li>\n  <li> <p>与其他分析型数据库对比</p> <p><img src=\"https://img-blog.csdnimg.cn/img_convert/1749d7e2af688c6c8a5aba3ebf56d928.png\" alt=\"img\"></p> <p>易观数据</p> <p>可以看出clickhouse在性能上有非常卓越的表现。但是这并不意味着它可以代替其他的查询数据库。</p> </li>\n </ul> \n <p>就像这样，时不时的，在使用numpy库或者各种Tensor张量库进行计算的时候，我们都会感叹这些库计算的速度之快，以至于远远超越自己写的for循环。然后，我们就会逐渐并且越来越多的听说到一个词——vectorization（向量化计算）——其带来了巨大的计算性能。</p> \n <h2><a id=\"Clickhouse_3457\"></a>Clickhouse的不足：</h2> \n <p>没有完美的设计，只有适合的设计。<br> clickhouse也有自己的限制。</p> \n <ul>\n  <li>不支持事务</li>\n  <li>缺少高频率，低延迟的修改或删除已存在数据的能力。仅能用于批量删除或修改数据(性能不太好)</li>\n  <li>稀疏索引使得ClickHouse不适合通过其键检索单行的点查询</li>\n  <li>不支持大量的并发请求。每秒上百甚至更少</li>\n </ul> \n <h2><a id=\"Clickhouse_3471\"></a>Clickhouse推荐使用场景</h2> \n <ol>\n  <li>数据被添加到数据库，基本不怎么修改。</li>\n  <li>查询并发相对不高。</li>\n  <li>大宽表存储，少部分字段使用。</li>\n  <li>批量操作，更新或者删除。</li>\n  <li>列值相对小，数字或者短字符串。</li>\n  <li>无事务处理。</li>\n </ol> \n <p>比如：用于存储数据和统计数据使用/ 用户行为数据记录和分析工作 / 日志分析</p> \n <h2><a id=\"_3486\"></a>参考文献</h2> \n <p><a href=\"https://www.jianshu.com/p/dfbe8eb3b26c\">ClickHouse docker 集群搭建学习(小白向) - 简书 (jianshu.com)</a></p> \n <p>https://zhuanlan.zhihu.com/p/366421463</p> \n <p>https://blog.csdn.net/sinat_41207450/article/details/126777357</p> \n <p>http://events.jianshu.io/p/5fc49abc3119</p> \n <p>https://zhuanlan.zhihu.com/p/72953129</p> \n <p>https://blog.csdn.net/sinat_22510827/article/details/125939191</p> \n <p>https://blog.csdn.net/fyire/article/details/120826881</p> \n <p>https://www.jianshu.com/p/42d9dcd4f8cd</p> \n <p>https://www.igvita.com/2012/02/06/sstable-and-log-structured-storage-leveldb/<br> http://www.benstopford.com/2015/02/14/log-structured-merge-trees/</p> \n <p>https://www.jianshu.com/p/a30b814ee1fc</p> \n <p>https://seaboat.blog.csdn.net/article/details/82976862</p> \n <p>https://blog.csdn.net/jyxmust/article/details/89803733</p> \n <p>https://article.itxueyuan.com/AWwJJE</p> \n <p>https://blog.csdn.net/shangsongwww/article/details/103420171</p> \n <p>https://blog.csdn.net/ws1296931325/article/details/86635751/</p> \n <p>https://www.cnblogs.com/yjt1993/p/14522536.html</p> \n <p>https://oreki.blog.csdn.net/article/details/117258004</p> \n <p>https://cloud.tencent.com/developer/article/1986902</p> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 2200);
INSERT INTO `crawlerblog` VALUES (123124020, 'nacos高可用（图解+秒懂+史上最全）', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <p>文章很长，建议收藏起来，慢慢读！ <a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\"><strong>Java 高并发 发烧友社群：疯狂创客圈</strong></a> 奉上以下珍贵的学习资源：</p> \n <ul>\n  <li> <p><strong>免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\">《Java高并发核心编程（卷1）》 </a> 面试必备 + 大厂必备 +涨薪必备</strong> 加尼恩免费领</p> </li>\n  <li> <p><strong>免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\">《Java高并发核心编程（卷2）》 </a> 面试必备 + 大厂必备 +涨薪必备</strong> 加尼恩免费领</p> </li>\n  <li> <p><strong>免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\">《Netty Zookeeper Redis 高并发实战》 </a> 面试必备 + 大厂必备 +涨薪必备</strong> 加尼恩免费领</p> </li>\n  <li> <p><strong>免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\">《SpringCloud Nginx高并发核心编程》 </a> 面试必备 + 大厂必备 +涨薪必备</strong> 加尼恩免费领</p> </li>\n  <li> <p><strong>免费赠送 资源宝库： Java 必备 百度网盘资源大合集 价值&gt;10000元</strong> <a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\">加尼恩领取</a> </p> </li>\n </ul> \n <hr> \n <h2><a id=\"_Java____11\"></a>推荐：入大厂 、做架构、大力提升Java 内功 的 精彩博文</h2> \n <table>\n  <thead>\n   <tr>\n    <th align=\"left\">入大厂 、做架构、大力提升Java 内功 必备的精彩博文</th>\n    <th>2021 秋招涨薪1W + 必备的精彩博文</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td align=\"left\">1：<a href=\"https://www.cnblogs.com/crazymakercircle/p/14731826.html\"><strong>Redis 分布式锁</strong> （图解-秒懂-史上最全）</a></td>\n    <td>2：<a href=\"https://www.cnblogs.com/crazymakercircle/p/14504520.html\"><strong>Zookeeper 分布式锁</strong> （图解-秒懂-史上最全）</a></td>\n   </tr>\n   <tr>\n    <td align=\"left\">3: <a href=\"https://www.cnblogs.com/crazymakercircle/p/14853622.html\"><strong>Redis与MySQL双写一致性如何保证？</strong></a> （面试必备）</td>\n    <td>4: <a href=\"https://www.cnblogs.com/crazymakercircle/p/14846136.html\"><strong>面试必备：秒杀超卖 解决方案</strong></a> （史上最全）</td>\n   </tr>\n   <tr>\n    <td align=\"left\">5:<a href=\"https://www.cnblogs.com/crazymakercircle/p/9833847.html\"><strong>面试必备之：Reactor模式</strong></a></td>\n    <td>6: <a href=\"https://www.cnblogs.com/crazymakercircle/p/10225159.html\"><strong>10分钟看懂， Java NIO 底层原理</strong></a></td>\n   </tr>\n   <tr>\n    <td align=\"left\">7:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14499211.html\"><strong>TCP/IP（图解+秒懂+史上最全）</strong></a></td>\n    <td>8：<a href=\"https://www.cnblogs.com/crazymakercircle/p/11965726.html\">Feign原理 （图解）</a></td>\n   </tr>\n   <tr>\n    <td align=\"left\">9:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14976612.html\">DNS图解（秒懂 + 史上最全 + 高薪必备）</a></td>\n    <td>10：<a href=\"https://www.cnblogs.com/crazymakercircle/p/14978513.html\">CDN图解（秒懂 + 史上最全 + 高薪必备）</a></td>\n   </tr>\n   <tr>\n    <td align=\"left\">11: <a href=\"https://www.cnblogs.com/crazymakercircle/p/13917517.html\"><strong>分布式事务（ 图解 + 史上最全 + 吐血推荐 ）</strong></a></td>\n    <td>12：<a href=\"https://www.cnblogs.com/crazymakercircle/p/15313875.html\">seata AT模式实战（图解+秒懂+史上最全）</a></td>\n   </tr>\n   <tr>\n    <td align=\"left\">13：<a href=\"https://www.cnblogs.com/crazymakercircle/p/15313951.html\">seata 源码解读（图解+秒懂+史上最全）</a></td>\n    <td>14：<a href=\"https://www.cnblogs.com/crazymakercircle/p/15314246.html\">seata TCC模式实战（图解+秒懂+史上最全）</a></td>\n   </tr>\n  </tbody>\n </table> \n <hr> \n <table>\n  <thead>\n   <tr>\n    <th align=\"left\">Java 面试题 30个专题 , 史上最全 , 面试必刷</th>\n    <th>阿里、京东、美团… 随意挑、横着走！！！</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td align=\"left\">1： <a href=\"https://www.cnblogs.com/crazymakercircle/p/14365820.html\">JVM面试题（史上最强、持续更新、吐血推荐）</a></td>\n    <td><a href=\"https://www.cnblogs.com/crazymakercircle/p/14366081.html\">2：Java基础面试题（史上最全、持续更新、吐血推荐</a></td>\n   </tr>\n   <tr>\n    <td align=\"left\"><a href=\"https://www.cnblogs.com/crazymakercircle/p/14367907.html\">3：架构设计面试题 （史上最全、持续更新、吐血推荐）</a></td>\n    <td><a href=\"https://www.cnblogs.com/crazymakercircle/p/14367101.html\">4：设计模式面试题 （史上最全、持续更新、吐血推荐）</a></td>\n   </tr>\n   <tr>\n    <td align=\"left\">17、<a href=\"https://www.cnblogs.com/crazymakercircle/p/14375424.html\">分布式事务面试题 （史上最全、持续更新、吐血推荐）</a></td>\n    <td><a href=\"https://www.cnblogs.com/crazymakercircle/p/14334422.html\"><strong>一致性协议</strong> （史上最全）</a></td>\n   </tr>\n   <tr>\n    <td align=\"left\">29、<a href=\"https://www.cnblogs.com/crazymakercircle/p/14655412.html\"><strong>多线程面试题</strong>（史上最全）</a></td>\n    <td>30、<a href=\"https://www.cnblogs.com/crazymakercircle/p/14659738.html\">HR面经，过五关斩六将后，小心阴沟翻船！</a></td>\n   </tr>\n   <tr>\n    <td align=\"left\">9.<a href=\"https://www.cnblogs.com/crazymakercircle/p/14370335.html\"><strong>网络协议面试题</strong>（史上最全、持续更新、吐血推荐）</a></td>\n    <td>更多专题， 请参见【<a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\"> 疯狂创客圈 高并发 总目录</a> 】</td>\n   </tr>\n  </tbody>\n </table> \n <hr> \n <table>\n  <thead>\n   <tr>\n    <th align=\"left\">SpringCloud 精彩博文</th>\n    <th></th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td align=\"left\"><a href=\"https://www.cnblogs.com/crazymakercircle/p/14231815.html\"> <strong>nacos 实战</strong>（史上最全）</a></td>\n    <td><a href=\"https://www.cnblogs.com/crazymakercircle/p/14285001.html\"> sentinel （史上最全+入门教程）</a></td>\n   </tr>\n   <tr>\n    <td align=\"left\"><a href=\"https://www.cnblogs.com/crazymakercircle/p/11704077.html\"> <strong>SpringCloud gateway</strong> （史上最全）</a></td>\n    <td>更多专题， 请参见【<a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\"> 疯狂创客圈 高并发 总目录</a> 】</td>\n   </tr>\n  </tbody>\n </table> \n <hr> \n <h2><a id=\"_42\"></a>背景：</h2> \n <p>下一个视频版本，从架构师视角，尼恩为大家打造高可用、高并发中间件的原理与实操。</p> \n <p>目标：通过视频和博客的方式，为各位潜力架构师，彻底介绍清楚架构师必须掌握的高可用、高并发环境，包括但不限于：</p> \n <ul>\n  <li> <p>高可用、高并发nginx架构的原理与实操</p> </li>\n  <li> <p>高可用、高并发mysql架构的原理与实操</p> </li>\n  <li> <p>高可用、高并发nacos架构的原理与实操</p> </li>\n  <li> <p>高可用、高并发rocketmq架构的原理与实操</p> </li>\n  <li> <p>高可用、高并发es架构的原理与实操</p> </li>\n  <li> <p>高可用、高并发minio架构的原理与实操</p> </li>\n </ul> \n <p><img src=\"https://img-blog.csdnimg.cn/53f9bf9a5ec94a20a24c113021c91d3b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5p625p6E5biILeWwvOaBqQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>why 高可用、高并发中间件的原理与实操：</p> \n <blockquote> \n  <ul>\n   <li> <p>实际的开发过程中，很多小伙伴聚焦crud开发，环境出了问题，都不能启动。</p> </li>\n   <li> <p>作为架构师，或者未来想走向高端开发，或者做架构，必须掌握高可用、高并发中间件的原理，掌握其实操。</p> </li>\n  </ul> \n </blockquote> \n <p>本系列博客的具体内容，请参见 <a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\"><strong>Java 高并发 发烧友社群：疯狂创客圈</strong></a></p> \n <h2><a id=\"Nacos__76\"></a>Nacos 高可用介绍</h2> \n <p>当我们在聊高可用时，我们在聊什么？</p> \n <ul>\n  <li>系统可用性达到 99.99%</li>\n  <li>在分布式系统中，部分节点宕机，依旧不影响系统整体运行</li>\n  <li>服务端集群化部署多个节点</li>\n </ul> \n <p>Nacos 高可用，则是 Nacos 为了提升系统稳定性而采取的一系列手段。</p> \n <p>Nacos 的高可用不仅仅存在于服务端，同时也存在于客户端，以及一些与可用性相关的功能特性中，这些点组装起来，共同构成了 Nacos 的高可用。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/b5e4fa5ae02a4ec78be17b43fea99c23.png\" alt=\"在这里插入图片描述\"></p> \n <h2><a id=\"_98\"></a>客户端高可用</h2> \n <p>先统一一下语义，在微服务架构中一般会有三个角色：</p> \n <ul>\n  <li> <p>Consumer</p> </li>\n  <li> <p>Provider</p> </li>\n  <li> <p>Registry</p> </li>\n </ul> \n <p>以上的registry 角色是 nacos-server，而 Consumer 角色和 Provider 角色都是 nacos-client。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/e2bf263a51974850a5498335a7d72f60.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5p625p6E5biILeWwvOaBqQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"nacosserver_116\"></a>客户端高可用的方式一：配置多个nacos-server</h3> \n <p>在生产环境，我们往往需要搭建 Nacos 集群，代码中，是这样配置的：</p> \n <pre><code class=\"prism language-text\">\nserver:\n  port: 8081\nspring:\n  cloud:\n    nacos:\n      server-addr: 127.0.0.1:8848,127.0.0.1:8848,127.0.0.1:8848\n\n\n</code></pre> \n <p>当其中一台Nacos server机器宕机时，为了不影响整体运行，客户端会存在重试机制。</p> \n <pre><code>package com.alibaba.nacos.client.naming.net;\n\n\n/**\n * @author nkorange\n */\npublic class NamingProxy {\n\n//api注册\n\npublic String reqAPI(String api, Map&lt;String, String&gt; params, String body, List&lt;String&gt; servers, String method) throws NacosException {\n\nparams.put(CommonParams.NAMESPACE_ID, getNamespaceId());\n\nif (CollectionUtils.isEmpty(servers) &amp;&amp; StringUtils.isEmpty(nacosDomain)) {\n    throw new NacosException(NacosException.INVALID_PARAM, \"no server available\");\n}\n\nNacosException exception = new NacosException();\n\nif (servers != null &amp;&amp; !servers.isEmpty()) {\n\n    Random random = new Random(System.currentTimeMillis());\n    int index = random.nextInt(servers.size());\n    \n    //拿到地址列表，在请求成功之前逐个尝试，直到成功为止\n\n    for (int i = 0; i &lt; servers.size(); i++) {\n        String server = servers.get(index);\n        try {\n            return callServer(api, params, body, server, method);\n        } catch (NacosException e) {\n            exception = e;\n            if (NAMING_LOGGER.isDebugEnabled()) {\n                NAMING_LOGGER.debug(\"request {} failed.\", server, e);\n            }\n        }\n        index = (index + 1) % servers.size();\n    }\n}\n\n...\n \n</code></pre> \n <p>该可用性保证存在于 nacos-client 端。</p> \n <h3><a id=\"Nacos_Java_Client_184\"></a>Nacos Java Client通用参数</h3> \n <table>\n  <thead>\n   <tr>\n    <th>参数名</th>\n    <th>含义</th>\n    <th>可选值</th>\n    <th>默认值</th>\n    <th>支持版本</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>endpoint</td>\n    <td>连接Nacos Server指定的连接点，可以参考<a href=\"https://nacos.io/zh-cn/blog/address-server.html\">文档</a></td>\n    <td>域名</td>\n    <td>空</td>\n    <td>&gt;= 0.1.0</td>\n   </tr>\n   <tr>\n    <td>endpointPort</td>\n    <td>连接Nacos Server指定的连接点端口，可以参考<a href=\"https://nacos.io/zh-cn/blog/address-server.html\">文档</a></td>\n    <td>合法端口号</td>\n    <td>空</td>\n    <td>&gt;= 0.1.0</td>\n   </tr>\n   <tr>\n    <td>namespace</td>\n    <td>命名空间的ID</td>\n    <td>命名空间的ID</td>\n    <td>config模块为空，naming模块为public</td>\n    <td>&gt;= 0.8.0</td>\n   </tr>\n   <tr>\n    <td>serverAddr</td>\n    <td>Nacos Server的地址列表，这个值的优先级比endpoint高</td>\n    <td>ip:port,ip:port,…</td>\n    <td>空</td>\n    <td>&gt;= 0.1.0</td>\n   </tr>\n   <tr>\n    <td>JM.LOG.PATH(-D)</td>\n    <td>客户端日志的目录</td>\n    <td>目录路径</td>\n    <td>用户根目录</td>\n    <td>&gt;= 0.1.0</td>\n   </tr>\n  </tbody>\n </table> \n <h3><a id=\"_Failover__198\"></a>客户端高可用的方式二：本地缓存文件 Failover 机制</h3> \n <p>注册中心发生故障最坏的一个情况是整个 Server 端宕机，如果三个Server 端都宕机了，怎么办呢？</p> \n <blockquote> \n  <p>这时候 Nacos 依旧有高可用机制做兜底。</p> \n </blockquote> \n <h4><a id=\"_Failover__204\"></a>本地缓存文件 Failover 机制</h4> \n <p>一道经典的 高可用的面试题：</p> \n <blockquote> \n  <p>当 springcloud 应用运行时，Nacos 注册中心宕机，会不会影响 RPC 调用。</p> \n </blockquote> \n <p>这个题目大多数人，应该都不能回答出来.</p> \n <p>Nacos 存在本地文件缓存机制，nacos-client 在接收到 nacos-server 的服务推送之后，会在内存中保存一份，随后会落盘存储一份快照snapshot 。有了这份快照，本地的RPC调用，还是能正常的进行。</p> \n <blockquote> \n  <p>关键是，这个本地文件缓存机制，默认是关闭的。</p> \n </blockquote> \n <p>Nacos 注册中心宕机，Dubbo /springcloud 应用发生重启，会不会影响 RPC 调用。如果了解了 Nacos 的 Failover 机制，应当得到和上一题同样的回答：不会。</p> \n <h4><a id=\"Naming_226\"></a>客户端Naming通用参数</h4> \n <table>\n  <thead>\n   <tr>\n    <th>参数名</th>\n    <th>含义</th>\n    <th>可选值</th>\n    <th>默认值</th>\n    <th>支持版本</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>namingLoadCacheAtStart</td>\n    <td>启动时是否优先读取本地缓存</td>\n    <td>true/false</td>\n    <td>false</td>\n    <td>&gt;= 1.0.0</td>\n   </tr>\n   <tr>\n    <td>namingClientBeatThreadCount</td>\n    <td>客户端心跳的线程池大小</td>\n    <td>正整数</td>\n    <td>机器的CPU数的一半</td>\n    <td>&gt;= 1.0.0</td>\n   </tr>\n   <tr>\n    <td>namingPollingThreadCount</td>\n    <td>客户端定时轮询数据更新的线程池大小</td>\n    <td>正整数</td>\n    <td>机器的CPU数的一半</td>\n    <td>&gt;= 1.0.0</td>\n   </tr>\n   <tr>\n    <td>com.alibaba.nacos.naming.cache.dir(-D)</td>\n    <td>客户端缓存目录</td>\n    <td>目录路径</td>\n    <td>{user.home}/nacos/naming</td>\n    <td>&gt;= 1.0.0</td>\n   </tr>\n   <tr>\n    <td>com.alibaba.nacos.naming.log.level(-D)</td>\n    <td>Naming客户端的日志级别</td>\n    <td>info,error,warn等</td>\n    <td>info</td>\n    <td>&gt;= 1.0.0</td>\n   </tr>\n   <tr>\n    <td>com.alibaba.nacos.client.naming.tls.enable(-D)</td>\n    <td>是否打开HTTPS</td>\n    <td>true/false</td>\n    <td>false</td>\n    <td></td>\n   </tr>\n  </tbody>\n </table> \n <p>snapshot 默认的存储路径为：{USER_HOME}/nacos/naming/ 中：</p> \n <p>这份文件有两种价值，一是用来排查服务端是否正常推送了服务；二是当客户端加载服务时，如果无法从服务端拉取到数据，会默认从本地文件中加载。</p> \n <p>在生产环境，推荐开启该参数，以避免注册中心宕机后，导致服务不可用，在服务注册发现场景，可用性和一致性 trade off 时，我们大多数时候会优先考虑可用性。</p> \n <p>另外：{USER_HOME}/nacos/naming/{namespace} 下除了缓存文件之外还有一个 failover 文件夹，里面存放着和 snapshot 一致的文件夹。</p> \n <p>这是 Nacos 的另一个 failover 机制，snapshot 是按照某个历史时刻的服务快照恢复恢复，而 failover 中的服务可以人为修改，以应对一些极端场景。</p> \n <p>该可用性保证存在于 nacos-client 端。</p> \n <h2><a id=\"Nacos_259\"></a>Nacos两种健康检查模式</h2> \n <h3><a id=\"agent_261\"></a>agent上报模式</h3> \n <p><strong>客户端（注册在nacos上的其它微服务实例）健康检查。</strong></p> \n <p>客户端通过心跳上报方式告知服务端(nacos注册中心)健康状态；</p> \n <p>默认心跳间隔5秒；</p> \n <p>nacos会在超过15秒未收到心跳后将实例设置为不健康状态；</p> \n <p>超过30秒将实例删除；</p> \n <h3><a id=\"_273\"></a>服务端主动检测</h3> \n <p><strong>服务端健康检查。</strong></p> \n <p>nacos主动探知客户端健康状态，默认间隔为20秒；</p> \n <p>健康检查失败后实例会被标记为不健康，不会被立即删除。</p> \n <h3><a id=\"_281\"></a>临时实例</h3> \n <p><strong>临时实例通过agent上报模式实现健康检查。</strong></p> \n <p>Nacos 在 1.0.0版本 <code>instance</code>级别增加了一个<code>ephemeral</code>字段，该字段表示注册的实例是否是临时实例还是持久化实例。</p> \n <p>微服务注册为临时实例：</p> \n <pre><code># 默认true\nspring:\n	cloud:\n		nacos:\n			discovery:\n				ephemeral: true\n</code></pre> \n <p>注意： 默认为临时实例，表示为临时实例。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/e1a1d0330a7d4d33aaf7848e7f8fc6f0.png\" alt=\"在这里插入图片描述\"></p> \n <h4><a id=\"ephemeral_302\"></a>注册实例支持ephemeral字段</h4> \n <p>如果是临时实例，则<code>instance</code>不会在 Nacos 服务端持久化存储，需要通过上报心跳的方式进行包活，</p> \n <p>如果<code>instance</code>一段时间内没有上报心跳，则会被 Nacos 服务端摘除。</p> \n <p>在被摘除后如果又开始上报心跳，则会重新将这个实例注册。</p> \n <p>持久化实例则会持久化被 Nacos 服务端，此时即使注册实例的客户端进程不在，这个实例也不会从服务端删除，只会将健康状态设为不健康。</p> \n <p>同一个服务下可以同时有临时实例和持久化实例，这意味着当这服务的所有实例进程不在时，会有部分实例从服务上摘除，剩下的实例则会保留在服务下。</p> \n <p>使用实例的<code>ephemeral</code>来判断，<code>ephemeral</code>为<code>true</code>对应的是服务健康检查模式中的 client 模式,为<code>false</code>对应的是 server 模式。</p> \n <p>Nacos 1.0.0 之前服务的健康检查模式有三种：client、server 和none, 分别代表客户端上报、服务端探测和取消健康检查。在控制台操作的位置如下所示：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/b086830c481e4f76954e31eb960b297b.png\" alt=\"在这里插入图片描述\"></p> \n <p>在 Nacos 1.0.0 中将把这个配置去掉，改为使用实例的<code>ephemeral</code>来判断，<code>ephemeral</code>为<code>true</code>对应的是服务健康检查模式中的 client 模式,为<code>false</code>对应的是 server 模式。</p> \n <h4><a id=\"_326\"></a>临时实例和持久化实例区别</h4> \n <p>临时和持久化的区别主要在健康检查失败后的表现，持久化实例健康检查失败后会被标记成不健康，而临时实例会直接从列表中被删除。</p> \n <p>这个特性比较适合那些需要应对流量突增，而弹性扩容的服务，当流量降下来后这些实例自己销毁自己就可以了，不用再去nacos里手动调用注销实例。持久化以后，可以实时看到健康状态，便于做后续的告警、扩容等一系列处理。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/20201101184001354.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4ODI2MDE5,size_16,color_FFFFFF,t_70\" alt=\"img\"></p> \n <h2><a id=\"Nacos_Server_336\"></a>Nacos Server运行模式</h2> \n <p>Server的运行模式，是指 Nacos Server 可以运行在多种模式下，当前支持三种模式：</p> \n <ul>\n  <li>AP、</li>\n  <li>CP</li>\n  <li>MIXED 。</li>\n </ul> \n <p>这里的运行模式，使用的是CAP理论里的C、A和P概念。</p> \n <p>CAP原则又称CAP定理，指的是在一个<a href=\"https://baike.baidu.com/item/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/4905336\">分布式系统</a>中， Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可得兼。</p> \n <p>一致性（C）：在<a href=\"https://baike.baidu.com/item/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/4905336\">分布式系统</a>中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本）</p> \n <p>可用性（A）：在集群中一部分节点故障后，<a href=\"https://baike.baidu.com/item/%E9%9B%86%E7%BE%A4/5486962\">集群</a>整体是否还能响应<a href=\"https://baike.baidu.com/item/%E5%AE%A2%E6%88%B7%E7%AB%AF/101081\">客户端</a>的读写请求。（对数据更新具备高可用性）</p> \n <p>分区容忍性（P）：以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。</p> \n <p>CAP原则的精髓就是要么AP，要么CP，要么AC，但是不存在CAP。如果在某个分布式系统中数据无副本， 那么系统必然满足强一致性条件， 因为只有独一数据，不会出现数据不一致的情况，此时C和P两要素具备，但是如果系统发生了网络分区状况或者宕机，必然导致某些数据不可以访问，此时可用性条件就不能被满足，即在此情况下获得了CP系统，但是CAP不可同时满足 。</p> \n <p>基于CAP理论，在分布式系统中，数据的一致性、服务的可用性和网络分区容忍性只能三者选二。一般来说分布式系统需要支持网络分区容忍性，那么就只能在C和A里选择一个作为系统支持的属性。C 的准确定义应该是所有节点在同一时间看到的数据是一致的，而A的定义是所有的请求都会收到响应。</p> \n <p>Nacos 支持 AP 和 CP 模式的切换，这意味着 Nacos 同时支持两者一致性协议。这样，Nacos能够以一个注册中心管理这些生态的服务。不过在Nacos中，AP模式和CP模式的具体含义，还需要再说明下。</p> \n <p>AP模式为了服务的可能性而减弱了一致性，因此AP模式下只支持注册临时实例。AP 模式是在网络分区下也能够注册实例。在AP模式下也不能编辑服务的元数据等非实例级别的数据，但是允许创建一个默认配置的服务。同时注册实例前不需要进行创建服务的操作，因为这种模式下，服务其实降级成一个简单的字符创标识，不在存储任何属性，会在注册实例的时候自动创建。</p> \n <p>CP模式下则支持注册持久化实例，此时则是以 Raft 协议为集群运行模式，因此网络分区下不能够注册实例，在网络正常情况下，可以编辑服务器别的配置。改模式下注册实例之前必须先注册服务，如果服务不存在，则会返回错误。</p> \n <p>MIXED 模式可能是一种比较让人迷惑的模式，这种模式的设立主要是为了能够同时支持临时实例和持久化实例的注册。这种模式下，注册实例之前必须创建服务，在服务已经存在的前提下，临时实例可以在网络分区的情况下进行注册。</p> \n <h3><a id=\"Nacos_CPAP_368\"></a>Nacos CP/AP模式设定</h3> \n <p>使用如下请求进行Server运行模式的设定：</p> \n <pre><code>curl -X PUT\n\'$NACOS_SERVER:8848/nacos/v1/ns/operator/switches?entry=serverMode&amp;value=CP\'\n</code></pre> \n <h3><a id=\"Nacos_CPAP_379\"></a>Nacos CP/AP模式切换</h3> \n <p>Nacos 集群默认支持的是CAP原则中的AP原则.</p> \n <p>但是Nacos 集群可切换为CP原则，切换命令如下：</p> \n <pre><code>curl -X PUT \'$NACOS_SERVER:8848/nacos/v1/ns/operator/switches?entry=serverMode&amp;value=CP\'\n</code></pre> \n <p>同时微服务的bootstrap.properties 需配置如下选项指明注册为临时/永久实例<br> AP模式不支持数据一致性，所以只支持服务注册的临时实例，CP模式支持服务注册的永久实例，满足配置文件的一致性</p> \n <pre><code>#false为永久实例，true表示临时实例开启，注册为临时实例\nspring.cloud.nacos.discovery.ephemeral=true\n</code></pre> \n <h2><a id=\"APCP_401\"></a>AP/CP的配套一致性协议</h2> \n <p>介绍一致性模型之前，需要回顾 Nacos 中的两个概念：临时服务和持久化服务。</p> \n <ul>\n  <li>临时服务（Ephemeral）：临时服务健康检查失败后会从列表中删除，常用于服务注册发现场景。</li>\n  <li>持久化服务（Persistent）：持久化服务健康检查失败后会被标记成不健康，常用于 DNS 场景。</li>\n </ul> \n <p>两种模式使用的是不同的一致性协议：</p> \n <ul>\n  <li> <p>临时服务使用的是 Nacos 为服务注册发现场景定制化的私有协议 distro，其一致性模型是 AP；</p> </li>\n  <li> <p>而持久化服务使用的是 raft 协议，其一致性模型是 CP。</p> </li>\n </ul> \n <h3><a id=\"APdistro__416\"></a>AP模式下的distro 协议</h3> \n <p>distro 协议的工作流程如下：</p> \n <ul>\n  <li>Nacos 启动时首先从其他远程节点同步全部数据。</li>\n  <li>Nacos 每个节点是平等的都可以处理写入请求，同时把新数据同步到其他节点。</li>\n  <li>每个节点只负责部分数据，定时发送自己负责数据的校验值到其他节点来保持数据一致性。</li>\n </ul> \n <p>如图所示，每个节点负责一部分服务的写入。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/ac70a91e92ed4268a41952cbadcc5752.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5p625p6E5biILeWwvOaBqQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>但每个节点都可以接收到写入请求，这时就存在两种情况：</p> \n <ul>\n  <li>当该节点接收到属于该节点负责的服务时，直接写入。</li>\n  <li>当该节点接收到不属于该节点负责的服务时，将在集群内部路由，转发给对应的节点，从而完成写入。</li>\n </ul> \n <p><img src=\"https://img-blog.csdnimg.cn/ff6fcab202374066b8c81483aedb9252.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5p625p6E5biILeWwvOaBqQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>读取操作则不需要路由，因为集群中的各个节点会同步服务状态，每个节点都会有一份最新的服务数据。</p> \n <p>而当节点发生宕机后，原本该节点负责的一部分服务的写入任务会转移到其他节点，从而保证 Nacos 集群整体的可用性。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/a76f7f610cec47cba2e16f2cd25e4753.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5p625p6E5biILeWwvOaBqQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>一个比较复杂的情况是，节点没有宕机，但是出现了网络分区，即下图所示：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/0ab6170189814283aa07cfdcfb9ae813.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5p625p6E5biILeWwvOaBqQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>这个情况会损害可用性，客户端会表现为有时候服务存在有时候服务不存在。</p> \n <p>综上，Nacos 的 distro 一致性协议可以保证在大多数情况下，集群中的机器宕机后依旧不损害整体的可用性。</p> \n <p>Nacos 有两个一致性协议：distro 和 raft，distro 协议不会有脑裂问题。</p> \n <h3><a id=\"CPraft_471\"></a>CP模式下的raft协议</h3> \n <blockquote> \n  <p>此文还是聚焦于介绍nacos的高可用， raft协议，请参考尼恩的架构师视频。</p> \n </blockquote> \n <h2><a id=\"_477\"></a>集群内部的特殊的心跳同步服务</h2> \n <p>心跳机制一般广泛存在于分布式通信领域，用于确认存活状态。</p> \n <p>一般心跳请求和普通请求的设计是有差异的，心跳请求一般被设计的足够精简，这样在定时探测时可以尽可能避免性能下降。</p> \n <p>而在 Nacos 中，出于可用性的考虑，一个心跳报文包含了全部的服务信息，这样相比仅仅发送探测信息降低了吞吐量，而提升了可用性，怎么理解呢？</p> \n <p>考虑以下的两种场景：</p> \n <ul>\n  <li>nacos-server 节点全部宕机，服务数据全部丢失。nacos-server 即使恢复运作，也无法恢复出服务，而心跳包含全部内容可以在心跳期间就恢复出服务，保证可用性。</li>\n  <li>nacos-server 出现网络分区。由于心跳可以创建服务，从而在极端网络故障下，依旧保证基础的可用性。</li>\n </ul> \n <p>调用 OpenApi 依次删除各个服务：</p> \n <pre><code class=\"prism language-text\">curl -X \"DELETE mse-xxx-p.nacos-ans.mse.aliyuncs.com:8848/nacos/v1/ns/service?serviceName=providers:com.alibaba.edas.boot.EchoService:1.0.0:DUBBO&amp;groupName=DEFAULT_GROUP\"\n</code></pre> \n <p>过 5s 后刷新，服务又再次被注册了上来，符合我们对心跳注册服务的预期。</p> \n <h2><a id=\"_502\"></a>集群部署模式高可用</h2> \n <p>最后给大家分享的 Nacos 高可用特性来自于其部署架构。</p> \n <h3><a id=\"_506\"></a>节点数量</h3> \n <p>我们知道在生产集群中肯定不能以单机模式运行 Nacos。</p> \n <p>那么第一个问题便是：我应该部署几台机器？</p> \n <p>Nacos 有两个一致性协议：distro 和 raft，distro 协议不会有脑裂问题，所以理论来说，节点数大于等于 2 即可；raft 协议的投票选举机制则建议是 2n+1 个节点。</p> \n <p>综合来看，选择 3 个节点是起码的，其次处于吞吐量和更吞吐量的考量，可以选择 5 个，7 个，甚至 9 个节点的集群。</p> \n <h3><a id=\"_516\"></a>多可用区部署</h3> \n <p>组成集群的 Nacos 节点，应该尽可能考虑两个因素：</p> \n <ul>\n  <li>各个节点之间的网络时延不能很高，否则会影响数据同步。</li>\n  <li>各个节点所处机房、可用区应当尽可能分散，以避免单点故障。</li>\n </ul> \n <blockquote> \n  <p>以阿里云的 ECS 为例，选择同一个 Region 的不同可用区就是一个很好的实践。</p> \n </blockquote> \n <h3><a id=\"_525\"></a>部署模式</h3> \n <p>生产环境，建议使用k8s部署或者阿里云的 ECS 部署。</p> \n <p>考虑的中等公司，都会有运维团队，开发人员不需要参与。</p> \n <p>所以，这里介绍的开发人员必须掌握的，docker模式的部署。</p> \n <h3><a id=\"nacos_535\"></a>高可用nacos的部署架构</h3> \n <p><img src=\"https://img-blog.csdnimg.cn/52f86d6a01494f15823049b0ccf6c100.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5p625p6E5biILeWwvOaBqQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"nacos_541\"></a>高可用nacos的部署实操</h3> \n <blockquote> \n  <p>实操这块，使用视频介绍更为清晰，请参考尼恩的架构师视频。</p> \n </blockquote> \n <h2><a id=\"_547\"></a>总结</h2> \n <p>本文从多个角度出发，总结了一下 Nacos 是如何保障高可用的。</p> \n <p>高可用特性绝不是靠服务端多部署几个节点就可以获得的，而是要结合客户端使用方式、服务端部署模式、使用场景综合来考虑的一件事。</p> \n <p>特别是在服务注册发现场景，Nacos 为可用性做了非常多的努力，而这些保障，ZooKeeper 是不一定有的。在做注册中心选型时，可用性保障上，Nacos 绝对是优秀的。</p> \n <h2><a id=\"_559\"></a>参考文献：</h2> \n <p>https://nacos.io/zh-cn/docs/what-is-nacos.html</p> \n <p>https://blog.csdn.net/qq_38826019/article/details/109433231</p> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 3931);
INSERT INTO `crawlerblog` VALUES (123124021, '队列之王： Disruptor 原理、架构、源码 一文穿透', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <p>文章很长，而且持续更新，建议收藏起来，慢慢读！<a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\"><strong>疯狂创客圈总目录 博客园版</strong></a> 为您奉上珍贵的学习资源 ：</p> \n <p>免费赠送 :<a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\"><strong>《尼恩Java面试宝典》</strong></a> 持续更新+ 史上最全 + 面试必备 2000页+ 面试必备 + 大厂必备 +涨薪必备<br> 免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\"><strong>《Java高并发核心编程（卷1）加强版》</strong></a> 面试必备 + 大厂必备 +涨薪必备 加尼恩免费领<br> 免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\"><strong>《Java高并发核心编程（卷2）加强版》</strong> </a> 面试必备 + 大厂必备 +涨薪必备 加尼恩免费领<br> 免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\"><strong>《Java高并发核心编程（卷3）加强版》</strong></a> 面试必备 + 大厂必备 +涨薪必备 加尼恩免费领<br> 免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\">《<strong>尼恩Java面试宝典 最新版</strong>》 </a> 面试必备 + 大厂必备 +涨薪必备 加尼恩免费领<br> 免费赠送 资源宝库： <strong>Java 必备 百度网盘资源大合集 价值</strong>&gt;10000元 加尼恩领取</p> \n <hr> \n <h2><a id=\"disruptor___16\"></a>disruptor 红宝书目的：</h2> \n <p>作为Java领域<strong>最高性能的 队列</strong>，没有之一， 大家不光要懂，而是 需要<strong>深入骨髓的搞懂</strong>。</p> \n <p>所以，给大家奉上了本书，并且配备了视频进行 详细介绍， 目的：</p> \n <p>帮助，大家穿透 一个 绝对核心高性能 Java高性能的 队列 的架构和原理，让 <strong>面试题 五体投地、顶礼膜拜</strong>。</p> \n <p></p> \n <div class=\"toc\"> \n  <h3>文章目录</h3> \n  <ul>\n   <li>\n    <ul>\n     <li><a href=\"#disruptor___16\">disruptor 红宝书目的：</a></li>\n    </ul> </li>\n   <li><a href=\"#_Disruptor__35\">队列之王 Disruptor 简介</a></li>\n   <li>\n    <ul>\n     <li><a href=\"#Java_49\">Java内置队列的问题</a></li>\n     <li><a href=\"#Disruptor__85\">Disruptor 的使用场景</a></li>\n    </ul> </li>\n   <li><a href=\"#1__106\">1 前置知识：伪共享原理与实操</a></li>\n   <li>\n    <ul>\n     <li><a href=\"#CPU_110\">CPU的结构</a></li>\n     <li><a href=\"#_cache_line_149\">缓存行 cache line</a></li>\n     <li><a href=\"#_False_Sharing_185\">什么是 伪共享（False Sharing）问题？</a></li>\n     <li><a href=\"#False_Sharing_237\">伪共享问题（False Sharing）的本质</a></li>\n     <li><a href=\"#__257\">伪共享问题 的解决方案</a></li>\n     <li><a href=\"#_271\">一个缓冲行填充的例子</a></li>\n     <li><a href=\"#False_Sharingjava_8_334\">伪共享False Sharing在java 8中解决方案</a></li>\n     <li><a href=\"#6_419\">伪共享性能比对实操：结论，差6倍</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#__429\">存在伪共享场景下的 耗时计算</a></li>\n       <li><a href=\"#__459\">消除伪共享场景下的 耗时计算</a></li>\n       <li><a href=\"#unsafe_487\">使用unsafe访问变量的耗时计算</a></li>\n       <li><a href=\"#_509\">性能总结</a></li>\n      </ul> </li>\n     <li><a href=\"#JDK__533\">JDK源码中如何解决 伪共享问题</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#LongAdder_Striped64_539\">LongAdder以及 Striped64如何解决伪共享问题</a></li>\n       <li><a href=\"#Cell_571\">Cell元素如何消除伪共享</a></li>\n      </ul> </li>\n     <li><a href=\"#_587\">对于伪共享，我们在实际开发中该怎么做？</a></li>\n     <li><a href=\"#3_Disruptor_607\">3 Disruptor框架是如何解决伪共享问题的？</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#Sequence_613\">Sequence的结构和源码</a></li>\n      </ul> </li>\n    </ul> </li>\n   <li><a href=\"#2Disruptor___683\">2：Disruptor 的 使用实战</a></li>\n   <li>\n    <ul>\n     <li>\n      <ul>\n       <li><a href=\"#Event_689\">定义一个Event和工厂</a></li>\n       <li><a href=\"#_717\">定义事件处理器（消费者）</a></li>\n       <li><a href=\"#_738\">定义事件源(生产者)</a></li>\n       <li><a href=\"#_813\">组装起来</a></li>\n       <li><a href=\"#_850\">事件转换器</a></li>\n       <li><a href=\"#Java_8_LambdaDisruptor_930\">通过Java 8 Lambda使用Disruptor</a></li>\n      </ul> </li>\n     <li><a href=\"#Disruptor_1011\">构造Disruptor对象的几个要点</a></li>\n     <li><a href=\"#Disruptor_1029\">Disruptor如何实现高性能？</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#DisruptorBlockingQueue_1059\">Disruptor和BlockingQueue比较:</a></li>\n      </ul> </li>\n     <li><a href=\"#Disruptor_Ring_Buffer_1069\">原理：Disruptor 的内部Ring Buffer环形队列</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#RingBuffer_1071\">RingBuffer是什么</a></li>\n       <li><a href=\"#Disruptor_1079\">Disruptor使用环形队列的优势：</a></li>\n      </ul> </li>\n     <li><a href=\"#Disruptor_1111\">关闭Disruptor</a></li>\n    </ul> </li>\n   <li><a href=\"#3Disruptor__1120\">3：Disruptor 的使用场景分析</a></li>\n   <li>\n    <ul>\n     <li><a href=\"#Disruptor__1143\">Disruptor 使用细分场景</a></li>\n     <li><a href=\"#_1160\">单生产者多消费者并行场景</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#ProducerType__1170\">ProducerType 的类型</a></li>\n       <li><a href=\"#_1180\">单生产者多消费者并行场景的参考代码</a></li>\n      </ul> </li>\n     <li><a href=\"#_1200\">多生产者单消费者场景</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#ProducerType__1214\">ProducerType 的类型</a></li>\n       <li><a href=\"#_1226\">多生产者场景的要点</a></li>\n       <li><a href=\"#_1233\">多生产者场景的参考代码</a></li>\n      </ul> </li>\n     <li><a href=\"#_1253\">单生产者多消费者竞争场景</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#disruptor_1269\">disruptor如何设置多个竞争消费者？</a></li>\n       <li><a href=\"#_1306\">演示代码如下:</a></li>\n      </ul> </li>\n     <li><a href=\"#_1322\">多个消费者串行消费场景</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#_1330\">多个消费者串行消费场景案例</a></li>\n       <li><a href=\"#_1338\">执行结果</a></li>\n      </ul> </li>\n     <li><a href=\"#_1344\">菱形方式执行场景</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#_1348\">场景特点</a></li>\n       <li><a href=\"#_1358\">菱形方式执行场景案例</a></li>\n      </ul> </li>\n     <li><a href=\"#_1372\">链式并行执行场景</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#_1374\">场景特点</a></li>\n       <li><a href=\"#_1385\">场景案例</a></li>\n      </ul> </li>\n     <li><a href=\"#_1399\">多组消费者相互隔离场景</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#_1403\">场景特点</a></li>\n       <li><a href=\"#_1414\">场景案例</a></li>\n      </ul> </li>\n     <li><a href=\"#_1426\">多组消费者航道执行模式</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#_1430\">场景特点</a></li>\n       <li><a href=\"#_1439\">场景案例</a></li>\n      </ul> </li>\n     <li><a href=\"#_1457\">六边形执行顺序</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#_1463\">场景特点</a></li>\n       <li><a href=\"#_1475\">参考代码</a></li>\n       <li><a href=\"#_1524\">执行结果</a></li>\n      </ul> </li>\n    </ul> </li>\n   <li><a href=\"#4Disruptor_1530\">4：架构师视角，深入Disruptor源码分析</a></li>\n   <li>\n    <ul>\n     <li><a href=\"#_1534\">核心概念</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#Ring_Buffer_1536\">Ring Buffer</a></li>\n       <li><a href=\"#Sequence_1544\">Sequence</a></li>\n       <li><a href=\"#Sequencer_1556\">Sequencer</a></li>\n       <li><a href=\"#Sequence_Barrier_1564\">Sequence Barrier</a></li>\n       <li><a href=\"#Wait_Strategy_1576\">Wait Strategy</a></li>\n       <li><a href=\"#Event_1580\">Event</a></li>\n       <li><a href=\"#EventProcessor_1586\">EventProcessor</a></li>\n       <li><a href=\"#EventHandler_1594\">EventHandler</a></li>\n       <li><a href=\"#Producer_1598\">Producer</a></li>\n       <li><a href=\"#RingBuffer_1602\">RingBuffer</a></li>\n       <li><a href=\"#Disruptor_1606\">Disruptor</a></li>\n      </ul> </li>\n     <li><a href=\"#Disruptor_1614\">Disruptor的无锁架构</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#_1646\">**如何管理消费者和生产者之间的依赖关系呢？**</a></li>\n       <li><a href=\"#_1654\">如何管理消费者与消费者之间的依赖关系呢？</a></li>\n       <li><a href=\"#_1664\">依赖关系管理的例子</a></li>\n       <li><a href=\"#_1674\">**如何避免未消费事件的写入覆盖呢？**</a></li>\n      </ul> </li>\n     <li><a href=\"#Disruptor_1682\">Disruptor的总体模块架构</a></li>\n     <li><a href=\"#Sequence_1688\">核心类Sequence</a></li>\n     <li><a href=\"#Sequencer_1718\">核心类Sequencer</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#Sequencer__1728\">Sequencer 的实现类</a></li>\n       <li><a href=\"#SingleProducerSequencer_1736\">SingleProducerSequencer</a></li>\n       <li><a href=\"#MultiProducerSequencer_1810\">MultiProducerSequencer</a></li>\n      </ul> </li>\n     <li><a href=\"#__1954\">核心类消费者仓库 和消费者信息</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#_ConsumerRepository_1958\">消费者仓库 ConsumerRepository</a></li>\n       <li><a href=\"#_ConsumerInfo_1986\">消费者的信息 ConsumerInfo</a></li>\n       <li><a href=\"#__1996\">消费者的信息 实现类</a></li>\n       <li><a href=\"#WorkerPoolInfo_2013\">WorkerPoolInfo多线程消费者信息</a></li>\n      </ul> </li>\n     <li><a href=\"#_2033\">消费者处理器</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#BatchEventProcessor_2062\">BatchEventProcessor单线程批处理事件</a></li>\n       <li><a href=\"#EventHandlerGroup_2070\">事件消费者组EventHandlerGroup</a></li>\n      </ul> </li>\n     <li><a href=\"#SequenceBarrier_2192\">SequenceBarrier协调屏障</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#disrutor_2202\">disrutor管理两种依赖关系</a></li>\n       <li><a href=\"#CAS_2217\">消除锁和CAS操作</a></li>\n       <li><a href=\"#SequenceBarrier_2232\">SequenceBarrier的几个方法</a></li>\n       <li><a href=\"#SequenceBarrier_2270\">SequenceBarrier进行依赖消费</a></li>\n       <li><a href=\"#ProcessingSequenceBarrier_2291\">ProcessingSequenceBarrier</a></li>\n      </ul> </li>\n     <li><a href=\"#RingBuffer_2326\">RingBuffer预分配内存</a></li>\n     <li><a href=\"#Disruptor_2353\">Disruptor的等待策略</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#uml_2357\">uml图</a></li>\n       <li><a href=\"#SleepingWaitStrategy_2371\">SleepingWaitStrategy</a></li>\n       <li>\n        <ul>\n         <li><a href=\"#_2387\">源码</a></li>\n        </ul> </li>\n       <li><a href=\"#YieldingWaitStrategy_2501\">YieldingWaitStrategy</a></li>\n       <li>\n        <ul>\n         <li><a href=\"#_2515\">源码</a></li>\n        </ul> </li>\n       <li><a href=\"#BusySpinW4aitStrategy_2591\">BusySpinW4aitStrategy</a></li>\n      </ul> </li>\n     <li><a href=\"#Disruptor__2599\">Disruptor 的缓存行填充</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#RingBuffer__2603\">RingBuffer 的缓存行填充</a></li>\n       <li><a href=\"#Sequence_2630\">Sequence是如何消除伪共享的</a></li>\n      </ul> </li>\n     <li><a href=\"#_2640\">推荐阅读：</a></li>\n     <li><a href=\"#_2674\">参考文献</a></li>\n    </ul> </li>\n  </ul> \n </div> \n <p></p> \n <h1><a id=\"_Disruptor__35\"></a>队列之王 Disruptor 简介</h1> \n <p>Disruptor是英国外汇交易公司LMAX开发的一个高性能队列，研发的初衷是解决内存队列的延迟问题（在性能测试中发现竟然与I/O操作处于同样的数量级）。</p> \n <p>基于Disruptor开发的系统单线程能支撑每秒600万订单，2010年在QCon演讲后，获得了业界关注。</p> \n <p>2011年，企业应用软件专家Martin Fowler专门撰写长文介绍Disruptor。</p> \n <p>2011年，Disruptor还获得了Oracle官方的<strong>Duke大奖</strong>。</p> \n <p>目前，包括Apache Storm、Camel、Log4j 2在内的很多知名项目都应用了Disruptor以获取高性能。</p> \n <p>要深入了解 disruptor ，咱们从 Java的 内置队列开始介绍起。</p> \n <h2><a id=\"Java_49\"></a>Java内置队列的问题</h2> \n <p>介绍Disruptor之前，我们先来看一看常用的线程安全的内置队列有什么问题。</p> \n <p>Java的内置队列如下表所示。</p> \n <table>\n  <thead>\n   <tr>\n    <th align=\"left\">队列</th>\n    <th align=\"left\">有界性</th>\n    <th align=\"left\">锁</th>\n    <th align=\"left\">数据结构</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td align=\"left\">ArrayBlockingQueue</td>\n    <td align=\"left\">bounded</td>\n    <td align=\"left\">加锁</td>\n    <td align=\"left\">arraylist</td>\n   </tr>\n   <tr>\n    <td align=\"left\">LinkedBlockingQueue</td>\n    <td align=\"left\">optionally-bounded</td>\n    <td align=\"left\">加锁</td>\n    <td align=\"left\">linkedlist</td>\n   </tr>\n   <tr>\n    <td align=\"left\">ConcurrentLinkedQueue</td>\n    <td align=\"left\">unbounded</td>\n    <td align=\"left\">无锁</td>\n    <td align=\"left\">linkedlist</td>\n   </tr>\n   <tr>\n    <td align=\"left\">LinkedTransferQueue</td>\n    <td align=\"left\">unbounded</td>\n    <td align=\"left\">无锁</td>\n    <td align=\"left\">linkedlist</td>\n   </tr>\n   <tr>\n    <td align=\"left\">PriorityBlockingQueue</td>\n    <td align=\"left\">unbounded</td>\n    <td align=\"left\">加锁</td>\n    <td align=\"left\">heap</td>\n   </tr>\n   <tr>\n    <td align=\"left\">DelayQueue</td>\n    <td align=\"left\">unbounded</td>\n    <td align=\"left\">加锁</td>\n    <td align=\"left\">heap</td>\n   </tr>\n  </tbody>\n </table> \n <p>队列的底层一般分成三种：数组、链表和堆。</p> \n <p>其中，堆一般情况下是为了实现带有优先级特性的队列，</p> \n <blockquote> \n  <p>暂时不做介绍，后面讲netty 定时任务的时候，再介绍。</p> \n </blockquote> \n <p>从数组和链表两种数据结构来看，两类结构如下：</p> \n <ul>\n  <li>基于数组线程安全的队列，比较典型的是ArrayBlockingQueue，它主要通过加锁的方式来保证线程安全；</li>\n  <li>基于链表的线程安全队列分成LinkedBlockingQueue和ConcurrentLinkedQueue两大类，前者也通过锁的方式来实现线程安全，而后者通过原子变量compare and swap（以下简称“CAS”）这种<strong>无锁方式</strong>来实现的。</li>\n </ul> \n <p>和ConcurrentLinkedQueue一样，上面表格中的LinkedTransferQueue都是通过原子变量compare and swap（以下简称“CAS”）这种不加锁的方式来实现的</p> \n <p>但是，对 volatile类型的变量进行 CAS 操作，存在伪共享问题，</p> \n <h2><a id=\"Disruptor__85\"></a>Disruptor 的使用场景</h2> \n <p>Disruptor 它可以用来作为高性能的有界内存队列， 适用于两大场景：</p> \n <ul>\n  <li>生产者消费者场景</li>\n  <li>发布订阅 场景</li>\n </ul> \n <p>生产者消费者场景。Disruptor的最常用的场景就是“生产者-消费者”场景，对场景的就是“一个生产者、多个消费者”的场景，并且要求顺序处理。</p> \n <blockquote> \n  <p>备注，这里和JCTool 的 MPSC 队列，刚好相反， MPSC 使用于多生产者，单消费者场景</p> \n </blockquote> \n <p>发布订阅 场景：Disruptor也可以认为是观察者模式的一种实现， 实现发布订阅模式。</p> \n <p>当前业界开源组件使用Disruptor的包括Log4j2、Apache Storm等，</p> \n <h1><a id=\"1__106\"></a>1 前置知识：伪共享原理与实操</h1> \n <p>在介绍 无锁框架 disruptor 之前，作为前置的知识，首先给大家介绍 伪共享 原理&amp;性能对比实战 。</p> \n <h2><a id=\"CPU_110\"></a>CPU的结构</h2> \n <p>下图是计算的基本结构。</p> \n <p>L1、L2、L3分别表示一级缓存、二级缓存、三级缓存，越靠近CPU的缓存，速度越快，容量也越小。</p> \n <ul>\n  <li>L1缓存很小但很快，并且紧靠着在使用它的CPU内核；</li>\n  <li>L2大一些，也慢一些，并且仍然只能被一个单独的CPU核使用；</li>\n  <li>L3更大、更慢，并且被单个插槽上的所有CPU核共享；</li>\n  <li>最后是主存，由全部插槽上的所有CPU核共享。</li>\n </ul> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/88925a861ca8ec89508d96e31105d0f0.png\" alt=\"计算机CPU与缓存示意图\"></p> \n <p>级别越小的缓存，越接近CPU， 意味着速度越快且容量越少。</p> \n <p>L1是最接近CPU的，它容量最小**（比如256个字节）**，速度最快，</p> \n <p>每个核上都有一个L1 Cache(准确地说每个核上有两个L1 Cache， 一个存数据 L1d Cache， 一个存指令 L1i Cache)；</p> \n <p>L2 Cache 更大一些**（比如256K个字节）**，速度要慢一些，一般情况下每个核上都有一个独立的L2 Cache；</p> \n <p>二级缓存就是一级缓存的存储器：</p> \n <blockquote> \n  <p>一级缓存制造成本很高因此它的容量有限，二级缓存的作用就是存储那些CPU处理时需要用到、一级缓存又无法存储的数据。</p> \n </blockquote> \n <p>L3 Cache是三级缓存中最大的一级，例如**（比如12MB个字节）**，同时也是最慢的一级，在同一个CPU插槽之间的核共享一个L3 Cache。</p> \n <p>三级缓存和内存可以看作是二级缓存的存储器，它们的容量递增，但<strong>单位制造成本却递减</strong>。</p> \n <p><strong>L3 Cache和L1，L2 Cache有着本质的区别。</strong></p> \n <p>L1和L2 Cache都是每个CPU core独立拥有一个，而L3 Cache是几个Cores共享的，可以认为是一个更小但是更快的内存。</p> \n <h2><a id=\"_cache_line_149\"></a>缓存行 cache line</h2> \n <p>为了提高IO效率，CPU每次从内存读取数据，并不是只读取我们需要计算的数据，而是一批一批去读取的，这一批数据，也叫Cache Line（缓存行）。</p> \n <p>也可以理解为<strong>批量读取，提升性能</strong>。 为啥要一批、一批的读取呢？ <strong>这也满足 空间的局部性原理（具体请参见葵花宝典）。</strong></p> \n <p>从读取的角度来说，缓存，是由缓存行Cache Line组成的。</p> \n <p>所以使用缓存时，并不是一个一个字节使用，而是一行缓存行、一行缓存行这样使用；</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/d220f1dfcc81d38fc4b412ce516fb8d9.jpeg\" alt=\"img\"></p> \n <p>换句话说，CPU存取缓存都是按照一行，为最小单位操作的。并不是按照字节为单位，进行操作的。</p> \n <p>一般而言，读取一行数据时，是将我们需要的数据周围的连续数据一次性全部读取到缓存中。这段连续的数据就称为一个<strong>缓存行</strong>。</p> \n <p>一般一行缓存行有64字节。intel处理器的缓存行是64字节。目前主流的CPU Cache的Cache Line大小都是64Bytes。</p> \n <p>假设我们有一个512 Bytes 的一级缓存，那么按照64 Bytes 的缓存单位大小来算，这个一级缓存所能存放的缓存个数就是512/64 = 8个。</p> \n <p>所以，Cache Line可以简单的理解为CPU Cache中的最小缓存单位。</p> \n <p>这些CPU Cache的写回和加载，都不是以一个变量作为单位。这些都是以整个Cache Line作为单位。</p> \n <p>如果一个常量和变量放在一行，那么变量的更新，也会影响常量的使用：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/3e0b4f29cb02f23dc1d65f663b6c7543.png\" alt=\"并发编程框架Disruptor之高性能设计_缓存_03\"></p> \n <p>CPU在加载数据时，整个缓存行过期了，加载常量的时候，自然也会把这个数据从内存加载到高速缓存。</p> \n <h2><a id=\"_False_Sharing_185\"></a>什么是 伪共享（False Sharing）问题？</h2> \n <blockquote> \n  <p>提前说明： 翻译 有瑕疵， 伪共享（False Sharing）， 应该翻译为 “错共享”， 才更准确</p> \n </blockquote> \n <p>CPU的缓存系统是以缓存行(cache line)为单位存储的，一般的大小为64bytes。</p> \n <p>在多线程程序的执行过程中，存在着一种情况，多个需要频繁修改的变量存在同一个缓存行当中。</p> \n <blockquote> \n  <p>假设：有两个线程分别访问并修改X和Y这两个变量，X和Y恰好在同一个缓存行上，这两个线程分别在不同的CPU上执行。</p> \n  <p>那么每个CPU分别更新好X和Y时将缓存行刷入内存时，发现有别的修改了各自缓存行内的数据，这时缓存行会失效，从L3中重新获取。</p> \n  <p>这样的话，程序执行效率明显下降。</p> \n </blockquote> \n <p>为了减少这种情况的发生，其实就是避免X和Y在同一个缓存行中，</p> \n <blockquote> \n  <p>如何操作呢？可以主动添加一些无关变量将缓存行填充满，</p> \n </blockquote> \n <p>比如在X对象中添加一些变量，让它有64 Byte那么大，正好占满一个缓存行。</p> \n <p><img src=\"https://img-blog.csdn.net/20160602150616280\" alt=\"img\"></p> \n <p>两个线程（Thread1 和 Thread2）同时修改一个同一个缓存行上的数据 X Y:</p> \n <p>如果线程1打算更改a的值，而线程2准备更改b的值：</p> \n <pre><code class=\"prism language-undefined\">Thread1：x=3;\n\nThread2：y=2;\n</code></pre> \n <p>由x值被更新了，所以x值需要在线程1和线程2之间传递（从线程1到线程2），</p> \n <blockquote> \n  <p>x、y的变更，都会引起 cache line 整块 64 bytes 被刷新，因为cpu核之间以cache line的形式交换数据(cache lines的大小一般为64bytes)。</p> \n </blockquote> \n <p>在并发执行的场景下，每个线程在不同的核中被处理。</p> \n <blockquote> \n  <p>假设 x,y是两个频繁修改的变量，x,y，还位于同一个缓存行.</p> \n </blockquote> \n <p>如果，CPU1修改了变量x时，L3中的缓存行数据就失效了，也就是CPU2中的缓存行数据也失效了，CPU2需要的y需要重新从内存加载。</p> \n <p>如果，CPU2修改了变量y时，L3中的缓存行数据就失效了，也就是CPU1中的缓存行数据也失效了，CPU1需要的x需要重新从内存加载。</p> \n <blockquote> \n  <p>x,y在两个cpu上进行修改，本来应该是互不影响的，但是由于缓存行在一起，导致了相互受到了影响。</p> \n </blockquote> \n <h2><a id=\"False_Sharing_237\"></a>伪共享问题（False Sharing）的本质</h2> \n <p>出现伪共享问题（False Sharing）的原因：</p> \n <ul>\n  <li>一个缓存行可以存储多个变量（存满当前缓存行的字节数）；64个字节可以放8个long，16个int</li>\n  <li>而CPU对缓存的修改又是以缓存行为最小单位的； 不是以long 、byte这样的数据类型为单位的</li>\n  <li>在多线程情况下，如果需要修改“共享同一个缓存行的其中一个变量”，该行中其他变量的状态 就会失效，甚至进行一致性保护</li>\n </ul> \n <p>所以，伪共享问题（False Sharing）的本质是：</p> \n <p><strong>对缓存行中的单个变量进行修改了，导致整个缓存行其他不相关的数据也就失效了，需要从主存重新加载</strong></p> \n <p><strong>如果 其中有 volatile 修饰的变量，需要保证线程可见性的变量，还需要进入 缓存与数据一致性的保障流程， 如mesi协议的数据一致性保障 用了其他变量的 Core的缓存一致性。</strong></p> \n <p>缓存一致性是根据缓存行为单元来进行同步的，假如 y是 volatile 类型的，假如a修改了x，而其他的线程用到y，虽然用到的不是同一个数据，但是他们（数据X和数据Y）在同一个缓存行中，其他的线程的缓存需要保障数据一致性而进行数据同步，当然，同步也需要时间。</p> \n <p>一个CPU核心在加载一个缓存行时要执行上百条指令。如果一个核心要等待另外一个核心来重新加载缓存行，那么他就必须等在那里，称之为<code>stall</code>(停止运转)。</p> \n <h2><a id=\"__257\"></a>伪共享问题 的解决方案</h2> \n <p>减少伪共享也就意味着减少了<code>stall</code>的发生，其中一个手段就是通过填充(Padding)数据的形式，来保证本应有可能位于同一个缓存行的两个变量，在被多线程访问时必定位于不同的缓存行。</p> \n <p>简单的说，就是 以<strong>空间换时间</strong>： 使用占位字节，将变量的所在的 缓冲行 塞满。</p> \n <p>disruptor 无锁框架就是这么干的。</p> \n <h2><a id=\"_271\"></a>一个缓冲行填充的例子</h2> \n <p>下面是一个填充了的缓存行的，尝试 p1, p2, p3, p4, p5, p6为AtomicLong的value的缓存行占位，将AtomicLong的value变量的所在的 缓冲行 塞满，</p> \n <p>代码如下:</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>crazymakercircle<span class=\"token punctuation\">.</span>demo<span class=\"token punctuation\">.</span>cas</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token import\"><span class=\"token namespace\">java<span class=\"token punctuation\">.</span>util<span class=\"token punctuation\">.</span>concurrent<span class=\"token punctuation\">.</span>atomic<span class=\"token punctuation\">.</span></span><span class=\"token class-name\">AtomicLong</span></span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">PaddedAtomicLong</span> <span class=\"token keyword\">extends</span> <span class=\"token class-name\">AtomicLong</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">long</span> serialVersionUID <span class=\"token operator\">=</span> <span class=\"token operator\">-</span><span class=\"token number\">3415778863941386253L</span><span class=\"token punctuation\">;</span>\n\n    <span class=\"token comment\">/** * Padded 6 long (48 bytes) */</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">volatile</span> <span class=\"token keyword\">long</span> p1<span class=\"token punctuation\">,</span> p2<span class=\"token punctuation\">,</span> p3<span class=\"token punctuation\">,</span> p4<span class=\"token punctuation\">,</span> p5<span class=\"token punctuation\">,</span> p6 <span class=\"token operator\">=</span> <span class=\"token number\">7L</span><span class=\"token punctuation\">;</span>\n\n    <span class=\"token comment\">/** * Constructors from {@link AtomicLong} */</span>\n    <span class=\"token keyword\">public</span> <span class=\"token class-name\">PaddedAtomicLong</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token keyword\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token keyword\">public</span> <span class=\"token class-name\">PaddedAtomicLong</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">long</span> initialValue<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token keyword\">super</span><span class=\"token punctuation\">(</span>initialValue<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\">/** * To prevent GC optimizations for cleaning unused padded references */</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">long</span> <span class=\"token function\">sumPaddingToPreventOptimization</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token keyword\">return</span> p1 <span class=\"token operator\">+</span> p2 <span class=\"token operator\">+</span> p3 <span class=\"token operator\">+</span> p4 <span class=\"token operator\">+</span> p5 <span class=\"token operator\">+</span> p6<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>例子的部分结果如下：</p> \n <pre><code class=\"prism language-csharp\">printable <span class=\"token operator\">=</span> com<span class=\"token punctuation\">.</span>crazymakercircle<span class=\"token punctuation\">.</span>basic<span class=\"token punctuation\">.</span>demo<span class=\"token punctuation\">.</span>cas<span class=\"token punctuation\">.</span>busi<span class=\"token punctuation\">.</span>PaddedAtomicLong <span class=\"token class-name\"><span class=\"token keyword\">object</span></span> internals<span class=\"token punctuation\">:</span>\n OFFSET  SIZE   TYPE DESCRIPTION                               VALUE\n      <span class=\"token number\">0</span>     <span class=\"token number\">4</span>        <span class=\"token punctuation\">(</span><span class=\"token class-name\"><span class=\"token keyword\">object</span></span> header<span class=\"token punctuation\">)</span>                           <span class=\"token number\">01</span> <span class=\"token number\">00</span> <span class=\"token number\">00</span> <span class=\"token number\">00</span> <span class=\"token punctuation\">(</span><span class=\"token number\">00000001</span> <span class=\"token number\">00000000</span> <span class=\"token number\">00000000</span> <span class=\"token number\">00000000</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n      <span class=\"token number\">4</span>     <span class=\"token number\">4</span>        <span class=\"token punctuation\">(</span><span class=\"token class-name\"><span class=\"token keyword\">object</span></span> header<span class=\"token punctuation\">)</span>                           <span class=\"token number\">00</span> <span class=\"token number\">00</span> <span class=\"token number\">00</span> <span class=\"token number\">00</span> <span class=\"token punctuation\">(</span><span class=\"token number\">00000000</span> <span class=\"token number\">00000000</span> <span class=\"token number\">00000000</span> <span class=\"token number\">00000000</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n      <span class=\"token number\">8</span>     <span class=\"token number\">4</span>        <span class=\"token punctuation\">(</span><span class=\"token class-name\"><span class=\"token keyword\">object</span></span> header<span class=\"token punctuation\">)</span>                           <span class=\"token number\">50</span> <span class=\"token number\">08</span> <span class=\"token number\">01</span> f8 <span class=\"token punctuation\">(</span><span class=\"token number\">01010000</span> <span class=\"token number\">00001000</span> <span class=\"token number\">00000001</span> <span class=\"token number\">11111000</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">134150064</span><span class=\"token punctuation\">)</span>\n     <span class=\"token number\">12</span>     <span class=\"token number\">4</span>        <span class=\"token punctuation\">(</span>alignment<span class=\"token operator\">/</span><span class=\"token class-name\">padding</span> gap<span class=\"token punctuation\">)</span>                  \n     <span class=\"token number\">16</span>     <span class=\"token number\">8</span>   <span class=\"token keyword\">long</span> AtomicLong<span class=\"token punctuation\">.</span><span class=\"token keyword\">value</span>                          <span class=\"token number\">0</span>\n     <span class=\"token number\">24</span>     <span class=\"token number\">8</span>   <span class=\"token keyword\">long</span> PaddedAtomicLong<span class=\"token punctuation\">.</span>p1                       <span class=\"token number\">0</span>\n     <span class=\"token number\">32</span>     <span class=\"token number\">8</span>   <span class=\"token keyword\">long</span> PaddedAtomicLong<span class=\"token punctuation\">.</span>p2                       <span class=\"token number\">0</span>\n     <span class=\"token number\">40</span>     <span class=\"token number\">8</span>   <span class=\"token keyword\">long</span> PaddedAtomicLong<span class=\"token punctuation\">.</span>p3                       <span class=\"token number\">0</span>\n     <span class=\"token number\">48</span>     <span class=\"token number\">8</span>   <span class=\"token keyword\">long</span> PaddedAtomicLong<span class=\"token punctuation\">.</span>p4                       <span class=\"token number\">0</span>\n     <span class=\"token number\">56</span>     <span class=\"token number\">8</span>   <span class=\"token keyword\">long</span> PaddedAtomicLong<span class=\"token punctuation\">.</span>p5                       <span class=\"token number\">0</span>\n     <span class=\"token number\">64</span>     <span class=\"token number\">8</span>   <span class=\"token keyword\">long</span> PaddedAtomicLong<span class=\"token punctuation\">.</span>p6                       <span class=\"token number\">7</span>\n\n<span class=\"token class-name\">Instance</span> size<span class=\"token punctuation\">:</span> <span class=\"token number\">72</span> bytes\n<span class=\"token class-name\">Space</span> losses<span class=\"token punctuation\">:</span> <span class=\"token number\">4</span> bytes <span class=\"token keyword\">internal</span> <span class=\"token operator\">+</span> <span class=\"token number\">0</span> <span class=\"token class-name\">bytes</span> external <span class=\"token operator\">=</span> <span class=\"token number\">4</span> bytes total\n</code></pre> \n <h2><a id=\"False_Sharingjava_8_334\"></a>伪共享False Sharing在java 8中解决方案</h2> \n <p>JAVA 8中添加了一个@Contended的注解，添加这个的注解，将会在自动进行缓存行填充。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/17ef447b0d3e4c59985f35ca48018978.png\" alt=\"在这里插入图片描述\"></p> \n <p>下面有一个@Contended的例子：</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>crazymakercircle<span class=\"token punctuation\">.</span>basic<span class=\"token punctuation\">.</span>demo<span class=\"token punctuation\">.</span>cas<span class=\"token punctuation\">.</span>busi</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">import</span> <span class=\"token import\"><span class=\"token namespace\">sun<span class=\"token punctuation\">.</span>misc<span class=\"token punctuation\">.</span></span><span class=\"token class-name\">Contended</span></span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">ContendedDemo</span>\n<span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token comment\">//有填充的演示成员</span>\n    <span class=\"token annotation punctuation\">@Contended</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">volatile</span> <span class=\"token keyword\">long</span> padVar<span class=\"token punctuation\">;</span>\n\n    <span class=\"token comment\">//没有填充的演示成员</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">volatile</span> <span class=\"token keyword\">long</span> notPadVar<span class=\"token punctuation\">;</span>\n\n\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>以上代码使得padVar和notPadVar都在不同的cache line中。@Contended 使得notPadVar字段远离了对象头部分。</p> \n <pre><code class=\"prism language-python\">printable <span class=\"token operator\">=</span> com<span class=\"token punctuation\">.</span>crazymakercircle<span class=\"token punctuation\">.</span>basic<span class=\"token punctuation\">.</span>demo<span class=\"token punctuation\">.</span>cas<span class=\"token punctuation\">.</span>busi<span class=\"token punctuation\">.</span>ContendedDemo <span class=\"token builtin\">object</span> internals<span class=\"token punctuation\">:</span>\n OFFSET  SIZE   TYPE DESCRIPTION               VALUE\n      <span class=\"token number\">0</span>     <span class=\"token number\">4</span>        <span class=\"token punctuation\">(</span><span class=\"token builtin\">object</span> header<span class=\"token punctuation\">)</span>           <span class=\"token number\">01</span> <span class=\"token number\">00</span> <span class=\"token number\">00</span> <span class=\"token number\">00</span> <span class=\"token punctuation\">(</span><span class=\"token number\">00000001</span> <span class=\"token number\">00000000</span> <span class=\"token number\">00000000</span> <span class=\"token number\">00000000</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n      <span class=\"token number\">4</span>     <span class=\"token number\">4</span>        <span class=\"token punctuation\">(</span><span class=\"token builtin\">object</span> header<span class=\"token punctuation\">)</span>           <span class=\"token number\">00</span> <span class=\"token number\">00</span> <span class=\"token number\">00</span> <span class=\"token number\">00</span> <span class=\"token punctuation\">(</span><span class=\"token number\">00000000</span> <span class=\"token number\">00000000</span> <span class=\"token number\">00000000</span> <span class=\"token number\">00000000</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n      <span class=\"token number\">8</span>     <span class=\"token number\">4</span>        <span class=\"token punctuation\">(</span><span class=\"token builtin\">object</span> header<span class=\"token punctuation\">)</span>           <span class=\"token number\">50</span> <span class=\"token number\">08</span> <span class=\"token number\">01</span> f8 <span class=\"token punctuation\">(</span><span class=\"token number\">01010000</span> <span class=\"token number\">00001000</span> <span class=\"token number\">00000001</span> <span class=\"token number\">11111000</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">134150064</span><span class=\"token punctuation\">)</span>\n     <span class=\"token number\">12</span>     <span class=\"token number\">4</span>        <span class=\"token punctuation\">(</span>alignment<span class=\"token operator\">/</span>padding gap<span class=\"token punctuation\">)</span>  \n     <span class=\"token number\">16</span>     <span class=\"token number\">8</span>   <span class=\"token builtin\">long</span> ContendedDemo<span class=\"token punctuation\">.</span>padVar      <span class=\"token number\">0</span>\n     <span class=\"token number\">24</span>     <span class=\"token number\">8</span>   <span class=\"token builtin\">long</span> ContendedDemo<span class=\"token punctuation\">.</span>notPadVar   <span class=\"token number\">0</span>\nInstance size<span class=\"token punctuation\">:</span> <span class=\"token number\">32</span> <span class=\"token builtin\">bytes</span>\nSpace losses<span class=\"token punctuation\">:</span> <span class=\"token number\">4</span> <span class=\"token builtin\">bytes</span> internal <span class=\"token operator\">+</span> <span class=\"token number\">0</span> <span class=\"token builtin\">bytes</span> external <span class=\"token operator\">=</span> <span class=\"token number\">4</span> <span class=\"token builtin\">bytes</span> total\n</code></pre> \n <p>执行时，必须加上虚拟机参数-XX:-RestrictContended，@Contended注释才会生效。</p> \n <p>很多文章把这个漏掉了，那样的话实际上就没有起作用。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/202011011215086.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70#pic_center\" alt=\"在这里插入图片描述\"></p> \n <p>新的结果；</p> \n <pre><code class=\"prism language-python\">printable <span class=\"token operator\">=</span> com<span class=\"token punctuation\">.</span>crazymakercircle<span class=\"token punctuation\">.</span>basic<span class=\"token punctuation\">.</span>demo<span class=\"token punctuation\">.</span>cas<span class=\"token punctuation\">.</span>busi<span class=\"token punctuation\">.</span>ContendedDemo <span class=\"token builtin\">object</span> internals<span class=\"token punctuation\">:</span>\n OFFSET  SIZE   TYPE DESCRIPTION               VALUE\n      <span class=\"token number\">0</span>     <span class=\"token number\">4</span>        <span class=\"token punctuation\">(</span><span class=\"token builtin\">object</span> header<span class=\"token punctuation\">)</span>           <span class=\"token number\">01</span> <span class=\"token number\">00</span> <span class=\"token number\">00</span> <span class=\"token number\">00</span> <span class=\"token punctuation\">(</span><span class=\"token number\">00000001</span> <span class=\"token number\">00000000</span> <span class=\"token number\">00000000</span> <span class=\"token number\">00000000</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n      <span class=\"token number\">4</span>     <span class=\"token number\">4</span>        <span class=\"token punctuation\">(</span><span class=\"token builtin\">object</span> header<span class=\"token punctuation\">)</span>           <span class=\"token number\">00</span> <span class=\"token number\">00</span> <span class=\"token number\">00</span> <span class=\"token number\">00</span> <span class=\"token punctuation\">(</span><span class=\"token number\">00000000</span> <span class=\"token number\">00000000</span> <span class=\"token number\">00000000</span> <span class=\"token number\">00000000</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n      <span class=\"token number\">8</span>     <span class=\"token number\">4</span>        <span class=\"token punctuation\">(</span><span class=\"token builtin\">object</span> header<span class=\"token punctuation\">)</span>           <span class=\"token number\">50</span> <span class=\"token number\">08</span> <span class=\"token number\">01</span> f8 <span class=\"token punctuation\">(</span><span class=\"token number\">01010000</span> <span class=\"token number\">00001000</span> <span class=\"token number\">00000001</span> <span class=\"token number\">11111000</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">134150064</span><span class=\"token punctuation\">)</span>\n     <span class=\"token number\">12</span>     <span class=\"token number\">4</span>        <span class=\"token punctuation\">(</span>alignment<span class=\"token operator\">/</span>padding gap<span class=\"token punctuation\">)</span>  \n     <span class=\"token number\">16</span>     <span class=\"token number\">8</span>   <span class=\"token builtin\">long</span> ContendedDemo<span class=\"token punctuation\">.</span>notPadVar   <span class=\"token number\">0</span>\n     <span class=\"token number\">24</span>   <span class=\"token number\">128</span>        <span class=\"token punctuation\">(</span>alignment<span class=\"token operator\">/</span>padding gap<span class=\"token punctuation\">)</span>  \n    <span class=\"token number\">152</span>     <span class=\"token number\">8</span>   <span class=\"token builtin\">long</span> ContendedDemo<span class=\"token punctuation\">.</span>padVar      <span class=\"token number\">0</span>\n    <span class=\"token number\">160</span>   <span class=\"token number\">128</span>        <span class=\"token punctuation\">(</span>loss due to the <span class=\"token builtin\">next</span> <span class=\"token builtin\">object</span> alignment<span class=\"token punctuation\">)</span>\nInstance size<span class=\"token punctuation\">:</span> <span class=\"token number\">288</span> <span class=\"token builtin\">bytes</span>\nSpace losses<span class=\"token punctuation\">:</span> <span class=\"token number\">132</span> <span class=\"token builtin\">bytes</span> internal <span class=\"token operator\">+</span> <span class=\"token number\">128</span> <span class=\"token builtin\">bytes</span> external <span class=\"token operator\">=</span> <span class=\"token number\">260</span> <span class=\"token builtin\">bytes</span> total\n</code></pre> \n <p>在Java 8中，使用@Contended注解的对象或字段的前后各增加128字节大小的padding，使用2倍于大多数硬件缓存行的大小来避免相邻扇区预取导致的伪共享冲突。我们目前的缓存行大小一般为64Byte，这里Contended注解为我们前后加上了128字节绰绰有余。</p> \n <blockquote> \n  <p>注意：如果想要@Contended注解起作用，需要在启动时添加JVM参数-XX:-RestrictContended 参数后 @sun.misc.Contended 注解才有。</p> \n </blockquote> \n <p>可见至少在JDK1.8以上环境下， 只有@Contended注解才能解决伪共享问题， 但是消耗也很大， 占用了宝贵的缓存， 用的时候要谨慎。</p> \n <p>另外：</p> \n <blockquote> \n  <p>@Contended 注释还可以添加在类上，每一个成员，都会加上。</p> \n </blockquote> \n <h2><a id=\"6_419\"></a>伪共享性能比对实操：结论，差6倍</h2> \n <p>三个实操：</p> \n <ul>\n  <li>首先存在伪共享场景下的 耗时计算</li>\n  <li>其次是消除伪共享场景下的 耗时计算</li>\n  <li>再次是使用unsafe访问变量时的耗时计算</li>\n </ul> \n <h3><a id=\"__429\"></a>存在伪共享场景下的 耗时计算</h3> \n <p>entity类</p> \n <p><img src=\"https://img-blog.csdnimg.cn/902f78f81c9d485fbc61e4b0199d1809.png\" alt=\"在这里插入图片描述\"></p> \n <p>并行的执行数据修改，<strong>这里抽取成为了一个通用的方法</strong></p> \n <p><img src=\"https://img-blog.csdnimg.cn/86cd8a33a83248c3a0750ea55728ffbd.png\" alt=\"在这里插入图片描述\"></p> \n <p>测试用例</p> \n <p><img src=\"https://img-blog.csdnimg.cn/3f84b7b8804e4585ab55f0900f563d5e.png\" alt=\"在这里插入图片描述\"></p> \n <p>执行的时间</p> \n <p><img src=\"https://img-blog.csdnimg.cn/76d667cc6e8e4d3bbc0b01876bf970df.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"__459\"></a>消除伪共享场景下的 耗时计算</h3> \n <p>entity类</p> \n <p><img src=\"https://img-blog.csdnimg.cn/15db0c4b9bab494f990d29e0d4ca746c.png\" alt=\"在这里插入图片描述\"></p> \n <p>测试用例</p> \n <p><img src=\"https://img-blog.csdnimg.cn/3f84b7b8804e4585ab55f0900f563d5e.png\" alt=\"在这里插入图片描述\"></p> \n <p>消除伪共享场景下的 耗时计算 （550ms）</p> \n <p><img src=\"https://img-blog.csdnimg.cn/819faef41871408eb3f7df4e1bb540e8.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"unsafe_487\"></a>使用unsafe访问变量的耗时计算</h3> \n <p>entity</p> \n <p><img src=\"https://img-blog.csdnimg.cn/d2826b8b3a954e2dad241cf366f8a703.png\" alt=\"在这里插入图片描述\"></p> \n <p><img src=\"https://img-blog.csdnimg.cn/df7241d955bb4a729d91ff40b2a1a250.png\" alt=\"在这里插入图片描述\"></p> \n <p>使用unsafe访问变量的耗时计算:</p> \n <p><strong>54ms</strong></p> \n <h3><a id=\"_509\"></a>性能总结</h3> \n <p><strong>消除伪共享场景 ，比存在伪共享场景 的性能 ， 性能提升 6倍左右</strong></p> \n <blockquote> \n  <p>实验数据，从 3000ms 提升 到 500ms</p> \n </blockquote> \n <p><strong>使用 unsafe 取消内存可见性，比消除伪共享场景 ，性能提升 10 倍左右</strong></p> \n <blockquote> \n  <p>实验数据，从 500ms 提升 到 50ms</p> \n </blockquote> \n <p>通过实验的对比， 可见Java 的性能，是可以大大优化的，尤其在高性能组件</p> \n <blockquote> \n  <p>以上实操的 详细介绍 ，请参见 《100wqps 日志平台实操》</p> \n </blockquote> \n <h2><a id=\"JDK__533\"></a>JDK源码中如何解决 伪共享问题</h2> \n <p>在LongAdder在java8中的实现已经采用了@Contended。</p> \n <h3><a id=\"LongAdder_Striped64_539\"></a>LongAdder以及 Striped64如何解决伪共享问题</h3> \n <p>LongAdder是大家常用的 高并发累加器</p> \n <p>通过分而治之的思想，实现 超高并发累加。</p> \n <p>LongAdder的 结构如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/a59a6a9dfa1547ecb4006aee042ffae3.png\" alt=\"在这里插入图片描述\"></p> \n <p>Striped64是在java8中添加用来支持累加器的并发组件，它可以在并发环境下使用来做某种计数，</p> \n <p>Striped64的设计思路是在竞争激烈的时候尽量分散竞争，</p> \n <p>Striped64维护了一个base Count和一个Cell数组，计数线程会首先试图更新base变量，如果成功则退出计数，否则会认为当前竞争是很激烈的，那么就会通过Cell数组来分散计数，</p> \n <p>Striped64根据线程来计算哈希，然后将不同的线程分散到不同的Cell数组的index上，然后这个线程的计数内容就会保存在该Cell的位置上面，</p> \n <p>基于这种设计，最后的总计数需要结合base以及散落在Cell数组中的计数内容。</p> \n <p>这种设计思路类似于java7的ConcurrentHashMap实现，也就是所谓的分段锁算法，ConcurrentHashMap会将记录根据key的hashCode来分散到不同的segment上，</p> \n <p>线程想要操作某个记录，只需要锁住这个记录对应着的segment就可以了，而其他segment并不会被锁住，其他线程任然可以去操作其他的segment，</p> \n <p>这样就显著提高了并发度，</p> \n <p>虽然如此，java8中的ConcurrentHashMap实现已经抛弃了java7中分段锁的设计，而采用更为轻量级的CAS来协调并发，效率更佳。</p> \n <h3><a id=\"Cell_571\"></a>Cell元素如何消除伪共享</h3> \n <p>Striped64 中的Cell元素，是如何消除伪共享的呢？</p> \n <p><img src=\"https://img-blog.csdnimg.cn/f52db3f4e2f44224bf531062c80752d2.png\" alt=\"在这里插入图片描述\"></p> \n <p>可以打印一下 cell的 内存结构</p> \n <p><img src=\"https://img-blog.csdnimg.cn/1d51006eeca84ef1832d75b07d598eb3.png\" alt=\"在这里插入图片描述\"></p> \n <p>当然，别忘记加上 vm 选项：-XX:-RestrictContended</p> \n <p><img src=\"https://img-blog.csdnimg.cn/a58a3ba807c642458b7b903e84e4cd38.png\" alt=\"在这里插入图片描述\"></p> \n <h2><a id=\"_587\"></a>对于伪共享，我们在实际开发中该怎么做？</h2> \n <p>通过上面大篇幅的介绍，我们已经知道伪共享的对程序的影响。</p> \n <p>那么，在实际的生产开发过程中，我们一定要通过缓存行填充去解决掉潜在的伪共享问题吗？</p> \n <p>其实并不一定。</p> \n <p>首先就是多次强调的，伪共享是很隐蔽的，我们暂时无法从系统层面上通过工具来探测伪共享事件。</p> \n <p>其次，不同类型的计算机具有不同的微架构（如 32 位系统和 64 位系统的 java 对象所占自己数就不一样），如果设计到跨平台的设计，那就更难以把握了，一个确切的填充方案只适用于一个特定的操作系统。</p> \n <p>还有，缓存的资源是有限的，如果填充会浪费珍贵的 cache 资源，并不适合大范围应用。</p> \n <h2><a id=\"3_Disruptor_607\"></a>3 Disruptor框架是如何解决伪共享问题的？</h2> \n <p>在Disruptor中有一个重要的类Sequence，该类包装了一个volatile修饰的long类型数据value，</p> \n <h3><a id=\"Sequence_613\"></a>Sequence的结构和源码</h3> \n <p>无论是Disruptor中的基于数组实现的缓冲区RingBuffer，还是生产者，消费者，都有各自独立的Sequence，</p> \n <p>Sequence的用途是啥呢？</p> \n <ul>\n  <li>在RingBuffer缓冲区中，Sequence标示着写入进度，例如每次生产者要写入数据进缓冲区时，都要调用RingBuffer.next（）来获得下一个可使用的相对位置。</li>\n  <li>对于生产者和消费者来说，Sequence标示着它们的事件序号。</li>\n </ul> \n <p>Sequence的结构图如下</p> \n <p><img src=\"https://img-blog.csdnimg.cn/6ec91a2aaeb2421886aead2c3d6133c1.png\" alt=\"在这里插入图片描述\"></p> \n <p>来看看Sequence类的源码：</p> \n <pre><code class=\"prism language-java\">  <span class=\"token keyword\">class</span> <span class=\"token class-name\">LhsPadding</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n	<span class=\"token keyword\">protected</span> <span class=\"token keyword\">long</span> p1<span class=\"token punctuation\">,</span> p2<span class=\"token punctuation\">,</span> p3<span class=\"token punctuation\">,</span> p4<span class=\"token punctuation\">,</span> p5<span class=\"token punctuation\">,</span> p6<span class=\"token punctuation\">,</span> p7<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Value</span> <span class=\"token keyword\">extends</span> <span class=\"token class-name\">LhsPadding</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n	<span class=\"token keyword\">protected</span> <span class=\"token keyword\">volatile</span> <span class=\"token keyword\">long</span> value<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">RhsPadding</span> <span class=\"token keyword\">extends</span> <span class=\"token class-name\">Value</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n	<span class=\"token keyword\">protected</span> <span class=\"token keyword\">long</span> p9<span class=\"token punctuation\">,</span> p10<span class=\"token punctuation\">,</span> p11<span class=\"token punctuation\">,</span> p12<span class=\"token punctuation\">,</span> p13<span class=\"token punctuation\">,</span> p14<span class=\"token punctuation\">,</span> p15<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">Sequence</span> <span class=\"token keyword\">extends</span> <span class=\"token class-name\">RhsPadding</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n	<span class=\"token keyword\">static</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">long</span> <span class=\"token constant\">INITIAL_VALUE</span> <span class=\"token operator\">=</span> <span class=\"token operator\">-</span><span class=\"token number\">1L</span><span class=\"token punctuation\">;</span>\n	<span class=\"token keyword\">private</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">final</span> <span class=\"token class-name\">Unsafe</span> <span class=\"token constant\">UNSAFE</span><span class=\"token punctuation\">;</span>\n	<span class=\"token keyword\">private</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">long</span> <span class=\"token constant\">VALUE_OFFSET</span><span class=\"token punctuation\">;</span>\n	<span class=\"token keyword\">static</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n		<span class=\"token constant\">UNSAFE</span> <span class=\"token operator\">=</span> <span class=\"token class-name\">Util</span><span class=\"token punctuation\">.</span><span class=\"token function\">getUnsafe</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n		<span class=\"token keyword\">try</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n			<span class=\"token constant\">VALUE_OFFSET</span> <span class=\"token operator\">=</span> <span class=\"token constant\">UNSAFE</span><span class=\"token punctuation\">.</span><span class=\"token function\">objectFieldOffset</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">Value</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span><span class=\"token punctuation\">.</span><span class=\"token function\">getDeclaredField</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"value\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n		<span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">final</span> <span class=\"token class-name\">Exception</span> e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n			 <span class=\"token keyword\">throw</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">RuntimeException</span><span class=\"token punctuation\">(</span>e<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n		<span class=\"token punctuation\">}</span>\n	<span class=\"token punctuation\">}</span>\n	\n\n\n<span class=\"token keyword\">public</span> <span class=\"token class-name\">Sequence</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n	<span class=\"token keyword\">this</span><span class=\"token punctuation\">(</span><span class=\"token constant\">INITIAL_VALUE</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">public</span> <span class=\"token class-name\">Sequence</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">final</span> <span class=\"token keyword\">long</span> initialValue<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n	<span class=\"token constant\">UNSAFE</span><span class=\"token punctuation\">.</span><span class=\"token function\">putOrderedLong</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">this</span><span class=\"token punctuation\">,</span> <span class=\"token constant\">VALUE_OFFSET</span><span class=\"token punctuation\">,</span> initialValue<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h1><a id=\"2Disruptor___683\"></a>2：Disruptor 的 使用实战</h1> \n <p>我们从一个简单的例子开始学习Disruptor：</p> \n <p>生产者传递一个long类型的值给消费者，而消费者消费这个数据的方式仅仅是把它打印出来。</p> \n <h3><a id=\"Event_689\"></a>定义一个Event和工厂</h3> \n <p>首先定义一个Event来包含需要传递的数据：</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">LongEvent</span> <span class=\"token punctuation\">{\n    <!-- --></span> \n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">long</span> value<span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">long</span> <span class=\"token function\">getValue</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span> \n        <span class=\"token keyword\">return</span> value<span class=\"token punctuation\">;</span> \n    <span class=\"token punctuation\">}</span> \n \n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">setValue</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">long</span> value<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span> \n        <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>value <span class=\"token operator\">=</span> value<span class=\"token punctuation\">;</span> \n    <span class=\"token punctuation\">}</span> \n<span class=\"token punctuation\">}</span> \n</code></pre> \n <p>由于需要让Disruptor为我们创建事件，我们同时还声明了一个EventFactory来创建Event对象。</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">LongEventFactory</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">EventFactory</span> <span class=\"token punctuation\">{\n    <!-- --></span> \n    <span class=\"token annotation punctuation\">@Override</span> \n    <span class=\"token keyword\">public</span> <span class=\"token class-name\">Object</span> <span class=\"token function\">newInstance</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span> \n        <span class=\"token keyword\">return</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">LongEvent</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n    <span class=\"token punctuation\">}</span> \n<span class=\"token punctuation\">}</span> \n</code></pre> \n <h3><a id=\"_717\"></a>定义事件处理器（消费者）</h3> \n <p>我们还需要一个事件消费者，也就是一个事件处理器。</p> \n <p>这个例子中，事件处理器的工作，就是简单地把事件中存储的数据打印到终端：</p> \n <pre><code class=\"prism language-java\">    <span class=\"token comment\">/** * 类似于消费者 * disruptor会回调此处理器的方法 */</span>\n    <span class=\"token keyword\">static</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">LongEventHandler</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">EventHandler</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">LongEvent</span><span class=\"token punctuation\">&gt;</span></span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token annotation punctuation\">@Override</span>\n        <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">onEvent</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">LongEvent</span> longEvent<span class=\"token punctuation\">,</span> <span class=\"token keyword\">long</span> l<span class=\"token punctuation\">,</span> <span class=\"token keyword\">boolean</span> b<span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> <span class=\"token class-name\">Exception</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n            <span class=\"token class-name\">System</span><span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span>longEvent<span class=\"token punctuation\">.</span><span class=\"token function\">getValue</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n</code></pre> \n <p>disruptor会回调此处理器的方法</p> \n <h3><a id=\"_738\"></a>定义事件源(生产者)</h3> \n <p>事件都会有一个生成事件的源，类似于 生产者的角色，</p> \n <p>如何产生事件，然后发出事件呢？</p> \n <p>通过从 环形队列中 获取 序号， 通过序号获取 对应的 事件对象， 将数据填充到 事件对象，再通过 序号将 事件对象 发布出去。</p> \n <p>一段生产者的代码如下：</p> \n <pre><code class=\"prism language-java\">    <span class=\"token comment\">// 事件生产者：业务代码</span>\n    <span class=\"token comment\">// 通过从 环形队列中 获取 序号， 通过序号获取 对应的 事件对象， 将数据填充到 事件对象，再通过 序号将 事件对象 发布出去。</span>\n    <span class=\"token keyword\">static</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">LongEventProducer</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> <span class=\"token class-name\">RingBuffer</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">LongEvent</span><span class=\"token punctuation\">&gt;</span></span> ringBuffer<span class=\"token punctuation\">;</span>\n\n        <span class=\"token keyword\">public</span> <span class=\"token class-name\">LongEventProducer</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">RingBuffer</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">LongEvent</span><span class=\"token punctuation\">&gt;</span></span> ringBuffer<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n            <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>ringBuffer <span class=\"token operator\">=</span> ringBuffer<span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n\n        <span class=\"token comment\">/** * onData用来发布事件，每调用一次就发布一次事件事件 * 它的参数会通过事件传递给消费者 * * @param data */</span>\n        <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">onData</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">long</span> data<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n\n            <span class=\"token comment\">// step1：通过从 环形队列中 获取 序号</span>\n            <span class=\"token comment\">//可以把ringBuffer看做一个事件队列，那么next就是得到下面一个事件槽</span>\n            <span class=\"token keyword\">long</span> sequence <span class=\"token operator\">=</span> ringBuffer<span class=\"token punctuation\">.</span><span class=\"token function\">next</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n            <span class=\"token keyword\">try</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n                \n                <span class=\"token comment\">//step2: 通过序号获取 对应的 事件对象， 将数据填充到 事件对象，</span>\n                <span class=\"token comment\">//用上面的索引，取出一个空的事件用于填充</span>\n                <span class=\"token class-name\">LongEvent</span> event <span class=\"token operator\">=</span> ringBuffer<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span>sequence<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span class=\"token comment\">// for the sequence</span>\n                event<span class=\"token punctuation\">.</span><span class=\"token function\">setValue</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span> <span class=\"token keyword\">finally</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n                \n                <span class=\"token comment\">//step3: 再通过 序号将 事件对象 发布出去。</span>\n                <span class=\"token comment\">//发布事件</span>\n                ringBuffer<span class=\"token punctuation\">.</span><span class=\"token function\">publish</span><span class=\"token punctuation\">(</span>sequence<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n\n</code></pre> \n <p>很明显的是：</p> \n <p>当用一个简单队列来发布事件的时候会牵涉更多的细节，这是因为事件对象还需要预先创建。</p> \n <p>发布事件最少需要三步：</p> \n <p>step1：获取下一个事件槽。</p> \n <p>如果我们使用RingBuffer.next()获取一个事件槽，那么一定要发布对应的事件。</p> \n <p>step2: 通过序号获取 对应的 事件对象， 将数据填充到 事件对象，</p> \n <p>step3: 再通过 序号将 事件对象 发布出去。</p> \n <p>发布事件的时候要使用try/finnally保证事件一定会被发布</p> \n <p>如果不能发布事件，那么就会引起Disruptor状态的混乱。</p> \n <p>尤其是在多个事件生产者的情况下会导致事件消费者失速，从而不得不重启应用才能会恢复。</p> \n <p>Disruptor 3.0提供了lambda式的API。</p> \n <p>这样可以把一些复杂的操作放在Ring Buffer，所以在Disruptor3.0以后的版本最好使用Event Publisher或者Event Translator(事件转换器)来发布事件。</p> \n <h3><a id=\"_813\"></a>组装起来</h3> \n <p>最后一步就是把所有的代码组合起来完成一个完整的事件处理系统。</p> \n <pre><code class=\"prism language-java\">  <span class=\"token annotation punctuation\">@org.junit.Test</span>\n    <span class=\"token keyword\">public</span>  <span class=\"token keyword\">void</span> <span class=\"token function\">testSimpleDisruptor</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> <span class=\"token class-name\">InterruptedException</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token comment\">// 消费者线程池</span>\n        <span class=\"token class-name\">Executor</span> executor <span class=\"token operator\">=</span> <span class=\"token class-name\">Executors</span><span class=\"token punctuation\">.</span><span class=\"token function\">newCachedThreadPool</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// 事件工厂</span>\n        <span class=\"token class-name\">LongEventFactory</span> eventFactory <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">LongEventFactory</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// 环形队列大小，2的指数</span>\n        <span class=\"token keyword\">int</span> bufferSize <span class=\"token operator\">=</span> <span class=\"token number\">1024</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// 构造 分裂者 （事件分发者）</span>\n        <span class=\"token class-name\">Disruptor</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">LongEvent</span><span class=\"token punctuation\">&gt;</span></span> disruptor <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Disruptor</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">LongEvent</span><span class=\"token punctuation\">&gt;</span></span><span class=\"token punctuation\">(</span>eventFactory<span class=\"token punctuation\">,</span> bufferSize<span class=\"token punctuation\">,</span> executor<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// 连接 消费者 处理器</span>\n        disruptor<span class=\"token punctuation\">.</span><span class=\"token function\">handleEventsWith</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">LongEventHandler</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// 开启 分裂者（事件分发）</span>\n        disruptor<span class=\"token punctuation\">.</span><span class=\"token function\">start</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// 获取环形队列，用于生产 事件</span>\n        <span class=\"token class-name\">RingBuffer</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">LongEvent</span><span class=\"token punctuation\">&gt;</span></span> ringBuffer <span class=\"token operator\">=</span> disruptor<span class=\"token punctuation\">.</span><span class=\"token function\">getRingBuffer</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token class-name\">LongEventProducer</span> producer <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">LongEventProducer</span><span class=\"token punctuation\">(</span>ringBuffer<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">long</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n            <span class=\"token comment\">//发布事件</span>\n            producer<span class=\"token punctuation\">.</span><span class=\"token function\">onData</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token class-name\">Thread</span><span class=\"token punctuation\">.</span><span class=\"token function\">sleep</span><span class=\"token punctuation\">(</span><span class=\"token number\">1000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n</code></pre> \n <h3><a id=\"_850\"></a>事件转换器</h3> \n <p>Disruptor3.0以后 , 提供了事件转换器， 帮助填充 LongEvent 的业务数据</p> \n <p>下面是一个例子</p> \n <pre><code class=\"prism language-java\">  <span class=\"token keyword\">static</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">LongEventProducerWithTranslator</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token comment\">//一个translator可以看做一个事件初始化器，publicEvent方法会调用它</span>\n        <span class=\"token comment\">//填充Event</span>\n        <span class=\"token keyword\">private</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">final</span> <span class=\"token class-name\">EventTranslatorOneArg</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">LongEvent</span><span class=\"token punctuation\">,</span> <span class=\"token class-name\">Long</span><span class=\"token punctuation\">&gt;</span></span> <span class=\"token constant\">TRANSLATOR</span> <span class=\"token operator\">=</span>\n                <span class=\"token keyword\">new</span> <span class=\"token class-name\">EventTranslatorOneArg</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">LongEvent</span><span class=\"token punctuation\">,</span> <span class=\"token class-name\">Long</span><span class=\"token punctuation\">&gt;</span></span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n                    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">translateTo</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">LongEvent</span> event<span class=\"token punctuation\">,</span> <span class=\"token keyword\">long</span> sequence<span class=\"token punctuation\">,</span> <span class=\"token class-name\">Long</span> data<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n                        event<span class=\"token punctuation\">.</span><span class=\"token function\">setValue</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                    <span class=\"token punctuation\">}</span>\n                <span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> <span class=\"token class-name\">RingBuffer</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">LongEvent</span><span class=\"token punctuation\">&gt;</span></span> ringBuffer<span class=\"token punctuation\">;</span>\n\n        <span class=\"token keyword\">public</span> <span class=\"token class-name\">LongEventProducerWithTranslator</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">RingBuffer</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">LongEvent</span><span class=\"token punctuation\">&gt;</span></span> ringBuffer<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n            <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>ringBuffer <span class=\"token operator\">=</span> ringBuffer<span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n\n        <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">onData</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">Long</span> data<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n            ringBuffer<span class=\"token punctuation\">.</span><span class=\"token function\">publishEvent</span><span class=\"token punctuation\">(</span><span class=\"token constant\">TRANSLATOR</span><span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n</code></pre> \n <p>使用事件转换器的好处，省了从 环形队列 获取 序号， 然后拿到事件 填充数据， 再发布序号 中的第二步骤</p> \n <p>给 事件 填充 数据 的动作，在 EventTranslatorOneArg 完成</p> \n <p>Disruptor提供了不同的接口去产生一个Translator对象：</p> \n <ul>\n  <li>EventTranslator,</li>\n  <li>EventTranslatorOneArg,</li>\n  <li>EventTranslatorTwoArg,</li>\n </ul> \n <p>很明显，Translator中方法的参数是通过RingBuffer来传递的。</p> \n <p>使用 事件转换器 转换器的进行事件的 生产与消费 代码，大致如下：</p> \n <pre><code class=\"prism language-java\">   <span class=\"token annotation punctuation\">@org.junit.Test</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">testSimpleDisruptorWithTranslator</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> <span class=\"token class-name\">InterruptedException</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token comment\">// 消费者线程池</span>\n        <span class=\"token class-name\">Executor</span> executor <span class=\"token operator\">=</span> <span class=\"token class-name\">Executors</span><span class=\"token punctuation\">.</span><span class=\"token function\">newCachedThreadPool</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// 事件工厂</span>\n        <span class=\"token class-name\">LongEventFactory</span> eventFactory <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">LongEventFactory</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// 环形队列大小，2的指数</span>\n        <span class=\"token keyword\">int</span> bufferSize <span class=\"token operator\">=</span> <span class=\"token number\">1024</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// 构造 分裂者 （事件分发者）</span>\n        <span class=\"token class-name\">Disruptor</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">LongEvent</span><span class=\"token punctuation\">&gt;</span></span> disruptor <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Disruptor</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">LongEvent</span><span class=\"token punctuation\">&gt;</span></span><span class=\"token punctuation\">(</span>eventFactory<span class=\"token punctuation\">,</span> bufferSize<span class=\"token punctuation\">,</span> executor<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// 连接 消费者 处理器</span>\n        disruptor<span class=\"token punctuation\">.</span><span class=\"token function\">handleEventsWith</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">LongEventHandler</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// 开启 分裂者（事件分发）</span>\n        disruptor<span class=\"token punctuation\">.</span><span class=\"token function\">start</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// 获取环形队列，用于生产 事件</span>\n        <span class=\"token class-name\">RingBuffer</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">LongEvent</span><span class=\"token punctuation\">&gt;</span></span> ringBuffer <span class=\"token operator\">=</span> disruptor<span class=\"token punctuation\">.</span><span class=\"token function\">getRingBuffer</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token class-name\">LongEventProducerWithTranslator</span> producer <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">LongEventProducerWithTranslator</span><span class=\"token punctuation\">(</span>ringBuffer<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">long</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n            <span class=\"token comment\">//发布事件</span>\n            producer<span class=\"token punctuation\">.</span><span class=\"token function\">onData</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token class-name\">Thread</span><span class=\"token punctuation\">.</span><span class=\"token function\">sleep</span><span class=\"token punctuation\">(</span><span class=\"token number\">1000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n</code></pre> \n <p>上面写法的另一个好处是，Translator可以分离出来并且更加容易单元测试。</p> \n <h3><a id=\"Java_8_LambdaDisruptor_930\"></a>通过Java 8 Lambda使用Disruptor</h3> \n <p>Disruptor在自己的接口里面添加了对于Java 8 Lambda的支持。</p> \n <p>大部分Disruptor中的接口都符合Functional Interface的要求（也就是在接口中仅仅有一个方法）。</p> \n <p>所以在Disruptor中，可以广泛使用Lambda来代替自定义类。</p> \n <pre><code class=\"prism language-java\"> <span class=\"token annotation punctuation\">@org.junit.Test</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">testSimpleDisruptorWithLambda</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> <span class=\"token class-name\">InterruptedException</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token comment\">// 消费者线程池</span>\n        <span class=\"token class-name\">Executor</span> executor <span class=\"token operator\">=</span> <span class=\"token class-name\">Executors</span><span class=\"token punctuation\">.</span><span class=\"token function\">newCachedThreadPool</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// 环形队列大小，2的指数</span>\n        <span class=\"token keyword\">int</span> bufferSize <span class=\"token operator\">=</span> <span class=\"token number\">1024</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// 构造 分裂者 （事件分发者）</span>\n        <span class=\"token class-name\">Disruptor</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">LongEvent</span><span class=\"token punctuation\">&gt;</span></span> disruptor <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Disruptor</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">LongEvent</span><span class=\"token punctuation\">&gt;</span></span><span class=\"token punctuation\">(</span><span class=\"token class-name\">LongEvent</span><span class=\"token operator\">::</span><span class=\"token keyword\">new</span><span class=\"token punctuation\">,</span> bufferSize<span class=\"token punctuation\">,</span> executor<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// 连接 消费者 处理器</span>\n        <span class=\"token comment\">// 可以使用lambda来注册一个EventHandler</span>\n        disruptor<span class=\"token punctuation\">.</span><span class=\"token function\">handleEventsWith</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>event<span class=\"token punctuation\">,</span> sequence<span class=\"token punctuation\">,</span> endOfBatch<span class=\"token punctuation\">)</span> <span class=\"token operator\">-&gt;</span> <span class=\"token class-name\">System</span><span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Event: \"</span> <span class=\"token operator\">+</span> event<span class=\"token punctuation\">.</span><span class=\"token function\">getValue</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// 开启 分裂者（事件分发）</span>\n        disruptor<span class=\"token punctuation\">.</span><span class=\"token function\">start</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// 获取环形队列，用于生产 事件</span>\n        <span class=\"token class-name\">RingBuffer</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">LongEvent</span><span class=\"token punctuation\">&gt;</span></span> ringBuffer <span class=\"token operator\">=</span> disruptor<span class=\"token punctuation\">.</span><span class=\"token function\">getRingBuffer</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token class-name\">LongEventProducerWithTranslator</span> producer <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">LongEventProducerWithTranslator</span><span class=\"token punctuation\">(</span>ringBuffer<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">long</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n            <span class=\"token comment\">//发布事件</span>\n            producer<span class=\"token punctuation\">.</span><span class=\"token function\">onData</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token class-name\">Thread</span><span class=\"token punctuation\">.</span><span class=\"token function\">sleep</span><span class=\"token punctuation\">(</span><span class=\"token number\">1000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n</code></pre> \n <p>由于在Java 8中方法引用也是一个lambda，因此还可以把上面的代码改成下面的代码：</p> \n <pre><code class=\"prism language-java\">\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">void</span> <span class=\"token function\">handleEvent</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">LongEvent</span> event<span class=\"token punctuation\">,</span> <span class=\"token keyword\">long</span> sequence<span class=\"token punctuation\">,</span> <span class=\"token keyword\">boolean</span> endOfBatch<span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token class-name\">System</span><span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span>event<span class=\"token punctuation\">.</span><span class=\"token function\">getValue</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token annotation punctuation\">@org.junit.Test</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">testSimpleDisruptorWithMethodRef</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> <span class=\"token class-name\">InterruptedException</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token comment\">// 消费者线程池</span>\n        <span class=\"token class-name\">Executor</span> executor <span class=\"token operator\">=</span> <span class=\"token class-name\">Executors</span><span class=\"token punctuation\">.</span><span class=\"token function\">newCachedThreadPool</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// 环形队列大小，2的指数</span>\n        <span class=\"token keyword\">int</span> bufferSize <span class=\"token operator\">=</span> <span class=\"token number\">1024</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// 构造 分裂者 （事件分发者）</span>\n        <span class=\"token class-name\">Disruptor</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">LongEvent</span><span class=\"token punctuation\">&gt;</span></span> disruptor <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Disruptor</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">LongEvent</span><span class=\"token punctuation\">&gt;</span></span><span class=\"token punctuation\">(</span><span class=\"token class-name\">LongEvent</span><span class=\"token operator\">::</span><span class=\"token keyword\">new</span><span class=\"token punctuation\">,</span> bufferSize<span class=\"token punctuation\">,</span> executor<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// 连接 消费者 处理器</span>\n        <span class=\"token comment\">// 可以使用lambda来注册一个EventHandler</span>\n        disruptor<span class=\"token punctuation\">.</span><span class=\"token function\">handleEventsWith</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">LongEventDemo</span><span class=\"token operator\">::</span><span class=\"token function\">handleEvent</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// 开启 分裂者（事件分发）</span>\n        disruptor<span class=\"token punctuation\">.</span><span class=\"token function\">start</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token comment\">// 获取环形队列，用于生产 事件</span>\n        <span class=\"token class-name\">RingBuffer</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">LongEvent</span><span class=\"token punctuation\">&gt;</span></span> ringBuffer <span class=\"token operator\">=</span> disruptor<span class=\"token punctuation\">.</span><span class=\"token function\">getRingBuffer</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token class-name\">LongEventProducerWithTranslator</span> producer <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">LongEventProducerWithTranslator</span><span class=\"token punctuation\">(</span>ringBuffer<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">long</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n            <span class=\"token comment\">//发布事件</span>\n            producer<span class=\"token punctuation\">.</span><span class=\"token function\">onData</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token class-name\">Thread</span><span class=\"token punctuation\">.</span><span class=\"token function\">sleep</span><span class=\"token punctuation\">(</span><span class=\"token number\">1000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span> \n</code></pre> \n <h2><a id=\"Disruptor_1011\"></a>构造Disruptor对象的几个要点</h2> \n <p>在构造Disruptor对象，有几个核心的要点：<br> 1：事件工厂(Event Factory)定义了如何实例化事件(Event)，Disruptor 通过 EventFactory 在 RingBuffer 中预创建 Event 的实例。<br> 2：ringBuffer这个数组的大小，一般根据业务指定成2的指数倍。<br> 3：消费者线程池，事件的处理是在构造的线程池里来进行处理的。<br> 4：指定等待策略，Disruptor 定义了 com.lmax.disruptor.WaitStrategy 接口用于抽象 <strong>Consumer 如何等待Event事件</strong>。</p> \n <p>Disruptor 提供了多个 WaitStrategy 的实现，每种策略都具有不同性能和优缺点，根据实际运行环境的 CPU 的硬件特点选择恰当的策略，并配合特定的 JVM 的配置参数，能够实现不同的性能提升。</p> \n <ul>\n  <li>BlockingWaitStrategy 是最低效的策略，但其对<strong>CPU的消耗最小</strong>并且在各种不同部署环境中能提供更加一致的性能表现；</li>\n  <li>SleepingWaitStrategy 的性能表现跟 BlockingWaitStrategy 差不多，对 CPU 的消耗也类似，但其对生产者线程的影响最小，适合用于异步日志类似的场景；</li>\n  <li>YieldingWaitStrategy 的性能是最好的，适合用于低延迟的系统。在要求极高性能且<strong>事件处理线数小于 CPU 逻辑核心数的场景中</strong>，推荐使用此策略；。</li>\n </ul> \n <h2><a id=\"Disruptor_1029\"></a>Disruptor如何实现高性能？</h2> \n <p>使用Disruptor，主要用于对性能要求高、延迟低的场景，它通过“榨干”机器的性能来换取处理的高性能。</p> \n <p>Disruptor实现高性能主要体现了去掉了锁，采用CAS算法，同时内部通过环形队列实现有界队列。</p> \n <ul>\n  <li> <p>环形数据结构<br> 数组元素不会被回收，避免频繁的GC，所以，为了避免垃圾回收，采用数组而非链表。<br> 同时，数组对处理器的缓存机制更加友好。</p> </li>\n  <li> <p>元素位置定位<br> 数组长度2^n，通过位运算，加快定位的速度。<br> 下标采取递增的形式。不用担心index溢出的问题。<br> index是long类型，即使100万QPS的处理速度，也需要30万年才能用完。</p> </li>\n  <li> <p>无锁设计<br> 采用CAS无锁方式，保证线程的安全性</p> <p>每个生产者或者消费者线程，会先申请可以操作的元素在数组中的位置，申请到之后，直接在该位置写入或者读取数据。整个过程通过原子变量CAS，保证操作的线程安全。</p> </li>\n  <li> <p>属性填充：</p> <p>通过添加额外的无用信息，避免伪共享问题</p> </li>\n </ul> \n <h3><a id=\"DisruptorBlockingQueue_1059\"></a>Disruptor和BlockingQueue比较:</h3> \n <ul>\n  <li><strong>BlockingQueue:</strong> FIFO队列.生产者Producer向队列中发布publish一个事件时,消费者Consumer能够获取到通知.如果队列中没有消费的事件,消费者就会被阻塞,直到生产者发布新的事件</li>\n  <li>Disruptor可以比BlockingQueue做到更多: \n   <ul>\n    <li>Disruptor队列中同一个事件可以有多个消费者,消费者之间既可以并行处理,也可以形成依赖图相互依赖,按照先后次序进行处理</li>\n    <li>Disruptor可以预分配用于存储事件内容的内存空间</li>\n    <li>Disruptor使用极度优化和无锁的设计实现极高性能的目标</li>\n   </ul> </li>\n </ul> \n <p>如果你的项目有对性能要求高，对延迟要求低的需求，并且需要一个无锁的有界队列，来实现生产者/消费者模式，那么Disruptor是你的不二选择。</p> \n <h2><a id=\"Disruptor_Ring_Buffer_1069\"></a>原理：Disruptor 的内部Ring Buffer环形队列</h2> \n <h3><a id=\"RingBuffer_1071\"></a>RingBuffer是什么</h3> \n <p>RingBuffer 是一个环(首尾相连的环)，用做在不同上下文(线程)间传递数据的buffer。</p> \n <p>RingBuffer 拥有一个序号，这个序号指向数组中下一个可用元素。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/20191204153302150.png\" alt=\"img\"></p> \n <h3><a id=\"Disruptor_1079\"></a>Disruptor使用环形队列的优势：</h3> \n <p>Disruptor框架就是一个使用CAS操作的内存队列，与普通的队列不同，</p> \n <p>Disruptor框架使用的是一个基于数组实现的环形队列，无论是生产者向缓冲区里提交任务，还是消费者从缓冲区里获取任务执行，都使用CAS操作。</p> \n <p>使用环形队列的优势：</p> \n <p>第一，简化了多线程同步的复杂度。</p> \n <p>学数据结构的时候，实现队列都要两个指针head和tail来分别指向队列的头和尾，对于一般的队列是这样，</p> \n <p>想象下，如果有多个生产者同时往缓冲区队列中提交任务，某一生产者提交新任务后，tail指针都要做修改的，那么多个生产者提交任务，头指针不会做修改，但会对tail指针产生冲突，</p> \n <p>例如某一生产者P1要做写入操作，在获得tail指针指向的对象值V后，执行compareAndSet（）方法前，tail指针被另一生产者P2修改了，这时生产者P1执行compareAndSet（）方法，发现tail指针指向的值V和期望值E不同，导致冲突。</p> \n <p>同样，如果多个消费者不断从缓冲区中获取任务，不会修改尾指针，但会造成队列头指针head的冲突问题（因为队列的FIFO特点，出列会从头指针出开始）。</p> \n <p>环形队列的一个特点就是只有一个指针，只通过一个指针来实现出列和入列操作。</p> \n <p>如果使用两个指针head和tail来管理这个队列，有可能会出现“伪共享”问题（伪共享问题在下面我会详细说），</p> \n <p>因为创建队列时，head和tail指针变量常常在同一个缓存行中，多线程修改同一缓存行中的变量就容易出现伪共享问题。</p> \n <p>第二，由于使用的是环形队列，那么队列创建时大小就被固定了，</p> \n <p>Disruptor框架中的环形队列本来也就是基于数组实现的，使用数组的话，减少了系统对内存空间管理的压力，</p> \n <p>因为数组不像链表，Java会定期回收链表中一些不再引用的对象，而数组不会出现空间的新分配和回收问题。</p> \n <h2><a id=\"Disruptor_1111\"></a>关闭Disruptor</h2> \n <ul>\n  <li><strong>disruptor.shutdown() : <strong>关闭</strong>Disruptor.</strong> 方法会阻塞，直至所有的事件都得到处理</li>\n  <li><strong>executor.shutdown() : <strong>关闭</strong>Disruptor</strong>使用的线程池，如果线程池需要关闭，必须进行手动关闭， <strong>Disruptor</strong>在<strong>shutdown</strong>时不会自动关闭使用的线程池</li>\n </ul> \n <h1><a id=\"3Disruptor__1120\"></a>3：Disruptor 的使用场景分析</h1> \n <p>Disruptor 它可以用来作为高性能的有界内存队列， 适用于两大场景：</p> \n <ul>\n  <li>生产者消费者场景</li>\n  <li>发布订阅 场景</li>\n </ul> \n <p>生产者消费者场景。Disruptor的最常用的场景就是“生产者-消费者”场景，对场景的就是“一个生产者、多个消费者”的场景，并且要求顺序处理。</p> \n <blockquote> \n  <p>备注，这里和JCTool 的 MPSC 队列，刚好相反， MPSC 使用于多生产者，单消费者场景</p> \n </blockquote> \n <p>发布订阅 场景：Disruptor也可以认为是观察者模式的一种实现， 实现发布订阅模式。</p> \n <p>当前业界开源组件使用Disruptor的包括Log4j2、Apache Storm等，</p> \n <h2><a id=\"Disruptor__1143\"></a>Disruptor 使用细分场景</h2> \n <p>Disruptor是一个优秀的并发框架，可以使用在多个生产者单消费者场景</p> \n <ul>\n  <li>单生产者多消费者场景</li>\n  <li>多生产者单消费者场景</li>\n  <li>单生产者多消费者场景</li>\n  <li>多个消费者串行消费场景</li>\n  <li>菱形方式执行场景</li>\n  <li>链式并行执行场景</li>\n  <li>多组消费者相互隔离场景</li>\n  <li>多组消费者航道执行模式</li>\n </ul> \n <h2><a id=\"_1160\"></a>单生产者多消费者并行场景</h2> \n <p>在并发系统中提高性能最好的方式之一就是单一写者原则，对Disruptor也是适用的。</p> \n <p>如果在生产者单消费者 需求中仅仅有一个事件生产者，那么可以设置为单一生产者模式来提高系统的性能。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/61c98bc110664b7f9a36ffd1734b2576.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"ProducerType__1170\"></a>ProducerType 的类型</h3> \n <p>ProducerType 定义了生产者的类型， 两类</p> \n <p><img src=\"https://img-blog.csdnimg.cn/207d0966c96846d7aac6a973eae2f0df.png\" alt=\"在这里插入图片描述\"></p> \n <p>在这种场景下，ProducerType 的类型的 SINGLE</p> \n <h3><a id=\"_1180\"></a>单生产者多消费者并行场景的参考代码</h3> \n <p>参考的代码如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/d7315767baa4471d89f17a2678486cec.png\" alt=\"在这里插入图片描述\"></p> \n <p>执行结果：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/af54f5a1ecb24354ac27b4873dcac8c6.png\" alt=\"在这里插入图片描述\"></p> \n <blockquote> \n  <p>以上用例的具体减少，请参见 尼恩《100wqps 日志平台实操，视频》</p> \n </blockquote> \n <h2><a id=\"_1200\"></a>多生产者单消费者场景</h2> \n <p>该场景较为简单，就是多个生产者，单个消费者</p> \n <p><img src=\"https://img-blog.csdnimg.cn/bca80568d8fa49bc84acf4ad3217fdf2.png\" alt=\"在这里插入图片描述\"></p> \n <p>其实，<strong>消费者也可以是多个</strong></p> \n <h3><a id=\"ProducerType__1214\"></a>ProducerType 的类型</h3> \n <p>ProducerType 定义了生产者的类型， 两类</p> \n <p><img src=\"https://img-blog.csdnimg.cn/207d0966c96846d7aac6a973eae2f0df.png\" alt=\"在这里插入图片描述\"></p> \n <p>在这种场景下，ProducerType 的类型的 MULTI</p> \n <h3><a id=\"_1226\"></a>多生产者场景的要点</h3> \n <p>在代码编写维度，多生产者单消费者场景的要点如下：</p> \n <ul>\n  <li>创建Disruptor 的时候，将ProducerType.SINGLE改为ProducerType.MULTI，</li>\n  <li>编写多线程生产者的相关代码即可。</li>\n </ul> \n <h3><a id=\"_1233\"></a>多生产者场景的参考代码</h3> \n <p>参考的代码如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/d2ce7689a1f041d7b3f939b052e4567f.png\" alt=\"在这里插入图片描述\"></p> \n <p>运行的结果如下</p> \n <p><img src=\"https://img-blog.csdnimg.cn/a25f3673ce974d68b8a080900fef812a.png\" alt=\"在这里插入图片描述\"></p> \n <blockquote> \n  <p>以上用例的具体减少，请参见 尼恩《100wqps 日志平台实操，视频》</p> \n </blockquote> \n <h2><a id=\"_1253\"></a>单生产者多消费者竞争场景</h2> \n <p>该场景中，生产者为一个，消费者为多个，多个消费者之间， 存在着竞争关系，</p> \n <p>也就是说，对于同一个事件event ，多个消费者 不重复消费</p> \n <p><img src=\"https://img-blog.csdnimg.cn/61c98bc110664b7f9a36ffd1734b2576.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"disruptor_1269\"></a>disruptor如何设置多个竞争消费者？</h3> \n <p>首先，得了解一下，disruptor框架的两个设置消费者的方法</p> \n <p>大概有两点：</p> \n <ul>\n  <li>消费者需要 实现 WorkHandler 接口，而不是 EventHandler 接口</li>\n  <li>使用 handleEventsWithWorkerPool 设置 disruptor的 消费者，而不是 handleEventsWith 方法</li>\n </ul> \n <p>在disruptor框架调用start方法之前，有两个方法设置消费者：</p> \n <ul>\n  <li>disruptor.handleEventsWith(EventHandler … handlers)，将多个EventHandler的实现类传入方法，封装成一个EventHandlerGroup，实现多消费者消费。</li>\n  <li>disruptor.handleEventsWithWorkerPool(WorkHandler … handlers)，将多个WorkHandler的实现类传入方法，封装成一个EventHandlerGroup实现多消费者消费。</li>\n </ul> \n <p>那么，以上的Disruptor类的handleEventsWith，handleEventsWithWorkerPool方法的联系及区别是什么呢？<br> <strong>相同的在于：</strong></p> \n <blockquote> \n  <p>两者共同点都是，将多个消费者封装到一起，供框架消费事件。</p> \n </blockquote> \n <p><strong>第一个不同点在于：</strong></p> \n <p>对于某一条事件 event，</p> \n <p>handleEventsWith 方法返回的EventHandlerGroup，Group中的每个消费者都会对 event 进行消费，各个消费者之间不存在竞争。</p> \n <p>handleEventsWithWorkerPool方法返回的EventHandlerGroup，Group的消费者对于同一条事件 event 不重复消费；也就是，如果c0消费了事件m，则c1不再消费事件m。</p> \n <p><strong>另外一个不同：</strong></p> \n <p>在设置消费者的时候，Disruptor类的handleEventsWith，handleEventsWithWorkerPool方法所传入的形参不同。对于独立消费的消费者，应当实现EventHandler接口。对于不重复消费的消费者，应当实现WorkHandler接口。</p> \n <p>因此，根据消费者集合是否独立消费事件，可以对不同的接口进行实现。也可以对两种接口同时实现，具体消费流程由disruptor的方法调用决定。</p> \n <h3><a id=\"_1306\"></a>演示代码如下:</h3> \n <p><img src=\"https://img-blog.csdnimg.cn/d92c1b66e7ad4a4790ecd5ba05891852.png\" alt=\"在这里插入图片描述\"></p> \n <p>执行结果</p> \n <p><img src=\"https://img-blog.csdnimg.cn/1068b2754ca649b0bc8b6af68e4d7ea7.png\" alt=\"在这里插入图片描述\"></p> \n <p>以上用例的具体减少，请参见 尼恩《100wqps 日志平台实操，视频》</p> \n <h2><a id=\"_1322\"></a>多个消费者串行消费场景</h2> \n <p>在 多个消费者串行消费场景中，多个消费者，可以按照次序，消费消息。</p> \n <p>比如：一个用户注册的Event，需要有一个Handler来存储信息，一个Hanlder来发邮件等等。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/c33f7e3abe1a485c9972071b145859b5.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"_1330\"></a>多个消费者串行消费场景案例</h3> \n <p><img src=\"https://img-blog.csdnimg.cn/33facd0545834be98ccb5d776e4a127c.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"_1338\"></a>执行结果</h3> \n <p><img src=\"https://img-blog.csdnimg.cn/605eb6b0951746858c09ae1bf7fb477b.png\" alt=\"在这里插入图片描述\"></p> \n <h2><a id=\"_1344\"></a>菱形方式执行场景</h2> \n <h3><a id=\"_1348\"></a>场景特点</h3> \n <p>先并发，后串行</p> \n <p><img src=\"https://img-blog.csdnimg.cn/0995a05915d74c798d093dcf699241f5.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"_1358\"></a>菱形方式执行场景案例</h3> \n <p><img src=\"https://img-blog.csdnimg.cn/25380878c2e445c1b66dc391a76c4517.png\" alt=\"在这里插入图片描述\"></p> \n <p>执行结果</p> \n <p><img src=\"https://img-blog.csdnimg.cn/09b83c6ecdbe4cfdbe3306062269588f.png\" alt=\"在这里插入图片描述\"></p> \n <h2><a id=\"_1372\"></a>链式并行执行场景</h2> \n <h3><a id=\"_1374\"></a>场景特点</h3> \n <p>多组消费者形成 并行链，特点是：</p> \n <ul>\n  <li>链内 串行</li>\n  <li>链间 并行</li>\n </ul> \n <p><img src=\"https://img-blog.csdn.net/20180521220750143\" alt=\"img\"></p> \n <h3><a id=\"_1385\"></a>场景案例</h3> \n <p><img src=\"https://img-blog.csdnimg.cn/e03ba024a10f43b8929e390c98b6d68b.png\" alt=\"在这里插入图片描述\"></p> \n <p>执行结果</p> \n <p><img src=\"https://img-blog.csdnimg.cn/ca8f79475c354049ab2c29b14e38308d.png\" alt=\"在这里插入图片描述\"></p> \n <h2><a id=\"_1399\"></a>多组消费者相互隔离场景</h2> \n <h3><a id=\"_1403\"></a>场景特点</h3> \n <p>多组消费者 相互隔离，特点是：</p> \n <ul>\n  <li>组内 相互竞争</li>\n  <li>组间 相互隔离</li>\n </ul> \n <p><img src=\"https://img-blog.csdn.net/20180521220931741\" alt=\"这里写图片描述\"></p> \n <h3><a id=\"_1414\"></a>场景案例</h3> \n <p><img src=\"https://img-blog.csdnimg.cn/3581a3e6a1e64d92831732f13b0be205.png\" alt=\"在这里插入图片描述\"></p> \n <p>执行结果</p> \n <p><img src=\"https://img-blog.csdnimg.cn/4f3d97358d384c4eafb5726e467851a2.png\" alt=\"在这里插入图片描述\"></p> \n <h2><a id=\"_1426\"></a>多组消费者航道执行模式</h2> \n <h3><a id=\"_1430\"></a>场景特点</h3> \n <p>多组消费者形成 并行链，特点是：</p> \n <ul>\n  <li>组内 相互竞争</li>\n  <li>组之间串行依次执行</li>\n </ul> \n <p><img src=\"https://img-blog.csdn.net/2018052122100814\" alt=\"这里写图片描述\"></p> \n <h3><a id=\"_1439\"></a>场景案例</h3> \n <p>组之间串行依次执行,组内有多个实例竞争执行</p> \n <p><img src=\"https://img-blog.csdnimg.cn/ece2f132de8945c6a6b2250ba418e4a1.png\" alt=\"在这里插入图片描述\"></p> \n <p>执行效果</p> \n <p><img src=\"https://img-blog.csdnimg.cn/f09236cbe9be4c729fd6c458c70a3d37.png\" alt=\"在这里插入图片描述\"></p> \n <h2><a id=\"_1457\"></a>六边形执行顺序</h2> \n <p>这是一种比较复杂的场景</p> \n <h3><a id=\"_1463\"></a>场景特点</h3> \n <p>单边内部是有序的</p> \n <p>边和边之间是并行的</p> \n <p><img src=\"https://img-blog.csdnimg.cn/db0fa0a45c0c42fb82909993f7089559.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"_1475\"></a>参考代码</h3> \n <pre><code class=\"prism language-java\">   <span class=\"token annotation punctuation\">@org.junit.Test</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">testHexagonConsumerDisruptorWithMethodRef</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> <span class=\"token class-name\">InterruptedException</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token comment\">// 消费者线程池</span>\n        <span class=\"token class-name\">Executor</span> executor <span class=\"token operator\">=</span> <span class=\"token class-name\">Executors</span><span class=\"token punctuation\">.</span><span class=\"token function\">newCachedThreadPool</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// 环形队列大小，2的指数</span>\n        <span class=\"token keyword\">int</span> bufferSize <span class=\"token operator\">=</span> <span class=\"token number\">1024</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// 构造 分裂者 （事件分发者）</span>\n        <span class=\"token class-name\">Disruptor</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">LongEvent</span><span class=\"token punctuation\">&gt;</span></span> disruptor <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Disruptor</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">LongEvent</span><span class=\"token punctuation\">&gt;</span></span><span class=\"token punctuation\">(</span><span class=\"token class-name\">LongEvent</span><span class=\"token operator\">::</span><span class=\"token keyword\">new</span><span class=\"token punctuation\">,</span> bufferSize<span class=\"token punctuation\">,</span>\n                executor<span class=\"token punctuation\">,</span>\n                <span class=\"token class-name\">ProducerType</span><span class=\"token punctuation\">.</span><span class=\"token constant\">SINGLE</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\">//多个生产者</span>\n                <span class=\"token keyword\">new</span> <span class=\"token class-name\">YieldingWaitStrategy</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token class-name\">EventHandler</span> consumer1 <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">LongEventHandlerWithName</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"consumer 1\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token class-name\">EventHandler</span> consumer2 <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">LongEventHandlerWithName</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"consumer 2\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token class-name\">EventHandler</span> consumer3 <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">LongEventHandlerWithName</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"consumer 3\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token class-name\">EventHandler</span> consumer4 <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">LongEventHandlerWithName</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"consumer 4\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token class-name\">EventHandler</span> consumer5 <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">LongEventHandlerWithName</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"consumer 5\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// 连接 消费者 处理器</span>\n        <span class=\"token comment\">// 可以使用lambda来注册一个EventHandler</span>\n\n        disruptor<span class=\"token punctuation\">.</span><span class=\"token function\">handleEventsWith</span><span class=\"token punctuation\">(</span>consumer1<span class=\"token punctuation\">,</span>consumer2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        disruptor<span class=\"token punctuation\">.</span><span class=\"token function\">after</span><span class=\"token punctuation\">(</span>consumer1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">handleEventsWith</span><span class=\"token punctuation\">(</span>consumer3<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        disruptor<span class=\"token punctuation\">.</span><span class=\"token function\">after</span><span class=\"token punctuation\">(</span>consumer2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">handleEventsWith</span><span class=\"token punctuation\">(</span>consumer4<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        disruptor<span class=\"token punctuation\">.</span><span class=\"token function\">after</span><span class=\"token punctuation\">(</span>consumer3<span class=\"token punctuation\">,</span>consumer4<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">handleEventsWith</span><span class=\"token punctuation\">(</span>consumer5<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// 开启 分裂者（事件分发）</span>\n        disruptor<span class=\"token punctuation\">.</span><span class=\"token function\">start</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// 获取环形队列，用于生产 事件</span>\n        <span class=\"token class-name\">RingBuffer</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">LongEvent</span><span class=\"token punctuation\">&gt;</span></span> ringBuffer <span class=\"token operator\">=</span> disruptor<span class=\"token punctuation\">.</span><span class=\"token function\">getRingBuffer</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">//1生产者，并发生产数据</span>\n        <span class=\"token class-name\">LongEventProducerWithTranslator</span> producer <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">LongEventProducerWithTranslator</span><span class=\"token punctuation\">(</span>ringBuffer<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token class-name\">Thread</span> thread <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Thread</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n            <span class=\"token annotation punctuation\">@Override</span>\n            <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">run</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n                <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">long</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n                    producer<span class=\"token punctuation\">.</span><span class=\"token function\">onData</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                    <span class=\"token class-name\">ThreadUtil</span><span class=\"token punctuation\">.</span><span class=\"token function\">sleepSeconds</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token punctuation\">}</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span>\n        thread<span class=\"token punctuation\">.</span><span class=\"token function\">start</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token class-name\">ThreadUtil</span><span class=\"token punctuation\">.</span><span class=\"token function\">sleepSeconds</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n</code></pre> \n <h3><a id=\"_1524\"></a>执行结果</h3> \n <p><img src=\"https://img-blog.csdnimg.cn/a0f56277ec88494eacc89035206f7b6c.png\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"4Disruptor_1530\"></a>4：架构师视角，深入Disruptor源码分析</h1> \n <p>Disruptor其实是“生产者-消费者”模型一种典型的应用场合，它的功能其实就是一种有界队列。</p> \n <h2><a id=\"_1534\"></a>核心概念</h2> \n <h3><a id=\"Ring_Buffer_1536\"></a>Ring Buffer</h3> \n <p>如其名，环形的缓冲区。</p> \n <p>曾经 RingBuffer 是 Disruptor 中的最主要的对象，但从3.0版本开始，其职责被简化为仅仅负责对通过 Disruptor 进行交换的数据（事件）进行存储和更新。</p> \n <p>在一些更高级的应用场景中，Ring Buffer 可以由用户的自定义实现来完全替代。</p> \n <h3><a id=\"Sequence_1544\"></a>Sequence</h3> \n <p>通过顺序递增的序号来编号管理通过其进行交换的数据（事件），对数据(事件)的处理过程总是沿着序号逐个递增处理。</p> \n <p>Sequence 采用缓存行填充的方式对long类型的一层包装，用以代表事件的序号。</p> \n <p>一个 Sequence 用于跟踪标识某个特定的事件处理者( RingBuffer/Consumer )的处理进度。</p> \n <p>虽然一个 AtomicLong 也可以用于标识进度，但定义 Sequence 来负责该问题还有另一个目的，那就是防止不同的 Sequence 之间的CPU缓存伪共享(Flase Sharing)问题。</p> \n <p>另外，Sequence 通过 unsafe 的cas方法从而避免了锁的开销。</p> \n <h3><a id=\"Sequencer_1556\"></a>Sequencer</h3> \n <p>Sequencer 是 Disruptor 的真正核心。</p> \n <p>生产者与缓存RingBuffer之间的桥梁、</p> \n <p>此接口有两个实现类 SingleProducerSequencer、MultiProducerSequencer ，它们定义在生产者和消费者之间快速、正确地传递数据的并发算法。</p> \n <h3><a id=\"Sequence_Barrier_1564\"></a>Sequence Barrier</h3> \n <p>消费者 与 消费者 直接的 隔离 屏障。</p> \n <p>消费者 之间，并不是通过 RingBuffer 进行加锁互斥 隔离，而是 通过 Sequence Barrier 来管理依赖次序关系， 从而能减少RingBuffer上的并发冲突；</p> \n <blockquote> \n  <p>在一定程度上， Sequence Barrier 类似与 aqs 同步队列</p> \n </blockquote> \n <p>Sequence Barrier 用于保持对 RingBuffer 的 main published Sequence 和Consumer依赖的其它Consumer的 Sequence 的引用。</p> \n <p>Sequence Barrier 还定义了: Consumer 是否还有可处理的事件的逻辑。</p> \n <h3><a id=\"Wait_Strategy_1576\"></a>Wait Strategy</h3> \n <p>定义 Consumer 如何进行等待下一个事件的策略。 （注：Disruptor 定义了多种不同的策略，针对不同的场景，提供了不一样的性能表现）</p> \n <h3><a id=\"Event_1580\"></a>Event</h3> \n <p>在 Disruptor 的语义中，生产者和消费者之间进行交换的数据被称为事件(Event)。</p> \n <p>它不是一个被 Disruptor 定义的特定类型，而是由 Disruptor 的使用者定义并指定。</p> \n <h3><a id=\"EventProcessor_1586\"></a>EventProcessor</h3> \n <p>事件处理器，是消费者线程池Executor的调度单元，</p> \n <p>EventProcessor 是对事件业务处理EventHandler与异常处理ExceptionHandler等的一层封装；</p> \n <p>EventProcessor 持有特定消费者(Consumer)的 Sequence，并提供事件循环(Event Loop)，用于调用业务事件处理实现EventHandler</p> \n <h3><a id=\"EventHandler_1594\"></a>EventHandler</h3> \n <p>Disruptor 定义的事件处理接口，由用户实现，用于处理事件，是 Consumer 的真正实现。</p> \n <h3><a id=\"Producer_1598\"></a>Producer</h3> \n <blockquote> \n  <p>即生产者，只是泛指调用 Disruptor 发布事件的用户代码，Disruptor 没有定义特定接口或类型</p> \n </blockquote> \n <h3><a id=\"RingBuffer_1602\"></a>RingBuffer</h3> \n <p>基于数组的缓存实现，也是创建sequencer与定义WaitStrategy的入口；</p> \n <h3><a id=\"Disruptor_1606\"></a>Disruptor</h3> \n <p>Disruptor的使用入口。</p> \n <p>持有RingBuffer、消费者线程池Executor、消费者仓库ConsumerRepository等引用。</p> \n <h2><a id=\"Disruptor_1614\"></a>Disruptor的无锁架构</h2> \n <p>并发领域的一个典型场景是生产者消费者模型，生产者消费者模型的经典方式，是使用queue作为生产者线程与消费者线程之间共享数据的方法，但是，经典方式对于queue的读写避免不了读写锁的竞争。</p> \n <p>通过序号屏障对依赖关系的管理，RingBuffer实现了事件缓存的无锁架构。</p> \n <p>Disruptor使用环形缓冲区RingBuffer作为共享数据的媒介。</p> \n <p>生产者通过Sequencer控制RingBuffer，以及唤醒等待事件的消费者，</p> \n <p>消费者通过SequenceBarrier监听RingBuffer的可消费事件。</p> \n <p>考虑一个场景，一个生产者A与三个消费者B、C、D,同时D的事件处理需要B与C先完成。</p> \n <p>则该模型结构如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/88bf5d04d4484a59a7eba9f0808fb896.png\" alt=\"在这里插入图片描述\"></p> \n <p>Disruptor 中，生产者与Sequencer有关系，由生产者通过Sequencer控制RingBuffer的写入。</p> \n <p>RingBuffer是Disruptor高性能的一个亮点。RingBuffer就是一个大数组，事件以循环覆盖的方式写入。</p> \n <p>与常规RingBuffer拥有2个首尾指针的方式不同，Disruptor的RingBuffer只有一个指针(或称序号)，指向数组下一个可写入的位置，该序号在Disruptor源码中就是<strong>Sequencer中的cursor</strong>，</p> \n <h3><a id=\"_1646\"></a><strong>如何管理消费者和生产者之间的依赖关系呢？</strong></h3> \n <p>还是通过SequenceBarrier 进行依赖管理，</p> \n <p>消费者的 processer，通过 SequenceBarrier 获取生产者的 生产 序号</p> \n <h3><a id=\"_1654\"></a>如何管理消费者与消费者之间的依赖关系呢？</h3> \n <p>每个消费者拥有各自独立的事件序号Sequence，消费者之间不通过Sequence在共享竞态，或者说依赖管理。</p> \n <p>消费者与消费者之间的依赖关系是，通过SequenceBarrier 进行依赖管理。</p> \n <h3><a id=\"_1664\"></a>依赖关系管理的例子</h3> \n <p>在上面的例子中：</p> \n <p>SequenceBarrier1 监听 RingBuffer 的序号 cursor，消费者B与C通过SequenceBarrier1等待可消费事件。</p> \n <p>SequenceBarrier2 除了监听 RingBuffer 的序号cursor，同时也监听B与C的序号Sequence，从而将最小的序号返回给消费者D，由此实现了D依赖B与C的逻辑。</p> \n <h3><a id=\"_1674\"></a><strong>如何避免未消费事件的写入覆盖呢？</strong></h3> \n <p>为了避免未消费事件的写入覆盖，生产者的 Sequencer需要监听所有消费者的消息处理进度，也就是 gatingSequences。</p> \n <h2><a id=\"Disruptor_1682\"></a>Disruptor的总体模块架构</h2> \n <p>结合执行流程进行梳理</p> \n <p><img src=\"https://img-blog.csdnimg.cn/8983e08edfca464bbd4b20c00905e4b5.png\" alt=\"在这里插入图片描述\"></p> \n <h2><a id=\"Sequence_1688\"></a>核心类Sequence</h2> \n <p>用来表达 event 序例号的对象，但这里为什么不直接用 long 呢 ？</p> \n <p>为了高并发下的可见性，肯定不能直接用 long 的，至少也是 volatile long。</p> \n <p>但 Disruptor 觉得 volatile long 还是不够用，所以创造了 Sequence 类。</p> \n <p>Sequence的内部实现主要是 volatile long，</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">volatile</span> <span class=\"token keyword\">long</span> value<span class=\"token punctuation\">;</span>\n</code></pre> \n <p>除此以外还支持以下特性：</p> \n <ul>\n  <li>CAS 更新</li>\n  <li>order writes (Store/Store barrier，改动不保证立即可见) vs volatile writes (Store/Load barrier，改动保证立即可见)</li>\n  <li>在 volatile 字段 附近添加 padding 解决伪共享问题</li>\n </ul> \n <p>简单理解就是高并发下优化的 long 类型。</p> \n <p>比如在对 EventProcessor.sequence 的更新中都是用的 order writes，不保证立即可见，但速度快很多。</p> \n <p>在这个场景里，造成的结果是显示的消费进度可能比实际上慢，导致生产者有可能在可以生产的情况下没有去生产。</p> \n <p>但生产者看的是多个消费者中最慢的那个消费进度，所以影响可能没有那么大。</p> \n <h2><a id=\"Sequencer_1718\"></a>核心类Sequencer</h2> \n <p>Sequencer 是生产者与缓存RingBuffer之间的桥梁、是 Disruptor 的真正核心。</p> \n <p>Sequencer 负责在生产者和消费者之间快速、正确地传递数据的序号。</p> \n <p>生产者发布 event 的时候首先需要预定一个 sequence，Sequencer 就是计算和发布 sequence 的。</p> \n <h3><a id=\"Sequencer__1728\"></a>Sequencer 的实现类</h3> \n <p>Sequencer 接口有两个重要实现类 SingleProducerSequencer、MultiProducerSequencer ，</p> \n <p><img src=\"https://img-blog.csdnimg.cn/3b91002c58a048f8a003267f387bf62c.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"SingleProducerSequencer_1736\"></a>SingleProducerSequencer</h3> \n <p>生产者发布事件的步骤：</p> \n <ul>\n  <li>通过 Sequencer.next(n) 来预定下面 n 个可以写入的位置序号</li>\n  <li>根据序号获取事件，然后修改事件数据，然后发布 event。</li>\n </ul> \n <p>因为 RingBuffer 是环形的，一个 size为 1024 的 RingBuffer ，当拿到的序号 Sequence 为 1024 时，相当于又要去写0 位置，</p> \n <p>问题来了，假如之前的0位置的数据，还没被消费呢？</p> \n <p><strong>此时，不能直接写，如果写的话，老数据就会被覆盖了。</strong></p> \n <p>如何解决数据覆盖的问题呢？</p> \n <p>答案就是使用：Sequencer 。 Sequencer 在内部维护了一个 gatingSequences 数组：</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">volatile</span> <span class=\"token class-name\">Sequence</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> gatingSequences <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Sequence</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n</code></pre> \n <p>gatingSequences 数据里边，记录的是消费者的 Sequence ，</p> \n <p>每个消费者会维护一个自己的 Sequence 对象，来记录自己已经消费到的序例位置。</p> \n <p>每添加一个消费者，都会把消费者的 Sequence 引用添加到 gatingSequences 中。</p> \n <p>通过访问 gatingSequences，Sequencer 可以得知消费的最慢的消费者消费到了哪个位置。</p> \n <pre><code class=\"prism language-java\"><span class=\"token number\">8</span>个消费者的例子，\ngatingSequences<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token number\">7</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">,</span> <span class=\"token number\">9</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">11</span><span class=\"token punctuation\">]</span>\n最慢的消费完了<span class=\"token number\">3</span>，此时可以写seq <span class=\"token number\">19</span>的数据，但不能写seq <span class=\"token number\">20</span>。\n</code></pre> \n <p>在 next(n)方法里，如果计算出的下一个 event 的 Sequence 值减去 bufferSize</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">long</span> nextValue <span class=\"token operator\">=</span> <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>nextValue<span class=\"token punctuation\">;</span><span class=\"token keyword\">long</span> nextSequence <span class=\"token operator\">=</span> nextValue <span class=\"token operator\">+</span> n<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">long</span> wrapPoint <span class=\"token operator\">=</span> nextSequence <span class=\"token operator\">-</span> bufferSize<span class=\"token punctuation\">;</span>\n</code></pre> \n <p>得出来的 wrapPoint &gt; min(gatingSequences)，说明即将写入的位置上，之前的 event 还有消费者没有消费，这时 SingleProducerSequencer 会等待并自旋。</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>wrapPoint <span class=\"token operator\">&gt;</span> <span class=\"token punctuation\">(</span>minSequence <span class=\"token operator\">=</span> <span class=\"token class-name\">Util</span><span class=\"token punctuation\">.</span><span class=\"token function\">getMinimumSequence</span><span class=\"token punctuation\">(</span>gatingSequences<span class=\"token punctuation\">,</span> nextValue<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>    <span class=\"token punctuation\">{\n    <!-- --></span>    \n  <span class=\"token class-name\">LockSupport</span><span class=\"token punctuation\">.</span><span class=\"token function\">parkNanos</span><span class=\"token punctuation\">(</span><span class=\"token number\">1L</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>   \n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>举个例子，gatingSequences=[7, 8, 9, 10, 3, 4, 5, 6, 11]， RingBuffer size 16 的情况下，如果算出来的 nextSequence 是 20，wrapPoint 是 20-16=4， 这时 gatingSequences 里最小的是 3。</p> \n <p>说明下一个打算写入的位置是 wrapPoint 4，但最慢的消费者才消费到 3，你不能去覆盖之前 4 上的数据，这时只能等待，等消费者把之前的 4 消费掉。</p> \n <p>为什么 wrapPoint = nextSequence - bufferSize，而不是 bufferSize 的 n 倍呢，因为消费者只能落后生产者一圈，不然就已经存在数据覆盖了。</p> \n <p>等到 SingleProducerSequencer 自旋到下一个位置所有人都消费过的时候，它就可以从 next 方法中返回，生产者拿着 sequence 就可以继续去发布。</p> \n <h3><a id=\"MultiProducerSequencer_1810\"></a>MultiProducerSequencer</h3> \n <p>MultiProducerSequencer 是在多个生产者的场合使用的，多个生产者的情况下存在竞争，导致它的实现更加复杂。</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">int</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> availableBuffer<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">int</span> indexMask<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">int</span> indexShift<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">public</span> <span class=\"token class-name\">MultiProducerSequencer</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> bufferSize<span class=\"token punctuation\">,</span> <span class=\"token keyword\">final</span> <span class=\"token class-name\">WaitStrategy</span> waitStrategy<span class=\"token punctuation\">)</span><span class=\"token punctuation\">{\n    <!-- --></span>   \n\n    <span class=\"token keyword\">super</span><span class=\"token punctuation\">(</span>bufferSize<span class=\"token punctuation\">,</span> waitStrategy<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  \n    availableBuffer <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token keyword\">int</span><span class=\"token punctuation\">[</span>bufferSize<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>  \n    indexMask <span class=\"token operator\">=</span> bufferSize <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span>  \n    indexShift <span class=\"token operator\">=</span> <span class=\"token class-name\">Util</span><span class=\"token punctuation\">.</span><span class=\"token function\">log2</span><span class=\"token punctuation\">(</span>bufferSize<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>   \n    <span class=\"token function\">initialiseAvailableBuffer</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>数据结构上多出来的主要就是这个 availableBuffer，用来记录 RingBuffer 上哪些位置有数据可以读。</p> \n <p>还是从 Sequencer.next(n)说起，计算下一个数据位 Sequence 的逻辑是一样的，包括消费者落后导致 Sequencer 自旋等待的逻辑。不同的是因为有多个 publisher 同时访问 Sequencer.next(n)方法，所以在确定最终位置的时候用了一个 CAS 操作，如果失败了就自旋再来一次。</p> \n <pre><code class=\"prism language-java\">cursor<span class=\"token punctuation\">.</span><span class=\"token function\">compareAndSet</span><span class=\"token punctuation\">(</span>current<span class=\"token punctuation\">,</span> next<span class=\"token punctuation\">)</span>\n</code></pre> \n <p>另一个不同的地方是 publish(final long sequence) 方法，SingleProducer 的版本很简单，就是移动了一下 cursor。</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">publish</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">long</span> sequence<span class=\"token punctuation\">)</span><span class=\"token punctuation\">{\n    <!-- --></span>  \n\ncursor<span class=\"token punctuation\">.</span><span class=\"token function\">set</span><span class=\"token punctuation\">(</span>sequence<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>    \nwaitStrategy<span class=\"token punctuation\">.</span><span class=\"token function\">signalAllWhenBlocking</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>MultiProducer 的版本则是</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">publish</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">final</span> <span class=\"token keyword\">long</span> sequence<span class=\"token punctuation\">)</span><span class=\"token punctuation\">{\n    <!-- --></span> \n\n<span class=\"token function\">setAvailable</span><span class=\"token punctuation\">(</span>sequence<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>   \nwaitStrategy<span class=\"token punctuation\">.</span><span class=\"token function\">signalAllWhenBlocking</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>setAvailable 做了什么事呢，它去设置 availableBuffer 的状态位了。给定一个 sequence，先计算出对应的数组下标 index，然后计算出在那个 index 上要写的数据 availabilityFlag，最后执行</p> \n <pre><code class=\"prism language-java\">availableBuffer<span class=\"token punctuation\">[</span>index<span class=\"token punctuation\">]</span><span class=\"token operator\">=</span>availabilityFlag\n</code></pre> \n <p>根据 calculateAvailabilityFlag(sequence) 方法计算出来的 availabilityFlag 实际上是该 sequence 环绕 RingBuffer 的圈数。</p> \n <pre><code class=\"prism language-java\">availableBuffer<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token number\">6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">]</span>例子：前<span class=\"token number\">4</span>个已经走到第<span class=\"token number\">6</span>圈。\n</code></pre> \n <p>availableBuffer 主要用于判断一个 sequence 下的数据是否可用</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">boolean</span> <span class=\"token function\">isAvailable</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">long</span> sequence<span class=\"token punctuation\">)</span><span class=\"token punctuation\">{\n    <!-- --></span>   \n<span class=\"token keyword\">int</span> index <span class=\"token operator\">=</span> <span class=\"token function\">calculateIndex</span><span class=\"token punctuation\">(</span>sequence<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>    \n<span class=\"token keyword\">int</span> flag <span class=\"token operator\">=</span> <span class=\"token function\">calculateAvailabilityFlag</span><span class=\"token punctuation\">(</span>sequence<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>   \n<span class=\"token keyword\">long</span> bufferAddress <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>index <span class=\"token operator\">*</span> <span class=\"token constant\">SCALE</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token constant\">BASE</span><span class=\"token punctuation\">;</span>  \n<span class=\"token keyword\">return</span> <span class=\"token constant\">UNSAFE</span><span class=\"token punctuation\">.</span><span class=\"token function\">getIntVolatile</span><span class=\"token punctuation\">(</span>availableBuffer<span class=\"token punctuation\">,</span> bufferAddress<span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> flag<span class=\"token punctuation\">;</span>\n\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>作为比较，来看一下 SingleProducer 的方法</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">boolean</span> <span class=\"token function\">isAvailable</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">long</span> sequence<span class=\"token punctuation\">)</span><span class=\"token punctuation\">{\n    <!-- --></span>   \n<span class=\"token keyword\">return</span> sequence <span class=\"token operator\">&lt;=</span> cursor<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>在单个生产者的场景下，publishEvent 的时候才会推进 cursor，所以只要 sequence&lt;=cursor，就说明数据是可消费的。</p> \n <p>多个生产者的场景下，在 next(n)方法中，就已经通过 cursor.compareAndSet(current, next) 移动 cursor 了，此时 event 还没有 publish，所以 cursor 所在的位置不能保证 event 一定可用。</p> \n <p>在 publish 方法中是去 setAvailable(sequence)了，所以 availableBuffer 是数据是否可用的标志。那为什么值要写成圈数呢，应该是避免把上一轮的数据当成这一轮的数据，错误判断 sequence 是否可用。</p> \n <p>另一个值得一提的是 getHighestPublishedSequence 方法，这个是消费者用来查询最高可用 event 数据的位置。</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">long</span> <span class=\"token function\">getHighestPublishedSequence</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">long</span> lowerBound<span class=\"token punctuation\">,</span> <span class=\"token keyword\">long</span> availableSequence<span class=\"token punctuation\">)</span><span class=\"token punctuation\">{\n    <!-- --></span> \n    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">long</span> sequence <span class=\"token operator\">=</span> lowerBound<span class=\"token punctuation\">;</span> sequence <span class=\"token operator\">&lt;=</span> availableSequence<span class=\"token punctuation\">;</span> sequence<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> \n    <span class=\"token punctuation\">{\n    <!-- --></span>       \n     <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span><span class=\"token function\">isAvailable</span><span class=\"token punctuation\">(</span>sequence<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>       \n     <span class=\"token punctuation\">{\n    <!-- --></span>        \n      <span class=\"token keyword\">return</span> sequence <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span>     \n     <span class=\"token punctuation\">}</span>    \n    <span class=\"token punctuation\">}</span>   \n    <span class=\"token keyword\">return</span> availableSequence<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>range，依次查询 availableBuffer，直到发现不可用的 Sequence，那么该 Sequence 之前的都是可用的。或全部都是可用的。</p> \n <p>单生产者的版本:</p> \n <pre><code class=\"prism language-java\">    <span class=\"token keyword\">public</span> <span class=\"token keyword\">long</span> <span class=\"token function\">getHighestPublishedSequence</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">long</span> lowerBound<span class=\"token punctuation\">,</span> <span class=\"token keyword\">long</span> availableSequence<span class=\"token punctuation\">)</span> \n    <span class=\"token punctuation\">{\n    <!-- --></span>    \n    <span class=\"token keyword\">return</span> availableSequence<span class=\"token punctuation\">;</span>  \n    <span class=\"token punctuation\">}</span>\n</code></pre> \n <p>说完了生产者，下面来看看消费者</p> \n <h2><a id=\"__1954\"></a>核心类消费者仓库 和消费者信息</h2> \n <h3><a id=\"_ConsumerRepository_1958\"></a>消费者仓库 ConsumerRepository</h3> \n <p>Disruptor中，通过ConsumerRepository来管理所有消费者，主要维护了以下结构：</p> \n <ul>\n  <li>EventHandler 到 消费者处理器 信息的映射，用于信息查询</li>\n </ul> \n <p><img src=\"https://img-blog.csdnimg.cn/0ae8947d3b9f455690b417afd3e0759c.png\" alt=\"在这里插入图片描述\"></p> \n <ul>\n  <li>Sequence 到消费者信息的映射</li>\n </ul> \n <p>ConsumerInfo 和 Sequence 是 一对多 关系</p> \n <p>一个 ConsumerInfo 消费者 可能有多个Sequence</p> \n <p>但是 一个Sequence只从属一个消费者。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/0fc9a1d4a4bd41f499e154ea8a71059a.png\" alt=\"在这里插入图片描述\"></p> \n <p>核心代码如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/44543f2512244d438ebdaff2fa62065f.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"_ConsumerInfo_1986\"></a>消费者的信息 ConsumerInfo</h3> \n <p>ConsumerRepository用于维护Disruptor的所有消费者的信息，管理的集合类里主要有ConsumerInfo接口，</p> \n <p><img src=\"https://img-blog.csdnimg.cn/d73e3ca7f5374207b8f206f8c88711ff.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"__1996\"></a>消费者的信息 实现类</h3> \n <p>ConsumerInfo 维护了消费者信息的抽象，目前主要有两个实现类：</p> \n <ul>\n  <li>EventProcessorInfo 单事件处理器消费者信息</li>\n  <li>WorkerPoolInfo 线程池消费者信息对象/工作者池信息。</li>\n </ul> \n <p>EventProcessorInfo ： 一个单线程的消费者(只有一个EventProcessor)， 代理EventHandler，管理处理事件以外的其他事情(如：拉取事件，等待事件…)</p> \n <p>WorkerPoolInfo 表示： WorkPool整体是一个消费者，是一个多线程的消费者，每个生产者publish的事件只会被WorkerPool里的某一个WorkProcessor消费</p> \n <p><img src=\"https://img-blog.csdnimg.cn/d73e3ca7f5374207b8f206f8c88711ff.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"WorkerPoolInfo_2013\"></a>WorkerPoolInfo多线程消费者信息</h3> \n <p>WorkerPoolInfo 包含了一个 WorkerPool 类型的成员</p> \n <p>WorkerPool 和 处理器 没有任何 继承关系，是一个独立的类</p> \n <p>协作者模式下，所有的消费者共用一个workSequence，通过CAS写workSequence</p> \n <p>多线程消费者信息, 包含了多个 工作处理器， 多个 工作处理器 ，放在下面的数组中</p> \n <pre><code class=\"prism language-java\"><span class=\"token comment\">// WorkProcessors are created to wrap each of the provided WorkHandlersprivate final WorkProcessor&lt;?&gt;[] workProcessors; </span>\n</code></pre> \n <p>由 WorkerPool的start方法 启动 WorkProcessor 工作处理器</p> \n <p><img src=\"https://img-blog.csdnimg.cn/ab10e8962fb340bd965edd5b15e9498c.png\" alt=\"在这里插入图片描述\"></p> \n <h2><a id=\"_2033\"></a>消费者处理器</h2> \n <p>Disruptor的消费者依赖EventProcessor 事件处理器。</p> \n <blockquote> \n  <p>handler和processer都可以翻译为“处理器”，但是process侧重于 处理执行，实际执行，</p> \n  <p>processer与cpu有关系，一个processer事件处理器关联一个执行线程</p> \n  <p>而handle侧重于 业务处理器，表示用户逻辑的处理， process表示 handler 的执行过程</p> \n  <p>handle和process 的关系，类似于 程序 与进程的关系</p> \n </blockquote> \n <p>消费者处理器类型比较多， uml图如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/f71d79ae17b346ca966880107c8b1eff.png\" alt=\"在这里插入图片描述\"></p> \n <p>主要的消费者处理器类型，两种：</p> \n <ul>\n  <li>BatchEventProcessor 单线程批处理消费者，同一批次添加的消费者，会消费每一个event</li>\n  <li>WorkProcessor 消费者池，同一批次添加的消费者，每个event只会被其中一个processer 消费。</li>\n </ul> \n <p>WorkProcessor 通过 WorkerPool 进行管理</p> \n <h3><a id=\"BatchEventProcessor_2062\"></a>BatchEventProcessor单线程批处理事件</h3> \n <p>在使用BatchEventProcessor时，通过Disruptor#handleEventsWith方法可以获取一个EventHandlerGroup，再通过EventHandlerGroup的and和then方法可以构建一个复杂的消费者链。</p> \n <h3><a id=\"EventHandlerGroup_2070\"></a>事件消费者组EventHandlerGroup</h3> \n <p>EventHandlerGroup表示一组事件消费者，内部持有了Disruptor类实例disruptor，其大部分功能都是通过调用disruptor实现，其实可以算作是Disruptor这个辅助类的一部分。</p> \n <p>EventHandlerGroup.java</p> \n <p>设置批处理程序以使用环形缓冲区中的事件。 这些处理程序仅在此组中的每个{@link EventProcessor}处理完事件后处理事件。<br> 该方法通常用作链的一部分。 例如，如果处理程序A必须在处理程序B dw.handleEventsWith（A）之前处理事件。那么（B）<br> @param处理将处理事件的批处理程序。<br> @return {@link EventHandlerGroup}，可用于在创建的事件处理器上设置事件处理器障碍。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/b96ab775043f08a2c75c68ced77a7ace.png\" alt=\"img\"></p> \n <p>设置批处理程序以处理来自环形缓冲区的事件。</p> \n <p>这些处理程序仅在此组中的每个{@link EventProcessor}处理完事件后处理事件。</p> \n <p>该方法通常用作链的一部分。 例如，如果A必须在Bdw.after（A）.handleEventsWith（B）之前处理事件<br> @param处理将处理事件的批处理程序。<br> @return {@link EventHandlerGroup}，可用于在创建的事件处理器上设置事件处理器障碍。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/08adf795c1d86235cbf49ab56850caac.png\" alt=\"img\"></p> \n <pre><code class=\"prism language-java\"><span class=\"token comment\">// 由EventHandlerGroup调用时，barrierSequences是EventHandlerGroup实例的序列，</span>\n<span class=\"token comment\">//也就是上一个事件处理者组的序列，作为当前事件处理的门控，防止后边的消费链超前</span>\n<span class=\"token comment\">// 如果第一次调用handleEventsWith，则barrierSequences为空</span>\n<span class=\"token class-name\">EventHandlerGroup</span><span class=\"token operator\">&lt;</span><span class=\"token class-name\">T</span> <span class=\"token function\">createEventProcessors</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">final</span> <span class=\"token class-name\">Sequence</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> barrierSequences<span class=\"token punctuation\">,</span>\n                                           <span class=\"token keyword\">final</span> <span class=\"token class-name\">EventHandler</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">?</span> <span class=\"token keyword\">super</span> <span class=\"token class-name\">T</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> eventHandlers<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token function\">checkNotStarted</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        \n        <span class=\"token comment\">// 对应此事件处理器组的序列组</span>\n        <span class=\"token keyword\">final</span> <span class=\"token class-name\">Sequence</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> processorSequences <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Sequence</span><span class=\"token punctuation\">[</span>eventHandlers<span class=\"token punctuation\">.</span>length<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">final</span> <span class=\"token class-name\">SequenceBarrier</span> barrier <span class=\"token operator\">=</span> ringBuffer<span class=\"token punctuation\">.</span><span class=\"token function\">newBarrier</span><span class=\"token punctuation\">(</span>barrierSequences<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> eventHandlersLength <span class=\"token operator\">=</span> eventHandlers<span class=\"token punctuation\">.</span>length<span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> eventHandlersLength<span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n            <span class=\"token keyword\">final</span> <span class=\"token class-name\">EventHandler</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">?</span> <span class=\"token keyword\">super</span> <span class=\"token class-name\">T</span> eventHandler <span class=\"token operator\">=</span> eventHandlers<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n     \n            <span class=\"token keyword\">final</span> <span class=\"token class-name\">BatchEventProcessor</span><span class=\"token operator\">&lt;</span><span class=\"token class-name\">T</span> batchEventProcessor <span class=\"token operator\">=</span>\n                <span class=\"token keyword\">new</span> <span class=\"token class-name\">BatchEventProcessor</span><span class=\"token operator\">&lt;</span><span class=\"token punctuation\">(</span>ringBuffer<span class=\"token punctuation\">,</span> barrier<span class=\"token punctuation\">,</span> eventHandler<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n            <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>exceptionHandler <span class=\"token operator\">!=</span> <span class=\"token keyword\">null</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n                batchEventProcessor<span class=\"token punctuation\">.</span><span class=\"token function\">setExceptionHandler</span><span class=\"token punctuation\">(</span>exceptionHandler<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n\n            consumerRepository<span class=\"token punctuation\">.</span><span class=\"token function\">add</span><span class=\"token punctuation\">(</span>batchEventProcessor<span class=\"token punctuation\">,</span> eventHandler<span class=\"token punctuation\">,</span> barrier<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            processorSequences<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> batchEventProcessor<span class=\"token punctuation\">.</span><span class=\"token function\">getSequence</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token comment\">// 每次添加完事件处理器后，更新门控序列，以便后续调用链的添加</span>\n        <span class=\"token comment\">// 所谓门控，是指后续消费链的消费，不能超过前边</span>\n        <span class=\"token function\">updateGatingSequencesForNextInChain</span><span class=\"token punctuation\">(</span>barrierSequences<span class=\"token punctuation\">,</span> processorSequences<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token keyword\">return</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">EventHandlerGroup</span><span class=\"token operator\">&lt;</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">this</span><span class=\"token punctuation\">,</span> consumerRepository<span class=\"token punctuation\">,</span> processorSequences<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n</code></pre> \n <pre><code class=\"prism language-java\"><span class=\"token comment\">// 为消费链下一组消费者，更新门控序列</span>\n<span class=\"token comment\">// barrierSequences是上一组事件处理器组的序列（如果本次是第一次，则为空数组），本组不能超过上组序列值</span>\n<span class=\"token comment\">// processorSequences是本次要设置的事件处理器组的序列</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">void</span> <span class=\"token function\">updateGatingSequencesForNextInChain</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">final</span> <span class=\"token class-name\">Sequence</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> barrierSequences<span class=\"token punctuation\">,</span> <span class=\"token keyword\">final</span> <span class=\"token class-name\">Sequence</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> processorSequences<span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>processorSequences<span class=\"token punctuation\">.</span>length  <span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">{\n    <!-- --></span>\n            <span class=\"token comment\">// 将本组序列添加到Sequencer中的gatingSequences中</span>\n            ringBuffer<span class=\"token punctuation\">.</span><span class=\"token function\">addGatingSequences</span><span class=\"token punctuation\">(</span>processorSequences<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n             <span class=\"token comment\">// 将上组序列从Sequencer中的gatingSequences中，gatingSequences一直保存消费链末端消费者的序列组</span>\n            <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">final</span> <span class=\"token class-name\">Sequence</span> barrierSequence <span class=\"token operator\">:</span> barrierSequences<span class=\"token punctuation\">)</span>\n            <span class=\"token punctuation\">{\n    <!-- --></span>\n                ringBuffer<span class=\"token punctuation\">.</span><span class=\"token function\">removeGatingSequence</span><span class=\"token punctuation\">(</span>barrierSequence<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n            <span class=\"token comment\">// 取消标记上一组消费者为消费链末端</span>\n            consumerRepository<span class=\"token punctuation\">.</span><span class=\"token function\">unMarkEventProcessorsAsEndOfChain</span><span class=\"token punctuation\">(</span>barrierSequences<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n</code></pre> \n <p>可以看到，使用BatchEventProcessor构建消费者链时的逻辑都在<code>createEventProcessors</code>方法中。</p> \n <p>ConsumerRepository 类主要保存消费者的各种关系，如通过EventHandler引用获取EventProcessorInfo信息，通过Sequence获取ConsumerInfo信息等。</p> \n <p>因为要使用引用做key，所以数据结构使用IdentityHashMap。</p> \n <p>IdentityHashMap和HashMap最大的不同，就是使用==而不是equals比较key。</p> \n <p>这个createEventProcessors方法接收两个参数，barrierSequences表示当前消费者组的屏障序列数组，如果当前消费者组是第一组，则取一个空的序列数组；否则，barrierSequences就是上一组消费者组的序列数组。</p> \n <p>createEventProcessors方法的另一个参数eventHandlers，这个参数是代表事件消费逻辑的EventHandler数组。<br> Disruptor为每个EventHandler实现类都创建了一个对应的BatchEventProcessor。</p> \n <p>在构建BatchEventProcessor时需要以下传入三个构造参数：dataProvider是数据存储结构如RingBuffer；sequenceBarrier用于跟踪生产者游标，协调数据处理；</p> \n <p>eventHandler是用户实现的事件处理器，也就是实际的消费者。</p> \n <p>注意，Disruptor并非为每个BatchEventProcessor都创建一个新的SequenceBarrier，而是每个消费者组共用一个SequenceBarrier。<br> BatchEventProcessor定义，请参见源码仓库。</p> \n <p>至于为什么要叫做BatchEventProcessor，可以看看在run()方法里每次waitFor获取的availableSequence是当前能够使用的最大值，然后再循环处理这些数据。</p> \n <p>这样当消费者有瞬时抖动，导致暂时落后生产者时，可在下一次循环中，批量处理所有落后的事件。</p> \n <p>可以看出：</p> \n <p>BatchEventProcessor可以处理超时，可以处理中断，可以通过用户实现的异常处理类处理异常，同时，发生异常之后再次启动，不会漏消费，也不会重复消费。</p> \n <h2><a id=\"SequenceBarrier_2192\"></a>SequenceBarrier协调屏障</h2> \n <p>SequenceBarrier：一个协调屏障，</p> \n <p>SequenceBarrier用来跟踪发布者(publisher)的游标(cursor)和事件处理者(EventProcessor)的序列号(sequence)。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/1df68b65de1a4a6b9b775768f515e60e.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"disrutor_2202\"></a>disrutor管理两种依赖关系</h3> \n <p>disrutor需要管理两种依赖关系：</p> \n <ul>\n  <li>生产者与消费者之间的依赖关系</li>\n  <li>以及消费者与消费者之间的依赖关系</li>\n </ul> \n <p>消费者与消费者之间的依赖关系 ,使用的 是sequenceBarrier 的 dependentSequence 来管理</p> \n <p>消费者对生产者之间的依赖关系 ,使用的 是sequenceBarrier 的 seqquencer 来管理</p> \n <p>生产者对最慢+末端消费者直接的依赖关系，使用门禁序号 gatingSequence 来管理</p> \n <h3><a id=\"CAS_2217\"></a>消除锁和CAS操作</h3> \n <ul>\n  <li><strong>Disruptor</strong>中,通过联合使用<strong>SequenceBarrier</strong>和<strong>Sequence,</strong> 协调和管理消费者和生产者之间的处理关系,避免了锁和<strong>CAS</strong>操作</li>\n  <li>Disruptor中的各个消费者和生产者持有自己的序号Sequence,</li>\n </ul> \n <p>序号Sequence需要满足以下条件:</p> \n <ul>\n  <li><strong>条件一:</strong> 消费者的序号<strong>Sequence</strong>的数值必须小于生产者的序号<strong>Sequence</strong>的数值</li>\n  <li><strong>条件二:</strong> 消费者的序号<strong>Sequence</strong>的数值必须小于依赖关系中前置的消费者的序号<strong>Sequence</strong>的数值</li>\n  <li><strong>条件三:</strong> 生产者的序号<strong>Sequence</strong>的数值不能大于消费者正在消费的序号<strong>Sequence</strong>的数值,防止生产者速度过快,将还没有来得及消费的事件消息覆盖</li>\n </ul> \n <blockquote> \n  <p><strong>条件一</strong>和<strong>条件二</strong>在<strong>SequenceBarrier</strong>中的<strong>waitFor()</strong> 方法中实现:<br> 条件三是针对生产者建立的SequenceBarrier,逻辑判定发生在生产者从RingBuffer获取下一个可用的entry时,RingBuffer会将获取下一个可用的entry委托给Sequencer处理:</p> \n </blockquote> \n <h3><a id=\"SequenceBarrier_2232\"></a>SequenceBarrier的几个方法</h3> \n <p>long waitFor(long sequence) throws AlertException, InterruptedException, TimeoutException;</p> \n <p>等待给定的序列号可用，用来消费。</p> \n <p>long getCursor();</p> \n <p>获取当前能读取到的游标(cursor)值。</p> \n <p>boolean isAlerted();</p> \n <p>barrier当前的状态是否是警报(alert)状态。</p> \n <p>void alert();</p> \n <p>提醒EventProcessor，一个状态发生了变化，直到清除之前，一直处于这种状态下。</p> \n <p>void clearAlert();</p> \n <p>清除当前的警报状态。</p> \n <p>void checkAlert() throws AlertException;</p> \n <p>检查是否提出了警报，如果提出了，就抛出异常。</p> \n <h3><a id=\"SequenceBarrier_2270\"></a>SequenceBarrier进行依赖消费</h3> \n <ol>\n  <li> <p>不同的BatchEventProcessor之间通过SequenceBarrier进行依赖消费。</p> <p>原理如下图所示：<br> <img src=\"https://img-blog.csdnimg.cn/img_convert/1c31abd096f6dd89843943784e2e2b86.jpeg\" alt=\"这里写图片描述\"></p> <p>假设我们有三个消费者BatchEventProcessor1，BatchEventProcessor2，BatchEventProcessor3.</p> <p>1需要先于2和3消费，那么构建BatchEventProcessor和SequenceBarrier时，</p> <p>我们需要让BatchEventProcessor2和BatchEventProcessor3的SequenceBarrier的dependentSequence中加入SequenceBarrier1的sequence。</p> <p><strong>其实这里2和3共用一个SequenceBarrier就行。</strong></p> </li>\n </ol> \n <h3><a id=\"ProcessingSequenceBarrier_2291\"></a>ProcessingSequenceBarrier</h3> \n <p>接下来看下它的实现类 - ProcessingSequenceBarrier</p> \n <p>SequenceBarrier只有一个重要的实现类，就是ProcessingSequenceBarrier。</p> \n <p>ProcessingSequenceBarrier有以下几个重要的属性：</p> \n <ul>\n  <li>生产者Sequencer，</li>\n  <li>消费定位cursorSequence，</li>\n  <li>等待策略waitStrategy ,</li>\n  <li>还有一组依赖sequence：dependentSequence</li>\n </ul> \n <p><img src=\"https://img-blog.csdnimg.cn/8a1c2f6d3db74915be4881275d63591f.png\" alt=\"在这里插入图片描述\"></p> \n <p>（上图是从它的构造器中截取的一部分）</p> \n <p>可以看出如果dependentSequence的长度是0，就将cursorSequence指向它，即两者有着相同的引用。</p> \n <p>否则，通过FixedSequenceGroup来创建它，即与cursorSequence之间，两者独立存在。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/20191015091444521.png\" alt=\"img\"></p> \n <p>然后重点看下如下几个实现方法：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/20191015091724681.png\" alt=\"img\"></p> \n <p><img src=\"https://img-blog.csdnimg.cn/20191015091807835.png\" alt=\"img\"></p> \n <p><img src=\"https://img-blog.csdnimg.cn/20191015091905820.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NTYxODky,size_16,color_FFFFFF,t_70\" alt=\"img\"></p> \n <h2><a id=\"RingBuffer_2326\"></a>RingBuffer预分配内存</h2> \n <p>RingBuffer使用数组Object[] entries来存储元素:</p> \n <ul>\n  <li>初始化<strong>RingBuffer</strong>时,会将所有数组元素<strong>entries</strong>的指定为特定的事件<strong>Event</strong>参数,此时<strong>Event</strong>中的<strong>detail</strong>属性为<strong>null</strong></li>\n  <li>生产者向<strong>RingBuffer</strong>写入消息时 <strong>,RingBuffer</strong>不是直接将数组元素<strong>entries</strong>指向<strong>Event</strong>对象,而是先获取<strong>Event</strong>对象,更改<strong>Event</strong>对象中的<strong>detail</strong>属性</li>\n  <li>消费者在消费时,也是从<strong>RingBuffer</strong>中读取<strong>Event,</strong> 读取<strong>Event</strong>对象中的<strong>detail</strong>属性</li>\n  <li>由此可见,在生产和消费过程中 <strong>,RingBuffer</strong>中的数组元素<strong>entries</strong>没有发生任何变化,没有产生临时对象,数组中的元素一直存活,直到<strong>RingBuffer</strong>消亡</li>\n </ul> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">private</span> <span class=\"token keyword\">void</span> <span class=\"token function\">fill</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">EventFactory</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">E</span><span class=\"token punctuation\">&gt;</span></span> eventFactory<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n	<span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> bufferSize<span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n		<span class=\"token comment\">// 使用工厂方法初始化数组中的entries元素</span>\n		entries<span class=\"token punctuation\">[</span><span class=\"token constant\">BUFFER_PAD</span> <span class=\"token operator\">+</span> i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> eventFactory<span class=\"token punctuation\">.</span><span class=\"token function\">newInstance</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n	<span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n</code></pre> \n <p>通过以上方式,可以最小化<strong>JVM</strong>中的垃圾回收<strong>GC</strong>的频率,提升性能</p> \n <h2><a id=\"Disruptor_2353\"></a>Disruptor的等待策略</h2> \n <h3><a id=\"uml_2357\"></a>uml图</h3> \n <p><img src=\"https://img-blog.csdnimg.cn/d81f96fae85b4a31bfa5005e7acf949a.png\" alt=\"在这里插入图片描述\"></p> \n <p>Disruptor默认的等待策略是BlockingWaitStrategy。</p> \n <p>这个策略的内部适用一个锁和条件变量来控制线程的执行和等待（Java基本的同步方法）。</p> \n <p>BlockingWaitStrategy是最慢的等待策略，但也是CPU使用率最低和最稳定的选项。然而，可以根据不同的部署环境调整选项以提高性能。</p> \n <h3><a id=\"SleepingWaitStrategy_2371\"></a>SleepingWaitStrategy</h3> \n <p>和BlockingWaitStrategy一样，SpleepingWaitStrategy的CPU使用率也比较低。</p> \n <p>它的方式是循环等待并且在循环中间调用LockSupport.parkNanos(1)来睡眠，（在Linux系统上面睡眠时间60µs）.</p> \n <p>然而，它的优点在于生产线程只需要计数，而不执行任何指令。并且没有条件变量的消耗。</p> \n <p>但是，事件对象从生产者到消费者传递的延迟变大了。</p> \n <p>SleepingWaitStrategy最好用在不需要低延迟，而且事件发布对于生产者的影响比较小的情况下。比如异步日志功能。</p> \n <h4><a id=\"_2387\"></a>源码</h4> \n <pre><code class=\"prism language-java\"><span class=\"token comment\">/* * Copyright 2011 LMAX Ltd. * * Licensed under the Apache License, Version 2.0 (the \"License\"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */</span>\n<span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>lmax<span class=\"token punctuation\">.</span>disruptor</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token import\"><span class=\"token namespace\">java<span class=\"token punctuation\">.</span>util<span class=\"token punctuation\">.</span>concurrent<span class=\"token punctuation\">.</span>locks<span class=\"token punctuation\">.</span></span><span class=\"token class-name\">Condition</span></span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">import</span> <span class=\"token import\"><span class=\"token namespace\">java<span class=\"token punctuation\">.</span>util<span class=\"token punctuation\">.</span>concurrent<span class=\"token punctuation\">.</span>locks<span class=\"token punctuation\">.</span></span><span class=\"token class-name\">Lock</span></span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">import</span> <span class=\"token import\"><span class=\"token namespace\">java<span class=\"token punctuation\">.</span>util<span class=\"token punctuation\">.</span>concurrent<span class=\"token punctuation\">.</span>locks<span class=\"token punctuation\">.</span></span><span class=\"token class-name\">ReentrantLock</span></span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token import\"><span class=\"token namespace\">com<span class=\"token punctuation\">.</span>lmax<span class=\"token punctuation\">.</span>disruptor<span class=\"token punctuation\">.</span>util<span class=\"token punctuation\">.</span></span><span class=\"token class-name\">ThreadHints</span></span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">/** * Blocking strategy that uses a lock and condition variable for {@link EventProcessor}s waiting on a barrier. * &lt;p&gt; * This strategy can be used when throughput and low-latency are not as important as CPU resource. */</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">BlockingWaitStrategy</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">WaitStrategy</span>\n<span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> <span class=\"token class-name\">Lock</span> lock <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">ReentrantLock</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> <span class=\"token class-name\">Condition</span> processorNotifyCondition <span class=\"token operator\">=</span> lock<span class=\"token punctuation\">.</span><span class=\"token function\">newCondition</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n    <span class=\"token comment\">/** * * @param sequence to be waited on. 消费者想要消费的下一个序号 * @param cursorSequence 当前ringbuffer最大的生产者序号？ * @param dependentSequence on which to wait. * @param barrier the processor is waiting on. * @return * @throws AlertException * @throws InterruptedException */</span>\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">long</span> <span class=\"token function\">waitFor</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">long</span> sequence<span class=\"token punctuation\">,</span> <span class=\"token class-name\">Sequence</span> cursorSequence<span class=\"token punctuation\">,</span> <span class=\"token class-name\">Sequence</span> dependentSequence<span class=\"token punctuation\">,</span> <span class=\"token class-name\">SequenceBarrier</span> barrier<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">throws</span> <span class=\"token class-name\">AlertException</span><span class=\"token punctuation\">,</span> <span class=\"token class-name\">InterruptedException</span>\n    <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token keyword\">long</span> availableSequence<span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// cursorSequence:生产者的序号</span>\n        <span class=\"token comment\">// 第一重条件判断：如果消费者消费速度，大于生产者生产速度（即消费者要消费的下一个数据已经大于生产者生产的数据时），</span>\n        <span class=\"token comment\">// 那么消费者等待一下</span>\n        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>cursorSequence<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> sequence<span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">{\n    <!-- --></span>\n            lock<span class=\"token punctuation\">.</span><span class=\"token function\">lock</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token keyword\">try</span>\n            <span class=\"token punctuation\">{\n    <!-- --></span>\n                <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>cursorSequence<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> sequence<span class=\"token punctuation\">)</span>\n                <span class=\"token punctuation\">{\n    <!-- --></span>\n                    barrier<span class=\"token punctuation\">.</span><span class=\"token function\">checkAlert</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                    processorNotifyCondition<span class=\"token punctuation\">.</span><span class=\"token function\">await</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                <span class=\"token punctuation\">}</span>\n            <span class=\"token punctuation\">}</span>\n            <span class=\"token keyword\">finally</span>\n            <span class=\"token punctuation\">{\n    <!-- --></span>\n                lock<span class=\"token punctuation\">.</span><span class=\"token function\">unlock</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token comment\">// 第一重条件判断：自旋等待</span>\n        <span class=\"token comment\">// 即当前消费者线程要消费的下一个sequence，大于其前面执行链路（若有依赖关系）的任何一个消费者最小sequence（dependentSequence.get()），</span>\n        <span class=\"token comment\">// 那么这个消费者要自旋等待，</span>\n        <span class=\"token comment\">// 直到前面执行链路（若有依赖关系）的任何一个消费者最小sequence（dependentSequence.get()）已经大于等于当前消费者的sequence时，</span>\n        <span class=\"token comment\">// 说明前面执行链路的消费者已经消费完了</span>\n        <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>availableSequence <span class=\"token operator\">=</span> dependentSequence<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> sequence<span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">{\n    <!-- --></span>\n            barrier<span class=\"token punctuation\">.</span><span class=\"token function\">checkAlert</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n            <span class=\"token class-name\">ThreadHints</span><span class=\"token punctuation\">.</span><span class=\"token function\">onSpinWait</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n\n        <span class=\"token keyword\">return</span> availableSequence<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\">/** * 如果生产者新生产一个元素，那么唤醒所有消费者 */</span>\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">signalAllWhenBlocking</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">{\n    <!-- --></span>\n        lock<span class=\"token punctuation\">.</span><span class=\"token function\">lock</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">try</span>\n        <span class=\"token punctuation\">{\n    <!-- --></span>\n            processorNotifyCondition<span class=\"token punctuation\">.</span><span class=\"token function\">signalAll</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">finally</span>\n        <span class=\"token punctuation\">{\n    <!-- --></span>\n            lock<span class=\"token punctuation\">.</span><span class=\"token function\">unlock</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> <span class=\"token class-name\">String</span> <span class=\"token function\">toString</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token keyword\">return</span> <span class=\"token string\">\"BlockingWaitStrategy{\"</span> <span class=\"token operator\">+</span>\n                <span class=\"token string\">\"processorNotifyCondition=\"</span> <span class=\"token operator\">+</span> processorNotifyCondition <span class=\"token operator\">+</span>\n                <span class=\"token char\">\'}\'</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n</code></pre> \n <h3><a id=\"YieldingWaitStrategy_2501\"></a>YieldingWaitStrategy</h3> \n <p>YieldingWaitStrategy是可以被用在低延迟系统中的两个策略之一，这种策略在减低系统延迟的同时也会增加CPU运算量。</p> \n <p>YieldingWaitStrategy策略会循环等待sequence增加到合适的值。</p> \n <p>循环中调用Thread.yield()允许其他准备好的线程执行。</p> \n <p>如果需要高性能而且事件消费者线程比逻辑内核少的时候，推荐使用YieldingWaitStrategy策略。</p> \n <p>例如：在开启超线程的时候。</p> \n <h4><a id=\"_2515\"></a>源码</h4> \n <pre><code class=\"prism language-java\"><span class=\"token comment\">/* * Copyright 2011 LMAX Ltd. * * Licensed under the Apache License, Version 2.0 (the \"License\"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */</span>\n<span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>lmax<span class=\"token punctuation\">.</span>disruptor</span><span class=\"token punctuation\">;</span>\n\n\n<span class=\"token comment\">/** * Yielding strategy that uses a Thread.yield() for {@link com.lmax.disruptor.EventProcessor}s waiting on a barrier * after an initially spinning. * &lt;p&gt; * This strategy will use 100% CPU, but will more readily give up the CPU than a busy spin strategy if other threads * require CPU resource. */</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">YieldingWaitStrategy</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">WaitStrategy</span>\n<span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">int</span> <span class=\"token constant\">SPIN_TRIES</span> <span class=\"token operator\">=</span> <span class=\"token number\">100</span><span class=\"token punctuation\">;</span>\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">long</span> <span class=\"token function\">waitFor</span><span class=\"token punctuation\">(</span>\n            <span class=\"token keyword\">final</span> <span class=\"token keyword\">long</span> sequence<span class=\"token punctuation\">,</span> <span class=\"token class-name\">Sequence</span> cursor<span class=\"token punctuation\">,</span> <span class=\"token keyword\">final</span> <span class=\"token class-name\">Sequence</span> dependentSequence<span class=\"token punctuation\">,</span> <span class=\"token keyword\">final</span> <span class=\"token class-name\">SequenceBarrier</span> barrier<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">throws</span> <span class=\"token class-name\">AlertException</span><span class=\"token punctuation\">,</span> <span class=\"token class-name\">InterruptedException</span>\n    <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token keyword\">long</span> availableSequence<span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">int</span> counter <span class=\"token operator\">=</span> <span class=\"token constant\">SPIN_TRIES</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">// 如果消费者需要消费的下一个序号超过了生产者已生产数据的最大序号，</span>\n        <span class=\"token comment\">// 那么消费者需要等待，否则返回生产者已生产数据的最大序号给消费者消费即可</span>\n        <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>availableSequence <span class=\"token operator\">=</span> dependentSequence<span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> sequence<span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">{\n    <!-- --></span>\n            counter <span class=\"token operator\">=</span> <span class=\"token function\">applyWaitMethod</span><span class=\"token punctuation\">(</span>barrier<span class=\"token punctuation\">,</span> counter<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n\n        <span class=\"token keyword\">return</span> availableSequence<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token annotation punctuation\">@Override</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">signalAllWhenBlocking</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">int</span> <span class=\"token function\">applyWaitMethod</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">final</span> <span class=\"token class-name\">SequenceBarrier</span> barrier<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> counter<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">throws</span> <span class=\"token class-name\">AlertException</span>\n    <span class=\"token punctuation\">{\n    <!-- --></span>\n        barrier<span class=\"token punctuation\">.</span><span class=\"token function\">checkAlert</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token number\">0</span> <span class=\"token operator\">==</span> counter<span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">{\n    <!-- --></span>\n            <span class=\"token class-name\">Thread</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">yield</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">else</span>\n        <span class=\"token punctuation\">{\n    <!-- --></span>\n            <span class=\"token operator\">--</span>counter<span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n\n        <span class=\"token keyword\">return</span> counter<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n</code></pre> \n <h3><a id=\"BusySpinW4aitStrategy_2591\"></a>BusySpinW4aitStrategy</h3> \n <p>BusySpinWaitStrategy是性能最高的等待策略，同时也是对部署环境要求最高的策略。</p> \n <p>这个性能最好用在事件处理线程比物理内核数目还要小的时候。例如：在禁用超线程技术的时候。</p> \n <h2><a id=\"Disruptor__2599\"></a>Disruptor 的缓存行填充</h2> \n <h3><a id=\"RingBuffer__2603\"></a>RingBuffer 的缓存行填充</h3> \n <p>Disruptor RingBuffer（环形缓冲区）定义了RingBufferFields类，里面有indexMask和其他几个变量存放RingBuffer的内部状态信息。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/22392ef58796be36d5f4d1bc09f9f23a.png\" alt=\"\"></p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/01ac50db593e6c731732a39506f1a9bd.png\" alt=\"\"><img src=\"https://img-blog.csdnimg.cn/img_convert/b87f80f28ae48f0be57ae928efe7547d.png\" alt=\"并发编程框架Disruptor之高性能设计_数据_06\"></p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/4708a91e62b800e45b63e516be35853e.png\" alt=\"\"></p> \n <p>对此，Disruptor利用了缓存行填充，在 RingBufferFields里面定义的变量的前后，分别定义了7个long类型的变量：</p> \n <ul>\n  <li>前面7个来自继承的 RingBufferPad 类</li>\n  <li>后面7个直接定义在 RingBuffer 类</li>\n </ul> \n <p>这14个变量无任何实际用途。我们既不读他们，也不写他们。而RingBufferFields里面定义的这些变量都是<strong>final</strong>，第一次写入后就不会再修改。</p> \n <p>所以，一旦它被加载到CPU Cache后，只要被频繁读取访问，就不会再被换出Cache。这意味着，对于该值的读取速度，会一直是CPU Cache的访问速度，而非内存的访问速度。</p> \n <h3><a id=\"Sequence_2630\"></a>Sequence是如何消除伪共享的</h3> \n <p>从Sequence的父类Value可以看到，真正使用到的变量是Value类的value，它的前后空间都由8个long型的变量填补了，对于一个大小为64字节的缓存行，它刚好被填补满（一个long型变量value，8个字节加上前/后个7long型变量填补，7*8=56，56+8=64字节）。</p> \n <p>这样做每次把变量value读进高速缓存中时，都能把缓存行填充满，保证每次处理数据时都不会与其他变量发生冲突。</p> \n <p>当然，对于大小为64个字节的缓存行来说，如果缓存行大小大于64个字节，那么还是会出现伪共享问题，但是毕竟<strong>非64个字节的Cache Line</strong>并不是当前的主流。</p> \n <h2><a id=\"_2640\"></a>推荐阅读：</h2> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124790425\">尼恩Java面试宝典</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057567\">Springcloud gateway 底层原理、核心实战 (史上最全)</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125059491\">sentinel （史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/123420859\">分库分表 Sharding-JDBC 底层原理、核心实战（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/109459593\">分布式事务 （秒懂）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128123114\">缓存之王：Caffeine 源码、架构、原理（史上最全，10W字 超级长文）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/113751575\">缓存之王：Caffeine 的使用（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126579528\">Java Agent 探针、字节码增强 ByteBuddy（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120747767\">Docker原理（图解+秒懂+史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/116425814\">Redis分布式锁（图解 - 秒懂 - 史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85956246\">Zookeeper 分布式锁 - 图解 - 秒懂</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85922561\">Zookeeper Curator 事件监听 - 10分钟看懂</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83957259\">Netty 粘包 拆包 | 史上最全解读</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83758107\">Netty 100万级高并发服务器配置</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/102557988\">Springcloud 高并发 配置 （一文全懂）</a>》</p> \n <h2><a id=\"_2674\"></a>参考文献</h2> \n <p>https://blog.51cto.com/u_11440114/5184594</p> \n <p>https://blog.csdn.net/hxg117/article/details/78064632</p> \n <p>http://openjdk.java.net/projects/jdk8/features</p> \n <p>http://beautynbits.blogspot.co.uk/2012/11/the-end-for-false-sharing-in-java.html</p> \n <p>http://openjdk.java.net/jeps/142</p> \n <p>http://mechanical-sympathy.blogspot.co.uk/2011/08/false-sharing-java-7.html</p> \n <p>http://stackoverflow.com/questions/19892322/when-will-jvm-use-intrinsics</p> \n <p>https://blogs.oracle.com/dave/entry/java_contented_annotation_to_help</p> \n <p>https://www.jianshu.com/p/b38ffa33d64d</p> \n <p>https://blog.csdn.net/MrYushiwen/article/details/123171635</p> \n <p>https://blog.csdn.net/everyok/article/details/88889057</p> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 637);
INSERT INTO `crawlerblog` VALUES (123124022, '环形队列、 条带环形队列 Striped-RingBuffer （史上最全）', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <p>文章很长，而且持续更新，建议收藏起来，慢慢读！<a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\"><strong>疯狂创客圈总目录 博客园版</strong></a> 为您奉上珍贵的学习资源 ：</p> \n <p>免费赠送 :<a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\"><strong>《尼恩Java面试宝典》</strong></a> 持续更新+ 史上最全 + 面试必备 2000页+ 面试必备 + 大厂必备 +涨薪必备<br> 免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\"><strong>《Java高并发核心编程（卷1）加强版》</strong></a> 面试必备 + 大厂必备 +涨薪必备 加尼恩免费领<br> 免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\"><strong>《Java高并发核心编程（卷2）加强版》</strong> </a> 面试必备 + 大厂必备 +涨薪必备 加尼恩免费领<br> 免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\"><strong>《Java高并发核心编程（卷3）加强版》</strong></a> 面试必备 + 大厂必备 +涨薪必备 加尼恩免费领<br> 免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\">《<strong>尼恩Java面试宝典 最新版</strong>》 </a> 面试必备 + 大厂必备 +涨薪必备 加尼恩免费领<br> 免费赠送 资源宝库： <strong>Java 必备 百度网盘资源大合集 价值</strong>&gt;10000元 加尼恩领取</p> \n <hr> \n <h2><a id=\"_BoundedBuffer__11\"></a>高性能 BoundedBuffer 条带环形队列</h2> \n <p>Caffeine 源码中，用到几个高性能数据结构要讲</p> \n <ul>\n  <li>一个是 条带环状 队列 （<strong>超高性能、无锁队列</strong>）</li>\n  <li>一个是mpsc队列 （<strong>超高性能、无锁队列</strong>）</li>\n  <li>一个是 多级时间轮</li>\n </ul> \n <p>这里给大家 介绍 环形队列、 条带环形队列 Striped-RingBuffer 。</p> \n <p>剩下的两个结构， 稍后一点 ，使用专门的 博文介绍。</p> \n <h3><a id=\"CAS__23\"></a>CAS 的优势与核心问题</h3> \n <p>由于JVM重量级锁使用了Linux内核态下的互斥锁（Mutex），这是重量级锁开销很大的原因。</p> \n <p>抢占与释放的过程中，涉及到 进程的 用户态和 内核态， 进程的 用户空间 和内核空间之间的切换， 性能非常低。</p> \n <p>而CAS进行自旋抢锁，这些CAS操作都处于用户态下，进程不存在用户态和内核态之间的运行切换，因此JVM轻量级锁开销较小。这是 CAS 的优势。</p> \n <p>但是， 任何事情，都有两面性。</p> \n <p>CAS 的核心问题是什么呢？</p> \n <p>在争用激烈的场景下，会导致大量的CAS空自旋。</p> \n <p>比如，在大量的线程同时并发修改一个AtomicInteger时，可能有很多线程会不停地自旋，甚至有的线程会进入一个无限重复的循环中。</p> \n <p>大量的CAS空自旋会浪费大量的CPU资源，大大降低了程序的性能。</p> \n <p>除了存在CAS空自旋之外，在SMP架构的CPU平台上，大量的CAS操作还可能导致“总线风暴”，具体可参见《Java高并发核心编程 卷2 加强版》第5章的内容。</p> \n <p>在高并发场景下如何提升CAS操作性能/ 解决CAS恶性空自旋 问题呢？</p> \n <p>较为常见的方案有两种：</p> \n <ul>\n  <li>分散操作热点、</li>\n  <li>使用队列削峰。</li>\n </ul> \n <p>比如，在自增的场景中， 可以使用LongAdder替代AtomicInteger。</p> \n <p>这是一种 分散操作热点 ，空间换时间 方案，</p> \n <p>也是 分而治之的思想。</p> \n <h3><a id=\"LongAdder__Striped64_62\"></a>以空间换时间：LongAdder 以及 Striped64</h3> \n <p>Java 8提供一个新的类LongAdder，以空间换时间的方式提升高并发场景下CAS操作性能。</p> \n <p>LongAdder核心思想就是热点分离，与ConcurrentHashMap的设计思想类似：将value值分离成一个数组，当多线程访问时，通过Hash算法将线程映射到数组的一个元素进行操作；而获取最终的value结果时，则将数组的元素求和。</p> \n <p>最终，通过LongAdder将内部操作对象从单个value值“演变”成一系列的数组元素，从而减小了内部竞争的粒度。LongAdder的演变如图3-10所示。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/e2825983ceb0429999abb02ac6aa3647.png\" alt=\"在这里插入图片描述\"></p> \n <p>图3-10 LongAdder的操作对象由单个value值“演变”成了数组</p> \n <h3><a id=\"LongAdder_80\"></a>LongAdder的分治思想和架构</h3> \n <p>LongAdder的操作对象由单个value值“演变”成了数组</p> \n <p><img src=\"https://img-blog.csdnimg.cn/3bc8977586b94abeb6bd251c2419b24d.png\" alt=\"在这里插入图片描述\"></p> \n <p>LongAdder 继承了 Striped64，核心源码在 Striped64中。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/281cd787fb9841358f1153ac59f1715a.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"Striped64_96\"></a>条带累加Striped64的结构和源码</h3> \n <p><img src=\"https://img-blog.csdnimg.cn/7f96bfa9d2624be08a989ed8326ec219.png\" alt=\"在这里插入图片描述\"></p> \n <pre><code>/**\n * A package-local class holding common representation and mechanics\n * for classes supporting dynamic striping on 64bit values. The class\n * extends Number so that concrete subclasses must publicly do so.\n */\n@SuppressWarnings(\"serial\")\nabstract class Striped64 extends Number {\n   \n\n    /**\n     * Padded variant of AtomicLong supporting only raw accesses plus CAS.\n     *\n     * JVM intrinsics note: It would be possible to use a release-only\n     * form of CAS here, if it were provided.\n     */\n    @sun.misc.Contended static final class Cell {\n        volatile long value;\n        Cell(long x) { value = x; }\n        final boolean cas(long cmp, long val) {\n            return UNSAFE.compareAndSwapLong(this, valueOffset, cmp, val);\n        }\n\n        // Unsafe mechanics\n        private static final sun.misc.Unsafe UNSAFE;\n        private static final long valueOffset;\n        static {\n            try {\n                UNSAFE = sun.misc.Unsafe.getUnsafe();\n                Class&lt;?&gt; ak = Cell.class;\n                valueOffset = UNSAFE.objectFieldOffset\n                    (ak.getDeclaredField(\"value\"));\n            } catch (Exception e) {\n                throw new Error(e);\n            }\n        }\n    }\n\n    /** Number of CPUS, to place bound on table size */\n    static final int NCPU = Runtime.getRuntime().availableProcessors();\n\n    /**\n     * Table of cells. When non-null, size is a power of 2.\n     */\n    transient volatile Cell[] cells;\n\n    /**\n     * Base value, used mainly when there is no contention, but also as\n     * a fallback during table initialization races. Updated via CAS.\n     */\n    transient volatile long base;\n\n    /**\n     * Spinlock (locked via CAS) used when resizing and/or creating Cells.\n     */\n    transient volatile int cellsBusy;\n\n    /**\n     * Package-private default constructor\n     */\n    Striped64() {\n    }\n\n</code></pre> \n <p>以上源码的特别复杂，请参见 《Java高并发核心编程 卷2 加强版》</p> \n <p><img src=\"https://img-blog.csdnimg.cn/e9972b9982b34c81ac299e5b2629c479.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"BoundedBuffer__179\"></a>BoundedBuffer 的核心源码</h3> \n <pre><code>/**\n * A striped, non-blocking, bounded buffer.\n *\n * @author ben.manes@gmail.com (Ben Manes)\n * @param &lt;E&gt; the type of elements maintained by this buffer\n */\nfinal class BoundedBuffer&lt;E&gt; extends StripedBuffer&lt;E&gt;\n\n</code></pre> \n <p>它是一个 striped、非阻塞、有界限的 buffer，继承于StripedBuffer类。</p> \n <p>下面看看StripedBuffer的实现：</p> \n <pre><code>/**\n * A base class providing the mechanics for supporting dynamic striping of bounded buffers. This\n * implementation is an adaption of the numeric 64-bit {@link java.util.concurrent.atomic.Striped64}\n * class, which is used by atomic counters. The approach was modified to lazily grow an array of\n * buffers in order to minimize memory usage for caches that are not heavily contended on.\n *\n * @author dl@cs.oswego.edu (Doug Lea)\n * @author ben.manes@gmail.com (Ben Manes)\n */\n\nabstract class StripedBuffer&lt;E&gt; implements Buffer&lt;E&gt;\n\n</code></pre> \n <h3><a id=\"StripedBuffer__213\"></a>StripedBuffer (条带缓冲)的架构</h3> \n <p>解决CAS恶性空自旋的有效方式之一是以空间换时间，较为常见的方案有两种：</p> \n <ul>\n  <li>分散操作热点、</li>\n  <li>使用队列削峰。</li>\n </ul> \n <p>这个StripedBuffer设计的思想是跟Striped64类似的，通过扩展结构把<strong>分散操作热点（/竞争热点分离)</strong>。</p> \n <p>具体实现是这样的，StripedBuffer维护一个Buffer[]数组，叫做table，每个元素就是一个RingBuffer，</p> \n <p>每个线程用自己id属性作为 hash 值的种子产生hash值，这样就相当于每个线程都有自己“专属”的RingBuffer，</p> \n <p>在hash分散很均衡的场景下，就不会尽量的降低竞争，避免空自旋，</p> \n <p>、</p> \n <p><img src=\"https://img-blog.csdnimg.cn/49b6e9e1721d4734800ed3fe870dac01.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"_234\"></a></h3> \n <p>看看StripedBuffer的属性</p> \n <pre><code>/** Table of buffers. When non-null, size is a power of 2. */\n//RingBuffer数组\ntransient volatile Buffer&lt;E&gt; @Nullable[] table;\n\n//当进行resize时，需要整个table锁住。tableBusy作为CAS的标记。\nstatic final long TABLE_BUSY = UnsafeAccess.objectFieldOffset(StripedBuffer.class, \"tableBusy\");\nstatic final long PROBE = UnsafeAccess.objectFieldOffset(Thread.class, \"threadLocalRandomProbe\");\n\n/** Number of CPUS. */\nstatic final int NCPU = Runtime.getRuntime().availableProcessors();\n\n/** The bound on the table size. */\n//table最大size\nstatic final int MAXIMUM_TABLE_SIZE = 4 * ceilingNextPowerOfTwo(NCPU);\n\n/** The maximum number of attempts when trying to expand the table. */\n//如果发生竞争时（CAS失败）的尝试次数\nstatic final int ATTEMPTS = 3;\n\n/** Table of buffers. When non-null, size is a power of 2. */\n//核心数据结构\ntransient volatile Buffer&lt;E&gt; @Nullable[] table;\n\n/** Spinlock (locked via CAS) used when resizing and/or creating Buffers. */\ntransient volatile int tableBusy;\n\n/** CASes the tableBusy field from 0 to 1 to acquire lock. */\nfinal boolean casTableBusy() {\n  return UnsafeAccess.UNSAFE.compareAndSwapInt(this, TABLE_BUSY, 0, 1);\n}\n\n/**\n * Returns the probe value for the current thread. Duplicated from ThreadLocalRandom because of\n * packaging restrictions.\n */\nstatic final int getProbe() {\n  return UnsafeAccess.UNSAFE.getInt(Thread.currentThread(), PROBE);\n}\n\n</code></pre> \n <p>offer方法，当没初始化或存在竞争时，则扩容为 2 倍。最大为不小于 CPU核数的 2幂值。</p> \n <pre><code>\n\n    /**\n     * The bound on the table size.\n     */\n    static final int MAXIMUM_TABLE_SIZE = 4 * ceilingPowerOfTwo(NCPU);\n\n\n</code></pre> \n <p>实际是调用RingBuffer的 offer 方法，把数据追加到RingBuffer后面。</p> \n <pre><code>@Override\npublic int offer(E e) {\n  int mask;\n  int result = 0;\n  Buffer&lt;E&gt; buffer;\n  //是否不存在竞争\n  boolean uncontended = true;\n  Buffer&lt;E&gt;[] buffers = table\n  //是否已经初始化\n  if ((buffers == null)\n      || (mask = buffers.length - 1) &lt; 0\n      //用thread的随机值作为hash值，得到对应位置的RingBuffer\n      || (buffer = buffers[getProbe() &amp; mask]) == null\n      //检查追加到RingBuffer是否成功\n      || !(uncontended = ((result = buffer.offer(e)) != Buffer.FAILED))) {\n    //其中一个符合条件则进行扩容\n    expandOrRetry(e, uncontended);\n  }\n  return result;\n}\n\n/**\n * Handles cases of updates involving initialization, resizing, creating new Buffers, and/or\n * contention. See above for explanation. This method suffers the usual non-modularity problems of\n * optimistic retry code, relying on rechecked sets of reads.\n *\n * @param e the element to add\n * @param wasUncontended false if CAS failed before call\n */\n\n//这个方法比较长，但思路还是相对清晰的。\n@SuppressWarnings(\"PMD.ConfusingTernary\")\nfinal void expandOrRetry(E e, boolean wasUncontended) {\n  int h;\n  if ((h = getProbe()) == 0) {\n    ThreadLocalRandom.current(); // force initialization\n    h = getProbe();\n    wasUncontended = true;\n  }\n  boolean collide = false; // True if last slot nonempty\n  for (int attempt = 0; attempt &lt; ATTEMPTS; attempt++) {\n    Buffer&lt;E&gt;[] buffers;\n    Buffer&lt;E&gt; buffer;\n    int n;\n    if (((buffers = table) != null) &amp;&amp; ((n = buffers.length) &gt; 0)) {\n      if ((buffer = buffers[(n - 1) &amp; h]) == null) {\n        if ((tableBusy == 0) &amp;&amp; casTableBusy()) { // Try to attach new Buffer\n          boolean created = false;\n          try { // Recheck under lock\n            Buffer&lt;E&gt;[] rs;\n            int mask, j;\n            if (((rs = table) != null) &amp;&amp; ((mask = rs.length) &gt; 0)\n                &amp;&amp; (rs[j = (mask - 1) &amp; h] == null)) {\n              rs[j] = create(e);\n              created = true;\n            }\n          } finally {\n            tableBusy = 0;\n          }\n          if (created) {\n            break;\n          }\n          continue; // Slot is now non-empty\n        }\n        collide = false;\n      } else if (!wasUncontended) { // CAS already known to fail\n        wasUncontended = true;      // Continue after rehash\n      } else if (buffer.offer(e) != Buffer.FAILED) {\n        break;\n      } else if (n &gt;= MAXIMUM_TABLE_SIZE || table != buffers) {\n        collide = false; // At max size or stale\n      } else if (!collide) {\n        collide = true;\n      } else if (tableBusy == 0 &amp;&amp; casTableBusy()) {\n        try {\n          if (table == buffers) { // Expand table unless stale\n            table = Arrays.copyOf(buffers, n &lt;&lt; 1);\n          }\n        } finally {\n          tableBusy = 0;\n        }\n        collide = false;\n        continue; // Retry with expanded table\n      }\n      h = advanceProbe(h);\n    } else if ((tableBusy == 0) &amp;&amp; (table == buffers) &amp;&amp; casTableBusy()) {\n      boolean init = false;\n      try { // Initialize table\n        if (table == buffers) {\n          @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n          Buffer&lt;E&gt;[] rs = new Buffer[1];\n          rs[0] = create(e);\n          table = rs;\n          init = true;\n        }\n      } finally {\n        tableBusy = 0;\n      }\n      if (init) {\n        break;\n      }\n    }\n  }\n}\n\n</code></pre> \n <h3><a id=\"_409\"></a>环形队列</h3> \n <p>我们知道，队列伴随着生产和消费，而队列一般也是由<strong>数组或链表</strong>来实现的，</p> \n <p>队列是一个先进先出的结构，那么随着游标在数组上向后移动，</p> \n <p>前面已经消费了的数据已没有意义，但是他们依然占据着内存空间，浪费越来越大，</p> \n <p><img src=\"https://img-blog.csdnimg.cn/3325554c737f4231a4d53b70da16f552.png\" alt=\"在这里插入图片描述\"></p> \n <p>所以：环形队列就很好的解决了这个问题。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/42453f68d1034ee3b1f778c3ebbcabd3.png\" alt=\"在这里插入图片描述\"></p> \n <p>环形队列是在实际编程极为有用的数据结构，它采用数组的线性空间，数据组织简单，能很快知道队列是否满或空，能以很快速度的来存取数据。</p> \n <p>从顺时针看，环形队列 有队头 head 和队尾 tail。</p> \n <p><strong>生产的流程是：</strong></p> \n <p>生产者顺时针向队尾 tail 插入元素，这会导致 head 位置不变，tail 位置在后移；</p> \n <p><strong>消费的流程是：</strong></p> \n <p>消费者则从队头 head 开始消费，这会导致 head 向后移动，而tail 位置不变，如果队列满了就不能写入。</p> \n <p><strong>环形队列的特点：</strong></p> \n <p>队头 head 和队尾 tail 的位置是不定的，位置一直在循环流动，空间就被重复利用起来了。</p> \n <p>因为有简单高效的原因，甚至在硬件都实现了环形队列.。</p> \n <p>环形队列广泛用于网络数据收发，和不同程序间数据交换（比如内核与应用程序大量交换数据，从硬件接收大量数据）均使用了环形队列。</p> \n <h4><a id=\"_453\"></a>环形队列的参考实现</h4> \n <p>下面的环形队列， 参考了 缓存之王 Caffeine 源码中的 命名</p> \n <pre><code>package com.crazymakercircle.queue;\n\n\npublic class SimpleRingBufferDemo {\n    public static void main(String[] args) {\n\n        //创建一个环形队列\n        SimpleRingBuffer queue = new SimpleRingBuffer(4);\n        queue.offer(11);\n        queue.offer(12);\n        queue.offer(13);\n        System.out.println(\"queue = \" + queue);\n        int temp = queue.poll();\n        System.out.println(\"temp = \" + temp);\n        System.out.println(\"queue = \" + queue);\n        temp = queue.poll();\n        System.out.println(\"temp = \" + temp);\n        System.out.println(\"queue = \" + queue);\n        temp = queue.poll();\n        System.out.println(\"temp = \" + temp);\n        System.out.println(\"queue = \" + queue);\n    }\n\n}\n\nclass SimpleRingBuffer {\n    private int maxSize;//表示数组的最大容量\n    private int head;  // 模拟 缓存之王 Caffeine 源码命名\n    //head就指向队列的第一个元素，也就是arr[head]就是队列的第一个元素\n    //head的初始值=0\n    private int tail; // 模拟 缓存之王 Caffeine 源码命名\n    //tail指向队列的最后一个元素的后一个位置，因为希望空出一个空间做为约定\n    //tail的初始化值=0\n    private int[] buffer;//该数据用于存放数据\n\n    public SimpleRingBuffer(int arrMaxSize) {\n        maxSize = arrMaxSize;\n        buffer = new int[maxSize];\n    }\n\n    //判断队列是否满\n    public boolean isFull() {\n        return (tail + 1) % maxSize == head;\n    }\n\n    //判断队列是否为空\n    public boolean isEmpty() {\n        return tail == head;\n    }\n\n    //添加数据到队列\n    public void offer(int n) {\n        //判断队列是否满\n        if (isFull()) {\n            System.out.println(\"队列满，不能加入数据\");\n            return;\n        }\n        //直接将数据加入\n        buffer[tail] = n;\n        //将tail后移，这里必须考虑取模\n        tail = (tail + 1) % maxSize;\n    }\n\n    //获取队列的数据，出队列\n    public int poll() {\n        //判断队列是否空\n        if (isEmpty()) {\n            //通过抛出异常\n            throw new RuntimeException(\"队列空，不能取数据\");\n        }\n        //这里需要分析出head是指向队列的第一个元素\n        //1.先把head对应的值保留到一个临时变量\n        //2.将head后移，考虑取模\n        //3.将临时保存的变量返回\n        int value = buffer[head];\n        head = (head + 1) % maxSize;\n        return value;\n    }\n\n    //求出当前队列有效数据的个数\n    public int size() {\n        return (tail + maxSize - head) % maxSize;\n    }\n\n    @Override\n    public String toString() {\n       return   String.format(\"head=%d , tail =%d\\n\",head,tail);\n\n    }\n}\n</code></pre> \n <h4><a id=\"_552\"></a>测试的结果</h4> \n <p><img src=\"https://img-blog.csdnimg.cn/03b049f5bd2842a5991d9f4f653963c1.png\" alt=\"在这里插入图片描述\"></p> \n <h4><a id=\"_560\"></a>环形核心的结构和流程说明</h4> \n <ol>\n  <li> <p><strong>约定head指向队列的第一个元素</strong>，</p> <p>也就是说data[head]就是队头数据，head初始值为0。</p> </li>\n  <li> <p><strong>约定tail指向队列的最后一个元素的后一个位置</strong>，</p> <p>也就是说data[tail-1]就是队尾数据，tail初始值为0。</p> </li>\n  <li> <p>队列满的条件是：</p> <p><em><strong>( tail+1 )% maxSize == head</strong></em></p> </li>\n  <li> <p>队列空的条件是：</p> <p><em><strong>tail == head</strong></em></p> </li>\n  <li> <p>队列中的元素个数为：</p> <p><em><strong>( tail + maxsize - head) % maxSize</strong></em></p> </li>\n  <li> <p>有效数据只有maxSize-1个</p> <p>因为tail指向队尾的后面一个位置，这个位置就不能存数据，因此有效数据只有maxSize-1个</p> </li>\n </ol> \n <h4><a id=\"_588\"></a>环形队列核心操作：判满</h4> \n <p>写入的时候，当前位置的下一位置是（tail+1）% maxSize</p> \n <p>由图可知：</p> \n <p>当head刚好指向tail的下一个位置时队列满，而tail的下一个位置是 <em><strong>（tail+1）% maxSize</strong></em>，</p> \n <p>所以当（ tail + 1 )% maxSize == head 时，队列就满了。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/3b23b59f488b44438f6e71e0e3435666.png\" alt=\"在这里插入图片描述\"></p> \n <h4><a id=\"_604\"></a>环形队列核心操作：判空</h4> \n <p>队列为空的情况如下图所示，当队头队尾都指向一个位置，即 <em><strong>head == tail</strong></em> 时，队列为空。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/0027fe7499734c7e9713352276d580cd.png\" alt=\"在这里插入图片描述\"></p> \n <p>当head == tail时，队列为空</p> \n <p>因为tail指向队尾的后面一个位置，这个位置就不能存数据，</p> \n <p>因此, 环形队列的有效数据只有maxSize-1个</p> \n <h3><a id=\"RingBuffer__628\"></a>RingBuffer 源码</h3> \n <p>caffeine源码中， 注意RingBuffer是BoundedBuffer的内部类。</p> \n <pre><code>/** The maximum number of elements per buffer. */\nstatic final int BUFFER_SIZE = 16;\n\n// Assume 4-byte references and 64-byte cache line (16 elements per line)\n//256长度，但是是以16为单位，所以最多存放16个元素\nstatic final int SPACED_SIZE = BUFFER_SIZE &lt;&lt; 4;\nstatic final int SPACED_MASK = SPACED_SIZE - 1;\nstatic final int OFFSET = 16;\n//RingBuffer数组\nfinal AtomicReferenceArray&lt;E&gt; buffer;\n\n //插入方法\n @Override\n public int offer(E e) {\n   long head = readCounter;\n   long tail = relaxedWriteCounter();\n   //用head和tail来限制个数\n   long size = (tail - head);\n   if (size &gt;= SPACED_SIZE) {\n     return Buffer.FULL;\n   }\n   //tail追加16\n   if (casWriteCounter(tail, tail + OFFSET)) {\n     //用tail“取余”得到下标\n     int index = (int) (tail &amp; SPACED_MASK);\n     //用unsafe.putOrderedObject设值\n     buffer.lazySet(index, e);\n     return Buffer.SUCCESS;\n   }\n   //如果CAS失败则返回失败\n   return Buffer.FAILED;\n }\n\n //用consumer来处理buffer的数据\n @Override\n public void drainTo(Consumer&lt;E&gt; consumer) {\n   long head = readCounter;\n   long tail = relaxedWriteCounter();\n   //判断数据多少\n   long size = (tail - head);\n   if (size == 0) {\n     return;\n   }\n   do {\n     int index = (int) (head &amp; SPACED_MASK);\n     E e = buffer.get(index);\n     if (e == null) {\n       // not published yet\n       break;\n     }\n     buffer.lazySet(index, null);\n     consumer.accept(e);\n     //head也跟tail一样，每次递增16\n     head += OFFSET;\n   } while (head != tail);\n   lazySetReadCounter(head);\n }\n\n</code></pre> \n <p>注意，ring buffer 的 size（固定是 16 个）是不变的，变的是 head 和 tail 而已。</p> \n <h3><a id=\"StripedRingBuffer__696\"></a>Striped-RingBuffer 有如下特点：</h3> \n <p>总的来说 Striped-RingBuffer 有如下特点：</p> \n <ul>\n  <li>使用 Striped-RingBuffer来提升对 buffer 的读写</li>\n  <li>用 thread 的 hash 来避开热点 key 的竞争</li>\n  <li>允许写入的丢失</li>\n </ul> \n <h2><a id=\"_703\"></a>推荐阅读：</h2> \n <ul>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124790425\">尼恩Java面试宝典</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057567\">Springcloud gateway 底层原理、核心实战 (史上最全)</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125059491\">sentinel （史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/123420859\">分库分表 Sharding-JDBC 底层原理、核心实战（史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/109459593\">分布式事务 （秒懂）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128123114\">缓存之王：Caffeine 源码、架构、原理（史上最全，10W字 超级长文）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/113751575\">缓存之王：Caffeine 的使用（史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126579528\">Java Agent 探针、字节码增强 ByteBuddy（史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120747767\">Docker原理（图解+秒懂+史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/116425814\">Redis分布式锁（图解 - 秒懂 - 史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85956246\">Zookeeper 分布式锁 - 图解 - 秒懂</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85922561\">Zookeeper Curator 事件监听 - 10分钟看懂</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83957259\">Netty 粘包 拆包 | 史上最全解读</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83758107\">Netty 100万级高并发服务器配置</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/102557988\">Springcloud 高并发 配置 （一文全懂）</a>》</p> </li>\n </ul> \n <h2><a id=\"_729\"></a>参考文献</h2> \n <ol>\n  <li> <p><a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\">疯狂创客圈 JAVA 高并发 总目录</a></p> <p>ThreadLocal（史上最全）<br> https://www.cnblogs.com/crazymakercircle/p/14491965.html</p> </li>\n  <li> <p>3000页《尼恩 Java 面试宝典 》的 35个面试专题 ：<br> https://www.cnblogs.com/crazymakercircle/p/13917138.html</p> </li>\n  <li> <p>价值10W的架构师知识图谱<br> https://www.processon.com/view/link/60fb9421637689719d246739</p> </li>\n </ol> \n <p>4、尼恩 架构师哲学<br> https://www.processon.com/view/link/616f801963768961e9d9aec8</p> \n <p>5、尼恩 3高架构知识宇宙<br> https://www.processon.com/view/link/635097d2e0b34d40be778ab4</p> \n <p>Guava Cache主页：https://github.com/google/guava/wiki/CachesExplained</p> \n <p>Caffeine的官网：https://github.com/ben-manes/caffeine/wiki/Benchmarks</p> \n <p>https://gitee.com/jd-platform-opensource/hotkey</p> \n <p>https://developer.aliyun.com/article/788271?utm_content=m_1000291945</p> \n <p>https://b.alipay.com/page/account-manage-oc/approval/setList</p> \n <p>Caffeine: <em>https://github.com/ben-manes/caffeine</em></p> \n <p>这里: <em>https://albenw.github.io/posts/df42dc84/</em></p> \n <p>Benchmarks: <em>https://github.com/ben-manes/caffeine/wiki/Benchmarks</em></p> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 1879);
INSERT INTO `crawlerblog` VALUES (123124023, '一文搞定：SpringBoot、SLF4j、Log4j、Logback、Netty之间混乱关系（史上最全）', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <p>文章很长，建议收藏起来慢慢读！<a href=\"https://www.yuque.com/crazymakercircle/gkkw8s/khigna\"><strong>疯狂创客圈总目录 语雀版</strong></a> | <a href=\"https://gitee.com/crazymaker/SimpleCrayIM/blob/master/%E7%96%AF%E7%8B%82%E5%88%9B%E5%AE%A2%E5%9C%88%E6%80%BB%E7%9B%AE%E5%BD%95.md\"><strong>总目录 码云版</strong></a>| <a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\"><strong>总目录 博客园版</strong></a> 为您奉上珍贵的学习资源 ：</p> \n <ul>\n  <li> <p><strong>免费赠送 :<a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\">《尼恩Java面试宝典》持续更新+ 史上最全 + 面试必备 2000页+ </a> 面试必备 + 大厂必备 +涨薪必备</strong></p> </li>\n </ul> \n <ul>\n  <li> <p><strong>免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\">《Java高并发核心编程（卷1）》 </a> 面试必备 + 大厂必备 +涨薪必备</strong> 加尼恩免费领</p> </li>\n  <li> <p><strong>免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\">《Java高并发核心编程（卷2）》 </a> 面试必备 + 大厂必备 +涨薪必备</strong> 加尼恩免费领</p> </li>\n  <li> <p><strong>免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\">《Netty Zookeeper Redis 高并发实战》 </a> 面试必备 + 大厂必备 +涨薪必备</strong> 加尼恩免费领</p> </li>\n  <li> <p><strong>免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\">《SpringCloud Nginx高并发核心编程》 </a> 面试必备 + 大厂必备 +涨薪必备</strong> 加尼恩免费领</p> </li>\n  <li> <p><strong>免费赠送 资源宝库： Java 必备 百度网盘资源大合集 价值&gt;10000元</strong> <a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\">加尼恩领取</a> </p> </li>\n  <li>\n   <hr> <h2><a id=\"_Java____14\"></a>推荐：入大厂 、做架构、大力提升Java 内功 的 精彩博文</h2> \n   <table>\n    <thead>\n     <tr>\n      <th align=\"left\">入大厂 、做架构、大力提升Java 内功 必备的精彩博文</th>\n      <th>秋招涨薪1W + 必备的精彩博文</th>\n     </tr>\n    </thead>\n    <tbody>\n     <tr>\n      <td align=\"left\">1：<a href=\"https://www.cnblogs.com/crazymakercircle/p/14731826.html\"><strong>Redis 分布式锁</strong> （图解-秒懂-史上最全）</a></td>\n      <td>2：<a href=\"https://www.cnblogs.com/crazymakercircle/p/14504520.html\"><strong>Zookeeper 分布式锁</strong> （图解-秒懂-史上最全）</a></td>\n     </tr>\n     <tr>\n      <td align=\"left\">3: <a href=\"https://www.cnblogs.com/crazymakercircle/p/14853622.html\"><strong>Redis与MySQL双写一致性如何保证？</strong></a> （面试必备）</td>\n      <td>4: <a href=\"https://www.cnblogs.com/crazymakercircle/p/14846136.html\"><strong>面试必备：秒杀超卖 解决方案</strong></a> （史上最全）</td>\n     </tr>\n     <tr>\n      <td align=\"left\">5:<a href=\"https://www.cnblogs.com/crazymakercircle/p/9833847.html\"><strong>面试必备之：Reactor模式</strong></a></td>\n      <td>6: <a href=\"https://www.cnblogs.com/crazymakercircle/p/10225159.html\"><strong>10分钟看懂， Java NIO 底层原理</strong></a></td>\n     </tr>\n     <tr>\n      <td align=\"left\">7:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14499211.html\"><strong>TCP/IP（图解+秒懂+史上最全）</strong></a></td>\n      <td>8：<a href=\"https://www.cnblogs.com/crazymakercircle/p/11965726.html\">Feign原理 （图解）</a></td>\n     </tr>\n     <tr>\n      <td align=\"left\">9:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14976612.html\">DNS图解（秒懂 + 史上最全 + 高薪必备）</a></td>\n      <td>10：<a href=\"https://www.cnblogs.com/crazymakercircle/p/14978513.html\">CDN图解（秒懂 + 史上最全 + 高薪必备）</a></td>\n     </tr>\n     <tr>\n      <td align=\"left\">11: <a href=\"https://www.cnblogs.com/crazymakercircle/p/13917517.html\"><strong>分布式事务（ 图解 + 史上最全 + 吐血推荐 ）</strong></a></td>\n      <td>12：<a href=\"https://www.cnblogs.com/crazymakercircle/p/15187184.html\">限流：计数器、漏桶、令牌桶 <br>三大算法的原理与实战（图解+史上最全）</a></td>\n     </tr>\n     <tr>\n      <td align=\"left\">13:<a href=\"https://www.cnblogs.com/crazymakercircle/p/15058702.html\">架构必看：12306抢票系统亿级流量架构<br>（图解+秒懂+史上最全）</a></td>\n      <td>14：<a href=\"https://www.cnblogs.com/crazymakercircle/p/15313875.html\">seata AT模式实战（图解+秒懂+史上最全）</a></td>\n     </tr>\n     <tr>\n      <td align=\"left\">15：<a href=\"https://www.cnblogs.com/crazymakercircle/p/15313951.html\">seata 源码解读（图解+秒懂+史上最全）</a></td>\n      <td>16：<a href=\"https://www.cnblogs.com/crazymakercircle/p/15314246.html\">seata TCC模式实战（图解+秒懂+史上最全）</a></td>\n     </tr>\n    </tbody>\n   </table> \n   <hr> \n   <table>\n    <thead>\n     <tr>\n      <th align=\"left\">SpringCloud 微服务 精彩博文</th>\n      <th></th>\n     </tr>\n    </thead>\n    <tbody>\n     <tr>\n      <td align=\"left\"><a href=\"https://www.cnblogs.com/crazymakercircle/p/14231815.html\"> <strong>nacos 实战</strong>（史上最全）</a></td>\n      <td><a href=\"https://www.cnblogs.com/crazymakercircle/p/14285001.html\"> sentinel （史上最全+入门教程）</a></td>\n     </tr>\n     <tr>\n      <td align=\"left\"><a href=\"https://www.cnblogs.com/crazymakercircle/p/11704077.html\"> <strong>SpringCloud gateway</strong> （史上最全）</a></td>\n      <td><a href=\"https://www.cnblogs.com/crazymakercircle/p/15955254.html\"><strong>分库分表sharding-jdbc底层原理与实操（史上最全，5W字长文，吐血推荐）</strong></a></td>\n     </tr>\n    </tbody>\n   </table> \n   <hr> <h2><a id=\"Java____httpswwwcnblogscomcrazymakercirclep13917138html_35\"></a>推荐：尼恩Java面试宝典（持续更新 + 史上最全 + 面试必备）<a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\">具体详情，请点击此链接</a></h2> <p>尼恩Java面试宝典，<strong>32个最新pdf</strong>，含<strong>2000多页</strong>，<strong>不断更新、持续迭代</strong> <a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\">具体详情，请点击此链接</a></p> <p><img src=\"https://img-blog.csdnimg.cn/729b33f6bc37429385edbef85fd805c3.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n   <hr> <h2><a id=\"Java_45\"></a>Java的日志系统</h2> <p>java领域存在多种日志框架，目前常用的日志框架包括Log4j，Log4j 2，Commons Logging，Slf4j，Logback，Jul。</p> <p>这些框架中可以分为两类，一类是日志框架，一类是日志实现。</p> <h3><a id=\"_55\"></a>日志框架</h3> <p>门面型日志框架：不实现日志功能，仅整合日志</p> <p>1）JCL：一套Apache基金所述的java日志接口，由Jakarta Commons Logging，更名为Commons Logging；</p> <p>Commons Logging：apache提供的一个通用的日志接口。用户可以自由选择第三方的日志组件作为具体实现，像log4j，或者jdk自带的logging， common-logging会通过动态查找的机制，在程序运行时自动找出真正使用的日志库。</p> <p>2）SIF4J：一套简易的Java日志门面，全称为Simple Logging Facade for Java。</p> <p>SLF4j：类似于Apache Common-Logging，是对不同日志框架提供的一个门面封装，可以在部署的时候不修改任何配置即可接入一种日志实现方案。</p> <h3><a id=\"_73\"></a>日志实现</h3> <p>实现日志的功能</p> <p>1）JUL:JDK中的日志记录工具，自Java1.4来由官方日志实现；</p> <p>JUL(java.util.logging)：JDK提供的日志系统。较混乱，不经常使用</p> <p>2）Log4j：具体的日志实现框架；</p> <p>Log4j：经典的一种日志解决方式。内部把日志系统抽象封装成Logger 、appender 、pattern 等实现。</p> <p>我们能够通过配置文件轻松的实现日志系统的管理和多样化配置。</p> <p>3）Log4j2：具体日志实现框架；</p> <p>4）Logback：一个具体的日志实现框架。</p> <p>Logback：Log4j的替代产品。须要配合日志框架SLF4j使用</p> <h3><a id=\"_101\"></a>日志框架的发展演变</h3> <h4><a id=\"1Log4j_103\"></a>1、Log4j</h4> <p>Gülcü于2001年发布了Log4j框架，也就是后来Apache基金会的顶级项目。</p> <p>在JDK1.3版本及以前，Java日志的实现依赖于System.out.print()、System.err.println()或者e.printStackTrace()、</p> <p>Debug日志被写到STDOUT流，</p> <p>错误日志被写到STDERR流。</p> <p>这样的日志系统无法定制且粒度太粗，无法精确定位错误。</p> <p>Log4j定义的Logger、Appender、Level等概念如今已经被广泛使用。</p> <p>Log4j 的短板在于性能，在Logback和 Log4j2出来之后，Log4j的使用也减少了，目前已停止更新。</p> <h4><a id=\"2JUL_123\"></a>2、JUL</h4> <p>受Logj启发，Sun在Java1.4版本中引入了java.util.logging，</p> <p>但是jull功能远不如log4j完善，开发者需要自己编写Appenders（Sun称之为Handlers），</p> <p>且只有两个Handlers可用（Console和File），jul在Java1.5以后性能和可用性才有所提升。</p> <h4><a id=\"3JCL_135\"></a>3、JCL</h4> <p>JCL（commons-logging）是一个门面框架，它由于项目的日志打印必然选择两个框架中至少一个，</p> <p>JCL只提供 Log API，不提供实现，实现采用Log4j或者 JUL 。</p> <h4><a id=\"4SLF4j_143\"></a>4、SLF4j</h4> <p>SLF4J（Simple Logging Facade for Java）和 Logback 也是Gülcü创立的项目，目的是为了提供更高性能的实现。</p> <p>从设计模式的角度说，SLF4J是用来在log和代码层之间起到门面作用，类似于 JCL的Log Facade。</p> <p>对于用户来说只要使用SLF4J提供的接口，即可隐藏日志的具体实现，</p> <p>SLF4J提供的核心API是一些接口和一个LoggerFactory的工厂类，用户只需按照它提供的统一纪录日志接口，最终日志的格式、纪录级别、输出方式等可通过具体日志系统的配置来实现，因此可以灵活的切换日志系统。</p> <h2><a id=\"_159\"></a>日志门面框架整合日志实现框架</h2> <p>在阿里开发手册上有关于日志门面使用系统的强制规约：</p> <p>应用中不可直接使用日志系统（log4j、logback）中的 API ，而应依赖使用日志框架中的 API 。</p> <p>使用门面模式的日志框架，有利于维护和各个类的日志处理方式的统一。</p> <h3><a id=\"slf4japijar_175\"></a>slf4j-api.jar日志系统(门面框架+桥接器)</h3> <p>由于具体日志框架比较多，而且互相也大都不兼容，日志门面接口要想实现与任意日志框架结合可能需要对应的桥接器，</p> <p>说白了，所谓**“桥接器”**，不过就是对某套API的伪实现。</p> <p><strong>“桥接器”</strong>：日志门面接口本身通常并没有实际的日志输出能力，它底层还是需要去调用具体的日志框架API的，也就是实际上它需要跟具体的日志框架结合使用。</p> <p>**“桥接器”**实现并不是直接去完成API所声明的功能，而是去调用有类似功能的别的API。这样就完成了从“某套API”到“别的API”的转调。</p> <p><img src=\"https://img-blog.csdnimg.cn/ad2648edab5942dcba2a73732b421d32.png\" alt=\"在这里插入图片描述\"></p> <p><strong>“桥接器” 类似于 适配层，</strong></p> <p>有的时候，这里的“桥接器”也叫适配层</p> <h4><a id=\"slf4japi_193\"></a>仅使用slf4j-api门面框架</h4> <p>此时没有日志系统的具体实现，所以会报错</p> <h4><a id=\"slf4jnop_197\"></a>使用slf4j-nop空实现</h4> <p>slf4j-nop不会输出任何日志，仅是让slf4j-api.jar不再报错。</p> <h3><a id=\"Sif4jLog4j_201\"></a>Sif4j门面框架+Log4j实现</h3> <p>若项目采用Slf4j门面以Log4j作为日志框架输出，结构图如下：</p> <p><img src=\"https://img-blog.csdnimg.cn/img_convert/87c7005eee893988666f71ec0d3c7b3e.png\" alt=\"img\"></p> <p>1）添加slf4j的核心依赖：</p> <pre><code>&lt;dependency&gt;\n&lt;groupId&gt;org.slf4j&lt;/groupId&gt;\n&lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre> <p>2）Sif4j门面框架+Log4j实现使用的桥接器：</p> <p>添加桥接依赖：</p> <pre><code>&lt;dependency&gt;\n&lt;groupId&gt;org.slf4j&lt;/groupId&gt;\n&lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre> <p>3）测试代码：</p> <pre><code>import org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\npublic class Log4jSif4jTest {\npublic static void main(String[] args) {\n        Logger logger = LoggerFactory.getLogger(Log4jSif4jTest.class);\n        logger.info(logger.getClass().getName());\n        logger.info(\"门面框架Sif4j整合Log4j输出\");\n}\n}\n</code></pre> <p>4）结果输出：</p> <p><img src=\"https://img-blog.csdnimg.cn/img_convert/91460be0943e27cf980f436ee5060645.png\" alt=\"img\"></p> <h3><a id=\"Sif4jlog4j_2x_261\"></a>Sif4j门面框架+log4j 2.x实现</h3> <p><img src=\"https://img-blog.csdnimg.cn/ad2648edab5942dcba2a73732b421d32.png\" alt=\"在这里插入图片描述\"></p> <p>这里的<strong>桥接器（适配层</strong>为<code>log4j-slf4j-impl.jar</code>。</p> <p>仅需依赖<code>org.apache.logging.log4j:log4j-slf4j-impl:2.12.1</code>，就可以引入所有依赖。</p> <h3><a id=\"Sif4jlogback_277\"></a>Sif4j门面框架+logback实现</h3> <p>logback一定会依赖slf4j的接口，</p> <p>所以使用logback的时候，一定使用了slf4j-api.jar的接口。</p> <p>仅需添加<code>ch.qos.logback:logback-classic:1.2.3</code>即可引入所有依赖的jar包。</p> <h2><a id=\"SpringBoot_291\"></a>SpringBoot的日志</h2> <p><strong>SpringBoot</strong> 默认使用<strong>info</strong>级别日志。日志级别由低到高：<strong>trace</strong>&lt;<strong>debug</strong>&lt;<strong>info</strong>&lt;<strong>warn</strong>&lt;<strong>error</strong></p> <p><strong>SpringBoot</strong> 底层使用<strong>slf4j</strong>+<strong>logback</strong> 方式。最底层依赖关系（如下图）导入了slf4j日志抽象层，slf4j-api。使用slf4j+logback的方式进行日志记录。</p> <p><strong>SpringBoot能自动适配所有的日志，</strong>，引入其他框架的时候，只需要把这个框架依赖的日志框架排除掉即可</p> <p><img src=\"https://img-blog.csdnimg.cn/2019122922270591.png\" alt=\"img\"></p> <p><strong>SpringBoot</strong> 也把其他日志替换成的 **slf4j。**给类路径下放置每个日志框架自己的配置文件后，<strong>SpringBoot</strong> 就不使用其他的默认配置了。</p> \n   <table>\n    <thead>\n     <tr>\n      <th align=\"left\">Logging System</th>\n      <th align=\"left\">Customization</th>\n     </tr>\n    </thead>\n    <tbody>\n     <tr>\n      <td align=\"left\">Logback</td>\n      <td align=\"left\"><code>logback-spring.xml</code>, <code>logback-spring.groovy</code>, <code>logback.xml</code>, or <code>logback.groovy</code></td>\n     </tr>\n     <tr>\n      <td align=\"left\">Log4j2</td>\n      <td align=\"left\"><code>log4j2-spring.xml</code> or <code>log4j2.xml</code></td>\n     </tr>\n     <tr>\n      <td align=\"left\">JDK (Java Util Logging)</td>\n      <td align=\"left\"><code>logging.properties</code></td>\n     </tr>\n    </tbody>\n   </table> <p><strong>logback-spring.xml：<strong>由 <strong>SpringBoot</strong> 解析日志配置，可以使用：</strong></strong> 等 <strong>SpringBoot</strong> 配置信息。</p> <p>**logback.xml：**直接被日志框架识别了。</p> <h3><a id=\"SpringBoot_313\"></a>SpringBoot记录日志</h3> <p>SpringBoot已经帮我们配置好了日志</p> <pre><code class=\"prism language-java\"><span class=\"token class-name\">Logger</span> logger <span class=\"token operator\">=</span> <span class=\"token class-name\">LoggerFactory</span><span class=\"token punctuation\">.</span><span class=\"token function\">getLogger</span><span class=\"token punctuation\">(</span><span class=\"token function\">getClass</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n \n    <span class=\"token annotation punctuation\">@Test</span>\n    <span class=\"token keyword\">void</span> <span class=\"token function\">contextLoads</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n      <!-- --></span>\n        logger<span class=\"token punctuation\">.</span><span class=\"token function\">trace</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"trace日志输出......\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        logger<span class=\"token punctuation\">.</span><span class=\"token function\">debug</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"debug日志输出......\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        logger<span class=\"token punctuation\">.</span><span class=\"token function\">info</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"info日志输出......\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        logger<span class=\"token punctuation\">.</span><span class=\"token function\">warn</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"warn日志输出......\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        logger<span class=\"token punctuation\">.</span><span class=\"token function\">error</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"error日志输出......\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n</code></pre> <p>Springboot默认使用的info级别的，没有指定级别就用默认的级别（root级别）</p> <pre><code class=\"prism language-java\">logger<span class=\"token punctuation\">.</span><span class=\"token function\">info</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"info日志输出......\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nlogger<span class=\"token punctuation\">.</span><span class=\"token function\">warn</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"warn日志输出......\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nlogger<span class=\"token punctuation\">.</span><span class=\"token function\">error</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"error日志输出......\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre> <h3><a id=\"_338\"></a>定日志级别方式在配置文件中配置</h3> <pre><code class=\"prism language-html\">#调整日志的输出级别\nlogging.level.com=trace\n</code></pre> <h3><a id=\"_345\"></a>指定日志输出的文件和路径</h3> <pre><code class=\"prism language-Delphi\">#不指定路径的情况下将日志打印在当前项目下,也可以带着文件的全路径\nlogging.file.name=E:/springboot.log\n#指定日志文件路径\nlogging.file.path=/springboot/spring.log\n</code></pre> <p><img src=\"https://img-blog.csdnimg.cn/20191230214428268.png\" alt=\"img\"></p> <h3><a id=\"_356\"></a>日志输出的格式</h3> <pre><code class=\"prism language-html\">#在控制台输出日志的格式\nlogging.pattern.console=%d{yyyy-MM-dd} [%thread] %-5level %logger{50} - %msg%n\n#在日志文件中输出的日志格式\nlogging.pattern.file=%d{yyyy-MM-dd} === [%thread] === %-5level === %logger{50} ==== %msg%n\n</code></pre> <h3><a id=\"imghttpsimgblogcsdnimgcn20191230214755199png_365\"></a><img src=\"https://img-blog.csdnimg.cn/20191230214755199.png\" alt=\"img\"></h3> <p><img src=\"https://img-blog.csdnimg.cn/20191230214852113.png\" alt=\"img\"></p> <pre><code class=\"prism language-html\">    日志输出格式：\n		%d表示日期时间，\n		%thread表示线程名，\n		%-5level：级别从左显示5个字符宽度\n		%logger{50} 表示logger名字最长50个字符，否则按照句点分割。 \n		%msg：日志消息，\n		%n是换行符\n    --&gt;\n    %d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n\n</code></pre> <h2><a id=\"Netty_383\"></a>Netty的封装</h2> <p>由于Java提供的日志框架较多，为了便于使用，Netty封装了一套通用的日志系统。</p> <p>主要思路是实现了InternalLogger和InternalLoggerFactory，将Logger和LogFactory抽象出来，</p> <p>netty默认的InternalLoggerFactory会自己查找当前引入的日志框架，然后使用Factory创建Logger实例。</p> <h3><a id=\"InternalLogger_392\"></a>InternalLogger</h3> <p>InternalLogger是一个接口，封装了trace、info、error、debug、warn等方法，用来提供记录日志的方法。</p> <pre><code>public interface InternalLogger {\nString name();\nboolean isTraceEnabled();\nvoid trace(String msg);\nvoid trace(String format, Object arg);\nvoid trace(String format, Object argA, Object argB);\nvoid trace(String format, Object... arguments);\nvoid trace(String msg, Throwable t);\nvoid trace(Throwable t);\n ... // 还有debug  info warn error log \n}\n</code></pre> <h3><a id=\"AbstractInternalLogger_410\"></a>AbstractInternalLogger</h3> <p>AbstractInternalLogger是一个抽象日志类，实现了InternalLogger接口中的部分方法，内部包含name变量，</p> <p>主要实现了log的6个方法，其会在内部会根据InternalLogLevel来调用相应的方法，其他方法在AbstractInternalLogger的子类中实现。</p> <pre><code>public abstract class AbstractInternalLogger implements InternalLogger, Serializable {\n	private final String name;\n    \n     public boolean isEnabled(InternalLogLevel level) {\n        switch (level) {\n        case TRACE:\n            return isTraceEnabled();\n        case DEBUG:\n            return isDebugEnabled();\n        case INFO:\n            return isInfoEnabled();\n        case WARN:\n            return isWarnEnabled();\n        case ERROR:\n            return isErrorEnabled();\n        default:\n            throw new Error();\n        }\n    }\n    \n    public void log(InternalLogLevel level, String msg, Throwable cause) {\n        switch (level) {\n        case TRACE:\n            trace(msg, cause);\n            break;\n        case DEBUG:\n            debug(msg, cause);\n            break;\n        case INFO:\n            info(msg, cause);\n            break;\n        case WARN:\n            warn(msg, cause);\n            break;\n        case ERROR:\n            error(msg, cause);\n            break;\n        default:\n            throw new Error();\n        }\n    }\n}\n</code></pre> <p>AbstractInternalLogger有5个实现类：</p> \n   <ul>\n    <li> <p>CommonsLogger 内部实现了InternalLogger的方法，使用了org.apache.commons.logging.Log logger</p> </li>\n    <li> <p>JdkLogger 内部使用java.util.logging.Logger logger作为实际的日志记录器</p> </li>\n    <li> <p>Log4J2Logger 内部使用org.apache.logging.log4j.Logger logger</p> </li>\n    <li> <p>Log4JLogger 内部使用org.apache.log4j.Logger logger</p> </li>\n    <li> <p>Slf4JLogger 内部使用org.slf4j.Logger logger</p> <p>以上这些记录日志类只是内部封装了不同的日志处理的具体框架。</p> <p>InternalLogLevel表示日志等级，是一个枚举，TRACE,DEBUG,INFO,WARN,ERROR</p> </li>\n   </ul> <h3><a id=\"InternalLoggerFactory_479\"></a><strong>InternalLoggerFactory</strong></h3> <p>InternalLoggerFactory是一个抽象的类，其子类有 ：</p> \n   <ul>\n    <li> <p>CommonsLoggerFactory，</p> </li>\n    <li> <p>JdkLoggerFactory，</p> </li>\n    <li> <p>Log4J2LoggerFactory，</p> </li>\n    <li> <p>Log4JLoggerFactory</p> </li>\n    <li> <p>Slf4JLoggerFactory 。</p> </li>\n   </ul> <p>每个factory需要实现newInstance方法返回InternalLogger实例。</p> <pre><code>//获取默认的Factory\nprivate static InternalLoggerFactory newDefaultFactory(String name) {\n        InternalLoggerFactory f;\n        try {\n            f = new Slf4JLoggerFactory(true);\n            f.newInstance(name).debug(\"Using SLF4J as the default logging framework\");\n        } catch (Throwable t1) {\n            try {\n                f = Log4JLoggerFactory.INSTANCE;\n                f.newInstance(name).debug(\"Using Log4J as the default logging framework\");\n            } catch (Throwable t2) {\n                f = JdkLoggerFactory.INSTANCE;\n                f.newInstance(name).debug(\"Using java.util.logging as the default logging framework\");\n            }\n        }\n        return f;\n    }\n</code></pre> <h3><a id=\"Nettylogback_518\"></a>Netty使用logback</h3> <p>1.加入依赖</p> <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;\n    &lt;artifactId&gt;logback-classic&lt;/artifactId&gt;\n    &lt;version&gt;${logback-classic.version}&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> <p>2.在resources目录加入logback.xml 配置文件</p> <p><img src=\"https://img-blog.csdnimg.cn/3997e27395a04e20a936b8d89e19fb1b.png\" alt=\"在这里插入图片描述\"></p> <p>3.netty代码中添加日志功能，</p> <p><img src=\"https://img-blog.csdnimg.cn/6c4005a00da44d10a04276161e0af877.png\" alt=\"在这里插入图片描述\"></p> <p>并添加注解@Slf4j即可， 输出的日志如下</p> <p><img src=\"https://img-blog.csdnimg.cn/e339489f66b748ff9025152be42342b7.png\" alt=\"在这里插入图片描述\"></p> <h3><a id=\"NettyLoggingHandler_554\"></a>Netty中的LoggingHandler</h3> <p>netty自带一个日志记录的Handler，叫LoggingHandler，这个Handler使用netty的日志框架打印日志，而netty默认 的日志是java的日志框架java logger，而java的日志框架默认级别是INFO级别，所以需要我们在pipeline中加入此Handler，则可以打印netty的运行日志。</p> <p>当在客户端和服务端的ChannelInitializer继承类中添加.addLast(“logging”, new LoggingHandler(LogLevel.INFO))这行代码时</p> <p>Netty就会以给定的日志级别打印出LoggingHandler中的日志。</p> <p>可以对入站\\出站事件进行日志记录，从而方便我们进行问题排查。</p> <pre><code class=\"prism language-java\"><span class=\"token keyword\">public</span>  <span class=\"token keyword\">class</span>  <span class=\"token class-name\">NettyClientChannelInitializer</span>  <span class=\"token keyword\">extends</span>  <span class=\"token class-name\">ChannelInitializer</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">SocketChannel</span><span class=\"token punctuation\">&gt;</span></span>  <span class=\"token punctuation\">{\n      <!-- --></span>\n\n        <span class=\"token comment\">//给pipeline设置处理器</span>\n        <span class=\"token keyword\">protected</span>  <span class=\"token keyword\">void</span>  <span class=\"token function\">initChannel</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">SocketChannel</span>  channel<span class=\"token punctuation\">)</span>  <span class=\"token keyword\">throws</span>  <span class=\"token class-name\">Exception</span>  <span class=\"token punctuation\">{\n      <!-- --></span>\n                <span class=\"token class-name\">ChannelPipeline</span>  p  <span class=\"token operator\">=</span>  channel<span class=\"token punctuation\">.</span><span class=\"token function\">pipeline</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n                p<span class=\"token punctuation\">.</span><span class=\"token function\">addLast</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"logging\"</span><span class=\"token punctuation\">,</span><span class=\"token keyword\">new</span>  <span class=\"token class-name\">LoggingHandler</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">LogLevel</span><span class=\"token punctuation\">.</span>INFO<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>      <span class=\"token comment\">//Netty自带的日志记录handler，这个handler使用Netty的日志框架打印日志，可以打印Netty的运行日志</span>\n                p<span class=\"token punctuation\">.</span><span class=\"token function\">addLast</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"decoder\"</span><span class=\"token punctuation\">,</span>  <span class=\"token keyword\">new</span>  <span class=\"token class-name\">StringDecoder</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">CharsetUtil</span><span class=\"token punctuation\">.</span>UTF_8<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>      向pipeline加入解码器\n                p<span class=\"token punctuation\">.</span><span class=\"token function\">addLast</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"encoder\"</span><span class=\"token punctuation\">,</span>  <span class=\"token keyword\">new</span>  <span class=\"token class-name\">StringEncoder</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">CharsetUtil</span><span class=\"token punctuation\">.</span>UTF_8<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>      向pipeline加入编码器\n                <span class=\"token comment\">//找到管道，添加handler</span>\n                p<span class=\"token punctuation\">.</span><span class=\"token function\">addLast</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span>  <span class=\"token class-name\">NettyClientHandler2</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n</code></pre> <p>假如现在添加这行代码访问http://127.0.0.1:8007/Action?name=1234510</p> <pre><code class=\"prism language-logging\">19:10:52.089 [nioEventLoopGroup-2-6] INFO io.netty.handler.logging.LoggingHandler - [id: 0x4a9db561, L:/127.0.0.1:8007 - R:/127.0.0.1:53151] REGISTERED\n19:10:52.089 [nioEventLoopGroup-2-6] INFO io.netty.handler.logging.LoggingHandler - [id: 0x4a9db561, L:/127.0.0.1:8007 - R:/127.0.0.1:53151] ACTIVE\n19:10:52.090 [nioEventLoopGroup-2-6] DEBUG com.bihang.seaya.server.handler.SeayaHandler - io.netty.handler.codec.http.DefaultHttpRequest\n19:10:52.090 [nioEventLoopGroup-2-6] DEBUG com.bihang.seaya.server.handler.SeayaHandler - uri/Action?name=1234510\n19:10:52.090 [nioEventLoopGroup-2-6] INFO io.netty.handler.logging.LoggingHandler - [id: 0x4a9db561, L:/127.0.0.1:8007 - R:/127.0.0.1:53151] CLOSE\n19:10:52.090 [nioEventLoopGroup-2-6] INFO io.netty.handler.logging.LoggingHandler - [id: 0x4a9db561, L:/127.0.0.1:8007 ! R:/127.0.0.1:53151] INACTIVE\n19:10:52.090 [nioEventLoopGroup-2-6] INFO io.netty.handler.logging.LoggingHandler - [id: 0x4a9db561, L:/127.0.0.1:8007 ! R:/127.0.0.1:53151] UNREGISTERED\n1234567\npublic  class  NettyServerChannelInitializer  extends  ChannelInitializer&lt;SocketChannel&gt;  {\n\n        //给pipeline设置处理器\n        protected  void  initChannel(SocketChannel  channel)  throws  Exception  {\n                ChannelPipeline  p  =  channel.pipeline();\n                p.addLast(\"logging\",new  LoggingHandler(LogLevel.INFO));      //Netty自带的日志记录handler，这个handler使用Netty的日志框架打印日志，可以打印Netty的运行日志\n                p.addLast(\"decoder\",  new  StringDecoder(CharsetUtil.UTF_8));      向pipeline加入解码器\n                p.addLast(\"encoder\",  new  StringEncoder(CharsetUtil.UTF_8));      向pipeline加入编码器\n                //找到管道，添加handler\n                p.addLast(new  NettyClientHandler2());\n        }\n}\n\n</code></pre> <p>如果没有这行代码的打印信息</p> <pre><code class=\"prism language-logging\">19:15:02.292 [nioEventLoopGroup-2-2] DEBUG com.bihang.seaya.server.handler.SeayaHandler - io.netty.handler.codec.http.DefaultHttpRequest\n19:15:02.292 [nioEventLoopGroup-2-2] DEBUG com.bihang.seaya.server.handler.SeayaHandler - uri/Action?name=1234510\n</code></pre> <h2><a id=\"_616\"></a>参考文献</h2> <p>https://blog.csdn.net/qq779247257/article/details/97489053</p> <p>https://www.kancloud.cn/ssj234/netty-source/433218</p> <p>https://baijiahao.baidu.com/s?id=1699987481329902906&amp;wfr=spider&amp;for=pc</p> <p>https://blog.csdn.net/qq_32785495/article/details/118964738</p> <p>https://blog.csdn.net/Lemon_MY/article/details/107220008</p></li>\n </ul> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 1689);
INSERT INTO `crawlerblog` VALUES (123124024, '单例模式（史上最全）', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <p>文章很长，而且持续更新，建议收藏起来，慢慢读！<a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\"><strong>疯狂创客圈总目录 博客园版</strong></a> 为您奉上珍贵的学习资源 ：</p> \n <p>免费赠送 :<a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\"><strong>《尼恩Java面试宝典》</strong></a> 持续更新+ 史上最全 + 面试必备 2000页+ 面试必备 + 大厂必备 +涨薪必备<br> 免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\"><strong>《Java高并发核心编程（卷1）加强版》</strong></a> 面试必备 + 大厂必备 +涨薪必备 加尼恩免费领<br> 免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\"><strong>《Java高并发核心编程（卷2）加强版》</strong> </a> 面试必备 + 大厂必备 +涨薪必备 加尼恩免费领<br> 免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\"><strong>《Java高并发核心编程（卷3）加强版》</strong></a> 面试必备 + 大厂必备 +涨薪必备 加尼恩免费领<br> 免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\">《<strong>尼恩Java面试宝典 最新版</strong>》 </a> 面试必备 + 大厂必备 +涨薪必备 加尼恩免费领<br> 免费赠送 资源宝库： <strong>Java 必备 百度网盘资源大合集 价值</strong>&gt;10000元 加尼恩领取</p> \n <hr> \n <h2><a id=\"_11\"></a>该如何优雅的、安全的使用单例模式呢？</h2> \n <p>单例模式是Java的核心模式，最好人人都精通。</p> \n <p>那么，该如何优雅的使用单例模式呢？</p> \n <p>来看看：</p> \n <ul>\n  <li>缓存之王 Caffeine 源码中，如何使用单例模式的？</li>\n  <li>链路之王 Skywalking 源码中，如何使用单例模式的？</li>\n </ul> \n <p>另外，也看看 美团是如何进行 单例模式 的面试的。下面是一个美团面试题：</p> \n <ul>\n  <li>单例模式懒汉式和饿汉式有哪些区别？(美团)</li>\n </ul> \n <blockquote> \n  <p>注：本文以 PDF 持续更新，最新尼恩 架构笔记、面试题 的PDF文件，请从下面的链接获取：<a href=\"https://www.yuque.com/crazymakercircle/gkkw8s/khigna\">语雀</a> 或者 <a href=\"https://gitee.com/crazymaker/SimpleCrayIM/blob/master/%E7%96%AF%E7%8B%82%E5%88%9B%E5%AE%A2%E5%9C%88%E6%80%BB%E7%9B%AE%E5%BD%95.md\">码云</a></p> \n </blockquote> \n <h3><a id=\"1_27\"></a>1.什么是单例</h3> \n <ul>\n  <li>保证一个类只有一个实例，并且提供一个访问该全局访问点</li>\n </ul> \n <h3><a id=\"2_31\"></a>2.那些地方用到了单例模式</h3> \n <ol>\n  <li>网站的计数器，一般也是采用单例模式实现，否则难以同步。</li>\n  <li>应用程序的日志应用，一般都是单例模式实现，只有一个实例去操作才好，否则内容不好追加显示。</li>\n  <li>多线程的线程池的设计一般也是采用单例模式，因为线程池要方便对池中的线程进行控制</li>\n  <li>Windows的（任务管理器）就是很典型的单例模式，他不能打开俩个</li>\n  <li>windows的（回收站）也是典型的单例应用。在整个系统运行过程中，回收站只维护一个实例。</li>\n </ol> \n <h3><a id=\"3_39\"></a>3.单例优缺点</h3> \n <p><strong>优点：</strong></p> \n <ol>\n  <li>在单例模式中，活动的单例只有一个实例，对单例类的所有实例化得到的都是相同的一个实例。这样就防止其它对象对自己的实例化，确保所有的对象都访问一个实例</li>\n  <li>单例模式具有一定的伸缩性，类自己来控制实例化进程，类就在改变实例化进程上有相应的伸缩性。</li>\n  <li>提供了对唯一实例的受控访问。</li>\n  <li>由于在系统内存中只存在一个对象，因此可以节约系统资源，当需要频繁创建和销毁的对象时单例模式无疑可以提高系统的性能。</li>\n  <li>允许可变数目的实例。</li>\n  <li>避免对共享资源的多重占用。</li>\n </ol> \n <p><strong>缺点：</strong></p> \n <ol>\n  <li>不适用于变化的对象，如果同一类型的对象总是要在不同的用例场景发生变化，单例就会引起数据的错误，不能保存彼此的状态。</li>\n  <li>由于单利模式中没有抽象层，因此单例类的扩展有很大的困难。</li>\n  <li>单例类的职责过重，在一定程度上违背了“单一职责原则”。</li>\n  <li>滥用单例将带来一些负面问题，如为了节省资源将数据库连接池对象设计为的单例类，可能会导致共享连接池对象的程序过多而出现连接池溢出；如果实例化的对象长时间不被利用，系统会认为是垃圾而被回收，这将导致对象状态的丢失。</li>\n </ol> \n <h3><a id=\"4_57\"></a>4.单例模式使用注意事项：</h3> \n <ol>\n  <li>使用时不能用反射模式创建单例，否则会实例化一个新的对象</li>\n  <li>使用懒单例模式时注意线程安全问题</li>\n  <li>饿单例模式和懒单例模式构造方法都是私有的，因而是不能被继承的，有些单例模式可以被继承（如登记式模式）</li>\n </ol> \n <h3><a id=\"5_63\"></a>5.单例防止反射漏洞攻击</h3> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">private</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">boolean</span> flag <span class=\"token operator\">=</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">private</span> <span class=\"token class-name\">Singleton</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n\n	<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>flag <span class=\"token operator\">==</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n		flag <span class=\"token operator\">=</span> <span class=\"token operator\">!</span>flag<span class=\"token punctuation\">;</span>\n	<span class=\"token punctuation\">}</span> <span class=\"token keyword\">else</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n		<span class=\"token keyword\">throw</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">RuntimeException</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"单例模式被侵犯！\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n	<span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">void</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">String</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> args<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h3><a id=\"6_82\"></a>6.如何选择单例创建方式</h3> \n <ul>\n  <li>如果不需要延迟加载单例，可以使用枚举或者饿汉式，相对来说枚举性好于饿汉式。<br> 如果需要延迟加载，可以使用静态内部类或者懒汉式，相对来说静态内部类好于懒韩式。<br> 最好使用饿汉式</li>\n </ul> \n <h3><a id=\"7_88\"></a>7.单例创建方式</h3> \n <p><strong>（主要使用懒汉和懒汉式）</strong></p> \n <p>1.饿汉式:<br> 类初始化时,会立即加载该对象，线程天生安全,调用效率高。</p> \n <p>2.懒汉式:<br> 类初始化时,不会初始化该对象,真正需要使用的时候才会创建该对象,具备懒加载功能。</p> \n <p>3.静态内部方式:<br> 结合了懒汉式和饿汉式各自的优点，真正需要对象的时候才会加载，加载类是线程安全的。</p> \n <p>4.枚举单例:<br> 使用枚举实现单例模式</p> \n <p>优点: 实现简单、调用效率高，枚举本身就是单例， 由jvm从根本上提供保障!避免通过反射和反序列化的漏洞;</p> \n <p>缺点: 没有延迟加载。</p> \n <p>5.双重检测锁方式</p> \n <p>因为JVM重排序、内存可见性的原因，可能会初始化多次，</p> \n <p>所以： 需要通过 Double Check 双重检查+ synchronized + Volatile 解决 同步问题和可见性问题。</p> \n <h4><a id=\"1_114\"></a>1.饿汉式</h4> \n <p>类初始化时,会立即加载该对象，线程天生安全,调用效率高。</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>crazymakercircle<span class=\"token punctuation\">.</span>designmodel<span class=\"token punctuation\">.</span>singleton</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">//饿汉式</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">FSingleton</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n\n    <span class=\"token comment\">// 类初始化时,会立即加载该对象，线程安全,调用效率高</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">final</span> <span class=\"token class-name\">FSingleton</span> instance <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">FSingleton</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n    <span class=\"token comment\">// 私有化构造方法</span>\n    <span class=\"token keyword\">private</span> <span class=\"token class-name\">FSingleton</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token punctuation\">}</span>\n\n <span class=\"token keyword\">public</span>   <span class=\"token keyword\">static</span> <span class=\"token class-name\">FSingleton</span> <span class=\"token function\">getInstance</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token keyword\">return</span> instance<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n\n<span class=\"token punctuation\">}</span>\n\n\n</code></pre> \n <p>饿汉模式就是类一旦加载，就把单例初始化完成，保证getInstance的时候，单例是已经存在的了。</p> \n <p>特点：</p> \n <ul>\n  <li>是否 Lazy 初始化：否</li>\n  <li>是否多线程安全：是</li>\n  <li>实现难度：易</li>\n </ul> \n <p>优点：</p> \n <ul>\n  <li>没有加锁，执行效率会提高。</li>\n  <li>这种方式比较常用，但容易产生垃圾对象</li>\n  <li>它基于JVM class loader 机制, 是单线程执行的， 避免了多线程的同步问题</li>\n </ul> \n <p>缺点：</p> \n <ul>\n  <li>类加载时就初始化，浪费内存，</li>\n </ul> \n <h4><a id=\"2_162\"></a>2.懒汉式</h4> \n <p>类初始化时,不会初始化该对象,</p> \n <p>真正需要使用的时候，才会创建该对象,具备懒加载功能。</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>crazymakercircle<span class=\"token punctuation\">.</span>designmodel<span class=\"token punctuation\">.</span>singleton</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">//懒汉模式</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">FLazySingleton</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n\n    <span class=\"token comment\">//类初始化时，不会初始化该对象，真正需要使用的时候才会创建该对象。</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">static</span>  <span class=\"token class-name\">FLazySingleton</span> instance <span class=\"token operator\">=</span> <span class=\"token keyword\">null</span><span class=\"token punctuation\">;</span>\n\n    <span class=\"token comment\">// 私有化构造方法</span>\n    <span class=\"token keyword\">private</span> <span class=\"token class-name\">FLazySingleton</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\">//真正需要使用的时候才会创建该对象</span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">synchronized</span> <span class=\"token class-name\">FLazySingleton</span> <span class=\"token function\">getInstance</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">null</span><span class=\"token operator\">==</span>instance<span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">{\n    <!-- --></span>\n            instance<span class=\"token operator\">=</span><span class=\"token keyword\">new</span> <span class=\"token class-name\">FLazySingleton</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> instance<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h4><a id=\"3_191\"></a>3.静态内部类</h4> \n <p>静态内部方式:</p> \n <p>结合了懒汉式和饿汉式各自的优点，真正需要对象的时候才会加载，加载类是线程安全的。</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>crazymakercircle<span class=\"token punctuation\">.</span>designmodel<span class=\"token punctuation\">.</span>singleton</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">Singleton</span> <span class=\"token punctuation\">{\n    <!-- --></span> \n    <span class=\"token comment\">//静态内部类 </span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">LazyHolder</span> <span class=\"token punctuation\">{\n    <!-- --></span> \n          <span class=\"token comment\">//通过final保障初始化时的线程安全 </span>\n           <span class=\"token keyword\">private</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">final</span> <span class=\"token class-name\">Singleton</span> <span class=\"token constant\">INSTANCE</span> <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Singleton</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n    <span class=\"token punctuation\">}</span> \n       <span class=\"token comment\">//私有的构造器 </span>\n    <span class=\"token keyword\">private</span> <span class=\"token class-name\">Singleton</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{\n    <!-- --></span><span class=\"token punctuation\">}</span> \n      <span class=\"token comment\">//获取单例的方法 </span>\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">final</span> <span class=\"token class-name\">Singleton</span> <span class=\"token function\">getInstance</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span> \n      <span class=\"token comment\">//返回内部类的静态、最终成员 </span>\n       <span class=\"token keyword\">return</span> <span class=\"token class-name\">LazyHolder</span><span class=\"token punctuation\">.</span><span class=\"token constant\">INSTANCE</span><span class=\"token punctuation\">;</span> \n    <span class=\"token punctuation\">}</span> \n<span class=\"token punctuation\">}</span> \n</code></pre> \n <h4><a id=\"4_216\"></a>4.枚举单例式</h4> \n <p>枚举单例:</p> \n <p>使用枚举实现单例模式 优点:实现简单、调用效率高，</p> \n <p>枚举本身就是单例，由jvm从根本上提供保障!避免通过反射和反序列化的漏洞， 缺点没有延迟加载。</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>lijie</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>crazymakercircle<span class=\"token punctuation\">.</span>designmodel<span class=\"token punctuation\">.</span>singleton</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">//饿汉式</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">enum</span> <span class=\"token class-name\">SingletonEnumStyle</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token constant\">INSTANCE</span><span class=\"token punctuation\">;</span>\n    <span class=\"token comment\">// 类初始化时,会立即加载该对象，线程安全,调用效率高</span>\n\n    <span class=\"token keyword\">public</span>  <span class=\"token keyword\">static</span> <span class=\"token class-name\">SingletonEnumStyle</span> <span class=\"token function\">getInstance</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token keyword\">return</span> <span class=\"token constant\">INSTANCE</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>枚举实现单例模式 优点:</p> \n <ul>\n  <li>实现简单、枚举本身就是单例，由jvm从根本上提供保障!</li>\n  <li>避免通过反射和反序列化的漏洞</li>\n </ul> \n <p>缺点：</p> \n <ul>\n  <li>没有延迟加载</li>\n </ul> \n <h4><a id=\"5_251\"></a>5.双重检测锁方式</h4> \n <p>所谓懒加载，就是直到第一次被调用时才加载。其实现需要考虑并发问题和指令重排，代码如下：</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">Singleton</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n \n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">volatile</span> <span class=\"token keyword\">static</span> <span class=\"token class-name\">Singleton</span> instance<span class=\"token punctuation\">;</span> <span class=\"token comment\">//①</span>\n \n    <span class=\"token keyword\">private</span> <span class=\"token class-name\">Singleton</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span> <span class=\"token comment\">//②</span>\n    <span class=\"token punctuation\">}</span>\n \n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token class-name\">Singleton</span> <span class=\"token function\">getInstance</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>instance <span class=\"token operator\">==</span> <span class=\"token keyword\">null</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span><span class=\"token comment\">//③</span>\n            <span class=\"token keyword\">synchronized</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">Singleton</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n                <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>instance <span class=\"token operator\">==</span> <span class=\"token keyword\">null</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span><span class=\"token comment\">//④</span>\n                    instance <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Singleton</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span class=\"token comment\">//⑤</span>\n                <span class=\"token punctuation\">}</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> instance<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>这段代码精简至极，没有一个字符是多余的，下面逐行解读一下：</p> \n <p>首先，注意到①处的volatile关键字，它具备两项特性：</p> \n <blockquote> \n  <p>一是保证此变量对于所有线程的可见性。</p> \n  <p>即当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。</p> \n  <p>二是禁止指令重排序优化。</p> \n </blockquote> \n <p>这里解释一下指令重排序优化：</p> \n <p>代码 ⑤ 处的instance = new Singleton(); 并不是原子的，大体可分为如下 3 步：</p> \n <ol>\n  <li>分配内存</li>\n  <li>调用构造函数初始化成实例</li>\n  <li>让instance指向分配的内存空间</li>\n </ol> \n <p>JVM 允许在保证结果正确的前提下进行指令重排序优化。</p> \n <p>即如上 3 步可能的顺序为1-&gt;2-&gt;3 或 1-&gt;3-&gt;2 。</p> \n <p>如果顺序是 1-&gt;3-&gt;2 ，当 3 执行完，2 还未执行时，另一个线程执行到代码 ③ 处，发现instance不为null，直接返回还未初始化好的instance并使用，就会报错。</p> \n <p>所以使用volatile，就是为了保证线程间的可见性和防止指令重排。</p> \n <p>其次，代码②处将构造函数声明为private目的：在于阻止使用new Singleton()这样的代码生成新实例。</p> \n <p>最后，当客户端调用Singleton.getInstance()时，先检查是否已经实例化(代码③)，未实例化时同步代码块，然后再次检查是否已实例化(代码④)，然后才执行代码⑤。</p> \n <p>两次检查的意义在于，防止synchronized同步过程中其他线程进行了实例化。</p> \n <p>这就是著名的双重检查锁(Double check lock)实现单例，也即懒加载。</p> \n <blockquote> \n  <p>TIPS:</p> \n  <p>网上也有直接对 getInstance()方法加锁的版本，这样大范围的方法级别加锁会导致并发变低，实际上第一次调用生成实例之后，后续获取实例根本不需要并发控制了。</p> \n  <p>而本例的双重检查锁版本可以避免此并发问题。</p> \n </blockquote> \n <p>双重检测锁 单例 非常重要， 涉及到Volatile 和可见性的底层原理， 深入学习/系统学习 双重检测锁 单例的内容， 请参见 《Java 高并发核心编程 卷2》 <strong>第8.1节：线程安全的单例模式</strong></p> \n <p><img src=\"https://img-blog.csdnimg.cn/95822f2f2e5f4efba9f865ad635b1682.png\" alt=\"\"></p> \n <h4><a id=\"_Caffeine__332\"></a>缓存之王 Caffeine 源码中，如何使用单例模式的？</h4> \n <p>答案是：枚举单例</p> \n <p>并且，单例的名称叫做 INSTANCE</p> \n <p>通过这个 INSTANCE 名字 做 关键词搜索， 能搜到一大把</p> \n <p><img src=\"https://img-blog.csdnimg.cn/4bce271b050b4a1f86f35a93881b1679.png\" alt=\"\"></p> \n <p>来一个案例</p> \n <p><img src=\"https://img-blog.csdnimg.cn/bd68fd21e671443fbfb16d037f677059.png\" alt=\"\"></p> \n <p>再来一个案例</p> \n <p><img src=\"https://img-blog.csdnimg.cn/bdc8393b66164d86b484a0b279274912.png\" alt=\"\"></p> \n <p>缓存之王 Caffeine 的详细资料，请参考下面的博客、或者对应的PDF文件：</p> \n <ul>\n  <li>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128123114\">彻底穿透 缓存之王：Caffeine 源码、架构、原理（史上最全，10W字 超级长文）</a>》</li>\n  <li>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/113751575\">彻底穿透 缓存之王：Caffeine 的使用（史上最全）</a>》</li>\n </ul> \n <h4><a id=\"_Skywalking__365\"></a>链路之王 Skywalking 源码中，如何使用单例模式的？</h4> \n <p>答案是：枚举单例</p> \n <p>并且，单例的名称叫做 INSTANCE</p> \n <p><img src=\"https://img-blog.csdnimg.cn/7700a7c00c3d4e5fb7d9f96257b34644.png\" alt=\"\"></p> \n <h3><a id=\"8__381\"></a>8 单例模式懒汉式和饿汉式有哪些区别？(美团)</h3> \n <p>单例模式是 Java 中最简单的设计模式之一。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。<br> 这种模式涉及到一个单一的类，该类负责创建自己的对象，同时确保只有单个对象被创建。这个类提供了一种访问其唯一的对象的方式，可以直接访问，不需要实例化该类的对象。</p> \n <p><strong>注意：</strong><br> 1、单例类只能有一个实例。<br> 2、单例类必须自己创建自己的唯一实例。<br> 3、单例类必须给所有其他对象提供这一实例。</p> \n <p>明确定义后，看一下代码：</p> \n <h4><a id=\"_393\"></a>饿汉模式</h4> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>crazymakercircle<span class=\"token punctuation\">.</span>designmodel<span class=\"token punctuation\">.</span>singleton</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">//饿汉式</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">FSingleton</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n\n    <span class=\"token comment\">// 类初始化时,会立即加载该对象，线程安全,调用效率高</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">final</span> <span class=\"token class-name\">FSingleton</span> instance <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">FSingleton</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n    <span class=\"token comment\">// 私有化构造方法</span>\n    <span class=\"token keyword\">private</span> <span class=\"token class-name\">FSingleton</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token punctuation\">}</span>\n\n <span class=\"token keyword\">public</span>   <span class=\"token keyword\">static</span> <span class=\"token class-name\">FSingleton</span> <span class=\"token function\">getInstance</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token keyword\">return</span> instance<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>饿汉模式就是类一旦加载，就把单例初始化完成，保证getInstance的时候，单例是已经存在的了。</p> \n <p>特点：</p> \n <ul>\n  <li>是否 Lazy 初始化：否</li>\n  <li>是否多线程安全：是</li>\n  <li>实现难度：易</li>\n </ul> \n <p>优点：</p> \n <ul>\n  <li>没有加锁，执行效率会提高。</li>\n  <li>这种方式比较常用，但容易产生垃圾对象</li>\n  <li>它基于JVM class loader 机制, 是单线程执行的， 避免了多线程的同步问题</li>\n </ul> \n <p>缺点：</p> \n <ul>\n  <li>类加载时就初始化，浪费内存，</li>\n </ul> \n <h4><a id=\"_435\"></a>懒汉模式</h4> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">Singleton</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n \n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">volatile</span> <span class=\"token keyword\">static</span> <span class=\"token class-name\">Singleton</span> instance<span class=\"token punctuation\">;</span> <span class=\"token comment\">//①</span>\n \n    <span class=\"token keyword\">private</span> <span class=\"token class-name\">Singleton</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span> <span class=\"token comment\">//②</span>\n    <span class=\"token punctuation\">}</span>\n \n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token class-name\">Singleton</span> <span class=\"token function\">getInstance</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>instance <span class=\"token operator\">==</span> <span class=\"token keyword\">null</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span><span class=\"token comment\">//③</span>\n            <span class=\"token keyword\">synchronized</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">Singleton</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n                <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>instance <span class=\"token operator\">==</span> <span class=\"token keyword\">null</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span><span class=\"token comment\">//④</span>\n                    instance <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Singleton</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span class=\"token comment\">//⑤</span>\n                <span class=\"token punctuation\">}</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">return</span> instance<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>而懒汉比较懒，只有当调用getInstance的时候，才回去初始化这个单例。</p> \n <p>特点：</p> \n <ul>\n  <li>是否 Lazy 初始化：是</li>\n  <li>是否多线程安全：是</li>\n  <li>实现难度：难</li>\n </ul> \n <h4><a id=\"1_470\"></a>1、线程安全：</h4> \n <p>饿汉式天生就是线程安全的，可以直接用于多线程而不会出现问题，</p> \n <p>懒汉式本身是非线程安全的，需要通过多种手段，保证线程安全和内存可见性：</p> \n <ul>\n  <li>volatile 保证内存可见性</li>\n  <li>synchronized + 双重检查 保证线程安全</li>\n </ul> \n <h4><a id=\"2_479\"></a>2、资源加载和性能：</h4> \n <p>饿汉式在类创建的同时就实例化一个静态对象出来，不管之后会不会使用这个单例，都会占据一定的内存，但是相应的，在第一次调用时速度也会更快，因为其资源已经初始化完成。</p> \n <p>而懒汉式顾名思义，会延迟加载，在第一次使用该单例的时候才会实例化对象出来，第一次调用时要做初始化，如果要做的工作比较多，性能上会有些延迟，之后就和饿汉式一样了。</p> \n <ul>\n  <li>意图：保证一个类仅有一个实例，并提供一个访问它的全局访问点。</li>\n  <li>主要解决：一个全局使用的类频繁地创建与销毁。</li>\n  <li>何时使用：当您想控制实例数目，节省系统资源的时候。</li>\n  <li>如何解决：判断系统是否已经有这个单例，如果有则返回，如果没有则创建。</li>\n  <li>关键代码：构造函数是私有的。</li>\n  <li>应用实例：</li>\n </ul> \n <p>1、一个党只能有一个主席。<br> 2、Windows是多进程多线程的，在操作一个文件的时候，就不可避免地出现多个进程或线程同时操作一个文件的现象，所以所有文件的处理必须通过唯一的实例来进行。<br> 3、一些设备管理器常常设计为单例模式，比如一个电脑有两台打印机，在输出的时候就要处理不能两台打印机打印同一个文件。</p> \n <p>优点：</p> \n <p>1、在内存里只有一个实例，减少了内存的开销，尤其是频繁的创建和销毁实例（比如管理学院首页页面缓存）。<br> 2、避免对资源的多重占用（比如写文件操作）。</p> \n <p>缺点：没有接口，不能继承，与单一职责原则冲突，一个类应该只关心内部逻辑，而不关心外面怎么样来实例化。</p> \n <p>使用场景：</p> \n <p>1、要求生产唯一序列号。<br> 2、WEB 中的计数器，不用每次刷新都在数据库里加一次，用单例先缓存起来。<br> 3、创建的一个对象需要消耗的资源过多，比如 I/O 与数据库的连接等。</p> \n <p>注意事项：getInstance() 方法中需要使用 Double Check 双重检查锁,synchronized (Singleton.class) 防止多线程同时进入造成instance 被多次实例化。</p> \n <blockquote> \n  <p>注：本文以 PDF 持续更新，最新尼恩 架构笔记、面试题 的PDF文件，请从下面的链接获取：<a href=\"https://www.yuque.com/crazymakercircle/gkkw8s/khigna\">语雀</a> 或者 <a href=\"https://gitee.com/crazymaker/SimpleCrayIM/blob/master/%E7%96%AF%E7%8B%82%E5%88%9B%E5%AE%A2%E5%9C%88%E6%80%BB%E7%9B%AE%E5%BD%95.md\">码云</a></p> \n </blockquote> \n <h2><a id=\"_520\"></a>推荐阅读：</h2> \n <ul>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124790425\">尼恩Java面试宝典</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057567\">Springcloud gateway 底层原理、核心实战 (史上最全)</a>》</p> </li>\n  <li> <p>《<a href=\"https://editor.csdn.net/md/?articleId=124120506\">Flux、Mono、Reactor 实战（史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125059491\">sentinel （史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057545\">Nacos (史上最全)</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/123420859\">分库分表 Sharding-JDBC 底层原理、核心实战（史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://editor.csdn.net/md/?articleId=126992542\">clickhouse 超底层原理 + 高可用实操 （史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://editor.csdn.net/md/?articleId=125427517\">redis 集群 实操 （史上最全、5w字长文）</a>》</p> </li>\n  <li> <p>《<a href=\"https://editor.csdn.net/md/?articleId=125135726\">一文搞定：SpringBoot、SLF4j、Log4j、Logback、Netty之间混乱关系（史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://editor.csdn.net/md/?articleId=125017316\">红黑树（ 图解 + 秒懂 + 史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/109459593\">分布式事务 （秒懂）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128123114\">缓存之王：Caffeine 源码、架构、原理（史上最全，10W字 超级长文）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/113751575\">缓存之王：Caffeine 的使用（史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126579528\">Java Agent 探针、字节码增强 ByteBuddy（史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120747767\">Docker原理（图解+秒懂+史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/116425814\">Redis分布式锁（图解 - 秒懂 - 史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85956246\">Zookeeper 分布式锁 - 图解 - 秒懂</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85922561\">Zookeeper Curator 事件监听 - 10分钟看懂</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83957259\">Netty 粘包 拆包 | 史上最全解读</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83758107\">Netty 100万级高并发服务器配置</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/102557988\">Springcloud 高并发 配置 （一文全懂）</a>》</p> </li>\n </ul> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 1821);
INSERT INTO `crawlerblog` VALUES (123124025, NULL, NULL, NULL, NULL, NULL);
INSERT INTO `crawlerblog` VALUES (123124026, '网易二面：CPU狂飙900%，该怎么处理？', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <h2><a id=\"_2\"></a>说在前面</h2> \n <p>社群一位小伙伴面试了 网易，遇到了一个 性能类的面试题：</p> \n <h2><a id=\"CPU900_7\"></a>CPU飙升900%，该怎么处理？</h2> \n <p>可惜的是，以上的问题，这个小伙没有回答理想。</p> \n <p><strong>最终，导致他网易之路，终止在二面，非常可惜</strong></p> \n <p>现在把这个 题目，以及参考答案，收入咱们的</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124790425\">尼恩Java面试宝典 PDF</a>》<br> ，供后面的小伙伴参考，前车之鉴啊</p> \n <h3><a id=\"CPU200__18\"></a>首先，说明一下问题：CPU飙升200% 以上是生产容易发生的场景</h3> \n <blockquote> \n  <p>注：本文以 PDF 持续更新，最新尼恩 架构笔记、面试题 的PDF文件，请从这里获取：<a href=\"https://gitee.com/crazymaker/SimpleCrayIM/blob/master/%E7%96%AF%E7%8B%82%E5%88%9B%E5%AE%A2%E5%9C%88%E6%80%BB%E7%9B%AE%E5%BD%95.md\">码云</a></p> \n </blockquote> \n <hr> \n <h4><a id=\"1MySQL900_25\"></a>场景:1：MySQL进程飙升900%</h4> \n <p>大家在使用MySQL过程，想必都有遇到过CPU突然过高，或者达到200%以上的情况。</p> \n <p>数据库执行查询或数据修改操作时，系统需要消耗大量的CPU资源维护从存储系统、内存数据中的一致性。</p> \n <p>并发量大并且大量SQL性能低的情况下，比如字段是没有建立索引，则会导致快速CPU飙升，如果还开启了慢日志记录，会导致性能更加恶化。生产上有MYSQL 飙升900% 的恶劣情况。</p> \n <h4><a id=\"2Java900_33\"></a>场景2：Java进程飙升900%</h4> \n <p>一般来说Java 进程不做大量 CPU 运算，正常情况下，CPU 应该在 100~200% 之间，</p> \n <p>但是，一旦高并发场景，要么走到了死循环，要么就是在做大量的 GC, 容易出现这种 CPU 飙升的情况，CPU飙升900%，是完全有可能的。</p> \n <h4><a id=\"900_39\"></a>其他场景：其他的类似进程飙升900%的场景</h4> \n <p>比如Redis、Nginx等等。</p> \n <p><em>尼恩提示：大家介绍场景的时候，就说自己主要涉及了两个场景， Java进程飙升900%、MySQL进程飙升900%两种场景，其实，这两个场景就足够讲半天了， 其他的，使用规避技巧规避一下就行。</em></p> \n <h3><a id=\"MySQLCPU900_45\"></a>场景一：MySQL进程CPU飙升到900%，怎么处理？</h3> \n <hr> \n <p><strong>定位过程：</strong></p> \n <ul>\n  <li>使用top 命令观察，确定是mysqld导致还是其他原因。</li>\n  <li>如果是mysqld导致的，show processlist，查看session情况，确定是不是有消耗资源的sql在运行。</li>\n  <li>找出消耗高的 sql，看看执行计划是否准确， index 是否缺失，或者实在是数据量太大造成。</li>\n </ul> \n <p><strong>处理过程：</strong></p> \n <ul>\n  <li>kill 掉这些线程(同时观察 cpu 使用率是否下降)， 一般来说，肯定要 kill 掉这些线程(同时观察 cpu 使用率是否下降)，等进行相应的调整(比如说加索引、改 sql、改内存参数)之后，再重新跑这些 SQL。</li>\n  <li>进行相应的调整(比如说加索引、改 sql、改内存参数)<br> index 是否缺失，如果是，则 建立索引。也有可能是每个 sql 消耗资源并不多，但是突然之间，有大量的 session 连进来导致 cpu 飙升，这种情况就需要跟应用一起来分析为何连接数会激增，再做出相应的调整，比如说限制连接数等</li>\n  <li>优化的过程，往往不是一步完成的，而是一步一步，执行一项优化措辞，再观察，再优化。</li>\n </ul> \n <h2><a id=\"1MySQL_62\"></a>场景1的真实案例：MySQL数据库优化的真实案例</h2> \n <p><em>尼恩提示：以下案例，来自互联网。大家参考一下，准备一个自己的案例。</em></p> \n <p>本问题亲身经历过。</p> \n <p>之前开发同事编写的SQL语句，就导致过线上CPU过高，MySQL的CPU使用率达到900%+，通过优化最后降低到70%~80%。下面说说个人在这个过程中的排查思路。</p> \n <p>首先，我们要对问题定位而不是盲目的开启什么 慢日志，在并发量大并且大量SQL性能低的情况下，开启慢日志无意是将MySQL推向崩溃的边缘。</p> \n <p>当时遇到这个情况，分析了当前的数据量、索引情况、缓存使用情况。目测数据量不大，也就几百万条而已。接下来就去定位索引、缓存问题。</p> \n <ol>\n  <li>经过询问，发现很多查询都是走MySQL，没有用到缓存。</li>\n  <li>既然没有用到缓存，则是大量请求全部查询MySQL导致。通过下面的命令查看:</li>\n </ol> \n <pre><code class=\"prism language-sql\"><span class=\"token keyword\">show</span> processlist<span class=\"token punctuation\">;</span>\n</code></pre> \n <p>发现类似很多相同的SQL语句，一直处于query状态中。</p> \n <pre><code class=\"prism language-sql\"><span class=\"token keyword\">select</span> id form <span class=\"token keyword\">user</span> <span class=\"token keyword\">where</span> user_code <span class=\"token operator\">=</span> <span class=\"token string\">\'xxxxx\'</span><span class=\"token punctuation\">;</span>\n</code></pre> \n <p>初步分析可能是 user_code 字段没有索引导致。接着查询user表的索引情况：</p> \n <pre><code class=\"prism language-sql\"><span class=\"token keyword\">show</span> <span class=\"token keyword\">index</span> form <span class=\"token keyword\">user</span><span class=\"token punctuation\">;</span>\n</code></pre> \n <p>发现这个字段是没有建立索引。增加索引之后，该条SQL查询能够正常执行。</p> \n <p>3、没隔一会，又发生大量的请求超时问题。接着进行分析，发现是开启了 慢日志查询。大量的SQL查询语句超过慢日志设置的阀值，于是将慢日志关闭之后，速度瞬间提升。CPU的使用率基本保持在300%左右。但还不是理想状态。</p> \n <p>4、紧接着将部分实时查询数据的SQL语句，都通过缓存(redis)读写实现。观察一段时间后，基本维持在了70%~80%。</p> \n <p>总结：其实本次事故的解决很简单，就是添加索引与缓存结合使用。</p> \n <ol>\n  <li>不推荐在这种CPU使用过高的情况下进行慢日志的开启。因为大量的请求，如果真是慢日志问题会发生日志磁盘写入，性能贼低。</li>\n  <li>直接通过MySQL show processlist命令查看，基本能清晰的定位出部分查询问题严重的SQL语句，在针对该SQL语句进行分析。一般可能就是索引、锁、查询大量字段、大表等问题导致。</li>\n  <li>再则一定要使用缓存系统，降低对MySQL的查询频次。</li>\n  <li>对于内存调优，也是一种解决方案。</li>\n </ol> \n <h4><a id=\"2JavaCPU900_108\"></a>场景2展开：Java进程CPU飙升到900%，怎么处理？</h4> \n <hr> \n <p><strong>定位过程：</strong></p> \n <p>CPU飙升问题定位的一般步骤是：</p> \n <ol>\n  <li>首先通过top指令查看当前占用CPU较高的进程PID；</li>\n  <li>查看当前进程消耗资源的线程PID：top -Hp PID</li>\n  <li>通过print命令将线程PID转为16进制，根据该16进制值去打印的堆栈日志内查询，查看该线程所驻留的方法位置。</li>\n  <li>通过jstack命令，查看栈信息，定位到线程对应的具体代码。</li>\n  <li>分析代码解决问题。</li>\n </ol> \n <p><strong>处理过程：</strong></p> \n <ol>\n  <li> <p>如果是空循环，或者空自旋。</p> <p>处理方式：可以使用Thread.sleep或者加锁，让线程适当的阻塞。</p> </li>\n  <li> <p>在循环的代码逻辑中，创建大量的新对象导致频繁GC。比如，从mysql查出了大量的数据，比如100W以上等等。</p> <p>处理方式：可以减少对象的创建数量，或者，可以考虑使用 对象池。</p> </li>\n  <li> <p>其他的一些造成CPU飙升的场景，比如 selector空轮训导致CPU飙升 。</p> <p>处理方式：参考Netty源码，无效的事件查询到了一定的次数，进行 selector 重建。</p> </li>\n </ol> \n <h3><a id=\"JavaCPU_700_138\"></a>Java的CPU 飙升700%优化的真实案例</h3> \n <hr> \n <p><em>尼恩提示：以下案例，来自互联网。大家参考一下，准备一个自己的案例。</em></p> \n <p>最近负责的一个项目上线，运行一段时间后发现对应的进程竟然占用了700%的CPU，导致公司的物理服务器都不堪重负，频繁宕机。</p> \n <p>那么,针对这类java进程CPU飙升的问题，我们一般要怎么去定位解决呢？、</p> \n <h4><a id=\"top_152\"></a>采用top命令定位进程</h4> \n <p>登录服务器，执行top命令，查看CPU占用情况，找到进程的pid</p> \n <pre><code>top\n</code></pre> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/c80a75bbcea98fbdbcfaca66beb6932f.png\" alt=\"\"></p> \n <p>很容易发现，PID为29706的java进程的CPU飙升到700%多，且一直降不下来，很显然出现了问题。</p> \n <h4><a id=\"top_Hp_168\"></a>使用top -Hp命令定位线程</h4> \n <p>使用 <code>top -Hp &lt;pid&gt;</code> 命令（为Java进程的id号）查看该Java进程内所有线程的资源占用情况（按shft+p按照cpu占用进行排序，按shift+m按照内存占用进行排序）</p> \n <p>此处按照cpu排序：</p> \n <pre><code>top -Hp 23602\n</code></pre> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/b000eaa5cd16429d8a1e38e231c33d85.png\" alt=\"\"></p> \n <p>很容易发现，多个线程的CPU占用达到了90%多。我们挑选线程号为30309的线程继续分析。</p> \n <h4><a id=\"jstack_189\"></a>使用jstack命令定位代码</h4> \n <p><strong>1.线程号转换5为16进制</strong></p> \n <p><code>printf “%x\\n”</code> 命令（tid指线程的id号）将以上10进制的线程号转换为16进制：</p> \n <pre><code>printf \"%x\\n\"  30309\n</code></pre> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/7d59f31286eaaba43200b5ddd5dd3d0a.png\" alt=\"\"></p> \n <p>转换后的结果分别为7665，由于导出的线程快照中线程的nid是16进制的，而16进制以0x开头，所以对应的16进制的线程号nid为0x7665</p> \n <p><strong>2.采用jstack命令导出线程快照</strong></p> \n <p>通过使用dk自带命令jstack获取该java进程的线程快照并输入到文件中：</p> \n <pre><code class=\"prism language-bash\"> jstack <span class=\"token parameter variable\">-l</span> 进程ID <span class=\"token operator\">&gt;</span> ./jstack_result.txt \n</code></pre> \n <p>命令（为Java进程的id号）来获取线程快照结果并输入到指定文件。</p> \n <pre><code class=\"prism language-bash\">jstack <span class=\"token parameter variable\">-l</span> <span class=\"token number\">29706</span> <span class=\"token operator\">&gt;</span> ./jstack_result.txt\n</code></pre> \n <p><strong>3.根据线程号定位具体代码</strong></p> \n <p>在jstack_result.txt 文件中根据线程好nid搜索对应的线程描述</p> \n <pre><code class=\"prism language-bash\"><span class=\"token function\">cat</span> jstack_result.txt <span class=\"token operator\">|</span><span class=\"token function\">grep</span> <span class=\"token parameter variable\">-A</span> <span class=\"token number\">100</span>  <span class=\"token number\">7665</span>\n</code></pre> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/25d3958861221b0ed64a13f4091f6809.png\" alt=\"\"></p> \n <p>根据搜索结果，判断应该是ImageConverter.run()方法中的代码出现问题</p> \n <p>当然，这里也可以直接采用</p> \n <pre><code class=\"prism language-bash\">jstack <span class=\"token operator\">&lt;</span>pid<span class=\"token operator\">&gt;</span> <span class=\"token operator\">|</span><span class=\"token function\">grep</span> <span class=\"token parameter variable\">-A</span> <span class=\"token number\">200</span> <span class=\"token operator\">&lt;</span>nid<span class=\"token operator\">&gt;</span>\n</code></pre> \n <p>来定位具体代码</p> \n <pre><code class=\"prism language-bash\"><span class=\"token variable\">$jstack</span> <span class=\"token number\">44529</span> <span class=\"token operator\">|</span><span class=\"token function\">grep</span> <span class=\"token parameter variable\">-A</span> <span class=\"token number\">200</span> ae24\n<span class=\"token string\">\"System Clock\"</span> <span class=\"token comment\">#28 daemon prio=5 os_prio=0 tid=0x00007efc19e8e800 nid=0xae24 waiting on condition [0x00007efbe0d91000]</span>\n   java.lang.Thread.State: TIMED_WAITING <span class=\"token punctuation\">(</span>sleeping<span class=\"token punctuation\">)</span>\n    at java.lang.Thread.sleep<span class=\"token punctuation\">(</span>Native Method<span class=\"token punctuation\">)</span>\n    at java.lang.Thread.sleep<span class=\"token punctuation\">(</span>Thread.java:340<span class=\"token punctuation\">)</span>\n    at java.util.concurrentC.TimeUnit.sleep<span class=\"token punctuation\">(</span>TimeUnit.java:386<span class=\"token punctuation\">)</span>\n    at com.*.order.Controller.OrderController.detail<span class=\"token punctuation\">(</span>OrderController.java:37<span class=\"token punctuation\">)</span>  //业务代码阻塞点\n</code></pre> \n <h4><a id=\"_258\"></a>分析代码解决问题</h4> \n <p>下面是ImageConverter.run()方法中的部分核心代码。</p> \n <p>逻辑说明：</p> \n <pre><code class=\"prism language-java\"><span class=\"token operator\">/</span>存储minicap的socket连接返回的数据   <span class=\"token punctuation\">(</span>改用消息队列存储读到的流数据<span class=\"token punctuation\">)</span> ，设置阻塞队列长度，防止出现内存溢出\n<span class=\"token comment\">//全局变量</span>\n<span class=\"token keyword\">private</span> <span class=\"token class-name\">BlockingQueue</span><span class=\"token operator\">&lt;</span><span class=\"token keyword\">byte</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token operator\">&gt;</span> dataQueue <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">LinkedBlockingQueue</span><span class=\"token operator\">&lt;</span><span class=\"token keyword\">byte</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token operator\">&gt;</span><span class=\"token punctuation\">(</span><span class=\"token number\">100000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">//消费线程</span>\n<span class=\"token annotation punctuation\">@Override</span>\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">run</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token comment\">//long start = System.currentTimeMillis();</span>\n    <span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>isRunning<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token comment\">//分析这里从LinkedBlockingQueue</span>\n        <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>dataQueue<span class=\"token punctuation\">.</span><span class=\"token function\">isEmpty</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n            <span class=\"token keyword\">continue</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token keyword\">byte</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> buffer <span class=\"token operator\">=</span> device<span class=\"token punctuation\">.</span><span class=\"token function\">getMinicap</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>dataQueue<span class=\"token punctuation\">.</span><span class=\"token function\">poll</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n       <span class=\"token keyword\">int</span> len <span class=\"token operator\">=</span> buffer<span class=\"token punctuation\">.</span>length<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>在while循环中，不断读取堵塞队列dataQueue中的数据，如果数据为空，则执行continue进行下一次循环。</p> \n <p>如果不为空，则通过poll()方法读取数据，做相关逻辑处理。</p> \n <p>初看这段代码好像每什么问题，但是如果dataQueue对象长期为空的话，这里就会一直空循环，导致CPU飙升。</p> \n <p>那么如果解决呢？</p> \n <p>分析LinkedBlockingQueue阻塞队列的API发现：</p> \n <pre><code class=\"prism language-java\"><span class=\"token comment\">//取出队列中的头部元素，如果队列为空则调用此方法的线程被阻塞等待，直到有元素能被取出，如果等待过程被中断则抛出InterruptedException</span>\n<span class=\"token class-name\">E</span> <span class=\"token function\">take</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> <span class=\"token class-name\">InterruptedException</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">//取出队列中的头部元素，如果队列为空返回null</span>\n<span class=\"token class-name\">E</span> <span class=\"token function\">poll</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre> \n <p>这两种取值的API，显然take方法更时候这里的场景。</p> \n <p>代码修改为：</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>isRunning<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n   <span class=\"token comment\">/* if (device.getMinicap().dataQueue.isEmpty()) { continue; }*/</span>\n    <span class=\"token keyword\">byte</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> buffer <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token keyword\">byte</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">try</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        buffer <span class=\"token operator\">=</span> device<span class=\"token punctuation\">.</span><span class=\"token function\">getMinicap</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>dataQueue<span class=\"token punctuation\">.</span><span class=\"token function\">take</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">InterruptedException</span> e<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n        e<span class=\"token punctuation\">.</span><span class=\"token function\">printStackTrace</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n……\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>重启项目后，测试发现项目运行稳定，对应项目进程的CPU消耗占比不到10%。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/d1cccf29d4c87d03b09c8d3face46c78.png\" alt=\"75.png\"></p> \n <blockquote> \n  <p>注：本文以 PDF 持续更新，最新尼恩 架构笔记、面试题 的PDF文件，请从这里获取：<a href=\"https://gitee.com/crazymaker/SimpleCrayIM/blob/master/%E7%96%AF%E7%8B%82%E5%88%9B%E5%AE%A2%E5%9C%88%E6%80%BB%E7%9B%AE%E5%BD%95.md\">码云</a></p> \n </blockquote> \n <h3><a id=\"_325\"></a>参考文献：</h3> \n <p>https://developer.aliyun.com/article/1053255</p> \n <p>https://www.zhihu.com/question/22002813/answer/2662962349</p> \n <h2><a id=\"_335\"></a>推荐阅读：</h2> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128725701\">峰值21WQps、亿级DAU，小游戏《羊了个羊》是怎么架构的？</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128533821\">场景题：假设10W人突访，你的系统如何做到不 雪崩？</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128697096\">2个大厂 100亿级 超大流量 红包 架构方案</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128684641\">Nginx面试题（史上最全 + 持续更新）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128671196\">K8S面试题（史上最全 + 持续更新）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128708648\">操作系统面试题（史上最全、持续更新）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128670335\">Docker面试题（史上最全 + 持续更新）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057567\">Springcloud gateway 底层原理、核心实战 (史上最全)</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124120506\">Flux、Mono、Reactor 实战（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125059491\">sentinel （史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057545\">Nacos (史上最全)</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/114527369\">TCP协议详解 (史上最全)</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/123420859\">分库分表 Sharding-JDBC 底层原理、核心实战（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126992542\">clickhouse 超底层原理 + 高可用实操 （史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120702536\">nacos高可用（图解+秒懂+史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264803\">队列之王： Disruptor 原理、架构、源码 一文穿透</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264508\">环形队列、 条带环形队列 Striped-RingBuffer （史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125135726\">一文搞定：SpringBoot、SLF4j、Log4j、Logback、Netty之间混乱关系（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128265067\">单例模式（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125017316\">红黑树（ 图解 + 秒懂 + 史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/109459593\">分布式事务 （秒懂）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128123114\">缓存之王：Caffeine 源码、架构、原理（史上最全，10W字 超级长文）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/113751575\">缓存之王：Caffeine 的使用（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126579528\">Java Agent 探针、字节码增强 ByteBuddy（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120747767\">Docker原理（图解+秒懂+史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/116425814\">Redis分布式锁（图解 - 秒懂 - 史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85956246\">Zookeeper 分布式锁 - 图解 - 秒懂</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85922561\">Zookeeper Curator 事件监听 - 10分钟看懂</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83957259\">Netty 粘包 拆包 | 史上最全解读</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83758107\">Netty 100万级高并发服务器配置</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/102557988\">Springcloud 高并发 配置 （一文全懂）</a>》</p> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 3409);
INSERT INTO `crawlerblog` VALUES (123124027, '一文说清楚http、tcp、socket、websocket区别', '诺浅', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <h1><a id=\"_0\"></a>写在开头</h1> \n <p>阅读本文，需要您对<code>tcp/ip协议簇</code>协议有一定的了解，本文旨在带你了解Socket到底是啥，他与<code>tcp/ip协议簇</code>、<code>WebSocket</code>、<code>Http</code>等协议之间的关系</p> \n <h1><a id=\"OSI__2\"></a>OSI 网络七层模型</h1> \n <ol>\n  <li>第一层：应用层，定义了用于在网络中进行通信和传输数据的接口；（Http协议位于该层）</li>\n  <li>第二层：表示层，定义不同系统中数据的传输格式，编码和解码规范等；</li>\n  <li>第三层：会话层，管理用户的会话，控制用户间逻辑连接的建立和中断；</li>\n  <li>第四层：传输层，管理着网络中端到端的数据传输；（Tcp协议位于该层）</li>\n  <li>第五层：网络层，定义网络设备间如何传输数据；（IP位于该层）</li>\n  <li>链路层，将上面的网络层的数据包封装成数据帧，便于物理层传输；</li>\n  <li>物理层，这一层主要就是传输这些二进制数据。</li>\n </ol> \n <h1><a id=\"TCPUDP_11\"></a>TCP/UDP</h1> \n <p>网上有大量关于TCP协议的讲解，我这里只说一句，TCP协议已经是比较底层的协议，后面要讲的HTTP、WebSocket等基本都是基于这个协议的上层协议。在TCP协议中规定了连接之前需要三次握手等约定。</p> \n <h1><a id=\"HTTP_13\"></a>HTTP</h1> \n <p>HTTP协议即超文本传送协议(Hypertext Transfer Protocol )，是Web联网的基础，也是手机联网常用的协议之一，HTTP协议是建立在TCP协议之上的一种应用层协议。</p> \n <p>HTTP连接最显著的特点是客户端发送的每次请求都需要服务器回送响应，在请求结束后，会主动释放连接。从建立连接到关闭连接的过程称为“一次连接”。</p> \n <p>在HTTP 1.0中，客户端的每次请求都要求建立一次单独的连接，在处理完本次请求后，就自动释放连接。<br> 在HTTP 1.1中，则可以在一次连接中处理多个请求，并且多个请求可以重叠进行，不需要等待一个请求结束后再发送下一个请求。</p> \n <p>由于HTTP在每次请求结束后都会主动释放连接，因此HTTP连接是一种“短连接”。</p> \n <p>要保持客户端程序的在线状态，需要不断地向服务器发起连接请求，通常情况下即使不需要获得任何数据，客户端也保持每隔一段固定的时间向服务器发送一次“保持连接”的请求，服务器在收到该请求后对客户端进行回复，表明知道客户端“在线”。若服务器长时间无法收到客户端的请求，则认为客户端“下线”，若客户端长时间无法收到服务器的回复，则认为网络已经断开。</p> \n <p><strong>为什么要有http，不能直接用TCP通信吗？</strong><br> TPC/IP协议是传输层协议，主要解决数据如何在网络中传输，而HTTP是应用层协议，主要解决如何包装数据。</p> \n <blockquote> \n  <p>在传输数据时，可以只使用（传输层）TCP/IP协议，但是那样的话，如果没有应用层，便无法识别数据内容，如果想要使传输的数据有意义，则必须使用到应用层协议</p> \n </blockquote> \n <p>应用层协议有很多，比如HTTP、FTP、TELNET等，也可以自己定义应用层协议。WEB使用HTTP协议作应用层协议，以封装HTTP文本信息，然后使用TCP/IP做传输层协议将它发到网络上。</p> \n <h1><a id=\"WebSocket_32\"></a>WebSocket</h1> \n <p>WebSocket也是基于TCP协议之上的应用层协议，他的出现解决了HTTP协议无法服务器主动推送的问题。<a href=\"https://blog.csdn.net/qq32933432/article/details/97943282?csdn_share_tail=%7B%22type%22:%22blog%22,%22rType%22:%22article%22,%22rId%22:%2297943282%22,%22source%22:%22qq32933432%22%7D\">http协议和Websocket协议的区别</a></p> \n <h1><a id=\"Socket_34\"></a>Socket</h1> \n <p>长久以来，我绝对技术猿们搞不清楚Socket是有原因的，网上很多文章会把Socket叫做Socket协议或socket连接，这其实是不对的，很容易让人误解Socket也是一个协议。但其实</p> \n <blockquote> \n  <p>Socket本身并不是协议，而是一个调用接口（API），通过Socket，才能使用TCP/IP协议。</p> \n </blockquote> \n <p>什么意思呢？比如你要喝水，你是不是要吸管？吸管就可以理解为Socket，而水就是TCP协议。</p> \n <p>你不给我吸管我怎么喝豆浆？你不给我筷子我怎么吃饭？你不给我方向盘我怎么开车？我感觉我的话已经触及到你们的灵魂。</p> \n <p>也就是说，可以把Socket理解为一个工具，可以用这个工具来使用TCP协议。</p> \n <blockquote> \n  <p>TCP/IP只是一个协议栈，就像操作系统的运行机制一样，必须要具体实现，同时还要提供对外的操作接口。这个就像操作系统会提供标准的编程接口，比如win32编程接口一样，TCP/IP也要提供可供程序员做网络开发所用的接口，这就是Socket编程接口。</p> \n </blockquote> \n <p>实际上，Socket跟TCP/IP协议没有必然的联系。Socket编程接口在设计的时候，就希望也能适应其他的网络协议。所以说，Socket的出现只是使得程序员更方便地使用TCP/IP协议栈而已，是对TCP/IP协议的抽象，从而形成了一些最基本的函数接口，比如create、 listen、connect、accept、send、read和write等等。</p> \n <h1><a id=\"_48\"></a>总结</h1> \n <ul>\n  <li><code>TCP</code>是底层通讯协议，定义的是数据传输和连接方式的规范。他的连接是<code>tcp://ip:port</code>的形式，比如<code>tcp://127.0.0.1:8888</code></li>\n  <li><code>HTTP</code>是应用层协议，定义的是传输数据的内容以及格式的规范。是对TCP的封装。他的连接是<code>http://ip:port/path</code>的形式，比如<code>http://127.0.0.1:8888/getUser</code></li>\n  <li><code>WebSocket</code>也是应用层协议，其出现解决了HTTP只能单向传输的问题。他的连接是<code>ws://ip:port/path</code>的形式，比如<code>ws://127.0.0.1:8888/getUser</code></li>\n  <li><code>Socket</code>本身不是协议，是一组接口，他可以支持不同的传输层协议（TCP/UDP），当使用TCP协议进行连接时，该Socket连接就是一个TCP连接。他的连接也是<code>ip:port</code>的形式，比如<code>127.0.0.1:8888</code>，你无法跟HTTP或WebSocket一样给他指定路径，如果要实现路径路由，只能是在传输的报文中加入路径参数，然后应用层进行路由，但这种做的本质，其实相当于你自己的应用实现了路由的功能，所以通过这里，你可能更能理解上面说的：<strong>在传输数据时，可以只使用（传输层）TCP/IP协议，但是那样的话，如果没有应用层，便无法识别数据内容，如果想要使传输的数据有意义，则必须使用到应用层协议。</strong></li>\n </ul> \n <p>参考：<br> https://zhuanlan.zhihu.com/p/542458842</p> \n</div>', 'https://profile.csdnimg.cn/E/B/A/3_qq32933432', 5355);
INSERT INTO `crawlerblog` VALUES (123124028, 'python小游戏——像素鸟代码开源', '小刘在C站', '<div id=\"content_views\" class=\"htmledit_views\"> \n <blockquote> \n  <p>♥️<strong>作者：<a href=\"https://blog.csdn.net/lzl10211345?type=blog\" title=\"小刘在这里\">小刘在这里</a></strong></p> \n  <p>♥️<strong>每天分享云计算网络运维课堂笔记，努力不一定有收获，但一定会有收获加油！一起努力，共赴美好人生！</strong></p> \n  <p>♥️<strong>夕阳下，是最美的，绽放，愿所有的美好，再疫情结束后如约而至。</strong></p> \n </blockquote> \n <p id=\"main-toc\"><strong>目录</strong></p> \n <p id=\"%E4%B8%80.%E5%91%88%E7%8E%B0%E6%95%88%E6%9E%9C-toc\" style=\"margin-left:0px;\"><a href=\"#%E4%B8%80.%E5%91%88%E7%8E%B0%E6%95%88%E6%9E%9C\">一.呈现效果</a></p> \n <p id=\"%C2%A0%E4%BA%8C.%E4%B8%BB%E4%BB%A3%E7%A0%81-toc\" style=\"margin-left:40px;\"><a href=\"#%C2%A0%E4%BA%8C.%E4%B8%BB%E4%BB%A3%E7%A0%81\">&nbsp;二.主代码</a></p> \n <p id=\"%E4%B8%89.cfg-toc\" style=\"margin-left:40px;\"><a href=\"#%E4%B8%89.cfg\">三.cfg</a></p> \n <p id=\"3.README-toc\" style=\"margin-left:0px;\"><a href=\"#3.README\">四.README</a></p> \n <hr id=\"hr-toc\"> \n <p></p> \n <h1 id=\"%E4%B8%80.%E5%91%88%E7%8E%B0%E6%95%88%E6%9E%9C\"><strong>一.呈现效果</strong></h1> \n <p class=\"img-center\"><img alt=\"\" height=\"748\" src=\"https://img-blog.csdnimg.cn/4fa7b4a6c03d4757adf6e8e830bf850e.png\" width=\"400\"></p> \n <h2 id=\"%C2%A0%E4%BA%8C.%E4%B8%BB%E4%BB%A3%E7%A0%81\">&nbsp;二.主代码</h2> \n <pre><code class=\"language-python\">\'\'\'\nFunction:\n    坠落的小鸟小游戏\ncsdn账号：顾木子吖\n\'\'\'\nimport cfg\nimport sys\nimport random\nimport pygame\nfrom modules import *\n\n\n\'\'\'游戏初始化\'\'\'\ndef initGame():\n    pygame.init()\n    pygame.mixer.init()\n    screen = pygame.display.set_mode((cfg.SCREENWIDTH, cfg.SCREENHEIGHT))\n    pygame.display.set_caption(\'坠落的小鸟 ——源码基地：959755565 \')\n    return screen\n\n\n\'\'\'显示当前分数\'\'\'\ndef showScore(screen, score, number_images):\n    digits = list(str(int(score)))\n    width = 0\n    for d in digits:\n        width += number_images.get(d).get_width()\n    offset = (cfg.SCREENWIDTH - width) / 2\n    for d in digits:\n        screen.blit(number_images.get(d), (offset, cfg.SCREENHEIGHT*0.1))\n        offset += number_images.get(d).get_width()\n\n\n\'\'\'主函数\'\'\'\ndef main():\n    screen = initGame()\n    # 加载必要的游戏资源\n    # --导入音频\n    sounds = dict()\n    for key, value in cfg.AUDIO_PATHS.items():\n        sounds[key] = pygame.mixer.Sound(value)\n    # --导入数字图片\n    number_images = dict()\n    for key, value in cfg.NUMBER_IMAGE_PATHS.items():\n        number_images[key] = pygame.image.load(value).convert_alpha()\n    # --管道\n    pipe_images = dict()\n    pipe_images[\'bottom\'] = pygame.image.load(random.choice(list(cfg.PIPE_IMAGE_PATHS.values()))).convert_alpha()\n    pipe_images[\'top\'] = pygame.transform.rotate(pipe_images[\'bottom\'], 180)\n    # --小鸟图片\n    bird_images = dict()\n    for key, value in cfg.BIRD_IMAGE_PATHS[random.choice(list(cfg.BIRD_IMAGE_PATHS.keys()))].items():\n        bird_images[key] = pygame.image.load(value).convert_alpha()\n    # --背景图片\n    backgroud_image = pygame.image.load(random.choice(list(cfg.BACKGROUND_IMAGE_PATHS.values()))).convert_alpha()\n    # --其他图片\n    other_images = dict()\n    for key, value in cfg.OTHER_IMAGE_PATHS.items():\n        other_images[key] = pygame.image.load(value).convert_alpha()\n    # 游戏开始界面\n    game_start_info = startGame(screen, sounds, bird_images, other_images, backgroud_image, cfg)\n    # 进入主游戏\n    score = 0\n    bird_pos, base_pos, bird_idx = list(game_start_info.values())\n    base_diff_bg = other_images[\'base\'].get_width() - backgroud_image.get_width()\n    clock = pygame.time.Clock()\n    # --管道类\n    pipe_sprites = pygame.sprite.Group()\n    for i in range(2):\n        pipe_pos = Pipe.randomPipe(cfg, pipe_images.get(\'top\'))\n        pipe_sprites.add(Pipe(image=pipe_images.get(\'top\'), position=(cfg.SCREENWIDTH+200+i*cfg.SCREENWIDTH/2, pipe_pos.get(\'top\')[-1])))\n        pipe_sprites.add(Pipe(image=pipe_images.get(\'bottom\'), position=(cfg.SCREENWIDTH+200+i*cfg.SCREENWIDTH/2, pipe_pos.get(\'bottom\')[-1])))\n    # --bird类\n    bird = Bird(images=bird_images, idx=bird_idx, position=bird_pos)\n    # --是否增加pipe\n    is_add_pipe = True\n    # --游戏是否进行中\n    is_game_running = True\n    while is_game_running:\n        for event in pygame.event.get():\n            if event.type == pygame.QUIT or (event.type == pygame.KEYDOWN and event.key == pygame.K_ESCAPE):\n                pygame.quit()\n                sys.exit()\n            elif event.type == pygame.KEYDOWN:\n                if event.key == pygame.K_SPACE or event.key == pygame.K_UP:\n                    bird.setFlapped()\n                    sounds[\'wing\'].play()\n        # --碰撞检测\n        for pipe in pipe_sprites:\n            if pygame.sprite.collide_mask(bird, pipe):\n                sounds[\'hit\'].play()\n                is_game_running = False\n        # --更新小鸟\n        boundary_values = [0, base_pos[-1]]\n        is_dead = bird.update(boundary_values, float(clock.tick(cfg.FPS))/1000.)\n        if is_dead:\n            sounds[\'hit\'].play()\n            is_game_running = False\n        # --移动base实现小鸟往前飞的效果\n        base_pos[0] = -((-base_pos[0] + 4) % base_diff_bg)\n        # --移动pipe实现小鸟往前飞的效果\n        flag = False\n        for pipe in pipe_sprites:\n            pipe.rect.left -= 4\n            if pipe.rect.centerx &lt; bird.rect.centerx and not pipe.used_for_score:\n                pipe.used_for_score = True\n                score += 0.5\n                if \'.5\' in str(score):\n                    sounds[\'point\'].play()\n            if pipe.rect.left &lt; 5 and pipe.rect.left &gt; 0 and is_add_pipe:\n                pipe_pos = Pipe.randomPipe(cfg, pipe_images.get(\'top\'))\n                pipe_sprites.add(Pipe(image=pipe_images.get(\'top\'), position=pipe_pos.get(\'top\')))\n                pipe_sprites.add(Pipe(image=pipe_images.get(\'bottom\'), position=pipe_pos.get(\'bottom\')))\n                is_add_pipe = False\n            elif pipe.rect.right &lt; 0:\n                pipe_sprites.remove(pipe)\n                flag = True\n        if flag: is_add_pipe = True\n        # --绑定必要的元素在屏幕上\n        screen.blit(backgroud_image, (0, 0))\n        pipe_sprites.draw(screen)\n        screen.blit(other_images[\'base\'], base_pos)\n        showScore(screen, score, number_images)\n        bird.draw(screen)\n        pygame.display.update()\n        clock.tick(cfg.FPS)\n    endGame(screen, sounds, showScore, score, number_images, bird, pipe_sprites, backgroud_image, other_images, base_pos, cfg)\n\n\n\'\'\'run\'\'\'\nif __name__ == \'__main__\':\n    while True:\n        main()</code></pre> \n <h2 id=\"%E4%B8%89.cfg\">三.cfg</h2> \n <p>\'\'\'配置文件\'\'\'<br> import os</p> \n <p><br> # FPS<br> FPS = 60<br> # 屏幕<br> SCREENWIDTH = 288<br> SCREENHEIGHT = 512<br> # 管道之间的空隙<br> PIPE_GAP_SIZE = 100<br> # 图片<br> NUMBER_IMAGE_PATHS = {\n  <!-- --><br> &nbsp;&nbsp;&nbsp; \'0\': os.path.join(os.getcwd(), \'resources/images/0.png\'),<br> &nbsp;&nbsp;&nbsp; \'1\': os.path.join(os.getcwd(), \'resources/images/1.png\'),<br> &nbsp;&nbsp;&nbsp; \'2\': os.path.join(os.getcwd(), \'resources/images/2.png\'),<br> &nbsp;&nbsp;&nbsp; \'3\': os.path.join(os.getcwd(), \'resources/images/3.png\'),<br> &nbsp;&nbsp;&nbsp; \'4\': os.path.join(os.getcwd(), \'resources/images/4.png\'),<br> &nbsp;&nbsp;&nbsp; \'5\': os.path.join(os.getcwd(), \'resources/images/5.png\'),<br> &nbsp;&nbsp;&nbsp; \'6\': os.path.join(os.getcwd(), \'resources/images/6.png\'),<br> &nbsp;&nbsp;&nbsp; \'7\': os.path.join(os.getcwd(), \'resources/images/7.png\'),<br> &nbsp;&nbsp;&nbsp; \'8\': os.path.join(os.getcwd(), \'resources/images/8.png\'),<br> &nbsp;&nbsp;&nbsp; \'9\': os.path.join(os.getcwd(), \'resources/images/9.png\')<br> }<br> BIRD_IMAGE_PATHS = {\n  <!-- --><br> &nbsp;&nbsp;&nbsp; \'red\': {\n  <!-- --><br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \'up\': os.path.join(os.getcwd(), \'resources/images/redbird-upflap.png\'),<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \'mid\': os.path.join(os.getcwd(), \'resources/images/redbird-midflap.png\'),<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \'down\': os.path.join(os.getcwd(), \'resources/images/redbird-downflap.png\')<br> &nbsp;&nbsp;&nbsp; },<br> &nbsp;&nbsp;&nbsp; \'blue\': {\n  <!-- --><br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \'up\': os.path.join(os.getcwd(), \'resources/images/bluebird-upflap.png\'),<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \'mid\': os.path.join(os.getcwd(), \'resources/images/bluebird-midflap.png\'),<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \'down\': os.path.join(os.getcwd(), \'resources/images/bluebird-downflap.png\')<br> &nbsp;&nbsp;&nbsp; },<br> &nbsp;&nbsp;&nbsp; \'yellow\': {\n  <!-- --><br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \'up\': os.path.join(os.getcwd(), \'resources/images/yellowbird-upflap.png\'),<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \'mid\': os.path.join(os.getcwd(), \'resources/images/yellowbird-midflap.png\'),<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \'down\': os.path.join(os.getcwd(), \'resources/images/yellowbird-downflap.png\')<br> &nbsp;&nbsp;&nbsp; }<br> }<br> BACKGROUND_IMAGE_PATHS = {\n  <!-- --><br> &nbsp;&nbsp;&nbsp; \'day\': os.path.join(os.getcwd(), \'resources/images/background-day.png\'),<br> &nbsp;&nbsp;&nbsp; \'night\': os.path.join(os.getcwd(), \'resources/images/background-night.png\')<br> }<br> PIPE_IMAGE_PATHS = {\n  <!-- --><br> &nbsp;&nbsp;&nbsp; \'green\': os.path.join(os.getcwd(), \'resources/images/pipe-green.png\'),<br> &nbsp;&nbsp;&nbsp; \'red\': os.path.join(os.getcwd(), \'resources/images/pipe-red.png\')<br> }<br> OTHER_IMAGE_PATHS = {\n  <!-- --><br> &nbsp;&nbsp;&nbsp; \'gameover\': os.path.join(os.getcwd(), \'resources/images/gameover.png\'),<br> &nbsp;&nbsp;&nbsp; \'message\': os.path.join(os.getcwd(), \'resources/images/message.png\'),<br> &nbsp;&nbsp;&nbsp; \'base\': os.path.join(os.getcwd(), \'resources/images/base.png\')<br> }<br> # 音频路径<br> AUDIO_PATHS = {\n  <!-- --><br> &nbsp;&nbsp;&nbsp; \'die\': os.path.join(os.getcwd(), \'resources/audios/die.wav\'),<br> &nbsp;&nbsp;&nbsp; \'hit\': os.path.join(os.getcwd(), \'resources/audios/hit.wav\'),<br> &nbsp;&nbsp;&nbsp; \'point\': os.path.join(os.getcwd(), \'resources/audios/point.wav\'),<br> &nbsp;&nbsp;&nbsp; \'swoosh\': os.path.join(os.getcwd(), \'resources/audios/swoosh.wav\'),<br> &nbsp;&nbsp;&nbsp; \'wing\': os.path.join(os.getcwd(), \'resources/audios/wing.wav\')<br> }</p> \n <h1 id=\"3.README\">四.README</h1> \n <p># Introduction<br> https://mp.weixin.qq.com/s/44CZjwvjnH0kkkKIn5U9Uw</p> \n <p># Environment<br> ```<br> OS: Windows10<br> Python: Python3.5+(have installed necessary dependencies)<br> ```</p> \n <p># Usage<br> ```<br> Step1:<br> pip install -r requirements.txt<br> Step2:<br> run \"python Game6.py\"<br> ```</p> \n <p># Game Display<br> ![giphy](demonstration/running.gif)</p> \n <blockquote> \n  <p>♥️关注，就是我创作的动力</p> \n  <p>♥️点赞，就是对我最大的认可</p> \n  <p>♥️这里是小刘，励志用心做好每一篇文章，谢谢大家</p> \n </blockquote> \n</div>', 'https://profile.csdnimg.cn/A/1/9/3_lzl10211345', 1522);
INSERT INTO `crawlerblog` VALUES (123124029, '这些低代码平台，你是否知悉？', '神州永泰', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <p>低代码low-code，无代码no-code，合称LCNC，近年来获得较快发展。低代码和无代码(LCNC)软件应用是当今商业领域最大的技术创新之一。顾名思义，低代码和无代码开发有助于简化开发流程，而不需要复杂的编程工具或专业知识。LCNC对用户的技术知识要求很低，是易于实施的开发解决方案。本文将集中介绍12种低代码平台。</p> \n <p>一 JeeSite</p> \n <p>1 简介<br> JeeSite 快速开发平台，不仅仅是一个后台开发框架，它是一个企业级快速开发解决方案，后端基于经典组合 Spring Boot、Shiro、MyBatis，前端采用 Beetl、Bootstrap、AdminLTE 经典开发模式，或者分离版 Vue3、Vite、Ant Design Vue、TypeScript、Vben Admin 最先进技术栈。提供在线代码生成功能，可自动创建业务模块工程和微服务模块工程，自动生成前端代码和后端代码；包括功能模块如：组织机构、角色用户、菜单及按钮授权、数据权限、系统参数、内容管理、工作流等。采用松耦合设计，微内核和插件架构，模块增减便捷；界面无刷新，一键换肤；众多账号安全设置，密码策略；文件在线预览；消息推送；多元化第三方登录；在线定时任务配置；支持集群，支持SAAS；支持多数据源；支持读写分离、分库分表；支持微服务应用。</p> \n <p>JeeSite快速开发平台的主要目的是能够让研发人员快速的开发出复杂的业务功能。让开发者注重专注业务，降低技术难度，从而节省人力成本，缩短项目周期，提高软件安全质量。</p> \n <p>JeeSite 自 2013 年发布以来已被广大爱好者用到了企业、政府、医疗、金融、互联网等各个领域中，JeeSite 架构精良、易于扩展、大众思维的设计模式、工匠精神打磨每一个细节，深入开发者的内心，并荣获开源中国《最受欢迎中国开源软件》奖杯，期间也帮助了不少刚毕业的大学生，教师作为入门教材，快速的去实践。</p> \n <p>JeeSite4的升级，作者结合了多年总结和经验，以及各方面的应用案例，对架构完成了一次全部重构，也纳入很多新的思想。不管是从开发者模式、底层架构、逻辑处理还是到用户界面，用户交互体验上都有很大的进步，在不忘学习成本、提高开发效率的情况下，安全方面也做和很多工作，包括：身份认证、密码策略、安全审计、日志收集等众多安全选项供你选择。努力为大中小微企业打造全方位企业级快速开发解决方案。</p> \n <p>2 官网地址<br> JeeSite 官网地址：<a href=\"http://jeesite.com\">http://jeesite.com</a><br> JeeSite 在线文档：<a href=\"http://docs.jeesite.com\">http://docs.jeesite.com</a><br> JeeSite 演示地址：<a href=\"http://demo.jeesite.com\">http://demo.jeesite.com</a><br> JeeSite 演示地址（Vue）：<a href=\"http://vue.jeesite.com\">http://vue.jeesite.com</a><br> JeeSite 源码下载：<a href=\"https://gitee.com/thinkgem\">https://gitee.com/thinkgem</a><br> JeeSite 在线提问：<a href=\"https://gitee.com/thinkgem/jeesite4/issues\">https://gitee.com/thinkgem/jeesite4/issues</a><br> ThinkGem 博客：<a href=\"http://my.oschina.net/thinkgem\">http://my.oschina.net/thinkgem</a></p> \n <p>二 JeecgBoot</p> \n <p>1 简介<br> JeecgBoot是一款基于BPM的低代码平台！前后端分离架构 SpringBoot 2.x，SpringCloud，Ant Design&amp;Vue，Mybatis-plus，Shiro，JWT，支持微服务。Jeecg不仅提高了UI能力，还降低了前后端分离的开发成本，具有一系列低代码能力：Online表单、Online报表、Online图表、表单设计、流程设计、报表设计、大屏设计等等。</p> \n <p>JeecgBoot基于代码生成器，支持无代码配置化快速开发，适用于常见的企业信息管理系统开发，比如OA办公、ERP系统、客户关系管理系统等，显著提高开发效率，降低开发成本。</p> \n <p>代码托管在Github和Gitee，star数量超14.7K，fork数量超5.7K，获得多个奖项，连续五年中国最火TOP5、十大优秀开源项目、2014年微信开发商大会第一名。</p> \n <p>JeecgBoot和多个项目一起，形成了完善的解决方案。</p> \n <p>(1) JeecgBoot</p> \n <p>基于代码生成器的低代码开发平台，无代码配置化，前后端分离架构，技术栈使用主流的Java + Spring Boot + MyBatis，前端使用node + Ant Design。</p> \n <p>最新版本JeecgBoot2.2.1，发布于2020年7月13日，包括多项功能优化，支持Docker一键部署。</p> \n <p>(2) JeecgCloud</p> \n <p>Jeecg Boot的微服务版本，基于Nacos服务注册和发现框架。</p> \n <p>最新版本1.0.0 Beta，发布于2020年5月21日。</p> \n <p>(3) JeecgUniApp</p> \n <p>一站式跨平台，完整的移动解决方案，采用Uniapp+ColorUI 框架，APP、小程序、H5多终端适配。</p> \n <p>版本1.0.0 Beta，发布于2020年6月8日，最新改版上线于8月17日。</p> \n <p>(4)JeewxBoot</p> \n <p>基于Java + Spring Boot开发的微信管理平台，采用插件机制，支持公众号、小程序、第三方平台，包括公众号基础管理、群发、系统权限、抽奖活动、小程序官网等功能。</p> \n <p>最新版本1.1.0，发布于2019年12月5日。</p> \n <p>(5) JeewxAppCMS</p> \n <p>基于wepy语言开发小程序，包含CMS网站基本功能，快速开发应用。</p> \n <p>最新版本1.1.0，发布于2020年5月30日。</p> \n <p>2 官网地址<br> Jeecg-boot 官网、Github 及详细测评<br> Jeecg-boot 官网：<a href=\"http://www.jeecg.com/\">http://www.jeecg.com/</a><br> Github：<a href=\"https://github.com/jeecgboot/jeecg-boot\">https://github.com/jeecgboot/jeecg-boot</a><br> JeecgBoot测评：《JeecgBoot 后台管理框架怎么样评价如何？》</p> \n <p>三 Pig - PigX 快速开发平台的开源版</p> \n <p>1 简介<br> Pig 基于 Spring Cloud、OAuth2.0、Vue的前后端分离的快速开发平台，PigX 是它的商业版本。Pig面向企业开发场景，封装了大量技术开发包、组件并支持 SaaS 多租户，为企业提供了一个可支持各类业务系统或产品快速开发实现的微服务应用数字化融合平台。</p> \n <p>Pig 基于 Spring Cloud 微服务框架进行封装，平台设计灵活可扩展、可移植、可应对高并发需求。同时兼顾本地化、私有云、公有云部署，支持SaaS模式应用。企业级应用系统所包含的常用开箱即用的模块，并支持灵活的可配置性和拓展性。一套基于 Spring Cloud 的微服务应用程序框架，可帮助公司更快，更高效地进行微服务开发。相较于业界使用广泛的开源版本平台，提供更强大的功能和更全面的服务支持。</p> \n <p>基于 Spring Cloud Hoxton 、Spring Boot 2.2、 OAuth2.0 的 RBAC 权限管理系统，基于数据驱动视图的理念封装 Element-ui，即使没有 Vue的使用经验也能快速上手。提供对常见容器化支持 Docker、Kubernetes、Rancher2 支持，内置低代码生成模块，可以适用于不同开发领域。</p> \n <p>2 Pig 官网、Github 及详细测评<br> Pig 官网：<a href=\"https://pig4cloud.com\">https://pig4cloud.com</a><br> Github：<a href=\"https://github.com/pig-mesh/pig\">https://github.com/pig-mesh/pig</a></p> \n <p>四 若依（RuoYi）</p> \n <p>1 简介<br> 若依 RuoYi 是一套完全开源，基础功能完备的 admin 后台管理框架系统。它基于经典技术组合 Spring Boot、SpringCloud、Apache Shiro、MyBatis、Thymeleaf ，若依前端有 BootsTrap 和 Vue + Element两个版本。若依是快速开发框架的佼佼者，内置了常见的后台管理系统模块，以及后端代码生成器，可一键生成后端代码，让开发者更好的专注在自己公司业务逻辑的开发上。基于SpringBoot、Spring Security、Jwt、Vue的前后端分离的后台管理系统<br> RuoYi-Vue 是一个 Java EE 企业级快速开发平台，基于经典技术组合（Spring Boot、Spring Security、MyBatis、Jwt、Vue），内置模块如：部门管理、角色用户、菜单及按钮授权、数据权限、系统参数、日志管理、代码生成等。在线定时任务配置；支持集群，支持多数据源，支持分布式事务。</p> \n <p>2 官网地址</p> \n <p>若依官网：<a href=\"http://ruoyi.vip\">http://ruoyi.vip</a></p> \n <p>3 主要特性</p> \n <p>完全响应式布局（支持电脑、平板、手机等所有主流设备）<br> 强大的一键生成功能（包括控制器、模型、视图、菜单等）<br> 支持多数据源，简单配置即可实现切换。<br> 支持按钮及数据权限，可自定义部门数据权限。<br> 对常用js插件进行二次封装，使js代码变得简洁，更加易维护<br> 完善的XSS防范及脚本过滤，彻底杜绝XSS攻击<br> Maven多项目依赖，模块及插件分项目，尽量松耦合，方便模块升级、增减模块。<br> 国际化支持，服务端及客户端支持<br> 完善的日志记录体系简单注解即可实现<br> 支持服务监控，数据监控，缓存监控功能。</p> \n <p>演示地址：<a href=\"http://vue.ruoyi.vip\">http://vue.ruoyi.vip</a><br> 代码下载：<a href=\"https://gitee.com/y_project/RuoYi-Vue\">https://gitee.com/y_project/RuoYi-Vue</a></p> \n <p>*技术选型<br> (1）系统环境</p> \n <p>Java EE 8<br> Servlet 3.0<br> Apache Maven 3<br> (2）主框架</p> \n <p>Spring Boot 2.2.x<br> Spring Framework 5.2.x<br> Spring Security 5.2.x<br> (3）持久层</p> \n <p>Apache MyBatis 3.5.x<br> Hibernate Validation 6.0.x<br> Alibaba Druid 1.2.x<br> (4）视图层</p> \n <p>Vue 2.6.x<br> Axios 0.21.x<br> Element 2.15.x</p> \n <p>*内置功能<br> 用户管理：用户是系统操作者，该功能主要完成系统用户配置。<br> 部门管理：配置系统组织机构（公司、部门、小组），树结构展现支持数据权限。<br> 岗位管理：配置系统用户所属担任职务。<br> 菜单管理：配置系统菜单，操作权限，按钮权限标识等。<br> 角色管理：角色菜单权限分配、设置角色按机构进行数据范围权限划分。<br> 字典管理：对系统中经常使用的一些较为固定的数据进行维护。<br> 参数管理：对系统动态配置常用参数。<br> 通知公告：系统通知公告信息发布维护。<br> 操作日志：系统正常操作日志记录和查询；系统异常信息日志记录和查询。<br> 登录日志：系统登录日志记录查询包含登录异常。<br> 在线用户：当前系统中活跃用户状态监控。<br> 定时任务：在线（添加、修改、删除)任务调度包含执行结果日志。<br> 代码生成：前后端代码的生成（java、html、xml、sql)支持CRUD下载 。<br> 系统接口：根据业务代码自动生成相关的api接口文档。<br> 服务监控：监视当前系统CPU、内存、磁盘、堆栈等相关信息。<br> 缓存监控：对系统的缓存信息查询，命令统计等。</p> \n <p>五 BladeX<br> 1 简介<br> BladeX 是一个基于 Spring Boot 2.7 &amp; Spring Cloud 2021 &amp; Mybatis 等核心技术，用于快速构建中大型系统的基础框架。<br> 已稳定生产近一年，经历了从Camden-&gt;2021的技术架构，也经历了从FatJar-&gt;Docker-&gt;K8S+Jenkins的部署架构。<br> 采用前后端分离的模式，前端开发两个框架：Sword(基于React、Ant Design)、Saber(基于Vue、ElementUI)。后端采用SpringCloud系列，对其基础组件做了高度的封装，单独出一个后端核心框架：BladeX-Tool。<br> BladeX-Tool已推送至Maven私有库，直接引入减少工程的模块与依赖，可更注重于业务开发。集成Sentinel从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。注册中心、配置中心选型Nacos，为工程瘦身的同时加强了各模块之间的联动。封装集成了基于注解+Web可视化的数据权限，灵活配置，无需重启直接生效。定制了基于Nacos的轻量级、高拓展性的动态网关，完美支持多团队开发。精心设计集成了minio，完美支持多租户模式下的oss对象存储需求。</p> \n <p>2 BladeX 官网、Github 及详细测评<br> BladeX 官网：<a href=\"https://bladex.vip/\">https://bladex.vip/</a><br> BladeX Github：<a href=\"https://github.com/chillzhuang/SpringBlade\">https://github.com/chillzhuang/SpringBlade</a></p> \n <p>3 架构简介<br> 基于SpringBoot2、SpringCloud Hoxton、Mybatis构建核心架构<br> 采用Oauth2协议进行统一的Token下发与鉴权，保证系统安全性<br> 使用Gateway进行网关的统一转发，生产环境采用Traefik代理<br> 微服务统一注册至Nacos，Nacos担任注册中心与配置中心的角色<br> 采用Feign进行远程调用，Ribbon进行负载，Hystrix进行熔断<br> 采用Sentinel进行限流，保障系统整体的性能<br> 集成Seata，为分布式事务保驾护航<br> 具有日志收集与监控服务为一体的能力<br> 支持FatJar、Docker、K8s、阿里云等多种部署方式</p> \n <p>六 卡拉云<br> 1 简介<br> 卡拉云是新一代企业级低代码开发平台，可帮助开发者快速搭建后台管理系统。卡拉云从 2020 年第一个公测版开始，已经迭代升级了多个大版本，特别针对国内企业级大型后台管理系统搭建场景优化。</p> \n <p>卡拉云可快速搭建企业级后台管理系统（ERP、CMS、CRM、OA、MES、订单管理、客户管理、物流管理、财务管理等复杂系统），它内置常用的前端组件，简单鼠标拖拽即可快速生成。可一键接入数据库和 RESTful API、企业微信、钉钉、飞书等常见的数据源，可在前端直接写 SQL &amp; js ，实现复杂的代码逻辑。</p> \n <p>卡拉云之所以能快速搭建后台管理系统，是因为它把后台管理系统抽象成三个部分，「前端组件」、「数据源」、「连接前端组件和数据源的简单 JS 代码」，每个部分卡拉云都帮开发者写好，不用再重复造轮子，开发者只需调用即可。</p> \n <p>卡拉云帮助开发者把所有前端组件写扎实，开发者只需要拖拽即可一键生成所需组件，无需操心任何前端问题。也无需自己搭建后端，只需要简单填写配置表即可接入数据库、API 等常见数据源。前后端卡拉云都帮助开发者写好，开发者只需要写简单的 JS &amp; SQL 代码连接前后端即可实现后台管理系统快速搭建。接下来，我来详细测评卡拉云的技术细节。</p> \n <p>卡拉云由三个部分组成，前端组件+后端数据源+连接组件与数据源的简单代码。</p> \n <p>卡拉云针对国内互联网应用场景进行了许多优化，不论是使用习惯上，还是应用场景上都更贴近国内用户。如集成了阿里、腾讯、华为等多家云存储、可轻松调用七牛云 API、Leancloud API、金数据、又拍云、企业微信、钉钉等常见的第三方应用接口，方便开发者直接使用。</p> \n <p>2 官网地址<br> 卡拉云官网：<a href=\"https://kalacloud.com/\">https://kalacloud.com/</a></p> \n <p>七 Retool</p> \n <p>Retool 是面向企业的低代码开发平台。使用 Retool 可快速搭建后台管理工具，比如快速构建 admin 后台管理、销售 ERP、客户 CRM、数据分析看板、amazon 云端文件上传管理等基于数据库或 API 的企业工具。</p> \n <p>新事物刚出现，没亲身体验前，总是很难理解。我们总会把新事物与我们已认知的东西来做对比，有人说 Retool 是帮你配置好的 Vue &amp; React 、是可视化拖拽编程平台、是在线前端生成器（并不是）。这些说法都只描述了 Retool 很小的一个点，Retool 是新一代低代码开发平台，是程序员的新效率工具，是历史上不曾有的新工具，拿旧地图看新世界总会有很大偏差，建议你亲自试试看。如果你访问 Retool 比较慢，或想用中文界面，国内也有类似概念的低代码平台，比如卡拉云，后文我们也会对比这两个平台的优缺点和差异。</p> \n <p>Retool 有三大特点，无需任何前端编程基础的拖拽组件生成、可连接一切数据库及API，前后端无缝衔接、高度灵活性，高度可定制，为开发者而生。、、</p> \n <p>八 AppSmith<br> 1 简介<br> AppSmith 是印度一家创业公司开发的低代码开发工具，它的原型是另一家名叫 Retool 的美国的创业公司。AppSmith 从 2019 年开始开发，到现在已经发行了 1.x 版本。用户可使用 AppSmith 开发自己的企业内部管理工具，一键接入数据库及 API（支持 RESTful API、PostgreSQL、DynamoDB、MongoDB、Firebase 等），仅需拖拽即可生成的前端 UI 组件。有清晰的权限系统，企业团队在 AppSmith 上开发的 app ，可根据使用者的身份划分权限。<br> AppSmith有以下特性：<br> （1）简单拖拽即可创建前端组件；<br> （2）可一键接入多种数据库及 API；<br> （3）无需处理前后端问题，会简单 JS 即可；<br> （4）权限清晰，一键邀请同事加入开发或使用；</p> \n <p>2 官网地址<br> AppSmith官网：<a href=\"https://www.appsmith.com/\">https://www.appsmith.com/</a></p> \n <p>九 Budibase</p> \n <p>1 简介<br> Budibase是一个开源的低代码平台，可以帮助在很短的时间内创建一个满足业务应用的web程序。Budibase是包括构建，设计以及自动化业务应用（比如，管理面板，表单，内部工具，客户入口等等），这些都集成在Budibase的低代码平台中。兼容多种数据源，包括MongoDB和PostgreSQL等流行数据库以及Google Sheets等电子表格程序，允许用户快速构建客户端门户和管理面板等应用程序。</p> \n <p>Budibase的特点：<br> 支持外部数据源，包括 MongoDB、MySQL 等；<br> 支持 Rest API 拉取数据；<br> 能够使用应用的内置数据库或上传 CSV 来导入数据；<br> 各种数据类型和功能，包括附件、关系、公式等；<br> API 整合平台，整合不同的 API，帮助你轻松建立内部应用、表单等；<br> 能够使用内部表格生成自动页面；<br> 构建单页应用；<br> 自动生成的 CRUD（创建、读取、更新和删除）页面；<br> 私人和公共应用；<br> 只需点击几下就可以定制你的应用的主题；<br> 容易为你的应用实现深色模式主题；<br> 一个功能丰富的表单生成器，满足广泛的要求；<br> 支持 Webhook；<br> 与诸如 Zapier 等的第三方集成；<br> 基于特定触发器的灵活自动化选项；<br> 能够将 JavaScript 添加到你的自动程序中；<br> 为拥有自己基础设施的用户提供自我托管选项；<br> 免费的单点登录认证/管理；<br> 用户管理选项，将团队分配到不同的应用；<br> 支持 SMTP 电子邮件；<br> 电子邮件模板，以配合你的品牌和风格；<br> 支持 OAuth 登录。目前仅限于谷歌；<br> 图表、表格和卡片来优雅地展示数据。</p> \n <p>2 官网地址<br> Budibase官网：<a href=\"https://budibase.com/\">https://budibase.com/</a></p> \n <p>十 ToolJet<br> 1 简介<br> ToolJet 是一套开源的低代码开发平台框架，可快速构建和部署企业内部工具，帮助开发团队节省大量开发时间。开发者可使用 ToolJet 连接多种常见的数据库（如 PostgreSQL、MongoDB、Elasticsearch 等）也可以直接接入 RESTful API，甚至可以直接调第三方工具（比如 Stripe、Slack、Google Sheets、Airtable 等），灵活的前端组件拖拽生成，无需懂任何前端技术。</p> \n <p>ToolJet的特点：</p> \n <p>（1）ToolJet 可接入多种数据源、API及第三方工具；<br> （2）ToolJet 拖拽生成前端组件；<br> （3）可参与共享开发。</p> \n <p>2 官网地址<br> ToolJet官网：<a href=\"https://www.tooljet.com/\">https://www.tooljet.com/</a></p> \n <p>十一 DronaHQ<br> 1 简介<br> DronaHQ 作为一个低代码工具，其最大突出优势便是能够在已有应用程序上，创建出美观且响应灵敏的内部系统。DronaHQ 提供了丰富的功能组件（多达 50+ 数据源连接、90+ UI 组件），并提供了教程一步步指导创建、设计、部署和托管自己的应用程序。</p> \n <p>DronaHQ特点：</p> \n <p>（1）丰富的数据源、UI 组件支持<br> （2）界面 UI 美观（有的人可能会觉得有点卡通）<br> （3）响应式 UI，支持在「桌面」「移动端」模式间切换<br> （4）丰富的文档支持</p> \n <p>2 官网地址<br> DronaHQ官网：<a href=\"https://www.dronahq.com/\">https://www.dronahq.com/</a></p> \n <p>十二 码匠<br> 1 简介<br> 码匠是一款对开发者友好的低代码平台，在支持多种数据源的同时提供了一套开箱即用的组件，帮助您快速构建功能完善的内部应用，让您专注于业务发展。码匠针对国内用户使用习惯做了大量优化，UI 界面设计更加适合国内场景，并整合了多款国内数据源，包括 飞书、企业微信、钉钉、阿里云 OSS，等等。不仅如此，码匠还提供了国内业务场景下常见的租户管理、更加细粒度的权限控制、审计日志等功能，为您的企业信息安全保驾护航。</p> \n <p>码匠特点：<br> （1）写SQL、配置组件，即可获得功能完善的内部应用，让您可以专注于业务发展。<br> （2）码匠提供了表格、按钮、输入框、选择器等一套功能强大、开箱即用的UI组件。您可以在5分钟内组装完成您的应用程序。<br> （3）可以轻松的连接到MySQL、MongoDB、Redis、Clickhouse等数据源。码匠会加密存储认证信息，此外不会存储客户任何数据。<br> 还提供了一个私有化部署版本，可以自行部署以便完全控制码匠实例和所有数据。</p> \n <p>2 官网地址<br> 码匠官网：<a href=\"https://majiang.co/\">https://majiang.co/</a></p> \n</div>', 'https://profile.csdnimg.cn/1/A/D/3_helloworldchina', 8709);
INSERT INTO `crawlerblog` VALUES (123124030, '《流浪地球 2》 Deepfake 小试牛刀，45+ 吴京「被」年轻，变身 21 岁小鲜肉', 'HyperAI超神经', '<div id=\"content_views\" class=\"htmledit_views\"> \n <p><strong>内容一览：</strong>在春节档科幻电影「流浪地球 2」中，主演吴京、刘德华、沙溢等人饰演的角色，跨越 14 年之久，视效团队正是借助 Deepfake de-aging 技术，呈现出了演员不同年龄段的容貌。</p> \n <p><strong>关键词：</strong>De-aging&nbsp; &nbsp;Deepfake&nbsp; &nbsp;流浪地球&nbsp; &nbsp;</p> \n <p></p> \n <p>「流浪地球 2」上映 8 天，总票房就已经突破了 24 亿，打破 36 项纪录，获得 91 项里程碑成就。其中，<strong>21 岁小鲜肉刘培强（吴京饰），以及年轻帅气图恒宇（刘德华饰），给观众留下了深刻的印象。</strong></p> \n <p></p> \n <p>流浪地球官方微博发布的一段视频中，讲述了换脸特效背后繁复的工程难度。</p> \n <div class=\"csdn-video-box\"> \n  <iframe id=\"rzrDThIG-1674970999301\" src=\"https://live.csdn.net/v/embed/271893\" allowfullscreen=\"true\" data-mediaembed=\"csdn\"></iframe> \n  <p>变！变！变！20 岁吴京变身小鲜肉</p> \n </div> \n <p>在知乎提问「《流浪地球 2》幕后有哪些不为人知的制作难题」中，《流浪地球 2》视效总监、MOREVFX 创始人徐建，<strong>坦言技术上第一难点就是「De-aging」数字换龄。</strong></p> \n <p></p> \n <p>查看徐建完整回答，请访问：</p> \n <p><em><strong><a class=\"link-info\" href=\"https://www.zhihu.com/question/579613527\" title=\"https://www.zhihu.com/question/579613527\">https://www.zhihu.com/question/579613527</a></strong></em></p> \n <p></p> \n <h1><strong>&nbsp;数字换龄，45+ 吴京变身 21 岁小鲜肉</strong></h1> \n <p></p> \n <p>de-aging 是一种应用于影视作品的视觉特效技术，<strong>是指利用数字编辑 (digitally editing)&nbsp;或计算机绘图 (computer graphics，简称 CG) 技术，</strong>实现演员在特定场景下的年轻化。</p> \n <p></p> \n <p>在电影「流浪地球 2」中，演员吴京、刘德华、王智等多人饰演的角色，<strong>都涉及到了角色年轻化，即 de-aging。</strong></p> \n <p></p> \n <p class=\"img-center\"><img alt=\"\" src=\"https://img-blog.csdnimg.cn/img_convert/2e168e1e3e18ca0909c10908010e23f2.png\"></p> \n <p style=\"text-align:center;\"><strong>用吴京年轻时的 2D 素材训练 AI 模型进行 de-aging</strong></p> \n <p style=\"text-align:center;\"><strong>为实拍素材完成换脸</strong></p> \n <p></p> \n <p><em><strong>一个小番外：</strong>根据电影剧情推算，刘培强出生年份正是 2023 年。</em></p> \n <p></p> \n <p>以吴京为例，现实中吴京在拍摄这部电影时，年龄 45+（根据百度百科资料推算），但是电影中 2044 年时的刘培强只有 21 岁，<strong>45+ 的演员挑战饰演 21 岁的「小鲜肉」，着实需要点技术加持。</strong></p> \n <p></p> \n <h1><strong>&nbsp;3 大主流 de-aging 方法梳理</strong></h1> \n <p></p> \n <p>实际上，当时全世界主流的 de-aging 方法共分为 3 类。</p> \n <p></p> \n <p class=\"img-center\"><img alt=\"\" src=\"https://img-blog.csdnimg.cn/img_convert/3525c8558a038c403817f1a79a81cd95.png\"></p> \n <p><strong>该方法分为两个主要步骤：</strong></p> \n <p></p> \n <p>* 制作数字人并进行 de-aging</p> \n <p>通过演员佩戴的表情捕捉设备，扫描演员并生成数据库，制作目标演员的数字人，然后根据演员早期职业生涯剧照及视频素材，对数字人进行 de-aging。</p> \n <p></p> \n <p>* 基于演员佩戴的动作捕捉设备，对数字人进行动画制作</p> \n <p>根据「流浪地球 2」视效总监徐建在知乎的分享，<strong>此方法预算高、国内相关人才不足，且身上的设备可能会影响打斗场景拍摄及演员表演情绪的传达。</strong></p> \n <p class=\"img-center\"><img alt=\"\" src=\"https://img-blog.csdnimg.cn/img_convert/9bd68c2482ba92304cd9204f625816a0.gif\"></p> \n <p></p> \n <p style=\"text-align:center;\"><strong>威尔史密斯佩戴设备进行动作及表情捕捉</strong></p> \n <p></p> \n <p class=\"img-center\"><img alt=\"\" src=\"https://img-blog.csdnimg.cn/img_convert/af6b88dbceccda3f0185a5526e2287fd.png\"></p> \n <p>在电影「爱尔兰人」中，工业光魔开发了一种无需佩戴物理设备或在面部做标记的 de-aging 技术，演员被三台摄像机设备环绕拍摄，一台为正常拍摄机位，另外两台负责记录 de-aging 需要的数据，<strong>通过拍摄红外镜头收集必要数据，以数字方式再现表演。</strong></p> \n <p></p> \n <p class=\"img-center\"><img alt=\"\" src=\"https://img-blog.csdnimg.cn/img_convert/3c2b3bbd6cf9818407bf136307010879.gif\"></p> \n <p style=\"text-align:center;\"><strong>摄像机记录的数据结合光线影响&nbsp; 对角色进行 de-aging</strong></p> \n <p></p> \n <p></p> \n <p class=\"img-center\"><img alt=\"\" src=\"https://img-blog.csdnimg.cn/img_convert/0758c42a169bcf04d729cb625bd3468b.png\"></p> \n <p>&nbsp;在电影「美国队长 3：内战」中，视效团队利用小罗伯特唐尼早期的影视作品、视觉素材，训练基于 Deepfake 算法的 AI 模型并完成换脸。</p> \n <p></p> \n <p class=\"img-center\"><img alt=\"\" src=\"https://img-blog.csdnimg.cn/img_convert/1117840154c0c95d8b17ca73895bd5a5.jpeg\"></p> \n <p style=\"text-align:center;\"><strong>Deepfake 年轻版钢铁侠 Tony Stark&nbsp;</strong></p> \n <p></p> \n <p>据「流浪地球 2」视效总监徐建介绍，早在电影开拍一年半之前，视效团队就开始了技术实验，测试了 5、6 种换脸方法后，视效团队最终决定采用 de-aging 方法三，<strong>基于 Deepfake 算法用演员年轻时的 2D 素材训练 AI 模型，最终迭代 500 多万次后，替换实拍素材。</strong></p> \n <p></p> \n <h1><strong>&nbsp;人脸年轻化及增龄的论文梳理</strong></h1> \n <h2></h2> \n <h2><strong><a class=\"link-info\" href=\"https://studios.disneyresearch.com/app/uploads/2022/10/Production-Ready-Face-Re-Aging-for-Visual-Effects.pdf\" title=\"《Production-Ready Face Re-Aging for Visual Effects》\">《Production-Ready Face Re-Aging for Visual Effects》</a></strong></h2> \n <p>DisneyResearch 团队提出了一个 Face Re-Aging Network，简称 FRAN，可以在不丢失身份的前提下，自动重塑视频中的人脸图像，实现目标人脸年轻化或增龄效果。</p> \n <p></p> \n <p class=\"img-center\"><img alt=\"\" src=\"https://img-blog.csdnimg.cn/img_convert/52a35eecf669633c9e7501ff70e56191.png\"></p> \n <p style=\"text-align:center;\"><strong>输入人像年龄 35 岁</strong></p> \n <p style=\"text-align:center;\"><strong>上下排分别为 re-aging 为 65 岁和 18 岁</strong></p> \n <p></p> \n <h2><strong><a class=\"link-info\" href=\"https://arxiv.org/pdf/2005.04410.pdf\" title=\"《High Resolution Face Age Editing》\">《High Resolution Face Age Editing》</a></strong></h2> \n <p>本篇论文提出了一个用于面部年龄编辑的 encoder-decoder 架构，<strong>使用一种简单的方法实现了高分辨率人脸年龄编辑，</strong>可以输出 1024*1024 分辨率的图像。</p> \n <p></p> \n <p class=\"img-center\"><img alt=\"\" src=\"https://img-blog.csdnimg.cn/img_convert/5264b10acdfd14b53c2ea48a916e9d6f.png\"></p> \n <p style=\"text-align:center;\"><strong>依据输入人脸（黄色框）</strong></p> \n <p style=\"text-align:center;\"><strong>输出不同年龄段的高质量人脸图像</strong></p> \n <p></p> \n <h2><strong><a class=\"link-info\" href=\"https://arxiv.org/pdf/2005.04410.pdf\" title=\"《Only a Matter of Style: Age Transformation Using a Style-Based Regression Model》\">《Only a Matter of Style: Age Transformation Using a Style-Based Regression Model》</a></strong></h2> \n <p>本篇论文提出了一种图像到图像的转换方法，直接将真实的面部图像编码到预先训练好的无条件 GAN 的 latent space 中，进行老化转变。<strong>可以仅凭试验者的一张照片就生成全年龄阶段的容貌，精确到每一条皱纹。</strong></p> \n <p></p> \n <p class=\"img-center\"><img alt=\"\" src=\"https://img-blog.csdnimg.cn/img_convert/9f0d16d4a6ce8c0f6e87ce37f550aaaa.png\"></p> \n <p style=\"text-align:center;\"><strong>使用论文提出的 SAM 架构生成的老化结果</strong></p> \n <p></p> \n <p></p> \n <h1><strong>&nbsp;像素级换脸技术任重道远，仍需行业规范&nbsp;</strong></h1> \n <p></p> \n <p>「流浪地球 2」中，年轻刘培强和图恒宇的呈现，虽然是基于 Deepfake 算法实现，然而通过考察众多相关论文，结合视效总监徐建的介绍，<strong>我们得知在电影制作的后期，仍需专业后期人员对换脸后的角色进行繁复的完善和修复。</strong></p> \n <p></p> \n <p>这是因为换脸技术在一些细节处理上仍存在不足，如表情生硬、眼神表情不自然，这些「不协调」在电影大荧幕上无疑会被放大，给观众带来不适。</p> \n <p></p> \n <p>减龄及增龄算法的发展，要实现与影视作品中的角色「完美适配」，恐怕还有很长的路要走，<strong>而如何监控 Deepfake 这项技术不被滥用，也是工业界、科技界乃至普通用户不得不面临的一个潜在风险和挑战。</strong></p> \n <p></p> \n <p></p> \n <p></p> \n <p><strong>参考链接：</strong></p> \n <p>[1]&nbsp;https://www.zhihu.com/question/579613527</p> \n <p>[2]&nbsp;https://onlinelibrary.wiley.com/doi/full/10.1111/oli.12302</p> \n <p>[3]&nbsp;https://www.respeecher.com/blog/de-aging-technology-changing-hollywood-future-film-making</p> \n <p></p> \n <p></p> \n</div>', 'https://profile.csdnimg.cn/9/F/4/3_hyperai', 7011);
INSERT INTO `crawlerblog` VALUES (123124031, '尼恩Java面试宝典', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <p>40岁老架构师 尼恩 梳理，不断迭代， 持续更新， 收入最新 面试题。</p> \n <h1><a id=\"Java____2\"></a>尼恩Java面试宝典： 体系化，形象化 梳理面试题，且 持续升级</h1> \n <p>尼恩梳理这些Java面试题， 致力于体系化， 系统化，形象化 梳理，形成一个大的知识体系，从而， 帮助大家<strong>薪酬猛涨， 进入大厂</strong></p> \n <p>举个例子：spring三级缓存是技术的难点，非常不好记忆， 但是，又是面试的<strong>重点，要点</strong></p> \n <p><strong>spring三级缓存的知识，社群好几个小伙伴和我反应，挂在这个问题上了，非常可惜</strong></p> \n <p>对spring三级缓存， 尼恩首创<strong>使用成品、半成品、原材料工厂，这样的浅显易懂的模式解读</strong>， 使得复杂的概念 ，变得更容易好懂</p> \n <p><img src=\"https://img-blog.csdnimg.cn/22a7ddcce0314d5b9f0829734bd21188.png\" alt=\"在这里插入图片描述\"></p> \n <p>关于 以上成品、半成品、原材料工厂 的详细介绍， 请参见： pdf 中的专题5。</p> \n <h1><a id=\"Java_32PDF_16\"></a>送：尼恩Java面试宝典 32个专题PDF（极致经典+史上最全+面试必备）</h1> \n <blockquote> \n  <p>加尼恩微信，免费领取此书， 尼恩微信二维码请参见 <a href=\"https://www.yuque.com/crazymakercircle/gkkw8s/khigna\"><strong>疯狂创客圈总目录 语雀版</strong></a> | <a href=\"https://gitee.com/crazymaker/SimpleCrayIM/blob/master/%E7%96%AF%E7%8B%82%E5%88%9B%E5%AE%A2%E5%9C%88%E6%80%BB%E7%9B%AE%E5%BD%95.md\"><strong>总目录 码云版</strong></a>| <a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\"><strong>总目录 博客园版</strong></a></p> \n </blockquote> \n <p><img src=\"https://img-blog.csdnimg.cn/729b33f6bc37429385edbef85fd805c3.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"_22\"></a>升级记录</h1> \n <p>会持续升级， 更新记录具体请关注 <a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\">博客园 尼恩Java面试宝典V2（卷王专供+ 史上最全 + 2022面试必备）</a></p> \n <h2><a id=\"2022518_1_24\"></a>2022-5-18升级说明 ：增加1个专题</h2> \n <p>新增了一个专题，第32专题， <strong>大厂面试的基本流程‌和面试准备</strong>，</p> \n <p>这个非常重要，帮助大家更好的备战大厂</p> \n <h2><a id=\"2022517_1_29\"></a>2022-5-17升级说明 ：增加1个专题</h2> \n <p>新增了一个专题，第31专题， <strong>Hash连环炮面试题</strong>，</p> \n <p><strong>Hash连环炮面试题</strong>，介绍了hashmap、cocurrenthashmap1.7、cocurrenthashmap1.8的内部结构、avl树、红黑树</p> \n <p><strong>这个非常重要，是面试的重点，绝对重点</strong></p> \n <h2><a id=\"2022516_3_37\"></a>2022-5-16升级说明 ：增加3个面试连环炮</h2> \n <p><strong>JVM内存连环炮：</strong></p> \n <p>JVM内存包括哪些？什么是堆内存? 什么是非堆内存? 什么是直接内存? 方法区和永久代有何区别?</p> \n <p><strong>对象结构连环炮：</strong></p> \n <p>给定一个具体的类，请分析对象的内存占用? 怎么计算出来一个对象的内存占用?对象头中包含哪些部分？</p> \n <p><strong>JVM调优连环炮：</strong></p> \n <p>常用的JVM启动参数有哪些? 调优命令有哪些？设置堆内存XMX应该考虑哪些因素？</p> \n <p>假设物理内存是8G，设置多大堆内存比较合适? 怎样开启GC日志？</p> \n <h1><a id=\"01JVM____2022_55\"></a>专题01：JVM面试题（卷王专供 + 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/3147521b3f984473ae1130926e87310b.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"02Java____2022_59\"></a>专题02：Java算法面试题（卷王专供 + 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/c22d13868ad14d41b5d648daabd7c394.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"03Java___2022_63\"></a>专题03：Java基础面试题（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/a346fa98bf60405a8f649dd56698709b.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"04___2022_66\"></a>专题04：架构设计面试题（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/939d95ab84034f4ebfaddcf3a8878649.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"05Spring__06SpringMVC__07Tomcat____70\"></a>专题05：Spring面试题__专题06：SpringMVC__专题07：Tomcat面试题（ 史上最全 + 面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/cbd6a32811444a05aada9ed3be6f13e2.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"08SpringBoot___2022_74\"></a>专题08：SpringBoot面试题（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/4682cc04b20e4eb29a908b5a3edef4ba.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"09___2022_78\"></a>专题09：网络协议面试题（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/4f00669a7fdc47129779920f300451d1.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"10TCPIP___2022_82\"></a>专题10：TCP-IP协议（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/d50926558d214794abed653e34728911.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"11JUC___2022_87\"></a>专题11：JUC并发包与容器类（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/95ca77a4fe4e41d8a749034e7431ac22.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"12____2022_90\"></a>专题12：设计模式面试题 （卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/d15b7f5692804f3d8359aefb5992ca73.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"13___2022_96\"></a>专题13：死锁面试题（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/d29c7d1066cf41fabb61f39dc690b44e.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"14Redis_____2022_100\"></a>专题14：Redis 面试题 （卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/9dde7f462dae442f9f328da7fff2fc14.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"15____2022_105\"></a>专题15：分布式锁 面试题（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/7e5620fea5e64e45899409738aee2b31.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"16Zookeeper____2022_110\"></a>专题16：Zookeeper 面试题（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/9d05e9c9173c4b5b8fa0b4d012bc4392.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"17____2022_115\"></a>专题17：分布式事务面试题（卷王专供 + 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/4d853d5275294ced8c87502cd9622ed4.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"18____2022_120\"></a>专题18：一致性协议 （卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/2968bbe9985d4579aacc1671b8796571.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"19Zab___2022_125\"></a>专题19：Zab协议（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/2cec5f595ce24e83befd20bb4bd914cb.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"20Paxos____2022_130\"></a>专题20：Paxos 协议（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/6525845236ba4e16b092d7cf5ddfde5b.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"21raft____2022_135\"></a>专题21：raft 协议（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/c0d2566813e14f87a156a4aa823ee989.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"22Linux___2022_139\"></a>专题22：Linux面试题（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/8679667ed36f478d9f45ba93c7913dad.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"23Mysql____2022_144\"></a>专题23：Mysql 面试题（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/c6210651842b4b44bfd0a690885946f2.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"24SpringCloud____2022_148\"></a>专题24：SpringCloud 面试题（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/fc83b67415f047c3935b15ce35762930.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"25Netty_____2022_153\"></a>专题25：Netty 面试题 （卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/75d398b705a04c4e9fffac6dcfc2e69a.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"26RabbitMQKafkaRocketMQ___2022_158\"></a>专题26：消息队列面试题：RabbitMQ、Kafka、RocketMQ（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/7decee925a6a45c7aaa62b8d043fdf26.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"27____2022_162\"></a>专题27：内存泄漏 内存溢出（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/5fb108dea5234e6087353d9a50b24ae9.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"28JVM_____2022_167\"></a>专题28：JVM 内存溢出 实战（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/711de19b057844d0b1b1b8aa14d2fff4.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"29___2022_172\"></a>专题29：多线程面试题（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/a990cd5c130947899979ffe24811a07d.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"30HR_177\"></a>专题30：HR面试题：过五关斩六将后，小心阴沟翻船！（史上最全、避坑宝典）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/c29f8dee6ec14db98aba2487156784cc.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"31Hash___2022_182\"></a>专题31：Hash连环炮面试题（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/5fa66cff7e1e483cacfd9e7270bd5a42.png#pic_center\" alt=\"在这里插入图片描述\"></p> \n <h1><a id=\"32___2022_186\"></a>专题32：大厂面试的基本流程‌和面试准备（卷王专供+ 史上最全 + 2022面试必备）</h1> \n <p><img src=\"https://img-blog.csdnimg.cn/5d4f36d379204de2b8ca8fdbeee2f72e.png\" alt=\"在这里插入图片描述\"></p> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 2726);
INSERT INTO `crawlerblog` VALUES (123124032, '峰值21WQps、亿级DAU，小游戏《羊了个羊》是怎么架构的？', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <p>小游戏《羊了个羊》 短短的7天内，DAU突破了1亿、吞吐量峰值21WQps。</p> \n <p>《羊了个羊》运营后台数据显示，在短短的7天内，这款小游戏的DAU就突破了1亿。</p> \n <p>要知道，除了王者荣耀、原神等屈指可数的现象级手游之外，1亿DAU是这个行业的天花板，</p> \n <p>可是，它却被一个看上去设计粗糙的小程序游戏轻松实现了。</p> \n <p>然而，其最初技术架构仅支撑 <strong>5000QPS并发</strong>，7天内突破了1亿、吞吐量峰值21WQps</p> \n <p><img src=\"https://img-blog.csdnimg.cn/fb7c94381162496b918a614af66e122c.png\" alt=\"\"></p> \n <p>如何通过架构优化，让一款小程序游戏可以在短时间内实现对上亿DAU的支持？</p> \n <p>技术架构、运维体系、以及安全防范等技术体系都存在巨大的挑战。</p> \n <p>那么：峰值21WQps、亿级DAU，超高吞吐小游戏，是怎么架构的？</p> \n <h2><a id=\"1__23\"></a>1 低吞吐、低可用的最初技术架构</h2> \n <p>《羊了个羊》最开始的技术架构，</p> \n <p>因为技术以及时间等因素，在设计上有些简单，</p> \n <p>如下图1所示，</p> \n <p><img src=\"https://img-blog.csdnimg.cn/2d0ced68cc034ffdbe45d5164824f037.png\" alt=\"\"></p> \n <p>玩家流量通过一个接入层 LB进入，</p> \n <p>传输给服务层几个 POD 进行游戏逻辑处理，</p> \n <p>再将数据进行存储，</p> \n <p>其中，热数据存储在Redis中, 持久化数据存在MongoDB。</p> \n <p>最初的服务层几个 POD ，都是单点服务</p> \n <p><strong>单点服务的性能瓶颈，再加上代码未进行充分优化，造成当时的系统最高只能承受5000的QPS</strong>，</p> \n <p>但实际流量增长很快， 并且持续升高并到达性能瓶颈，游戏服务开始瘫痪，全部玩家无法再进行游戏。</p> \n <h2><a id=\"2__51\"></a>2 技术架构全面升级</h2> \n <p>大部分项目，都存在低吞吐、低可用的最初技术架构</p> \n <p>但是，如果吞吐量一上来，就面临着优化</p> \n <p>so，</p> \n <p>面对服务中断， 《羊了个羊》团队在详细分析原来架构的不足之后，</p> \n <p>《羊了个羊》 做了 技术架构全面升级</p> \n <p>具体如下图：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/62ccfa9156354bb49b6d238d01c5f63f.png\" alt=\"\"></p> \n <h3><a id=\"_67\"></a>接入层的架构优化：</h3> \n <ul>\n  <li>启用CDN做游戏动静态资源分离，让玩家使用的游戏资源实现就近下载，减轻网络端压力；</li>\n  <li>设计多LB入口实现入口高可用和限流，避免系统被超额流量过载；</li>\n </ul> \n <h3><a id=\"_72\"></a>服务层的架构优化：</h3> \n <ul>\n  <li>优化服务层的自动扩容，应对巨量的 突发流量</li>\n  <li>具体措施上，首先通过引入腾讯云TKE Serverless 的弹性机制，实现游戏服自动纵向和横向扩展，</li>\n  <li>实现服务解藕，增加容错和熔断机制；</li>\n </ul> \n <h3><a id=\"Cache_78\"></a>Cache层的架构优化：</h3> \n <ul>\n  <li>Redis缓存热数据，分担数据库查询压力等。</li>\n </ul> \n <h3><a id=\"_82\"></a>存储层的架构优化：</h3> \n <ul>\n  <li>把MongoDB转换为读写分离模式，配合代码逻辑优化实现性能提升，</li>\n  <li>引入分库实现业务分层与隔离，</li>\n </ul> \n <p>优化之后，《羊了个羊》最新技术架构</p> \n <p><img src=\"https://img-blog.csdnimg.cn/0a11d190a91b4146a7dc22a1570d18d8.png\" alt=\"\"></p> \n <p>经过上述一系列技术升级， 新架构经受住了一波又一波的流量峰值考验，</p> \n <p>在高峰期DAU过亿后，游戏技术系统依旧表现稳定，</p> \n <p>这对于一个发布才几个月的小游戏来说，在国内也很难再找到这样的例子。</p> \n <h2><a id=\"3__105\"></a>3 运维体系的升级</h2> \n <p>通过技术架构的迭代以及不断激增的用户，《羊了个羊》技术团队也认识到，因为爆火太快，更需要快速补齐运维能力，才能更好的持续调整和提升游戏体验。</p> \n <p>在运维体系这块，包括 业务日志、性能监测等。</p> \n <p>为快速补齐运维能力，通过<strong>业务日志诊断</strong>程序性能，配合业务调优以减少服务器压力；</p> \n <p>《羊了个羊》选择了开箱即用的日志服务 云服务度 CLS，</p> \n <p>当然，有条件的团队，使用自建的 elk平台，或者基于clickhouse的高并发分布式日志监测平台，也是可以的。</p> \n <p>CLS 对游戏接口稳定性、异常调用趋势的监控可帮助他们快速观测产品质量 ，并第一时间获取到异常panic统计分析和告警 ；</p> \n <p>在游戏运营方面，玩家登录链路耗时/对局时间等数据亦可通过 CLS 分析、校验及处理，进而调整和提升游戏体验；同时还能满足游戏用户行为及审计对账等需求。</p> \n <p><strong>CLS的云原生特性，辅助进行稳定性和程序性能调优。另外，CLS用作简单运维工具查日志、做接口调用告警</strong></p> \n <p>借助CLS的SQL分析、仪表盘、监控告警能力，</p> \n <p>可以分析出程序可优化点，解决游戏开发商在初期和爆发期对游戏稳定性和运营数据分析的难题。</p> \n <p>除了运维数据外，</p> \n <p>CLS还提供了数据观测功能</p> \n <p>在游戏调整玩法、分析活动数据时，运营人员可借助CLS快速观测数据变化，并作出应对策略。</p> \n <p>另外，还将游戏的通关数据、用户行为分析、审计对账等运营数据在CLS中存储分析。</p> \n <h2><a id=\"4__141\"></a>4 安全防范领域的升级</h2> \n <p>哪里有流量，哪里就有黑产。</p> \n <p>许多恶意BOT流量大量涌入到游戏中，导致游戏服务器 QPS、带宽快速升高，影响服务可用性等情况</p> \n <p>由于设计之初没有充分考虑安全问题，因此引来大量不法分子通过恶意BOT抢刷游戏排行，</p> \n <p>几乎每分每秒，都有恶意流量访问游戏接口，</p> \n <p>并且这一部分恶意群体通过互联网、QQ群和微信群中传播恶意刷排行的脚本，</p> \n <p>极大的破坏了游戏公平性，让本该属于游戏对抗的乐趣被恶意BOT抹杀。</p> \n <p>而且更重要的是随着羊了个羊热度的不但攀升，许多恶意BOT流量的大量涌入，导致游戏服务器 QPS、带宽快速升高，一度影响服务可用性。</p> \n <p><strong>《羊了个羊》接入腾讯云WAF进行防护，</strong></p> \n <p><strong>一开始接入WAF的时候，相关 QPS 峰值已达 21W，</strong></p> \n <p><strong>接入WAF之前CPU一直处于临界值水位 、网络链接打满的导致服务不可用的情况。</strong></p> \n <p><img src=\"https://img-blog.csdnimg.cn/c9365826cbb34d86bfc72c11ef7ecedc.png\" alt=\"\"></p> \n <p>通过选择负载均衡型WAF, 即可在不改动网络架构的情况下3秒完成业务接入WAF，实现在用户无感的情况下对恶意流量进行清洗及防护。</p> \n <p>为了有效打击攻击者的恶意流量，</p> \n <p>WAF 中 BOT 行为管理也提供了全链路、全生命周期的的恶意行为流量体系，实现快速高效的恶意流量治理。</p> \n <p>最后在安全防范领域，通过安全方案抵抗异常流量攻击。</p> \n <blockquote> \n  <p>注：本文以 PDF 持续更新，最新尼恩 架构笔记、面试题 的PDF文件，请从这里获取：<a href=\"https://gitee.com/crazymaker/SimpleCrayIM/blob/master/%E7%96%AF%E7%8B%82%E5%88%9B%E5%AE%A2%E5%9C%88%E6%80%BB%E7%9B%AE%E5%BD%95.md\">码云</a></p> \n </blockquote> \n <h2><a id=\"5__180\"></a>5 互联网应用设计的“三高”原则</h2> \n <p>通过《羊了个羊》团队在小游戏架构扩容、系统运维以及安全防范领域的实战经验，可以给大家一些参考。</p> \n <p>面对突发流量，互联网应用在设计的过程中需要考虑以下能力：</p> \n <p>第一是<strong>高并发</strong>，能够承载瞬时爆发流量，保证响应时长在可接受的范围；</p> \n <p>其次是<strong>高可用</strong>，系统持续提供服务，小概率发生宕机时，过载保护将故障控制在可承受范围内，不影响核心业务；</p> \n <p>最后是<strong>高扩展</strong>，服务系统应该具备水平和垂直扩展能力，在成本和可用性中实现最佳平衡点。</p> \n <h2><a id=\"_195\"></a>推荐阅读：</h2> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128670335\">Docker面试题（史上最全 + 持续更新）</a>》</p> \n <p>《 <a href=\"https://blog.csdn.net/crazymakercircle/article/details/128533821\">场景题：假设10W人突访，你的系统如何做到不 雪崩？</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124790425\">尼恩Java面试宝典</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057567\">Springcloud gateway 底层原理、核心实战 (史上最全)</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124120506\">Flux、Mono、Reactor 实战（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125059491\">sentinel （史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057545\">Nacos (史上最全)</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/123420859\">分库分表 Sharding-JDBC 底层原理、核心实战（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/114527369\">TCP协议详解 (史上最全)</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126992542\">clickhouse 超底层原理 + 高可用实操 （史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120702536\">nacos高可用（图解+秒懂+史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264803\">队列之王： Disruptor 原理、架构、源码 一文穿透</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264508\">环形队列、 条带环形队列 Striped-RingBuffer （史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125135726\">一文搞定：SpringBoot、SLF4j、Log4j、Logback、Netty之间混乱关系（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128265067\">单例模式（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125017316\">红黑树（ 图解 + 秒懂 + 史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/109459593\">分布式事务 （秒懂）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128123114\">缓存之王：Caffeine 源码、架构、原理（史上最全，10W字 超级长文）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/113751575\">缓存之王：Caffeine 的使用（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126579528\">Java Agent 探针、字节码增强 ByteBuddy（史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120747767\">Docker原理（图解+秒懂+史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/116425814\">Redis分布式锁（图解 - 秒懂 - 史上最全）</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85956246\">Zookeeper 分布式锁 - 图解 - 秒懂</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85922561\">Zookeeper Curator 事件监听 - 10分钟看懂</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83957259\">Netty 粘包 拆包 | 史上最全解读</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83758107\">Netty 100万级高并发服务器配置</a>》</p> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/102557988\">Springcloud 高并发 配置 （一文全懂）</a>》</p> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 1951);
INSERT INTO `crawlerblog` VALUES (123124033, '场景题：假设10W人突访，你的系统如何做到不 雪崩？', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <p>文章很长，而且持续更新，建议收藏起来，慢慢读！<a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\"><strong>疯狂创客圈总目录 博客园版</strong></a> 为您奉上珍贵的学习资源 ：</p> \n <p>免费赠送 :<a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\"><strong>《尼恩Java面试宝典》</strong></a> 持续更新+ 史上最全 + 面试必备 2000页+ 面试必备 + 大厂必备 +涨薪必备<br> 免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\"><strong>《Java高并发核心编程（卷1）加强版》</strong></a> 面试必备 + 大厂必备 +涨薪必备 加尼恩免费领<br> 免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\"><strong>《Java高并发核心编程（卷2）加强版》</strong> </a>面试必备 + 大厂必备 +涨薪必备 加尼恩免费领<br> 免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/14493539.html\"><strong>《Java高并发核心编程（卷3）加强版》</strong></a> 面试必备 + 大厂必备 +涨薪必备 加尼恩免费领<br> 免费赠送 经典图书:<a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\">《<strong>尼恩Java面试宝典 V11</strong>》 </a>面试必备 + 大厂必备 +涨薪必备 加尼恩免费领<br> 免费赠送 资源宝库： <strong>Java 必备 百度网盘资源大合集 价值</strong>&gt;10000元 加尼恩领取</p> \n <h2><a id=\"10W__9\"></a>一个普通系统，假设10W人同时访问，如何保证不 雪崩？</h2> \n <p><strong>这个，是面试当中，一道非常场景的： 场景题。</strong></p> \n <p>如果面试遇到这个问题，很多小伙伴的第一反应：</p> \n <p><strong>怎么可能，我们的系统，总体的用户量，不到1万， 怎么可能会有10W人同时访问。</strong></p> \n <p>这个问题，如果遇到了，只能会硬着头皮作答。</p> \n <p>如果直接用这个疑问，去反问面试官，那么 ，面试官一定会说这小子 没有遇到过事情。</p> \n <p>为啥呢？</p> \n <p>因为哪怕用户不到1万，还是可能会有10W人同时访问。</p> \n <p>这些人包括：</p> \n <ul>\n  <li>爬虫</li>\n  <li>刷子（羊毛党）</li>\n </ul> \n <h3><a id=\"_31\"></a>爬虫对访问量的贡献</h3> \n <p>大家应该听过一句话吧，整个互联网上大概有 50%以上的流量其实是爬虫。</p> \n <p>一个做反爬虫哥们，发现了一个极端案例，</p> \n <p>某个页面12000次点击里边，98%的点击率，是爬虫贡献的。</p> \n <p>爬虫和用户的比例是 19比1.</p> \n <p>那么 1W用户， 可能会对应到19W 爬虫，</p> \n <p>那么 1W用户， 有没有 10W的 同时访问的可能呢？</p> \n <p>因为 大量爬虫的存着， 当然有的。</p> \n <h3><a id=\"_47\"></a>刷子用户（羊毛党）对访问量的贡献</h3> \n <p>“羊毛党”战术之一：开启机器人批量注册新账号，招募“新兵”。</p> \n <p>“这是个‘昏招’，批量注册的账号很容易识别。</p> \n <p>“羊毛党”战术之二：提前囤积账号，囤积的老账号”。</p> \n <p>但通过注册时间、注册地与下单地比对等方式，很快识别出来。</p> \n <p>某年的“618”电商节活动期间，某电商公司，平均每天拦截“羊毛党”账号2000万个。</p> \n <p>那么 1W用户， 可能会对应到多少羊毛党用户呢？</p> \n <p>其中，可能会包含部分 <strong>提前囤积账号</strong></p> \n <p>另外，在 活动执行的过程中， 还是有 可能 <strong>批量注册大量的新账号</strong></p> \n <p>那么 1W用户， 有没有 10W的 同时访问的可能呢？</p> \n <p>只要有利可图，就会有 刷子用户（羊毛党），他们会通过群体人手，或者 <strong>自动化工具</strong>，<strong>制造大量的瞬间流量</strong>。</p> \n <p>这些自动化工具，在 1s之内， 尝试10W次。</p> \n <p>所以，只要是有利可图，如 秒杀等， 那么 1W用户， 有没有 10W的 同时访问的可能呢？</p> \n <p>当然有的。</p> \n <h2><a id=\"10W_77\"></a>假设10W人突然访问，现有架构能否扛住？</h2> \n <p>按照之前尼恩和大家分析的架构理论</p> \n <p>一个系统10W人同时访问 ， 也就是：并发量为 10w Qps</p> \n <p><strong>那么 10w Qps ，对应到多少用户量呢 ?</strong></p> \n <p><strong>是 一个1亿的用户量。</strong></p> \n <p>而 ，我们很多同学手上的 系统， 总体的用户量 不到1万，</p> \n <p>不到1万的用户，对应到多少 的 吞吐量呢？</p> \n <p>是 10。</p> \n <p>没错，如果 总体的用户量 不到1万，按照 正常估算， 吞吐量就只有 10。</p> \n <p>也就是说， 如果我们按照 1万 做系统架构</p> \n <p><img src=\"https://img-blog.csdnimg.cn/5f79eddf0b5b4d7489257e2d266321f7.png\" alt=\"在这里插入图片描述\"></p> \n <p>这种架构，对于 qps 为10 的小流量来说，可以说是 小菜一碟。</p> \n <p>可以说，用牛刀 在 杀鸡。</p> \n <img src=\"https://inews.gtimg.com/newsapp_bt/0/13738654191/1000.jpg\" alt=\"img\"> \n <p>那么，如果发生突发情况，</p> \n <p>假设10W人突然访问，我们的架构，如何抵抗？</p> \n <p><img src=\"https://img-blog.csdnimg.cn/fe36ff8dff9742fa836fdc97df11b818.png\" alt=\"在这里插入图片描述\"></p> \n <p>大家看看，上面的架构， 能抵抗吗？</p> \n <h3><a id=\"_127\"></a>接入层和服务层如何抵抗？</h3> \n <p>方式之一： 扩容</p> \n <p>方式之二：限流</p> \n <h3><a id=\"__137\"></a>首先能用到的策略： 扩容</h3> \n <p>大家首先会想到的策略，就是扩容。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/87b83c89142a4e2290514ab46682b454.png\" alt=\"在这里插入图片描述\"></p> \n <p>但是，如果流量是突发的， 又不知道什么时候扩， 怎么办呢？</p> \n <p>那么就是<strong>自动扩容</strong>。</p> \n <p><strong>自动扩容</strong>虽然比较难，办法总是有的，只要稍微想想，就出来了。</p> \n <p>大致有两种自动扩容方式，具体请参见 《java 高并发核心编程 卷3》 第 1.5.3 小节。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/af502ec939274e9baa22621ca8adedf9.png\" alt=\"在这里插入图片描述\"></p> \n <h3><a id=\"__161\"></a>其次能用到的策略： 限流</h3> \n <ul>\n  <li>nginx 限流</li>\n  <li>SpringCloud gateway 限流</li>\n </ul> \n <p>接入层限流可以进行 nginx 限流</p> \n <p><img src=\"https://img-blog.csdnimg.cn/65da6367f8a04f3f9810ea346916be53.png\" alt=\"在这里插入图片描述\"></p> \n <p>微服务 SpringCloud gateway 里边，</p> \n <p>还 可以使用 redis lua进行分布式限流， 或者使用 sentinel 进行 限流，</p> \n <p>经过 扩容和限流， 咱们的系统，应该可以扛住 10Wqps， 因为可以把流量限制到 1Wqps，甚至是 1 K qps。</p> \n <p>谁怪 有那么多刷子流量，或者 爬虫流量呢。</p> \n <p>但是，限流是无奈之举。</p> \n <p>或者说，如果10Wqps，都是有效流量， 不能使用限流这 简单粗暴的方式 ， 而是这个 10Wqps 必须进入到服务层。</p> \n <h3><a id=\"Redis_194\"></a>分布式Redis集群如何抵抗？</h3> \n <p>这个 10Wqps 必须进入到服务层。</p> \n <p>怎么办？</p> \n <p>服务层 倒是好说，和网关一样， 可以通过扩容解决。</p> \n <p>所以，后面的 流量就进入 redis集群。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/9f8e30f9ed254029ae2311bf7e2299d5.png\" alt=\"在这里插入图片描述\"></p> \n <p>redis 集群一般搭建的是 3主3从：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/bd1960e818f9640d3800b1c7ddf56b8d.png\" alt=\"img\"></p> \n <p>一般来说，主节点提供服务， 从节点是做冗余的， 并不提供数据的写入服务。</p> \n <p>redis cluster模式官方默认主节点提供读写, 从节点提供slot数据备份以及故障转移。默认情况下，从节点并不提供数据读写服务。</p> \n <p>单个redis 的吞吐量，一般就是 2W左右。</p> \n <p>那么 10Wqps，访问 redis cluster，分布到 3个节点， 还是不够。</p> \n <p>如果 10Wqps 访问的是同一个key， 那就问题更大了。</p> \n <p>因为 单个redis 的吞吐量，一般就是 2W左右。 怎么可能扛住 5倍的吞吐量。</p> \n <p>于是就很容易出现 redis cpu 100%， 请求排队， 没有响应，严重的情况 出现 redis 雪崩。</p> \n <p>于是乎，改怎么办?</p> \n <p>大概也有两种方案：</p> \n <p>方法一： redis 扩容</p> \n <p>方法二： 本地缓存</p> \n <p>方法一 redis 扩容 可以解决 key 的访问量比较 均匀的问题。比如扩容到 10主10从，就可以承担 20Wqps的 流量。</p> \n <p>但是方法一 要求每个key的访问量 必须分布得比较均匀。如果20w qps 的流量，全部来自一个key， 则方案一 无效。</p> \n <p>方法二 本地缓存 可以解决 单个key 访问量 巨大的问题。这种 占据大量流量的 单个key，叫做 hotkey（热key）。</p> \n <p>所以，接下来，还是得调整系统的架构， 加入本地缓存的 环节。</p> \n <h2><a id=\"_10WQps__254\"></a>解决 10WQps 突发流量的本地缓存架构</h2> \n <p>解决 10WQps 突发流量的本地缓存架构，大致有两种：</p> \n <ul>\n  <li>二级缓存架构</li>\n  <li>三级缓存架构</li>\n </ul> \n <h3><a id=\"_265\"></a>二级缓存架构：</h3> \n <p>java 本地缓存+ redis 分布式缓存，具体如下图：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/38fb9161986240fc93436c7fcaf34b8b.png\" alt=\"在这里插入图片描述\"></p> \n <p>先发问一级缓存caffeine ，如果 没有找到，再访问 二级缓存 redis 集群</p> \n <h3><a id=\"_281\"></a>三级缓存架构：</h3> \n <p>nginx本地缓存+ java 本地缓存+ redis 分布式缓存，具体如下图：</p> \n <img src=\"https://img-blog.csdnimg.cn/cf89eb4e346646448403df675b6c73f1.png\" alt=\"在这里插入图片描述\"> \n <h3><a id=\"_289\"></a>本地缓存的优缺点</h3> \n <p><strong>1. 快但是量少：访问速度快，但无法进行大数据存储</strong></p> \n <p>本地缓存相对于分布式缓存的好处是，由于数据不需要跨网络传输，故性能更好，</p> \n <p>但是由于占用了应用进程的内存空间，如 Java 进程的 JVM 内存空间，故不能进行大数据量的数据存储。</p> \n <p><strong>2. 需要解决数据一致性问题：本地缓存、分布式缓存、DB数据一致性问题</strong></p> \n <p>与此同时，本地缓存只支持被该应用进程访问，一般无法被其他应用进程访问，故在应用进程的集群部署当中，</p> \n <p>如果对应的数据库数据，存在数据更新，则需要<strong>同步更新不同部署节点的缓存数据</strong>来包保证数据一致性，</p> \n <p>复杂度较高并且容易出错，如基于 rocketmq 的发布订阅机制来同步更新各个部署节点。</p> \n <p><strong>3.未持久化，容易丢失： 数据随应用进程的重启而丢失</strong></p> \n <p>由于本地缓存的数据是存储在应用进程的内存空间的，所以当应用进程重启时，本地缓存的数据会丢失。</p> \n <p>所以对于需要更改然后持久化的数据，需要注意及时保存，否则可能会造成数据丢失。</p> \n <p><strong>4.需要尽量缓存热点key，而提升缓存的命中率</strong></p> \n <p>由于本地缓存太小，从而很容易被淘汰，</p> \n <p>如果还没有来得及访问，本地缓存中的数据，就被淘汰了，那就失去了本地缓存的价值， 当然，本地缓存的命中率也会很低。</p> \n <h3><a id=\"_317\"></a>如何提升缓存的命中率？</h3> \n <p><strong>方式1： 采用更好的 缓存淘汰策略</strong></p> \n <p>比如caffeine中，使用了 w-tinylfu 策略。</p> \n <p>这种策略的 缓存的命中率，比较简单的 lfu、lru 都 高出很多。</p> \n <p>有测试表明： caffeine 比 guava 的命中率，不同场景，都会高出10%以上。</p> \n <p><strong>方式2： 尽量识别和缓存 热点数据</strong></p> \n <p>简单的说，把热点数据， 加载到本地缓存。</p> \n <h2><a id=\"HotKey_337\"></a>什么是HotKey？</h2> \n <p>在某个Key接收到的访问次数、显著高于其它Key时，我们可以将其称之为HotKey，</p> \n <p>从访问量上来说，常见的HotKey如：</p> \n <ul>\n  <li>某Redis实例的每秒总访问量为10000，而其中一个Key的每秒访问量达到了7000（访问次数显著高于其它Key）</li>\n  <li>对一个拥有上千个成员且总大小为1MB的HASH Key每秒发送大量的HGETALL（带宽占用显著高于其它Key）</li>\n  <li>对一个拥有数万个成员的ZSET Key每秒发送大量的ZRANGE（CPU时间占用显著高于其它Key）</li>\n </ul> \n <p>从业务上来说， 常见的HotKey如：</p> \n <p><strong>1 、MySQL等数据库会被频繁访问的热数据</strong></p> \n <p>如爆款商品的skuId。</p> \n <p><strong>2 、redis的被密集访问的key</strong></p> \n <p>如爆款商品的各维度信息，skuId、shopId等。</p> \n <p><strong>3 、机器人、爬虫、刷子用户</strong></p> \n <p>如用户的userId、uuid、ip等。</p> \n <p><strong>4 、某个接口地址</strong></p> \n <p>如/sku/query或者更精细维度的。</p> \n <p>注意，我们的HotKey探测框架只关心key，其实就是一个字符串，</p> \n <h3><a id=\"HotKey_375\"></a>HotKey对服务层和数据层的风险</h3> \n <p>在拥有大量并发用户的系统中，HotKey一直以来都是一个不可避免的问题。</p> \n <ul>\n  <li> <p>或许是突然某些商品成了爆款，</p> </li>\n  <li> <p>或许是海量用户突然涌入某个店铺，</p> </li>\n  <li> <p>或许是秒杀时瞬间大量开启的爬虫用户，</p> </li>\n  <li> <p><strong>突发大批机器人</strong>以远超正常用户的速度发起极其密集的请求，这些机器人只需要很小的代价，就能发出百倍于普通用户的请求量，从而大幅挤占正常用户的资源。</p> </li>\n </ul> \n <p>以京东为例的这些头部互联网公司，动辄某个爆品，会瞬间引入每秒上百万甚至数百万的请求，当然流量多数会在几秒内就消失。</p> \n <p>但就是这短短的几秒的HotKey，就会瞬间造成其所在redis分片集群瘫痪。</p> \n <p>原因也很简单，redis作为一个单线程的结构，所有的请求到来后都会去排队，当请求量远大于自身处理能力时，后面的请求会陷入等待、超时。</p> \n <p>由于该redis分片完全被这个key的请求给打满，导致该分片上所有其他数据操作都无法继续提供服务，也就是HotKey不仅仅影响自己，还会影响和它合租的数据。</p> \n <p>这样，redis 缓存没有响应之后，相当于 redis 击穿， 请求直接转向DB</p> \n <p>DB的吞吐量，比如会低很多，DB 就会雪崩。</p> \n <h4><a id=\"HotKey_400\"></a>总结一下，HotKey带来的常见问题</h4> \n <ul>\n  <li>HotKey占用大量的Redis CPU时间，使其性能变差并影响其它请求；</li>\n  <li>Redis Cluster中各node流量不均衡造成Redis Cluster的分布式优势无法被Client利用，一个分片负载很高而其它分片十分空闲从而产生读/写热点问题；</li>\n  <li>在抢购、秒杀活动中，由于商品对应库存Key的请求量过大，超出Redis处理能力造成超卖；</li>\n  <li>HotKey的请求压力数量超出Redis的承受能力造成缓存击穿，此时大量强求将直接指向后端存储，将后端存储打挂并影响到其它业务；</li>\n </ul> \n <h4><a id=\"HotKey_407\"></a><strong>HotKey问题的根本：</strong></h4> \n <p>HotKey问题归根到底就是如何找到HotKey，并将HotKey放到本地内存的问题。</p> \n <p>只要该key在内存里，我们就能极快地来对它做逻辑，内存访问和redis访问的速度不在一个量级。</p> \n <p>如果该key是在本地内存中，读取一个内存中的值，每秒多少个万次都是很正常的，不存在任何数据层的瓶颈。</p> \n <p>但问题是事先不知道HotKey在哪里？</p> \n <p>那么，问题就来了，如何进行 HotKey的探测？</p> \n <h3><a id=\"HotKey_421\"></a>HotKey探测关键指标</h3> \n <p><strong>1、实时性</strong></p> \n <p>这个很容易理解，key往往是突发性瞬间就热了，根本不给你再慢悠悠手工去配置中心添加HotKey再推送到jvm的机会。</p> \n <p>它大部分时间不可预知，来得也非常迅速，可能某个商家上个活动，瞬间HotKey就出现了。如果短时间内没能进到内存，就有redis集群被打爆的风险。</p> \n <p>所以HotKey探测框架最重要的就是实时性，最好是某个key刚有热的苗头，在1秒内它就已经进到整个服务集群的内存里了，1秒后就不会再去密集访问redis了。</p> \n <p>同理，对于刷子用户也一样，刚开始刷，1秒内我就把它给禁掉了。</p> \n <p><strong>2、准确性</strong></p> \n <p>这个很重要，也容易实现，累加数量，做到不误探，精准探测，保证探测出的HotKey是完全符合用户自己设定的阈值。</p> \n <p><strong>3、集群一致性</strong></p> \n <p>这个比较重要，尤其是某些带删除key的场景，要能做到删key时整个集群内的该key都会删掉，以避免数据的错误。</p> \n <p><strong>4、高性能</strong></p> \n <p>这个是核心之一，高性能带来的就是低成本，做HotKey探测目的就是为了降低数据层的负载，提升应用层的性能，节省服务器资源。不然，大家直接去整体扩充redis集群规模就好了。</p> \n <p>理论上，在不影响实时性的情况下，要完成实时HotKey探测，所消耗的机器资源越少，那么经济价值就越大。</p> \n <h2><a id=\"HotKey_451\"></a>如何实现HotKey探测？</h2> \n <h4><a id=\"HotKey1___455\"></a>HotKey探测方案1： 流计算集群</h4> \n <p>通过 流式计算集群 storm/ flink 集群，进行 topkey</p> \n <p><img src=\"https://img-blog.csdnimg.cn/3d0e120e4ef74232bd74aa8cc0490778.png\" alt=\"在这里插入图片描述\"></p> \n <p>java 应用将访问 记录发送到 消息队列，如 kafka</p> \n <p>storm、flink 集群，进行top N 的计算，把top N 结果存在 redis</p> \n <p>其中的 top N 的key，就是热点 key</p> \n <h4><a id=\"HotKey2___473\"></a>HotKey探测方案2： 流计算集群</h4> \n <p>有赞透明多级缓存解决方案</p> \n <h4><a id=\"HotKey3__hotkey_481\"></a>HotKey探测方案3： 结合开源hotkey，做热点探测</h4> \n <p>比如：结合京东开源hotkey，做热点探测</p> \n <h2><a id=\"HotKey2TMC_489\"></a>HotKey探测方案2：有赞透明多级缓存解决方案（TMC）</h2> \n <h3><a id=\"TMC_491\"></a>一、TMC简介</h3> \n <h4><a id=\"11_TMC__493\"></a>1-1. TMC 是什么</h4> \n <p>TMC ，即“透明多级缓存（ Transparent Multilevel Cache ）”，是有赞 PaaS 团队给公司内应用提供的整体缓存解决方案。</p> \n <p>TMC 在通用“分布式缓存解决方案（如 CodisProxy + Redis ，如有赞自研分布式缓存系统 zanKV ）”基础上，增加了以下功能：</p> \n <ul>\n  <li>应用层热点探测</li>\n  <li>应用层本地缓存</li>\n  <li>应用层缓存命中统计</li>\n </ul> \n <p>以帮助应用层解决缓存使用过程中出现的热点访问问题。</p> \n <h4><a id=\"12__TMC_505\"></a>1-2. 为什么要做 TMC</h4> \n <p>使用有赞服务的电商商家数量和类型很多，商家会不定期做一些“商品秒杀”、“商品推广”活动，导致“营销活动”、“商品详情”、“交易下单”等链路应用出现 <strong>缓存热点访问</strong> 的情况：</p> \n <ul>\n  <li>活动时间、活动类型、活动商品之类的信息不可预期，导致 <em>缓存热点访问</em> 情况不可提前预知；</li>\n  <li><em>缓存热点访问</em> 出现期间，应用层少数 <strong>热点访问 key</strong> 产生大量缓存访问请求：冲击分布式缓存系统，大量占据内网带宽，最终影响应用层系统稳定性；</li>\n </ul> \n <p>为了应对以上问题，需要一个能够 <em>自动发现热点</em> 并 <em>将热点缓存访问请求前置在应用层本地缓存</em> 的解决方案，这就是 TMC 产生的原因。</p> \n <h4><a id=\"13__514\"></a>1-3. 多级缓存解决方案的痛点</h4> \n <p>基于上述描述，我们总结了下列 <strong>多级缓存解决方案</strong> 需要解决的需求痛点：</p> \n <ul>\n  <li>热点探测：如何快速且准确的发现 <strong>热点访问 key</strong> ？</li>\n  <li>数据一致性：前置在应用层的本地缓存，如何保障与分布式缓存系统的数据一致性？</li>\n  <li>效果验证：如何让应用层查看本地缓存命中率、热点 key 等数据，验证多级缓存效果？</li>\n  <li>透明接入：整体解决方案如何减少对应用系统的入侵，做到快速平滑接入？</li>\n </ul> \n <p>TMC 聚焦上述痛点，设计并实现了整体解决方案。</p> \n <p>以支持“热点探测”和“本地缓存”，减少热点访问时对下游分布式缓存服务的冲击，避免影响应用服务的性能及稳定性。</p> \n <h3><a id=\"_TMC__527\"></a>二、 TMC 整体架构</h3> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/d6ec25bff00b047fef725f0b0328bd22.png\" alt=\"图片描述\"></p> \n <p>TMC 整体架构如上图，共分为三层：</p> \n <ul>\n  <li>存储层：提供基础的kv数据存储能力，针对不同的业务场景选用不同的存储服务（ codis / zankv / aerospike ）；</li>\n  <li>代理层：为应用层提供统一的缓存使用入口及通信协议，承担分布式数据水平切分后的路由功能转发工作；</li>\n  <li>应用层：提供统一客户端给应用服务使用，内置“热点探测”、“本地缓存”等功能，对业务透明；</li>\n </ul> \n <h3><a id=\"_TMC__541\"></a>三、 TMC 本地缓存</h3> \n <h4><a id=\"31__543\"></a>3-1. 如何透明</h4> \n <p>TMC 是如何减少对业务应用系统的入侵，做到透明接入的？</p> \n <p>对于公司 Java 应用服务，在缓存客户端使用方式上分为两类：</p> \n <ul>\n  <li>基于<code>spring.data.redis</code>包，使用<code>RedisTemplate</code>编写业务代码；</li>\n  <li>基于<code>youzan.framework.redis</code>包，使用<code>RedisClient</code>编写业务代码；</li>\n </ul> \n <p>不论使用以上那种方式，最终通过<code>JedisPool</code>创建的<code>Jedis</code>对象与缓存服务端代理层做请求交互。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/3831041bc339fcea2f09ae1126817099.png\" alt=\"图片描述\"></p> \n <p>TMC 对原生jedis包的<code>JedisPool</code>和<code>Jedis</code>类做了改造，</p> \n <p>在JedisPool初始化过程中, 集成TMC“热点发现”+“本地缓存”功能<code>Hermes-SDK</code>包的初始化逻辑，</p> \n <p>使<code>Jedis</code>客户端与缓存服务端代理层交互时, 先与<code>Hermes-SDK</code>交互，从而完成 “热点探测”+“本地缓存”功能的透明接入。</p> \n <p>对于 Java 应用服务，只需使用特定版本的 jedis-jar 包，无需修改代码，即可接入 TMC 使用“热点发现”+“本地缓存”功能，做到了对应用系统的最小入侵。</p> \n <h4><a id=\"32__566\"></a>3-2. 整体结构</h4> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/dbf1157261101a8676a4cb9a63922894.png\" alt=\"图片描述\"></p> \n <h5><a id=\"321__572\"></a>3-2-1. 模块划分</h5> \n <p>TMC 本地缓存整体结构分为如下模块：</p> \n <ul>\n  <li><strong>Jedis-Client</strong>： Java 应用与缓存服务端交互的直接入口，接口定义与原生 Jedis-Client 无异；</li>\n  <li><strong>Hermes-SDK</strong>：自研“热点发现+本地缓存”功能的SDK封装， Jedis-Client 通过与它交互来集成相应能力；</li>\n  <li><strong>Hermes服务端集群</strong>：接收 Hermes-SDK 上报的缓存访问数据，进行热点探测，将热点 key 推送给 Hermes-SDK 做本地缓存；</li>\n  <li><strong>缓存集群</strong>：由代理层和存储层组成，为应用客户端提供统一的分布式缓存服务入口；</li>\n  <li><strong>基础组件</strong>： etcd 集群、 Apollo 配置中心，为 TMC 提供“集群推送”和“统一配置”能力；</li>\n </ul> \n <h5><a id=\"322__582\"></a>3-2-2. 基本流程</h5> \n <p>1） key 值获取</p> \n <ul>\n  <li>Java 应用调用 <strong>Jedis-Client</strong> 接口获取key的缓存值时，<strong>Jedis-Client</strong> 会询问 <strong>Hermes-SDK</strong> 该 key 当前是否是 <strong>热点key</strong>；</li>\n  <li>对于 <strong>热点key</strong> ，直接从 <strong>Hermes-SDK</strong> 的 <em>热点模块</em> 获取热点 key 在本地缓存的 value 值，不去访问 <strong>缓存集群</strong> ，从而将访问请求前置在应用层；</li>\n  <li>对于非 <strong>热点key</strong> ，<strong>Hermes-SDK</strong> 会通过<code>Callable</code>回调 <strong>Jedis-Client</strong> 的原生接口，从 <strong>缓存集群</strong> 拿到 value 值；</li>\n  <li>对于 <strong>Jedis-Client</strong> 的每次 key 值访问请求，<strong>Hermes-SDK</strong> 都会通过其 <em>通信模块</em> 将 <strong>key访问事件</strong> 异步上报给 <strong>Hermes服务端集群</strong> ，以便其根据上报数据进行“热点探测”；</li>\n </ul> \n <p>2）key值过期</p> \n <ul>\n  <li>Java 应用调用 <strong>Jedis-Client</strong> 的<code>set()</code> <code>del()</code> <code>expire()</code>接口时会导致对应 key 值失效，<strong>Jedis-Client</strong> 会同步调用 <strong>Hermes-SDK</strong> 的<code>invalid()</code>方法告知其“ key 值失效”事件；</li>\n  <li>对于 <strong>热点key</strong> ，<strong>Hermes-SDK</strong> 的 <em>热点模块</em> 会先将 key 在本地缓存的 value 值失效，以达到本地数据<strong>强一致</strong>。同时 <em>通信模块</em> 会异步将“ key 值失效”事件通过 <strong>etcd集群</strong> 推送给 Java 应用集群中其他 <strong>Hermes-SDK</strong> 节点；</li>\n  <li>其他<strong>Hermes-SDK</strong>节点的 <em>通信模块</em> 收到 “ key 值失效”事件后，会调用 <em>热点模块</em> 将 key 在本地缓存的 value 值失效，以达到集群数据<strong>最终一致</strong>；</li>\n </ul> \n <p>3）热点发现</p> \n <ul>\n  <li><strong>Hermes服务端集群</strong> 不断收集 <strong>Hermes-SDK</strong>上报的 <strong>key访问事件</strong>，对不同业务应用集群的缓存访问数据进行周期性（3s一次）分析计算，以探测业务应用集群中的<strong>热点key</strong>列表；</li>\n  <li>对于探测到的<strong>热点key</strong>列表，<strong>Hermes服务端集群</strong> 将其通过 <strong>etcd集群</strong> 推送给不同业务应用集群的 <strong>Hermes-SDK</strong> <em>通信模块</em>，通知其对<strong>热点key</strong>列表进行本地缓存；</li>\n </ul> \n <p>4）配置读取</p> \n <ul>\n  <li><strong>Hermes-SDK</strong> 在启动及运行过程中，会从 <strong>Apollo配置中心</strong> 读取其关心的配置信息（如：启动关闭配置、黑白名单配置、etcd地址…）；</li>\n  <li><strong>Hermes服务端集群</strong> 在启动及运行过程中，会从 <strong>Apollo配置中心</strong> 读取其关心的配置信息（如：业务应用列表、热点阈值配置、 etcd 地址…）；</li>\n </ul> \n <h5><a id=\"323__607\"></a>3-2-3. 稳定性</h5> \n <p>TMC本地缓存稳定性表现在以下方面：</p> \n <ul>\n  <li>数据上报异步化：<strong>Hermes-SDK</strong> 使用<code>rsyslog技术</code>对“ key 访问事件”进行异步化上报，不会阻塞业务；</li>\n  <li>通信模块线程隔离：<strong>Hermes-SDK</strong> 的 <em>通信模块</em> 使用独立线程池+有界队列，保证事件上报&amp;监听的I/O操作与业务执行线程隔离，即使出现非预期性异常也不会影响基本业务功能；</li>\n  <li>缓存管控：<strong>Hermes-SDK</strong> 的 <em>热点模块</em> 对本地缓存大小上限进行了管控，使其占用内存不超过 64MB（LRU），杜绝 JVM 堆内存溢出的可能；</li>\n </ul> \n <h4><a id=\"324__615\"></a>3-2-4. 一致性</h4> \n <p>TMC 本地缓存一致性表现在以下方面：</p> \n <ul>\n  <li><strong>Hermes-SDK</strong> 的 <em>热点模块</em> 仅缓存 <strong>热点key</strong> 数据，绝大多数非热点 key 数据由 <strong>缓存集群</strong> 存储；</li>\n  <li><strong>热点key</strong> 变更导致 value 失效时，<strong>Hermes-SDK</strong> 同步失效本地缓存，保证 <strong>本地强一致</strong>；</li>\n  <li><strong>热点key</strong> 变更导致 value 失效时，<strong>Hermes-SDK</strong> 通过 <strong>etcd集群</strong> 广播事件，异步失效业务应用集群中其他节点的本地缓存，保证 <strong>集群最终一致</strong>；</li>\n </ul> \n <h3><a id=\"TMC_623\"></a>四、TMC热点发现</h3> \n <h4><a id=\"41__625\"></a>4-1. 整体流程</h4> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/9314a40b5f685e0dcb229d04e95ba07a.png\" alt=\"图片描述\"></p> \n <p>TMC 热点发现流程分为四步：</p> \n <ul>\n  <li><strong>数据收集</strong>：收集 <strong>Hermes-SDK</strong> 上报的 <em>key访问事件</em>；</li>\n  <li><strong>热度滑窗</strong>：对 App 的每个 Key ，维护一个时间轮，记录基于当前时刻滑窗的访问热度；</li>\n  <li><strong>热度汇聚</strong>：对 App 的所有 Key ，以<code>&lt;key,热度&gt;</code>的形式进行 <em>热度排序汇总</em>；</li>\n  <li><strong>热点探测</strong>：对 App ，从 <em>热Key排序汇总</em> 结果中选出 <em>TopN的热点Key</em> ，推送给 <strong>Hermes-SDK</strong>；</li>\n </ul> \n <h4><a id=\"42__636\"></a>4-2. 数据收集</h4> \n <p><strong>Hermes-SDK</strong> 通过本地<code>rsyslog</code>将 <strong>key访问事件</strong> 以协议格式放入 <strong>kafka</strong> ，<strong>Hermes服务端集群</strong> 的每个节点消费 kafka 消息，实时获取 <strong>key访问事件</strong>。</p> \n <p>访问事件协议格式如下：</p> \n <ul>\n  <li>appName：集群节点所属业务应用</li>\n  <li>uniqueKey：业务应用 <em>key访问事件</em> 的 key</li>\n  <li>sendTime：业务应用 <em>key访问事件</em> 的发生时间</li>\n  <li>weight：业务应用 <em>key访问事件</em> 的访问权值</li>\n </ul> \n <p><strong>Hermes服务端集群</strong> 节点将收集到的 <strong>key访问事件</strong> 存储在本地内存中，</p> \n <p>内存数据结构为<code>Map&lt;String, Map&lt;String, LongAdder&gt;&gt;</code>，</p> \n <p>对应业务含义映射为<code>Map&lt; appName , Map&lt; uniqueKey , 热度 &gt;&gt;</code>。</p> \n <h4><a id=\"43__653\"></a>4-3. 热度滑窗</h4> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/13b85b1aa6e4c6a1cd015aa45f52f003.png\" alt=\"图片描述\"></p> \n <h5><a id=\"431__657\"></a>4-3-1. 时间滑窗</h5> \n <p><strong>Hermes服务端集群</strong> 节点，对每个App的每个 key ，维护了一个 <strong>时间轮</strong>：</p> \n <ul>\n  <li>时间轮中共10个 <strong>时间片</strong>，每个时间片记录当前 key 对应 3 秒时间周期的总访问次数；</li>\n  <li>时间轮10个时间片的记录累加即表示当前 key 从当前时间向前 30 秒时间窗口内的总访问次数；</li>\n </ul> \n <h5><a id=\"432__664\"></a>4-3-2. 映射任务</h5> \n <p><strong>Hermes服务端集群</strong> 节点，对每个 App <em>每3秒</em> 生成一个 <strong>映射任务</strong> ，交由节点内 <em>“缓存映射线程池”</em> 执行。</p> \n <p><strong>映射任务</strong> 内容如下：</p> \n <ul>\n  <li>对当前 App ，从<code>Map&lt; appName , Map&lt; uniqueKey , 热度 &gt;&gt;</code>中取出 <em>appName</em> 对应的Map <code>Map&lt; uniqueKey , 热度 &gt;&gt;</code>；</li>\n  <li>遍历<code>Map&lt; uniqueKey , 热度 &gt;&gt;</code>中的 key ，对每个 key 取出其热度存入其 <strong>时间轮</strong> 对应的时间片中；</li>\n </ul> \n <h4><a id=\"44__673\"></a>4-4. 热度汇聚</h4> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/c2f01e09eb99a84c64fc94ecef5c4735.jpeg\" alt=\"图片描述\"></p> \n <p>完成第二步“热度滑窗”后，<strong>映射任务</strong> 继续对当前 App 进行“热度汇聚”工作：</p> \n <ul>\n  <li>遍历 App 的 key ，将每个 key 的 <strong>时间轮</strong> 热度进行汇总（即30秒时间窗口内总热度）得到探测时刻 <strong>滑窗总热度</strong>；</li>\n  <li>将 <code>&lt; key , 滑窗总热度 &gt;</code> 以排序集合的方式存入 <em>Redis存储服务</em> 中，即 <strong>热度汇聚结果</strong>；</li>\n </ul> \n <h4><a id=\"45__682\"></a>4-5. 热点探测</h4> \n <ul>\n  <li>在前几步，<strong>每3秒</strong> 一次的 <strong>映射任务</strong> 执行，对每个 App 都会产生一份当前时刻的 <strong>热度汇聚结果</strong> ；</li>\n  <li><strong>Hermes服务端集群</strong> 中的“热点探测”节点，对每个 App ，只需周期性从其最近一份 <strong>热度汇聚结果</strong> 中取出达到热度阈值的 TopN 的 key 列表，即可得到本次探测的 <strong>热点key列表</strong>；</li>\n </ul> \n <p>TMC 热点发现整体流程如下图：<br> <img src=\"https://img-blog.csdnimg.cn/img_convert/862a9b09061181d3de724bb3e6864d35.png\" alt=\"图片描述\"></p> \n <h4><a id=\"46__690\"></a>4-6. 特性总结</h4> \n <h5><a id=\"461__692\"></a>4-6-1. 实时性</h5> \n <p><strong>Hermes-SDK</strong>基于rsyslog + kafka 实时上报 <strong>key访问事件</strong>。<br> <strong>映射任务</strong> 3秒一个周期完成“热度滑窗” + “热度汇聚”工作，当有 <strong>热点访问场景</strong> 出现时最长3秒即可探测出对应 <strong>热点key</strong>。</p> \n <h5><a id=\"462__697\"></a>4-6-2. 准确性</h5> \n <p>key 的<strong>热度汇聚结果</strong>由“基于时间轮实现的滑动窗口”汇聚得到，相对准确地反应当前及最近正在发生访问分布。</p> \n <h5><a id=\"463_701\"></a>4-6-3.扩展性</h5> \n <p><strong>Hermes服务端集群</strong> 节点无状态，节点数可基于 kafka 的 partition 数量横向扩展。</p> \n <p>“热度滑窗” + “热度汇聚” 过程基于 App 数量，在单节点内多线程扩展。</p> \n <h3><a id=\"TMC_707\"></a>五、TMC实战效果</h3> \n <h4><a id=\"51__709\"></a>5-1. 快手商家某次商品营销活动</h4> \n <p>有赞商家通过快手直播平台为某商品搞活动，造成该商品短时间内被集中访问产生访问热点，活动期间 TMC 记录的实际热点访问效果数据如下：</p> \n <p>5-1-1. 某核心应用的缓存请求&amp;命中率曲线图</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/bb1d2e284c3cdf73b7fb37f487a58189.png\" alt=\"图片描述\"></p> \n <ul>\n  <li>上图蓝线为应用集群调用<code>get()</code>方法访问缓存次数</li>\n  <li>上图绿线为获取缓存操作命中 TMC 本地缓存的次数</li>\n </ul> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/51ea19d068a1556ed2fb887b4c0738a0.png\" alt=\"图片描述\"></p> \n <ul>\n  <li>上图为本地缓存命中率曲线图</li>\n </ul> \n <p>可以看出活动期间缓存请求量及本地缓存命中量均有明显增长，本地缓存命中率达到近 80% （即应用集群中 80% 的缓存查询请求被 TMC 本地缓存拦截）。</p> \n <h4><a id=\"512__726\"></a>5-1-2. 热点缓存对应用访问的加速效果</h4> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/c78797dde51d8c0cc5ceb567fb5134da.png\" alt=\"图片描述\"></p> \n <ul>\n  <li>上图为应用接口QPS曲线</li>\n </ul> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/0990c08e079651b86f46c1e1d5833933.png\" alt=\"图片描述\"></p> \n <ul>\n  <li>上图为应用接口RT曲线</li>\n </ul> \n <p>可以看出活动期间应用接口的请求量有明显增长，由于 TMC 本地缓存的效果应用接口的 RT 反而出现下降。</p> \n <h4><a id=\"52__TMC__738\"></a>5-2. 双十一期间部分应用 TMC 效果展示</h4> \n <h5><a id=\"521__740\"></a>5-2-1. 商品域核心应用效果</h5> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/df6a1b7c354a45b65cf5c3e517f5df04.png\" alt=\"图片描述\"></p> \n <h5><a id=\"522__744\"></a>5-2-2. 活动域核心应用效果</h5> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/2d35f592b31b258660a9537a6d094965.png\" alt=\"图片描述\"><br> <img src=\"https://img-blog.csdnimg.cn/img_convert/04b5dd68b1a0661cd7e9aad1887ee540.png\" alt=\"图片描述\"></p> \n <h3><a id=\"TMC_751\"></a>六、TMC功能展望</h3> \n <p>在有赞， TMC 目前已为商品中心、物流中心、库存中心、营销活动、用户中心、网关&amp;消息等多个核心应用模块提供服务，后续应用也在陆续接入中。</p> \n <p>TMC 在提供“热点探测” + “本地缓存”的核心能力同时，也为应用服务提供了灵活的配置选择，应用服务可以结合实际业务情况在“热点阈值”、“热点key探测数量”、“热点黑白名单”维度进行自由配置以达到更好的使用效果。</p> \n <p>配合三级缓存的使用，需要进行 热key的 探测，有赞平台通过 热key的探测和 支持，</p> \n <p><strong>其中：活动期间，本地缓存命中率达到近 80%的命中率</strong>， 并且， 响应时间，和平峰时段，没有变化。</p> \n <h2><a id=\"HotKey3__hotkey_769\"></a>HotKey探测方案3： 结合开源hotkey，做热点探测</h2> \n <p>基于开源hotkey进行 热点探测，有很多小伙伴，在生产系统进行了 缓存系统的重构</p> \n <p>下面将重构前与重构后做下对照，来说明这套机制的优缺点。</p> \n <table>\n  <thead>\n   <tr>\n    <th>特性</th>\n    <th>重构系统前</th>\n    <th>使用京东hotkey重构系统后</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>机器资源</td>\n    <td>高配物理机/虚拟机</td>\n    <td>普通物理机/虚拟机/容器</td>\n   </tr>\n   <tr>\n    <td>管控复杂</td>\n    <td>无法控制热点，不易监控</td>\n    <td>热点数据可以监控统计，可以手动刷新</td>\n   </tr>\n   <tr>\n    <td>资源利用率</td>\n    <td>资源利用率低，无论是否是热点数据都占用资源</td>\n    <td>资源利用率高，大部分热点数据持有资源</td>\n   </tr>\n   <tr>\n    <td>突发流量</td>\n    <td>无法弹性应对突发流量</td>\n    <td>弹性应对突发流量</td>\n   </tr>\n   <tr>\n    <td>预发流量</td>\n    <td>预设所有数据</td>\n    <td>只提前预设热点数据</td>\n   </tr>\n   <tr>\n    <td>数据一致性</td>\n    <td>集群内数据不一致情况时常发生，出现“横跳”现象</td>\n    <td>集群内数据一致性高，极少或不发生不一致性情况</td>\n   </tr>\n  </tbody>\n </table> \n <p>以上内容的视频介绍，将在 《第26章 百万qps 三级缓存 组件实操》 中 详细介绍。</p> \n <h2><a id=\"10W__792\"></a>假设10W人同时访问，如何保证不 雪崩？</h2> \n <ul>\n  <li> <p>扩容</p> </li>\n  <li> <p>限流</p> </li>\n  <li> <p>三级缓存</p> </li>\n </ul> \n <p>三级缓存 强烈推荐进行 热点探测 相结合， 主要的优势是：</p> \n <ul>\n  <li> <p>通过热点探测，既能提升 本地缓存命中率，</p> </li>\n  <li> <p>除此之外，还能识别 刷子用户， 把刷子用户加入 黑名单， 并且利用 bloom 过滤器进行缓存。 从而提升系统的安全性。</p> </li>\n </ul> \n <p>以上内容的视频介绍，将在 《第26章 百万qps 三级缓存 组件实操》 中 详细介绍。</p> \n <h2><a id=\"_816\"></a>参考文献</h2> \n <ol>\n  <li> <p><a href=\"https://www.cnblogs.com/crazymakercircle/p/9904544.html\">疯狂创客圈 JAVA 高并发 总目录</a></p> <p><a href=\"https://www.cnblogs.com/crazymakercircle/p/14491965.html\">ThreadLocal 史上最全</a></p> </li>\n  <li> <p><a href=\"https://www.cnblogs.com/crazymakercircle/p/13917138.html\">4000页《尼恩 Java 面试宝典 》的 35个面试专题</a></p> </li>\n  <li> <p><a href=\"https://www.processon.com/view/link/60fb9421637689719d246739\">价值10W的架构师知识图谱</a></p> </li>\n </ol> \n <p>4、<a href=\"https://www.processon.com/view/link/616f801963768961e9d9aec8\">尼恩 架构师哲学</a></p> \n <p>5、<a href=\"https://www.processon.com/view/link/635097d2e0b34d40be778ab4\">尼恩 3高架构知识宇宙</a></p> \n <p>https://segmentfault.com/a/1190000017142556</p> \n <p>https://gitee.com/jd-platform-opensource/hotkey</p> \n <h2><a id=\"_838\"></a>推荐阅读：</h2> \n <ul>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124790425\">尼恩Java面试宝典</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057567\">Springcloud gateway 底层原理、核心实战 (史上最全)</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124120506\">Flux、Mono、Reactor 实战（史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125059491\">sentinel （史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057545\">Nacos (史上最全)</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/123420859\">分库分表 Sharding-JDBC 底层原理、核心实战（史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/114527369\">TCP协议详解 (史上最全)</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126992542\">clickhouse 超底层原理 + 高可用实操 （史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120702536\">nacos高可用（图解+秒懂+史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264803\">队列之王： Disruptor 原理、架构、源码 一文穿透</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264508\">环形队列、 条带环形队列 Striped-RingBuffer （史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125135726\">一文搞定：SpringBoot、SLF4j、Log4j、Logback、Netty之间混乱关系（史上最全）</a></p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128265067\">单例模式（史上最全）</a></p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125017316\">红黑树（ 图解 + 秒懂 + 史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/109459593\">分布式事务 （秒懂）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128123114\">缓存之王：Caffeine 源码、架构、原理（史上最全，10W字 超级长文）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/113751575\">缓存之王：Caffeine 的使用（史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126579528\">Java Agent 探针、字节码增强 ByteBuddy（史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120747767\">Docker原理（图解+秒懂+史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/116425814\">Redis分布式锁（图解 - 秒懂 - 史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85956246\">Zookeeper 分布式锁 - 图解 - 秒懂</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85922561\">Zookeeper Curator 事件监听 - 10分钟看懂</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83957259\">Netty 粘包 拆包 | 史上最全解读</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83758107\">Netty 100万级高并发服务器配置</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/102557988\">Springcloud 高并发 配置 （一文全懂）</a>》</p> </li>\n </ul> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 15669);
INSERT INTO `crawlerblog` VALUES (123124034, '2个大厂 100亿级 超大流量 红包 架构方案', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <h2><a id=\"2_100____0\"></a>2个大厂 100亿级 超大流量 红包 架构方案</h2> \n <p></p> \n <div class=\"toc\"> \n  <h3>文章目录</h3> \n  <ul>\n   <li>\n    <ul>\n     <li><a href=\"#2_100____0\">2个大厂 100亿级 超大流量 红包 架构方案</a></li>\n     <li><a href=\"#100_____2\">100亿级 红包 应用 场景</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#_3\">概述</a></li>\n      </ul> </li>\n     <li><a href=\"#__21\">百亿级 微信红包技术架构</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#_29\">架构</a></li>\n       <li>\n        <ul>\n         <li><a href=\"#_39\">**南北分布**</a></li>\n         <li><a href=\"#_81\">**拆红包入账异步化**</a></li>\n         <li><a href=\"#cache_105\">**发拆落地，其他操作双层cache**</a></li>\n        </ul> </li>\n       <li><a href=\"#_121\">高并发</a></li>\n       <li>\n        <ul>\n         <li><a href=\"#_191\">**红包算法**</a></li>\n         <li><a href=\"#_207\">**柔性降级方案**</a></li>\n        </ul> </li>\n      </ul> </li>\n     <li><a href=\"#360w_QPS__100___253\">360w QPS 100亿级 字节红包 体系架构</a></li>\n     <li>\n      <ul>\n       <li><a href=\"#1__255\">1. 背景&amp;挑战&amp;目标</a></li>\n       <li>\n        <ul>\n         <li><a href=\"#11__257\">1.1 业务背景</a></li>\n         <li><a href=\"#12__271\">1.2 核心挑战</a></li>\n         <li><a href=\"#13__279\">1.3 最终目标</a></li>\n        </ul> </li>\n       <li><a href=\"#2__291\">2. 产品需求介绍</a></li>\n       <li><a href=\"#3__312\">3. 钱包资产中台设计与实现</a></li>\n       <li>\n        <ul>\n         <li><a href=\"#31__326\">3.1 春节资产资产中台总体架构图如下：</a></li>\n         <li><a href=\"#32__348\">3.2 资产订单中心设计</a></li>\n        </ul> </li>\n       <li><a href=\"#4___389\">4. 核心难点问题解决</a></li>\n       <li>\n        <ul>\n         <li><a href=\"#41__391\">4.1 难点一：支持八端奖励数据互通</a></li>\n         <li><a href=\"#42__408\">4.2 难点二：高场景下的奖励入账实现</a></li>\n         <li>\n          <ul>\n           <li><a href=\"#421__token__443\">4.2.1 红包雨 token 方案：</a></li>\n          </ul> </li>\n         <li><a href=\"#43__504\">4.3 难点三：发奖励链路依赖多的稳定性保障</a></li>\n         <li><a href=\"#44__536\">4.4 难点四：大流量发卡券预算控制</a></li>\n         <li><a href=\"#45__QPS__key__558\">4.5 难点五：高 QPS 场景下的热 key 的读取和写入稳定性保障</a></li>\n         <li>\n          <ul>\n           <li><a href=\"#451__568\">4.5.1 方案一</a></li>\n           <li><a href=\"#452__598\">4.5.2 方案二</a></li>\n           <li><a href=\"#453__654\">4.5.3 方案对比</a></li>\n          </ul> </li>\n         <li><a href=\"#46__665\">4.6 难点六：大流量场景下资金安全保障</a></li>\n        </ul> </li>\n       <li><a href=\"#5__688\">5. 通用模式抽象</a></li>\n       <li>\n        <ul>\n         <li><a href=\"#51__692\">5.1 容灾降级层面</a></li>\n         <li>\n          <ul>\n           <li><a href=\"#511__698\">5.1.1 限流层面</a></li>\n           <li><a href=\"#512__724\">5.1.2 降级层面</a></li>\n           <li><a href=\"#513__732\">5.1.3 资源隔离层面</a></li>\n           <li><a href=\"#514__742\">5.1.4 存储预估</a></li>\n           <li><a href=\"#515__752\">5.1.5 压测层面</a></li>\n          </ul> </li>\n         <li><a href=\"#52__768\">5.2 微服务思考</a></li>\n        </ul> </li>\n       <li><a href=\"#6__776\">6. 系统的未来演进方向</a></li>\n      </ul> </li>\n     <li><a href=\"#_790\">推荐阅读：</a></li>\n    </ul> </li>\n  </ul> \n </div> \n <p></p> \n <h2><a id=\"100_____2\"></a>100亿级 红包 应用 场景</h2> \n <h3><a id=\"_3\"></a>概述</h3> \n <p>话说每逢双十一节或春节等节假日，对大家来讲是最欢乐的日子，可以在微信群中收发红包，此外今年微信还推出了面对面红包，让大家拜年时可直接收发，对于用户来讲很爽也很方便。但对于技术架构侧的考量，这使得微信红包的收发数据成几何倍数上升，处理的复杂度也增加了很多。</p> \n <p>2017年微信红包发送量最大的时间段是除夕夜，达到了142亿个。</p> \n <p>如此大规模、高并发、高峰值的业务场景，怕是在美帝互联网的技术团队，包括EBay、Amazon等也无法想象，在这种巨大的流量与并发后面，需要什么样级别的技术架构支撑？</p> \n <p>当达百亿级别的资金交易规模时，我们该怎样来保证系统的并发性能和交易安全？</p> \n <p>当今中国的互联网平台，有两个场景称得上亿级以上的并发量：</p> \n <p>一个是微信的红包，</p> \n <p>一个是字节的红包，</p> \n <p>都是在一个单位时间达到亿万以以上的请求负载。</p> \n <h2><a id=\"__21\"></a>百亿级 微信红包技术架构</h2> \n <blockquote> \n  <p>与传统意义上的红包相比，近两年火起来的“红包”，似乎才是如今春节的一大重头戏。历经上千年时代传承与变迁，春节发红包早已成为历史沉淀的文化习俗，融入了民族的血脉。按照各家公布的数据，除夕全天微信用户红包总发送量达到80.8亿个，红包峰值收发量为40.9万个/秒。春晚直播期间讨论春晚的微博达到5191万条，网友互动量达到1.15亿，网友抢微博红包的总次数超过8亿次。</p> \n </blockquote> \n <p>微信红包在经过15年春晚摇一摇之后，2015年上半年业务量一度呈指数级增长。尤其是微信红包活跃用户数的大量增长，使得2016除夕跨年红包成为极大挑战。为了应对16年春节可预知的红包海量业务，红包系统在架构上进行了一系列调整和优化。主要包括异地架构、cache系统优化、拆红包并发策略优化、存储优化一系列措施，为迎接2016春节红包挑战做好准备。 下面介绍最主要的一些思路。</p> \n <h3><a id=\"_29\"></a>架构</h3> \n <p>微信用户在国内有深圳、上海两个接入点，习惯性称之为南、北（即深圳为南，上海为北）。用户请求接入后，不同业务根据业务特性选择部署方式。微信红包在信息流上可以分为订单纬度与用户纬度。</p> \n <p>其中订单是贯穿红包发、抢、拆、详情列表等业务的关键信息，属于交易类信息；而用户纬度指的是红包用户的收红包列表、发红包列表，属于展示类信息。红包系统在架构上，有以下几个方面：</p> \n <h4><a id=\"_39\"></a><strong>南北分布</strong></h4> \n <p>1、订单层南北独立体系，数据不同步</p> \n <p>用户就近接入，请求发红包时分配订单南北，并在单号打上南北标识。抢红包、拆红包、查红包详情列表时，接入层根据红包单号上的南北标识将流量分别引到南北系统闭环。根据发红包用户和抢红包用户的所属地不同，有以下四种情况：</p> \n <p>1）深圳用户发红包，深圳用户抢</p> \n <p>订单落在深圳，深圳用户抢红包时不需要跨城，在深圳完成闭环。</p> \n <p>2）深圳用户发红包，上海用户抢</p> \n <p>订单落在深圳，上海用户抢红包，在上海接入后通过专线跨城到深圳，最后在深圳闭环完成抢红包。</p> \n <p>3）上海用户发红包，上海用户抢</p> \n <p>订单落在上海，上海用户抢红包时不需要跨城，在上海完成闭环。</p> \n <p>4）上海用户发红包，深圳用户抢</p> \n <p>订单落在上海，深圳用户抢红包，从深圳接入后通过专线跨城到上海，最后在上海闭环完成抢红包。</p> \n <p>系统这样设计，好处是南北系统分摊流量，降低系统风险。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/d4a234477da446b29aec4e1fd89f272e.png\" alt=\"\"></p> \n <p>2、用户数据写多读少，全量存深圳，异步队列写入，查时一边跨城</p> \n <p>用户数据的查询入口，在微信钱包中，隐藏的很深。这决定了用户数据的访问量不会太大，而且也被视为可旁路的非关键信息，实时性要求不高。因此，只需要在发红包、拆红包时，从订单纬度拆分出用户数据写入请求，由MQ异步写入深圳。后台将订单与用户进行定时对账保证数据完整性即可。</p> \n <p>3、支持南北流量灵活调控</p> \n <p>红包系统南北分布后，订单落地到深圳还是上海，是可以灵活分配的，只需要在接入层上做逻辑。例如，可以在接入层中，实现让所有红包请求，都落地到深圳（无论用户从上海接入，还是深圳接入），这样上海的红包业务系统将不会有请求量。提升了红包系统的容灾能力。同时，实现了接入层上的后台管理系统，实现了秒级容量调控能力。可根据南北请求量的实时监控，做出对应的调配。</p> \n <p>4、DB故障时流量转移能力 基于南北流量的调控能力，当发现DB故障时，可将红包业务流量调到另外一边，实现DB故障的容灾。</p> \n <p>预订单</p> \n <p>支付前订单落cache，同时利用cache的原子incr操作顺序生成红包订单号。优点是cache的轻量操作，以及减少DB废单。在用户请求发红包与真正支付之间，存在一定的转化率，部分用户请求发红包后，并不会真正去付款。</p> \n <h4><a id=\"_81\"></a><strong>拆红包入账异步化</strong></h4> \n <p>信息流与资金流分离。</p> \n <p>拆红包时，DB中记下拆红包凭证，然后异步队列请求入账。</p> \n <p>入账失败通过补偿队列补偿，最终通过红包凭证与用户账户入账流水对账，保证最终一致性。如下图所示：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/983c9680875c4e3a9ce172c261565285.png\" alt=\"\"></p> \n <p>这个架构设计，理论基础是快慢分离。</p> \n <p>红包的入账是一个分布事务，属于慢接口。</p> \n <p>而拆红包凭证落地则速度快。</p> \n <p>实际应用场景中，用户抢完红包，只关心详情列表中谁是“最佳手气”，很少关心抢到的零是否已经到账。</p> \n <p>因为只需要展示用户的拆红包凭证即可。</p> \n <h4><a id=\"cache_105\"></a><strong>发拆落地，其他操作双层cache</strong></h4> \n <p>1、Cache住所有查询，两层cache</p> \n <p>除了使用ckv做全量缓存，还在数据访问层dao中增加本机内存cache做二级缓存，cache住所有读请求。</p> \n <p>查询失败或者查询不存在时，降级内存cache；内存cache查询失败或记录不存在时降级DB。</p> \n <p><strong>DB本身不做读写分离。</strong></p> \n <p>2、DB写同步cache，容忍少量不一致， DB写操作完成后，dao中同步内存cache，业务服务层同步ckv，失败由异步队列补偿，</p> \n <p>定时的ckv与DB备机对账，保证最终数据一致。</p> \n <h3><a id=\"_121\"></a>高并发</h3> \n <p>微信红包的并发挑战，主要在于微信大群，多人同时抢同一个红包。</p> \n <p>以上这种情况，存在竞争MySQL行锁。为了控制这种并发，团队做了以下一些事情：</p> \n <p><strong>1、请求按红包订单路由，逻辑块垂直sticky，事务隔离</strong></p> \n <p>按红包订单划分逻辑单元，单元内业务闭环。服务rpc调用时，使用红包订单号的hash值为key寻找下一跳地址。对同一个红包的所有拆请求、查询请求，都路由到同一台逻辑机器、同一台DB中处理。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/78c0bc00c06c4b8ba86372887f657de2.png\" alt=\"\"></p> \n <p><strong>2、Dao搭建本机Memcache内存cache，控制同一红包并发个数</strong></p> \n <p>在DB的接入机dao中，搭建本机内存cache。以红包订单号为key，对同一个红包的拆请求做原子计数，控制同一时刻能进DB中拆红包的并发请求数。</p> \n <p>这个策略的实施，依赖于请求路由按红包订单hash值走，确保同一红包的所有请求路由到同一逻辑层机器。</p> \n <p><strong>3、多层级并发量控制</strong></p> \n <p>1）发红包控制</p> \n <p>发红包是业务流程的入口，控制了这里的并发量，代表着控制了红包业务整体的并发量。在发红包的业务链路里，做了多层的流量控制，确保产生的有效红包量级在可控范围。</p> \n <p>2）抢红包控制</p> \n <p>微信红包领取时分为两个步骤，抢和拆。</p> \n <p>抢红包这个动作本身就有控制拆并发的作用。因为抢红包时，只需要查cache中的数据，不需要请求DB。</p> \n <p>对于红包已经领完、用户已经领过、红包已经过期等流量可以直接拦截。而对于有资格进入拆红包的请求量，也做流量控制。通过这些处理，最后可进入拆环节的流量大大减少，并且都是有效请求。</p> \n <p>3）拆时内存cache控制</p> \n <p>针对同一个红包并发拆的控制，上面的文章已介绍。</p> \n <p><strong>4、DB简化和拆分</strong></p> \n <p>DB的并发能力，有很多影响因素。红包系统结合红包使用情境，进行了一些优化。比较有借鉴意义的，主要有以下两点：</p> \n <p>1）订单表只存关键字段，其他字段只在cache中存储，可柔性。</p> \n <p>红包详情的展示中，除了订单关键信息（用户、单号、金额、时间、状态）外，还有用户头像、昵称、祝福语等字段。这些字段对交易来说不是关键信息，却占据大量的存储空间。</p> \n <p>将这些非关键信息拆出来，只存在cache，用户查询展示，而订单中不落地。</p> \n <p>这样可以维持订单的轻量高效，同时cache不命中时，又可从实时接口中查询补偿，达到优化订单DB容量的效果。</p> \n <p>2）DB双重纬度分库表，冷热分离</p> \n <p>使用订单hash、订单日期，两个纬度分库表，也即db_xxx.t_x_dd这样的格式。</p> \n <p>其中，x表示订单hash值，dd表示01-31循环日。</p> \n <p>订单hash纬度，是为了将订单打散到不同的DB服务器中，均衡压力。</p> \n <p>订单日期循环日纬度，是为了避免单表数据无限扩张，使每天都是一张空表。</p> \n <p>另外，红包的订单访问热度，是非常典型的冷热型。</p> \n <p>热数据集中在一两天内，且随时间急剧消减。</p> \n <p>线上热数据库只需要存几天的数据，其他数据可以定时移到成本低的冷数据库中。</p> \n <p>循环日表也使得历史数据的迁移变得方便。</p> \n <h4><a id=\"_191\"></a><strong>红包算法</strong></h4> \n <p>首先，如果红包只有一个，本轮直接使用全部金额，确保红包发完。</p> \n <p>然后，计算出本轮红包最少要领取多少，才能保证红包领完，即本轮下水位；轮最多领取多少，才能保证每个人都领到，即本轮上水位。主要方式如下：</p> \n <p>计算本轮红包金额下水位：假设本轮领到最小值1分，那接下来每次都领到200元红包能领完，那下水位为1分；如果不能领完，那按接下来每次都领200元，剩下的本轮应全部领走，是本轮的下水位。</p> \n <p>计算本轮红包上水位：假设本轮领200元，剩下的钱还足够接下来每轮领1分钱，那本轮上水位为200元；如果已经不够领，那按接下来每轮领1分，计算本轮的上水位。</p> \n <p>为了使红包金额不要太悬殊，使用红包均值调整上水位。如果上水位金额大于两倍红包均值，那么使用两倍红包均值作为上水位。换句话说，每一轮抢到的红包金额，最高为两倍剩下红包的均值。</p> \n <p>最后，获取随机数并用上水位取余，如果结果比下水位还小，则直接使用下水位，否则使用随机金额为本轮拆到金额。</p> \n <h4><a id=\"_207\"></a><strong>柔性降级方案</strong></h4> \n <p>系统到处存在发生异常的可能，需要对所有的环节做好应对的预案。</p> \n <p>下面列举微信红包对系统异常的主要降级考虑。</p> \n <p>1、 下单cache故障降级DB</p> \n <p>下单cache有两个作用，生成红包订单与订单缓存。</p> \n <p>缓存故障情况下，降级为直接落地DB，并使用id生成器独立生成订单号。</p> \n <p>2、 抢时cache故障降级DB</p> \n <p>抢红包时，查询cache，拦截红包已经抢完、用户已经抢过、红包已经过期等无效请求。当cache故障时，降级DB查询，同时打开DB限流保护开关，防止DB压力过大导致服务不可用。</p> \n <p>另外，cache故障降级DB时，DB不存储用户头像、用户昵称等（上文提到的优化），此时一并降级为实时接口查询。查询失败，继续降级为展示默认头像与昵称。</p> \n <p>3、 拆时资金入账多级柔性</p> \n <p>拆红包时，DB记录拆红包单据，然后执行资金转账。单据需要实时落地，而资金转账，这里做了多个层级的柔性降级方案：</p> \n <p>大额红包实时转账，小额红包入队列异步转账 所有红包进队列异步转账 实时流程不执行转账，事后凭单据批量入账。</p> \n <p>总之，单据落地后，真实入账可实时、可异步，最终保证一致即可。</p> \n <p>4、 用户列表降级</p> \n <p>用户列表数据在微信红包系统中，属于非关键路径信息，属于可被降级部分。</p> \n <p>首先，写入时通过MQ异步写，通过定时对账保证一致性。</p> \n <p>其次，cache中只缓存两屏，用户查询超过两屏则查用户列表DB。在系统压力大的情况下，可以限制用户只查两屏。</p> \n <p>调整后的系统经过了2016年春节的实践检验，平稳地度过了除夕业务高峰，保障了红包用户的体验。</p> \n <blockquote> \n  <p>上文参考来源：架构说公众号，作者：方乐明</p> \n  <p>方乐明，2011年毕业于华南理工大学通信与信息系统专业，毕业后就职于财付通科技有限公司。微信支付团队组建后，主要负责微信红包、微信转账、AA收款等支付应用产品的后台架构。</p> \n </blockquote> \n <h2><a id=\"360w_QPS__100___253\"></a>360w QPS 100亿级 字节红包 体系架构</h2> \n <h3><a id=\"1__255\"></a>1. 背景&amp;挑战&amp;目标</h3> \n <h4><a id=\"11__257\"></a>1.1 业务背景</h4> \n <p>（1）<strong>支持八端</strong>：</p> \n <p>2022 年字节系产品春节活动需要支持八端 APP 产品（包含抖音/抖音火山/抖音极速版/西瓜/头条/头条极速版/番茄小说/番茄畅听）的奖励互通。用户在上述任意一端都可以参与活动，得到的奖励在其他端都可以提现与使用。</p> \n <p>（2）<strong>玩法多变</strong>：</p> \n <p>主要有集卡、朋友页红包雨、红包雨、集卡开奖与烟火大会等。</p> \n <p>（3）<strong>多种奖励</strong>：</p> \n <p>奖励类型包含现金红包、补贴视频红包、商业化广告券、电商券、支付券、消费金融券、保险券、信用卡优惠券、喜茶券、电影票券、dou+券、抖音文创券、头像挂件等。</p> \n <h4><a id=\"12__271\"></a>1.2 核心挑战</h4> \n <p>（1）超高吞吐，超大并发，最高预估 360w QPS 发奖。</p> \n <p>（2）奖励类型多，共 10 余种奖励。多种发奖励的场景，玩法多变；</p> \n <p>（3）从奖励系统稳定性、用户体验、资金安全与运营基础能力全方位保障，确保活动顺利进行 。</p> \n <h4><a id=\"13__279\"></a>1.3 最终目标</h4> \n <p>（1）<strong>奖励入账</strong>：数据高可靠。提供统一的错误处理机制，入账幂等能力和奖励预算控制。</p> \n <p>（2）**奖励展示/使用：**支持用户查看、提现（现金），使用卡券/挂件等能力。</p> \n <p>（3）<strong>稳定性保障</strong>：在大流量的入账场景下，保证钱包核心路径稳定性与完善，通过常用稳定性保障手段如资源扩容、限流、熔断、降级、兜底、资源隔离等方式保证用户奖励方向的核心体验。</p> \n <p>（4）<strong>资金安全</strong>：通过幂等、对账、监控与报警等机制，保证资金安全，保证用户资产应发尽发，不少发。</p> \n <p>（5）<strong>活动隔离</strong>：实现内部测试、灰度放量和正式春节活动三个阶段的奖励入账与展示的数据隔离，不互相影响。</p> \n <h3><a id=\"2__291\"></a>2. 产品需求介绍</h3> \n <p>用户可以在任意一端参与字节的春节活动获取奖励，以抖音红包雨现金红包入账场景为例，具体的业务流程如下：</p> \n <p>登录抖音 → 参与活动 → 活动钱包页 → 点击提现按钮 → 进入提现页面 → 进行提现 → 提现结果页，</p> \n <p>另外从钱包页也可以进入活动钱包页。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/4d3df05e8e8dac360c03e20d36601d29.png\" alt=\"\"></p> \n <p>奖励发放核心场景：</p> \n <ol>\n  <li><strong>集卡</strong>：集卡抽卡时发放各类卡券，集卡锦鲤还会发放大额现金红包，集卡开奖时发放瓜分奖金和优惠券；</li>\n  <li><strong>红包雨</strong>：发红包、卡券以及视频补贴红包，其中红包和卡券最高分别 180w QPS；</li>\n </ol> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/dd6af98d51f5db710872248ae51a30e4.png\" alt=\"\"></p> \n <h3><a id=\"3__312\"></a>3. 钱包资产中台设计与实现</h3> \n <p>在 2022 年春节活动中，业务方分为：</p> \n <p>UG、激励中台、视频红包、钱包方向、资产中台等</p> \n <p>其中，UG 主要负责活动的玩法实现，包含集卡、红包雨以及烟火大会等具体的活动相关业务逻辑和稳定性保障。</p> \n <p>而钱包方向定位是大流量场景下实现奖励入账、奖励展示、奖励使用与资金安全保障的相关任务。</p> \n <p>其中资产中台负责<strong>奖励发放与奖励展示</strong>部分。</p> \n <h4><a id=\"31__326\"></a>3.1 春节资产资产中台总体架构图如下：</h4> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/768d79e164975d1794d875abaf74b627.png\" alt=\"\"></p> \n <p>钱包资产中台核心系统划分如下：</p> \n <ol>\n  <li> <p><strong>资产订单层</strong>：</p> <p>收敛八端奖励入账链路，</p> <p>提供统一的接口协议，对接上游活动业务方的奖励发放功能，</p> <p>同时，支持预算控制、补偿、订单号幂等。</p> </li>\n  <li> <p><strong>活动钱包 api 层</strong>：</p> <p>统一奖励展示链路，同时支持大流量场景</p> </li>\n </ol> \n <h4><a id=\"32__348\"></a>3.2 资产订单中心设计</h4> \n <p><strong>核心发放模型：</strong></p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/37c250c4a4b5e91b0dc4ce1e236ae00f.png\" alt=\"\"></p> \n <p><strong>说明：</strong></p> \n <p>活动 ID 唯一区分一个活动，</p> \n <p>本次春节分配了一个单独的母活动 ID</p> \n <p>场景 ID 和具体的一种奖励类型一一对应，</p> \n <p>定义该场景下发奖励的唯一配置，</p> \n <p>场景 ID 可以配置的能力有：</p> \n <ul>\n  <li>发奖励账单文案；</li>\n  <li>是否需要补偿；</li>\n  <li>限流配置；</li>\n  <li>是否进行库存控制；</li>\n  <li>是否要进行对账。</li>\n  <li>提供可插拔的能力，供业务可选接入。</li>\n </ul> \n <p><strong>订单号设计：</strong></p> \n <p>资产订单层支持订单号维度的发奖幂等，订单号设计逻辑为</p> \n <p><code>${actID}_${scene_id}_${rain_id}_${award_type}_${statge}</code></p> \n <p>从单号设计层面保证不超发，每个场景的奖励用户最多只领一次。</p> \n <h3><a id=\"4___389\"></a>4. 核心难点问题解决</h3> \n <h4><a id=\"41__391\"></a>4.1 难点一：支持八端奖励数据互通</h4> \n <p>有八个产品端，需要统一对接，</p> \n <p>其中抖音系和头条系 APP 是不同的账号体系，所以不能通过用户 ID 打通奖励互通。</p> \n <p>具体解决方案是：</p> \n <ul>\n  <li>给每个用户生成唯一的 actID</li>\n  <li>手机号优先级最高，如果不同端登录的手机号一样，在不同端的 actID 是一致的。</li>\n </ul> \n <p>在唯一 actID 基础上，每个用户的奖励数据是绑定在 actID 上的，入账和查询是通过 actID 维度实现的，即可实现八端奖励互通。</p> \n <p>示意图如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/d5e9bb782bba0c3e5fd950a64664d2c6.png\" alt=\"\"></p> \n <h4><a id=\"42__408\"></a>4.2 难点二：高场景下的奖励入账实现</h4> \n <p>超高并发场景，发现金红包都是最关键的一环。有几个原因如下：</p> \n <ol>\n  <li>预估发现金红包最大流量有 180w TPS。</li>\n  <li>现金红包本身价值高，需要保证资金安全。</li>\n  <li>用户对现金的敏感度很高，在保证用户体验与功能完整性同时也要考虑成本问题。</li>\n </ol> \n <p>终上所述，<strong>发现金红包面临比较大的技术挑战。</strong></p> \n <p>发红包其实是一种交易行为，资金流走向是从公司成本出然后进入个人账户。</p> \n <p>（1）从技术方案上是要支持订单号维度的幂等，同一订单号多次请求只入账一次。订单号生成逻辑为</p> \n <p><code>${actID}_${scene_id}_${rain_id}_${award_type}_${statge}</code></p> \n <p>从单号设计层面保证不超发。</p> \n <p>（2）支持高并发，有以下 2 个传统方案：</p> \n <table>\n  <thead>\n   <tr>\n    <th>具体方案类型</th>\n    <th>实现思路</th>\n    <th>优点</th>\n    <th>缺点</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>同步入账</td>\n    <td>申请和预估流量相同的计算和存储资源</td>\n    <td>1.开发简单； 2.不容易出错；</td>\n    <td><strong>浪费存储成本。</strong> 拿账户数据库举例，经实际压测结果：支持 30w 发红包需要 152 个数据库实例，如果支持 180w 发红包，至少需要 1152 个数据库实例，还没有算上 tce 和 redis 等其他计算和存储资源。</td>\n   </tr>\n   <tr>\n    <td>异步入账</td>\n    <td>申请部分计算和存储资源资源，实际入账能力与预估有一定差值</td>\n    <td>1.开发简单； 2.不容易出错； 3.不浪费资源；</td>\n    <td><strong>用户体验受到很大影响。</strong> 入账延迟较大，以今年活动举例会有十几分钟延迟。用户参与玩法得到奖励后在活动钱包页看不到奖励，也无法进行提现，会有大量客诉，影响抖音活动的效果。</td>\n   </tr>\n  </tbody>\n </table> \n <p>以上两种传统意义上的技术方案都有明显的缺点，</p> \n <p>那么进行思考，既能相对节约资源又能保证用户体验的方案是什么？</p> \n <p>最终采用的是红包雨 token 方案，具体方案是：</p> \n <p><strong>使用异步入账加较少量分布式存储和较复杂方案来实现，</strong></p> \n <p>下面具体介绍一下。</p> \n <h5><a id=\"421__token__443\"></a>4.2.1 红包雨 token 方案：</h5> \n <p><strong>根据预估发放红包估算</strong>，红包雨 token 方案, 计算实际入账最低要支持的 TPS 为 30w，所以实际发放中有压单的过程。</p> \n <p><strong>设计目标：</strong></p> \n <p>在活动预估给用户发放（180w）与实际入账（30w）有很大 gap 的情况下，保证用户的核心体验。</p> \n <p>用户在前端页面查看与使用过当中不能感知压单的过程，即查看与使用体验不能受到影响，相关展示的数据包含余额，累计收入与红包流水，使用包含提现等。</p> \n <p><strong>具体设计方案：</strong></p> \n <p>我们在大流量场景下每次给用户发红包会生成一个加密 token（<strong>使用非对称加密</strong>，包含发红包的元信息：红包金额，actID，与发放时间等），</p> \n <p>分别存储在客户端和服务端（<strong>容灾互备</strong>），每个用户有个 token 列表。</p> \n <p>每次发红包的时候会在 Redis 里记录该 token 的入账状态，</p> \n <p>然后用户在活动钱包页看到的现金红包流水、余额等数据，是合并已入账红包列表+token 列表-已入账/入账中 token 列表的结果。</p> \n <p>同时为保证用户提现体验不感知红包压单流程，</p> \n <p>在进入提现页或者点击提现时，将未入账的 token 列表进行强制入账，</p> \n <p>保证用户提现时账户的余额为应入账总金额，不 block 用户提现流程。</p> \n <p><strong>示意图如下：</strong></p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/fcf21c86fa2ef5ea8c132ca58883cf91.png\" alt=\"\"></p> \n <p><strong>token 数据结构：</strong></p> \n <p>token 使用的是 protobuf 格式，</p> \n <p>经单测验证存储消耗实际比使用 json 少了一倍，节约请求网络的带宽和存储成本；</p> \n <p>同时序列化与反序列化消耗 cpu 也有降低。</p> \n <pre><code class=\"prism language-go\"><span class=\"token comment\">// 红包雨token结构</span>\n<span class=\"token keyword\">type</span> RedPacketToken <span class=\"token keyword\">struct</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n   AppID      <span class=\"token builtin\">int64</span>  <span class=\"token string\">`protobuf: varint,1,opt json: AppID,omitempty `</span> <span class=\"token comment\">// 端ID</span>\n   ActID     <span class=\"token builtin\">int64</span>  <span class=\"token string\">`protobuf: varint,2,opt json: UserID,omitempty `</span> <span class=\"token comment\">// ActID</span>\n   ActivityID <span class=\"token builtin\">string</span> <span class=\"token string\">`protobuf: bytes,3,opt json: ActivityID,omitempty `</span> <span class=\"token comment\">// 活动ID</span>\n   SceneID    <span class=\"token builtin\">string</span> <span class=\"token string\">`protobuf: bytes,4,opt json: SceneID,omitempty `</span> <span class=\"token comment\">// 场景ID</span>\n   Amount     <span class=\"token builtin\">int64</span>  <span class=\"token string\">`protobuf: varint,5,opt json: Amount,omitempty `</span> <span class=\"token comment\">// 红包金额</span>\n   OutTradeNo <span class=\"token builtin\">string</span> <span class=\"token string\">`protobuf: bytes,6,opt json: OutTradeNo,omitempty `</span> <span class=\"token comment\">// 订单号</span>\n   OpenTime   <span class=\"token builtin\">int64</span>  <span class=\"token string\">`protobuf: varint,7,opt json: OpenTime,omitempty `</span> <span class=\"token comment\">// 开奖时间</span>\n   RainID     <span class=\"token builtin\">int32</span>  <span class=\"token string\">`protobuf: varint,8,opt,name=rainID json: rainID,omitempty `</span> <span class=\"token comment\">// 红包雨ID</span>\n   Status     <span class=\"token builtin\">int64</span>  <span class=\"token string\">`protobuf: varint,9,opt,name=status json: status,omitempty `</span> <span class=\"token comment\">//入账状态</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p><strong>token 安全性保障：</strong></p> \n <p>采用非对称加密算法，保障存储在的客户端尽可能不被破解。</p> \n <p>如果 token 加密算法被黑产破译，可监控报警发现，可降级。</p> \n <h4><a id=\"43__504\"></a>4.3 难点三：发奖励链路依赖多的稳定性保障</h4> \n <p>发红包流程降级示意图如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/8677db831f49ccf481df9fc43f6fcd6e.png\" alt=\"\"></p> \n <p>根据历史经验，实现的功能越复杂，依赖会变多，对应的稳定性风险就越高，那么如何保证高依赖的系统稳定性呢？</p> \n <p><strong>解决方案：</strong></p> \n <p>现金红包入账最基础要保障的功能，</p> \n <p>是将用户得到的红包进行入账，</p> \n <p>核心的功能，需要支持幂等与预算控制（避免超发），</p> \n <p>红包账户的幂等设计强依赖数据库保持事务一致性。</p> \n <p>但是如果极端情况发生，中间的链路可能会出现问题，如果是弱依赖，需要支持降级掉，不影响发放主流程。</p> \n <p>钱包方向发红包<strong>最短路径</strong>为依赖服务实例计算资源和 MySQL 存储资源实现现金红包入账。</p> \n <p>发红包强弱依赖梳理图示：</p> \n <table>\n  <thead>\n   <tr>\n    <th>psm</th>\n    <th>依赖服务</th>\n    <th>是否强依赖</th>\n    <th>降级方案</th>\n    <th>降级后影响</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>资产中台</td>\n    <td>tcc</td>\n    <td><strong>是</strong></td>\n    <td>降级读本地缓存</td>\n    <td>无</td>\n   </tr>\n   <tr>\n    <td></td>\n    <td>bytkekv</td>\n    <td>否</td>\n    <td>主动降级开关，跳过 bytekv，依赖下游做幂等</td>\n    <td>无</td>\n   </tr>\n   <tr>\n    <td>资金交易层</td>\n    <td>分布式锁 Redis</td>\n    <td>否</td>\n    <td>被动降级，调用失败，直接跳过</td>\n    <td>基本无</td>\n   </tr>\n   <tr>\n    <td></td>\n    <td>token Redis</td>\n    <td>否</td>\n    <td>主动降级开关，不调用 Redis</td>\n    <td>用户能感知到入账有延迟，会有很多客诉</td>\n   </tr>\n   <tr>\n    <td></td>\n    <td>MySQL</td>\n    <td><strong>是</strong></td>\n    <td>主有问题，联系 dba 切主</td>\n    <td>故障期间发红包不可用</td>\n   </tr>\n  </tbody>\n </table> \n <h4><a id=\"44__536\"></a>4.4 难点四：大流量发卡券预算控制</h4> \n <p>大流量集中发券的一个场景，钱包侧与算法策略配合进行卡券发放库存控制，防止超发。</p> \n <p><strong>具体实现：</strong></p> \n <p>（1）钱包资产中台维护每个卡券模板 ID 的消耗发放量。</p> \n <p>（2）每次卡券发放前，读取该卡券模板 ID 的消耗量以及总库存数。同时会设置一个阈值，如果卡券剩余量小于 10%后不发这个券（使用兜底券或者祝福语进行兜底）。</p> \n <p>（3） 发券流程 累计每个券模板 ID 的消耗量（使用 Redis incr 命令原子累加消耗量），然后与总活动库存进行比对，如果消耗量大于总库存数则拒绝掉，防止超发，也是一个兜底流程。</p> \n <p><strong>具体流程图：</strong></p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/9074ea1e5bc8d3a06b7958c380876833.png\" alt=\"\"></p> \n <p><strong>优化方向：</strong></p> \n <p>（1）大流量下使用 Redis 计数，单 key 会存在热 key 问题，需要拆分 key 来解决。</p> \n <p>（2）大流量场景下，<strong>操作 Redis 会存在超时问题</strong>，返回上游处理中，上游继续重试发券，会多消耗库存少发，本次春节活动实际活动库存在预估库存基础上加了 5%的量级来缓解超时带来的少发问题。</p> \n <h4><a id=\"45__QPS__key__558\"></a>4.5 难点五：高 QPS 场景下的热 key 的读取和写入稳定性保障</h4> \n <p>最大流量预估读取有 180wQPS，写入 30wQPS。</p> \n <p>这是典型的超大流量，热点 key、更新延迟不敏感，非数据强一致性场景（数字是一直累加），</p> \n <p>同时要做好<strong>容灾降级处理</strong>，最后实际活动展示的金额与产品预计发放数值误差小于 1%。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/bad435d6650fdb6b002016da05a29b1d.png\" alt=\"\"></p> \n <h5><a id=\"451__568\"></a>4.5.1 方案一</h5> \n <p>高 QPS 下的读取和写入单 key，比较容易想到的是使用 Redis 分布式缓存来进行实现，但是单 key 读取和写入的会打到一个实例上，压测过单实例的瓶颈为 3w QPS。</p> \n <p>所以做的一个优化是拆分多个 key，然后用本地缓存兜底。</p> \n <p><strong>具体写入流程：</strong></p> \n <p>设计拆分 100 个 key，每次发红包根据请求的 actID%100 使用 incr 命令累加该数字，因为不能保证幂等性，所以超时不重试。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/8029924d3b366d73aff105bf7b2874bc.png\" alt=\"\"></p> \n <p><strong>读取流程：</strong></p> \n <p>与写入流程类似，优先读取本地缓存，</p> \n <p>如果本地缓存值为为 0，那么去读取各个 Redis 的 key 值累加到一起，进行返回。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/73a7b7c3a4dfd9c721119a3a55e511a5.png\" alt=\"\"></p> \n <p><strong>问题：</strong></p> \n <p>（1）拆分 100 个 key 会出现读扩散的问题，需要申请较多 Redis 资源，存储成本比较高。</p> \n <p>而且可能存在读取超时问题，不能保证一次读取所有 key 都读取成功，故返回的结果可能会较上一次有减少。</p> \n <p>（2）容灾方案方面，如果申请备份 Redis，也需要较多的存储资源，需要的额外存储成本。</p> \n <h5><a id=\"452__598\"></a>4.5.2 方案二</h5> \n <p><strong>设计思路：</strong></p> \n <p>在方案一实现的基础上进行优化，</p> \n <p>在写场景，通过本地缓存进行合并写请求，进行原子性累加，</p> \n <p>读场景返回本地缓存的值，减少额外的存储资源占用。</p> \n <p>使用 Redis 实现中心化存储，最终大家读到的值都是一样的。</p> \n <p><strong>具体设计方案：</strong></p> \n <p>每个 docker 实例启动时都会执行定时任务，分为读 Redis 任务和写 Redis 任务。</p> \n <p><strong>读取流程：</strong></p> \n <ol>\n  <li> <p>本地的定时任务每秒执行一次，</p> <p>读取 Redis 单 key 的值，如果获取到的值大于本地缓存那么更新本地缓存的值。</p> </li>\n  <li> <p>对外暴露的 sdk 直接返回本地缓存的值即可。</p> </li>\n  <li> <p>有个问题需要注意下，每次实例启动第一秒内是没有数据的，所以会阻塞读，等有数据再返回。</p> </li>\n </ol> \n <p><strong>写入流程：</strong></p> \n <ol>\n  <li> <p>因为读取都是读取本地缓存（本地缓存不过期），所以处理好并发情况下的写即可。</p> </li>\n  <li> <p>本地缓存写变量使用 go 的 atomic.AddInt64 支持原子性累加本地写缓存的值。</p> </li>\n  <li> <p>每次执行更新 Redis 的定时任务，</p> <p>先将本地写缓存复制到 amount 变量，最后将 amount 的值 incr 到 Redis 单 key 上，实现 Redis 的单 key 的值一直累加。</p> </li>\n  <li> <p>容灾方案是使用备份 Redis 集群，写入时进行双写，</p> <p>一旦主机群挂掉，设计了一个配置开关支持读取备份 Redis。两个 Redis 集群的数据一致性，通过定时任务兜底实现。</p> </li>\n </ol> \n <p>具体写入流程图如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/e109f0690f711922dc101c6702e3eaaf.png\" alt=\"\"></p> \n <p><strong>本方案调用 Redis 的流量是跟实例数成正比</strong>，</p> \n <p>经调研读取侧的服务为主会场实例数 2 万个，写入侧服务为资产中台实例数 8 千个，</p> \n <p>所以实际 Redis 要支持的 QPS 为 2.8 万/定时任务执行间隔（单位为 s），</p> \n <p>经压测验证 Redis 单实例可以支持单 key2 万 get，8k incr 的操作，</p> \n <p>所以设置定时任务的<strong>执行时间间隔是 1s</strong>，如果实例数更多可以考虑延长执行时间间隔。</p> \n <h5><a id=\"453__654\"></a>4.5.3 方案对比</h5> \n <table>\n  <thead>\n   <tr>\n    <th></th>\n    <th>优点</th>\n    <th>缺点</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>方案一</td>\n    <td>1. 实现成本简单</td>\n    <td>1. 浪费存储资源； 2. 难以做容灾； 3. 不能做到一直累加；</td>\n   </tr>\n   <tr>\n    <td>方案二</td>\n    <td>1. 节约资源； 2. 容灾方案比较简单，同时也节约资源成本；</td>\n    <td>1. 实现稍复杂，需要考虑好并发原子性累加问题</td>\n   </tr>\n  </tbody>\n </table> \n <p><strong>结论：</strong></p> \n <p>从实现效果，资源成本和容灾等方面考虑，最终选择了方案二上线。</p> \n <h4><a id=\"46__665\"></a>4.6 难点六：大流量场景下资金安全保障</h4> \n <p>钱包方向在本次春节活动期间做了三件事情来保障大流量大预算的现金红包发放的资金安全：</p> \n <ol>\n  <li>现金红包发放整体预算控制的拦截</li>\n  <li>单笔现金红包发放金额上限的拦截</li>\n  <li>大流量发红包场景的资金对账</li>\n </ol> \n <ul>\n  <li>小时级别对账：支持红包雨/集卡/烟火红包发放 h+1 小时级对账，并针对部分场景设置兜底 h+2 核对。</li>\n  <li>准实时对账：红包雨已入账的红包数据反查钱包资产中台和活动侧做准实时对账</li>\n </ul> \n <p>多维度核对示意图：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/ac8168ba12977b430d33d7a5f3c27f3c.png\" alt=\"\"></p> \n <p>准实时对账流程图：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/2e0ae5cd61906fc5d264ae6f5fa4e411.png\" alt=\"\"></p> \n <p><strong>说明：</strong></p> \n <p>准实时对账监控和报警可以及时发现是否异常入账情况，如果报警发现会有紧急预案处理。</p> \n <h3><a id=\"5__688\"></a>5. 通用模式抽象</h3> \n <p>在经历过春节超大流量活动后的设计与实现后，有一些总结和经验与大家一起分享一下。</p> \n <h4><a id=\"51__692\"></a>5.1 容灾降级层面</h4> \n <p>大流量场景，为了保证活动最终上线效果，容灾是一定要做好的。</p> \n <p>参考业界通用实现方案，如降级、限流、熔断、资源隔离，根据预估活动参与人数和效果进行使用存储预估等。</p> \n <h5><a id=\"511__698\"></a>5.1.1 限流层面</h5> \n <p>（1）限流方面应用了 api 层 nginx 入流量限流，分布式入流量限流，分布式出流量限流。</p> \n <p>这几个限流器都是字节跳动公司层面公共的中间件，经过大流量的验证。</p> \n <p>（2）首先进行了实际单实例压测，根据单实例扛住的流量与本次春节活动预估流量打到该服务的流量进行扩容，并结合下游能抗住的情况，</p> \n <p>在 tlb 入流量、入流量限流以及出流量限流分别做好了详细完整的配置并同。</p> \n <p><strong>限流目标：</strong></p> \n <p>保证自身服务稳定性，防止外部预期外流量把本身服务打垮，防止造成雪崩效应，保证核心业务和用户核心体验。</p> \n <p>简单集群限流是实例维度的限流，</p> \n <p>每个实例限流的 QPS=总配置限流 QPS/实例数，</p> \n <p>对于多机器低 QPS 可能会有不准的情况，要<strong>经过实际压测并且及时调整配置值。</strong></p> \n <p>对于分布式入流量和出流量限流，两种使用方式如下，每种方式都支持高低 QPS，区别只是 SDK 使用方式和功能不同。</p> \n <p>一般低 QPS 精度要求高，采用 redis 计数方式，使用方提供自己的 redis 集群。</p> \n <p>高 QPS 精度要求低，退化为总 QPS/tce 实例数的单实例限流。</p> \n <h5><a id=\"512__724\"></a>5.1.2 降级层面</h5> \n <p>对于高流量场景，每个核心功能都要有对应的<strong>降级方案</strong>来保证突发情况核心链路的稳定性。</p> \n <p>（1）本次春节奖励入账与活动活动钱包页方向做好了充分的操作预案，一共有 26 个降级开关，关键时刻弃车保帅，防止有单点问题影响核心链路。</p> \n <p>（2）以发现金红包链路举例，钱包方向最后完全降级的方案是只依赖 docker 和 MySQL，其他依赖都是可以降级掉的，MySQL 主有问题可以紧急联系切主，虽说最后一个都没用上，但是前提要设计好保证活动的万无一失。</p> \n <h5><a id=\"513__732\"></a>5.1.3 资源隔离层面</h5> \n <p>（1）提升开发效率<strong>不重复造轮子</strong>。</p> \n <p>因为钱包资产中台也日常支持抖音资产发放的需求，本次春节活动也复用了现有的接口和代码流程支持发奖。</p> \n <p>（2）同时针对本次春节活动，服务层面做了<strong>集群隔离</strong>，</p> \n <p>创建专用活动集群，底层存储资源隔离，活动流量和常规流量互不影响。</p> \n <h5><a id=\"514__742\"></a>5.1.4 存储预估</h5> \n <p>（1）不但要考虑和验证了 Redis 或者 MySQL 存储能抗住对应的流量，同时也要按照实际的获取参与和发放数据等预估存储资源是否足够。</p> \n <p>（2）对于字节跳动公司的 Redis 组件来讲，</p> \n <p>可以进行<strong>垂直扩容</strong>（每个实例增加存储，最大 10G），也可以进行<strong>水平扩容</strong>（单机房上限是 500 个实例），因为 Redis 是三机房同步的，所以计算存储时只考虑一个机房的存储上限即可。</p> \n <p>要留足 buffer，因为水平扩容是很慢的一个过程，突发情况遇到存储资源不足只能通过配置开关提前下掉依赖存储，需要提前设计好。</p> \n <h5><a id=\"515__752\"></a>5.1.5 压测层面</h5> \n <p>本次春节活动，钱包奖励入账和活动钱包页做了充分的全链路压测验证，下面是一些经验总结。</p> \n <ol>\n  <li>在压测前要建立好压测整条链路的监控大盘，在压测过程当中及时和方便的发现问题。</li>\n  <li>对于 MySQL 数据库，在红包雨等大流量正式活动开始前，进行小流量压测预热数据库，峰值流量前提前建链，减少正式活动时的大量建链耗时，保证发红包链路数据库层面的稳定性。</li>\n  <li>压测过程当中一定要传压测标，支持全链路识别压测流量做特殊逻辑处理，与线上正常业务互不干扰。</li>\n  <li>针对压测流量不做特殊处理，压测流量处理流程保持和线上流量一致。</li>\n  <li>压测中要验证计算资源与存储资源是否能抗住预估流量</li>\n </ol> \n <ul>\n  <li><strong>梳理好压测计划</strong>，基于历史经验，设置合理初始流量，渐进提升压测流量，实时观察各项压测指标。</li>\n  <li><strong>存储资源压测数据要与线上数据隔离</strong>，对于 MySQL 和 Bytekv 这种来讲是建压测表，对于 Redis 和 Abase 这种来讲是压测 key 在线上 key 基础加一下压测前缀标识 。</li>\n  <li><strong>压测数据要及时清理</strong>，Redis 和 Abase 这种加短时间的过期时间，过期机制处理比较方便，如果忘记设置过期时间，可以根据写脚本识别压测标前缀去删除。</li>\n </ul> \n <ol>\n  <li>压测后也要关注存储资源各项指标是否符合预期。</li>\n </ol> \n <h4><a id=\"52__768\"></a>5.2 微服务思考</h4> \n <p>在日常技术设计中，大家都会遵守微服务设计原则和规范，根据系统职责和核心数据模型拆分不同模块，提升开发迭代效率并不互相影响。</p> \n <p>但是微服务也有它的弊端，对于超大流量的场景功能也比较复杂，会经过多个链路，这样是极其消耗计算资源的。</p> \n <p>本次春节活动<strong>资产中台提供了 sdk 包代替 rpc 进行微服务链路聚合对外提供基础能力</strong>，如查询余额、判断用户是否获取过奖励，强制入账等功能。访问流量最高上千万，与使用微服务架构对比节约了上万核 CPU 的计算资源。</p> \n <h3><a id=\"6__776\"></a>6. 系统的未来演进方向</h3> \n <p>（1）梳理上下游需求和痛点，优化资产中台设计实现，完善基础能力，优化服务架构，提供一站式服务，让接入活动方可以更专注进行活动业务逻辑的研发工作。</p> \n <p>（2）加强实时和离线数据看板能力建设，让奖励发放数据展示的更清晰更准确。</p> \n <p>（3）加强配置化和文档建设，对内减少对接活动的对接成本，对外提升活动业务方接入效率。</p> \n <blockquote> \n  <p>上文参考来源：字节跳动技术团队：春节钱包大流量奖励系统入账及展示的设计与实现</p> \n </blockquote> \n <h2><a id=\"_790\"></a>推荐阅读：</h2> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128670335\">Docker面试题（史上最全 + 持续更新）</a>》<br> 《 <a href=\"https://blog.csdn.net/crazymakercircle/article/details/128533821\">场景题：假设10W人突访，你的系统如何做到不 雪崩？</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124790425\">尼恩Java面试宝典</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057567\">Springcloud gateway 底层原理、核心实战 (史上最全)</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124120506\">Flux、Mono、Reactor 实战（史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125059491\">sentinel （史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057545\">Nacos (史上最全)</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/123420859\">分库分表 Sharding-JDBC 底层原理、核心实战（史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/114527369\">TCP协议详解 (史上最全)</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126992542\">clickhouse 超底层原理 + 高可用实操 （史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120702536\">nacos高可用（图解+秒懂+史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264803\">队列之王： Disruptor 原理、架构、源码 一文穿透</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264508\">环形队列、 条带环形队列 Striped-RingBuffer （史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125135726\">一文搞定：SpringBoot、SLF4j、Log4j、Logback、Netty之间混乱关系（史上最全）</a><br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128265067\">单例模式（史上最全）</a><br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125017316\">红黑树（ 图解 + 秒懂 + 史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/109459593\">分布式事务 （秒懂）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128123114\">缓存之王：Caffeine 源码、架构、原理（史上最全，10W字 超级长文）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/113751575\">缓存之王：Caffeine 的使用（史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126579528\">Java Agent 探针、字节码增强 ByteBuddy（史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120747767\">Docker原理（图解+秒懂+史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/116425814\">Redis分布式锁（图解 - 秒懂 - 史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85956246\">Zookeeper 分布式锁 - 图解 - 秒懂</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85922561\">Zookeeper Curator 事件监听 - 10分钟看懂</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83957259\">Netty 粘包 拆包 | 史上最全解读</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83758107\">Netty 100万级高并发服务器配置</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/102557988\">Springcloud 高并发 配置 （一文全懂）</a>》</p> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 1691);
INSERT INTO `crawlerblog` VALUES (123124035, 'Nginx面试题（史上最全 + 持续更新）', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <h2><a id=\"39Nginx_0\"></a>尼恩面试宝典专题39：Nginx面试题（史上最全、持续更新）</h2> \n <h4><a id=\"V27_1\"></a>本文版本说明：V27</h4> \n <h2><a id=\"_3\"></a>《尼恩面试宝典》升级规划为：</h2> \n <p>后续基本上，<strong>每一个月，都会发布一次</strong>，最新版本，可以联系构师尼恩获取， 发送 “领取电子书” 获取。<br> <img src=\"https://img-blog.csdnimg.cn/img_convert/9cab24afac032e4952398bf2f84a867f.png\" alt=\"\"></p> \n <p>Nginx的并发能力在同类型网页服务器中的表现，相对而言是比较好的，因此受到了很多企业的青睐，我国使用Nginx网站的知名用户包括腾讯、淘宝、百度、京东、新浪、网易等等。</p> \n <p>Nginx是系统架构师、开发人员、网页服务器运维人员必备技能之一，下面的面试题，为大家提供系统化、体系化的学习资料， 比一般的专业书籍，更有价值</p> \n <p>最新版本，可以联系构师尼恩获取， 发送 “领取电子书” 获取。</p> \n <h2><a id=\"Nginx_15\"></a>聊聊：什么是Nginx?</h2> \n <p>Nginx是一个web服务器和反向代理服务器，用于HTTP、HTTPS、SMTP、POP3和IMAP协议。</p> \n <p>Nginx—Ngine X，是一款免费的、自由的、开源的、高性能HTTP服务器和反向代理服务器；</p> \n <p>也是一个IMAP、POP3、SMTP代理服务器；</p> \n <p>Nginx以其高性能、稳定性、丰富的功能、简单的配置和低资源消耗而闻名。</p> \n <p>也就是说Nginx本身就可以托管网站（类似于Tomcat一样），进行Http服务处理，也可以作为反向代理服务器 、负载均衡器和HTTP缓存。</p> \n <p>Nginx 解决了服务器的C10K（就是在一秒之内连接客户端的数目为10k即1万）问题。</p> \n <p>它的设计不像传统的服务器那样使用线程处理请求，而是一个更加高级的机制—事件驱动机制，是一种异步事件驱动结构。</p> \n <h2><a id=\"Nginx_35\"></a>聊聊：Nginx的一些特性。</h2> \n <p>Nginx服务器的特性包括：</p> \n <ul>\n  <li>反向代理/L7负载均衡器</li>\n  <li>嵌入式Perl解释器</li>\n  <li>动态二进制升级</li>\n  <li>可用于重新编写URL，具有非常好的PCRE支持</li>\n </ul> \n <h2><a id=\"Nginx_46\"></a>聊聊：Nginx的优缺点？</h2> \n <p>核心优点：</p> \n <ul>\n  <li>占内存小，可实现高并发连接，处理响应快</li>\n  <li>可实现http服务器、虚拟主机、方向代理、负载均衡</li>\n  <li>Nginx配置简单</li>\n  <li>可以不暴露正式的服务器IP地址</li>\n </ul> \n <p>核心缺点：</p> \n <ul>\n  <li>动态处理差：</li>\n </ul> \n <p>nginx处理静态文件好,耗费内存少，但是处理动态页面则很鸡肋，</p> \n <p>现在一般前端用nginx作为反向代理抗住压力。</p> \n <h2><a id=\"Nginx_65\"></a>聊聊：Nginx应用场景？</h2> \n <ul>\n  <li>http服务器。</li>\n </ul> \n <p>Nginx是一个http服务可以独立提供http服务。可以做网页静态服务器。</p> \n <ul>\n  <li>虚拟主机。</li>\n </ul> \n <p>可以实现在一台服务器虚拟出多个网站，例如个人网站使用的虚拟机。</p> \n <ul>\n  <li>反向代理，负载均衡。</li>\n </ul> \n <p>当网站的访问量达到一定程度后，单台服务器不能满足用户的请求时，需要用多台服务器集群可以使用nginx做反向代理。</p> \n <p>并且多台服务器可以平均分担负载，不会应为某台服务器负载高宕机而某台服务器闲置的情况。</p> \n <p>nginz 中也可以配置安全管理、比如可以使用Nginx搭建API接口网关,对每个接口服务进行拦截。</p> \n <h2><a id=\"_87\"></a>聊聊：使用“反向代理服务器”的优点是什么?</h2> \n <p>反向代理服务器可以隐藏源服务器的存在和特征。</p> \n <p>它充当互联网云和web服务器之间的中间层。</p> \n <p>这对于安全方面来说是很好的，特别是当您使用web托管服务时。</p> \n <h2><a id=\"_97\"></a>聊聊：什么是正向代理和反向代理？</h2> \n <p>首先，代理服务器一般指局域网内部的机器通过代理服务器发送请求到互联网上的服务器，代理服务器一般作用在客户端。例如：GoAgent翻墙软件。</p> \n <p>我们的客户端在进行翻墙操作的时候，我们使用的正是正向代理，通过正向代理的方式，在我们的客户端运行一个软件，将我们的HTTP请求转发到其他不同的服务器端，实现请求的分发。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/f9f5b077d05fc0ce06315cbb858ed2e2.png\" alt=\"\"></p> \n <p>反向代理服务器作用在服务器端，它在服务器端接收客户端的请求，然后将请求分发给具体的服务器进行处理，然后再将服务器的相应结果反馈给客户端。Nginx就是一个反向代理服务器软件。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/1ff61e511967bb0f0d59c9a83dcf1897.png\" alt=\"\"></p> \n <p>从上图可以看出：客户端必须设置正向代理服务器，当然前提是要知道正向代理服务器的IP地址，还有代理程序的端口。</p> \n <p>反向代理正好与正向代理相反，对于客户端而言代理服务器就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理的命名空间（name-space）中的内容发送普通请求，接着反向代理将判断向何处（原始服务器）转交请求，并将获得的内容返回给客户端。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/567f7de140fb416d8abeb72c0879e568.png\" alt=\"\"></p> \n <h2><a id=\"_121\"></a>聊聊：反向代理好处</h2> \n <ol>\n  <li>保护了真实的 web 服务器，web 服务器对外不可见，外网只能看到反向代理服务器，而反向代理服务器上并没有真实数据，因此，保证了 web 服务器的资源安全。</li>\n  <li>反向代理为基础产生了动静资源分离以及负载均衡的方式，减轻 web 服务器的负担，加速了对网站访问速度。</li>\n  <li>节约了有限的 IP 地址资源，企业内所有的网站共享一个在 internet 中注册的IP地址，这些服务器分配私有地址，采用虚拟主机的方式对外提供服务。</li>\n </ol> \n <h2><a id=\"Nginx___131\"></a>聊聊：什么是Nginx? 它的优势和功能?</h2> \n <p>Nginx是一个web服务器和方向代理服务器，用于HTTP、HTTPS、SMTP、POP3和IMAP协议。因它的稳定性、丰富的功能集、示例配置文件和低系统资源的消耗而闻名。<br> 优点：</p> \n <p><strong>（1）更快</strong></p> \n <p>这表现在两个方面：一方面，在正常情况下，单次请求会得到更快的响应；另一方面，在高峰期（如有数以万计的并发请求），Nginx可以比其他Web服务器更快地响应请求。</p> \n <p><strong>（2）高扩展性，跨平台</strong></p> \n <p>Nginx的设计极具扩展性，它完全是由多个不同功能、不同层次、不同类型且耦合度极低的模块组成。因此，当对某一个模块修复Bug或进行升级时，可以专注于模块自身，无须在意其他。而且在HTTP模块中，还设计了HTTP过滤器模块：一个正常的HTTP模块在处理完请求后，会有一串HTTP过滤器模块对请求的结果进行再处理。这样，当我们开发一个新的HTTP模块时，不但可以使用诸如HTTP核心模块、events模块、log模块等不同层次或者不同类型的模块，还可以原封不动地复用大量已有的HTTP过滤器模块。这种低耦合度的优秀设计，造就了Nginx庞大的第三方模块，当然，公开的第三方模块也如官方发布的模块一样容易使用。<br> Nginx的模块都是嵌入到二进制文件中执行的，无论官方发布的模块还是第三方模块都是如此。这使得第三方模块一样具备极其优秀的性能，充分利用Nginx的高并发特性，因此，许多高流量的网站都倾向于开发符合自己业务特性的定制模块。</p> \n <p><strong>（3）高可靠性：用于反向代理，宕机的概率微乎其微</strong></p> \n <p>高可靠性是我们选择Nginx的最基本条件，因为Nginx的可靠性是大家有目共睹的，很多家高流量网站都在核心服务器上大规模使用Nginx。Nginx的高可靠性来自于其核心框架代码的优秀设计、模块设计的简单性；另外，官方提供的常用模块都非常稳定，每个worker进程相对独立，master进程在1个worker进程出错时可以快速“拉起”新的worker子进程提供服务。</p> \n <p><strong>（4）低内存消耗</strong></p> \n <p>一般情况下，10 000个非活跃的HTTP Keep-Alive连接在Nginx中仅消耗2.5MB的内存，这是Nginx支持高并发连接的基础。</p> \n <p><strong>（5）单机支持10万以上的并发连接</strong></p> \n <p>这是一个非常重要的特性！</p> \n <p>随着互联网的迅猛发展和互联网用户数量的成倍增长，各大公司、网站都需要应付海量并发请求，一个能够在峰值期顶住10万以上并发请求的Server，无疑会得到大家的青睐。</p> \n <p>理论上，Nginx支持的并发连接上限取决于内存，10万远未封顶。当然，能够及时地处理更多的并发请求，是与业务特点紧密相关的。</p> \n <p><strong>（6）热部署</strong></p> \n <p>master管理进程与worker工作进程的分离设计，使得Nginx能够提供热部署功能，即可以在7×24小时不间断服务的前提下，升级Nginx的可执行文件。</p> \n <p>当然，它也支持不停止服务就更新配置项、更换日志文件等功能。</p> \n <p><strong>（7）最自由的BSD许可协议</strong></p> \n <p>这是Nginx可以快速发展的强大动力。</p> \n <p>BSD许可协议不只是允许用户免费使用Nginx，它还允许用户在自己的项目中直接使用或修改Nginx源码，然后发布。这吸引了无数开发者继续为Nginx贡献自己的智慧。</p> \n <p>以上7个特点当然不是Nginx的全部，拥有无数个官方功能模块、第三方功能模块使得Nginx能够满足绝大部分应用场景，这些功能模块间可以叠加以实现更加强大、复杂的功能，有些模块还支持Nginx与Perl、Lua等脚本语言集成工作，大大提高了开发效率。这些特点促使用户在寻找一个Web服务器时更多考虑Nginx。</p> \n <p>选择Nginx的核心理由还是它能在支持高并发请求的同时保持高效的服务</p> \n <h2><a id=\"Nginx_179\"></a>聊聊：为什么要用Nginx？</h2> \n <ul>\n  <li> <p>跨平台、配置简单、方向代理、高并发连接：处理2-3万并发连接数，官方监测能支持5万并发，内存消耗小：开启10个nginx才占150M内存 ，nginx处理静态文件好，耗费内存少，</p> </li>\n  <li> <p>而且Nginx内置的健康检查功能：如果有一个服务器宕机，会做一个健康检查，再发送的请求就不会发送到宕机的服务器了。重新将请求提交到其他的节点上。</p> </li>\n  <li> <p>使用Nginx的话还能：</p> \n   <ol>\n    <li>节省宽带：支持GZIP压缩，可以添加浏览器本地缓存</li>\n    <li>稳定性高：宕机的概率非常小</li>\n    <li>接收用户请求是异步的</li>\n   </ol> </li>\n </ul> \n <h2><a id=\"C10K_189\"></a>聊聊：请解释什么是C10K问题?</h2> \n <p>C10K问题是指无法同时处理大量客户端(10,000)的网络套接字。</p> \n <h2><a id=\"C10K_195\"></a>聊聊：C10K问题的本质和解决方案</h2> \n <h3><a id=\"C10K_197\"></a>什么是C10K问题</h3> \n <p>所谓 c10k 问题，指的是服务器如何支持 10k 个并发连接，也就是 concurrent 10000 connection（这也是 c10k 这个名字的由来）。</p> \n <p>由于硬件成本的大幅度降低和硬件技术的进步，如果一台服务器能够同时服务更多的客户端，那么也就意味着服务每一个客户端的成本大幅度降低。从这个角度来看，c10k 问题显得非常有意义。</p> \n <h4><a id=\"C10K_203\"></a>C10K问题由来</h4> \n <p>互联网的基础是网络通信，早期的互联网可以说是一个小群体的集合。互联网还不够普及，用户也不多，一台服务器同时在线 100 个用户，在当时已经算是大型应用了，所以并不存在 C10K 的难题。互联网的爆发期是在 www 网站、浏览器出现后。最早的互联网称之为 Web1.0，大部分的使用场景是下载一个 HTML 页面，用户在浏览器中查看网页上的信息，这个时期也不存在 C10K 问题。</p> \n <p>Web2.0 时代到来后，就不同了。一方面是，互联网普及率大大提高了，用户群体几何倍增长。另一方面是，互联网不再是单纯地浏览 www 网页，逐渐开始进行交互，而且应用程序的逻辑也变得更复杂。从简单的表单提交，到即时通信和在线实时互动，C10K 的问题才体现出来了。因为每一个用户都必须与服务器保持连接，才能进行实时数据交互。诸如 Facebook 这样的网站，同一时间的并发 TCP 连接很可能已经过亿。</p> \n <pre><code>早期的腾讯QQ也同样面临C10K问题，只不过他们是用了UDP这种原始的包交换协议来实现的，绕开了这个难题，当然过程肯定是痛苦的。如果当时有 epoll 技术，他们肯定会用 TCP。众所周之，后来的手机 QQ、微信都采用 TCP 协议。\n实际上，当时也有异步模式，如：select/poll 模型。这些技术都有一定的缺点：selelct 最大不能超过 1024；poll 没有限制，但每次收到数据时，需要遍历每一个连接，查看哪个连接有数据请求。\n</code></pre> \n <p>这时候问题就来了，最初的服务器都是基于进程/线程模型的，新到来一个 TCP 连接，就需要分配 1 个进程（或者线程）。进程又是操作系统最昂贵的资源，一台机器无法创建很多进程。如果是 C10K，就要创建 1 万个进程，那么就单机而言，操作系统是无法承受的（往往出现效率低下、甚至完全瘫痪）。如果是采用分布式系统，维持 1 亿用户在线需要 10 万台服务器，成本巨大，也只有 Facebook、Google、Apple 等巨头，才有财力购买如此多的服务器。</p> \n <p>基于上述考虑，如何突破单机性能局限，是高性能网络编程所必须要直面的问题。这些局限和问题，最早被 Dan Kegel 进行了归纳和总结，并首次系统地分析和提出了解决方案。后来，这种普遍的网络现象和技术局限，都被大家称为 C10K 问题。</p> \n <h3><a id=\"C10K_218\"></a>C10K问题的本质</h3> \n <p>C10K 问题，本质上是操作系统的问题。对于 Web1.0/2.0 时代的操作系统而言，传统的同步阻塞 I/O 模型都是一样的，处理的方式都是 requests per second，并发 10K 和 100 的区别关键在于 CPU。</p> \n <p>创建的进程、线程多了，数据拷贝频繁（缓存 I/O、内核将数据拷贝到用户进程空间、阻塞）， 进程/线程上下文切换消耗大， 导致操作系统崩溃，这就是 C10K 问题的本质！</p> \n <p>可见，解决 C10K 问题的关键就是：尽可能减少 CPU 等核心资源消耗，从而榨干单台服务器的性能，突破 C10K 问题所描述的瓶颈。</p> \n <h3><a id=\"C10K_226\"></a>C10K问题的解决方案探讨</h3> \n <p>从网络编程技术的角度来说，主要思路为：</p> \n <ol>\n  <li>为每个连接分配一个独立的线程/进程。</li>\n  <li>同一个线程/进程同时处理多个连接（IO 多路复用）。</li>\n </ol> \n <h4><a id=\"_233\"></a>为每个连接分配一个独立的线程/进程</h4> \n <p>这一思路最为直接。但是，由于申请进程/线程会占用相当可观的系统资源，同时对于多进程/线程的管理会对系统造成压力，因此，这种方案不具备良好的可扩展性。</p> \n <p>这一思路在服务器资源还没有富裕到足够程度的时候，是不可行的。即便资源足够富裕，效率也不够高。</p> \n <p>总之，此思路技术实现会使得资源占用过多，可扩展性差，在实际应用中已被抛弃。</p> \n <h4><a id=\"IO_241\"></a>同一个线程/进程同时处理多个连接（IO多路复用）</h4> \n <p>IO 多路复用，从技术实现上，又分很多种。我们逐一来看看下述各种实现方式的优劣。</p> \n <p><strong>实现方式1：循环逐个处理各个连接，每个连接对应一个 socket</strong></p> \n <p>循环逐个处理各个连接，每个连接对应一个 socket。当所有 socket 都有数据的时候，这种方法是可行的。但是，当应用读取某个 socket 的文件数据不 ready 的时候，整个应用会阻塞在这里，等待该文件句柄 ready，即使别的文件句柄 ready，也无法往下处理。</p> \n <p>实现小结：直接循环处理多个连接。</p> \n <p>问题归纳：任一文件句柄的不成功会阻塞住整个应用。</p> \n <p><strong>实现方式2：使用 select 方法</strong></p> \n <p>使用 select 方法解决上面阻塞的问题，思路比较简单。在读取文件句柄之前，先查下它的状态，如果 ready 了，就进行处理；如果不 ready， 就不进行处理；这不就解决了这个问题了嘛？于是，有了 select 方案。用一个 fd_set 结构体来告诉内核同时监控多个文件句柄，当其中有文件句柄的状态发生指定变化（例如某句柄由不可用变为可用）或超时，则调用返回。</p> \n <p>之后，应用可以使用 FD_ISSET 来逐个查看，确定哪个文件句柄的状态发生了变化。这样做，小规模的连接问题不大，但当连接数很多（文件句柄个数很多）的时候，逐个检查状态就很慢了。因此，select 往往存在管理的句柄上限（FD_SETSIZE）。同时，在使用上，因为只有一个字段记录关注和发生事件，所以每次调用之前，要重新初始化 fd_set 结构体。</p> \n <pre><code class=\"prism language-bash\">intselect<span class=\"token punctuation\">(</span>intnfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds,structtimeval *timeout<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n</code></pre> \n <p>实现小结：有连接请求抵达了，再检查处理。</p> \n <p>问题归纳：句柄上限+重复初始化+逐个排查所有文件句柄状态，效率不高。</p> \n <p><strong>实现方式3：使用 poll 方法</strong></p> \n <p>poll 主要解决 select 的前两个问题：</p> \n <ol>\n  <li>通过一个 pollfd 数组，向内核传递需要关注的事件，以消除文件句柄上限。</li>\n  <li>使用不同字段分别标注 “关注事件和发生事件”，来避免重复初始化。</li>\n </ol> \n <p>实现小结：设计新的数据结构，提高使用效率。</p> \n <p>问题归纳：逐个排查所有文件句柄状态，效率不高。</p> \n <p><strong>实现方式4：使用 epoll 方法</strong></p> \n <p>既然 “poll 逐个排查所有文件句柄状态” 效率不高，很自然的，在调用返回的时候，如果只给应用提供发生了状态变化（很可能是数据 ready）的文件句柄，进行排查的效率就高很多。epoll 采用了这种设计，适用于大规模的应用场景。实验表明：当文件句柄数目超过10之后，epoll 性能将优于 select 和 poll；当文件句柄数目达到 10K 的时候，epoll 已经超过 select 和 poll 两个数量级。</p> \n <p>实现小结：只返回状态变化的文件句柄。</p> \n <p>问题归纳：依赖特定平台（Linux）。</p> \n <p>因为 Linux 是互联网企业中使用率最高的操作系统，所以 Epoll 就成为 “C10K killer、高并发、高性能、异步非阻塞” 这些技术的代名词了。FreeBSD 推出了 kqueue，Linux 推出了 epoll，Windows 推出了 IOCP，Solaris 推出了 /dev/poll。这些操作系统提供的功能，就是为了解决 C10K 问题。epoll 技术的编程模型就是异步非阻塞回调，也可以叫做 Reactor、事件驱动、事件轮循（EventLoop）。Nginx、libevent、node.js 这些就是 Epoll 时代的产物。</p> \n <p><strong>实现方式5：使用 libevent 库</strong></p> \n <p>由于 epoll,、kqueue、IOCP 每个接口都有自己的特点，程序移植非常困难，所以需要对这些接口进行封装，以让它们易于使用和移植，其中 libevent 库就是其中之一。跨平台，封装底层平台的调用，提供统一的 API，但底层在不同平台上自动选择合适的调用。</p> \n <p>按照 libevent 的官方网站，libevent 库提供了以下功能：当一个文件描述符的特定事件（如可读，可写或出错）发生了，或一个定时事件发生了，libevent 就会自动执行用户指定的回调函数，来处理事件。目前，libevent 已支持以下接口 /dev/poll、kqueue、event ports、select、poll 和 epoll。Libevent 的内部事件机制完全是基于所使用的接口的。因此，libevent 非常容易移植，也使它的扩展性非常容易。目前，libevent 已在以下操作系统中编译通过：Linux、BSD、Mac OS X、Solaris 和 Windows。使用 libevent 库进行开发非常简单，也很容易在各种 unix 平台上移植。</p> \n <h2><a id=\"Nginx_298\"></a>聊聊：Nginx如何实现超高并发？</h2> \n <h4><a id=\"_300\"></a>面试官心理分析</h4> \n <p>主要是看应聘人员的对NGINX的基本原理是否熟悉，因为大多数人多多少少都懂点NGINX，但是真正其明白原理的可能少之又少。</p> \n <p>明白其原理，才能做优化，否则只能照样搬样，出了问题也无从下手。</p> \n <p>懂皮毛的人，一般会做个 Web Server，搭建一个 Web 站点；</p> \n <p>初级运维可能搞个 HTTPS 、配置一个反向代理; 中级运维定义个 upstream、写个正则判断；</p> \n <p>老鸟做个性能优化、写个ACL，还有可能改改源码。</p> \n <h4><a id=\"_312\"></a>面试题剖析</h4> \n <p>异步，非阻塞，使用了epoll 和大量的底层代码优化。</p> \n <p>如果一个server采用一个进程负责一个request的方式，那么进程数就是并发数。正常情况下，会有很多进程一直在等待中。</p> \n <p>而nginx采用一个master进程，多个woker进程的模式。</p> \n <ul>\n  <li>master进程主要负责收集、分发请求。每当一个请求过来时，master就拉起一个worker进程负责处理这个请求。</li>\n  <li>同时master进程也负责监控woker的状态，保证高可靠性</li>\n  <li>woker进程一般设置为跟cpu核心数一致。nginx的woker进程在同一时间可以处理的请求数只受内存限制，可以处理多个请求。</li>\n  <li>Nginx 的异步非阻塞工作方式正把当中的等待时间利用起来了。在需要等待的时候，这些进程就空闲出来待命了，因此表现为少数几个进程就解决了大量的并发问题。</li>\n </ul> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/75f53c1f410adb8a740fc11ba49bce6a.png\" alt=\"\"></p> \n <p>每进来一个request，会有一个worker进程去处理。但不是全程的处理，处理到什么程度呢？处理到可能发生阻塞的地方，比如向上游（后端）服务器转发request，并等待请求返回。那么，这个处理的worker很聪明，他会在发送完请求后，注册一个事件：“如果upstream返回了，告诉我一声，我再接着干”。于是他就休息去了。</p> \n <p>此时，如果再有request 进来，他就可以很快再按这种方式处理。而一旦上游服务器返回了，就会触发这个事件，worker才会来接手，这个request才会接着往下走。</p> \n <h2><a id=\"Nginx_333\"></a>聊聊：Nginx如何实现超高并发？</h2> \n <p>Nginx 是一个高性能的 Web 服务器，能够同时处理大量的并发请求。</p> \n <p>它结合多进程机制和异步机制 ，异步机制使用的是异步非阻塞方式，</p> \n <p>接下来就给大家介绍一下 Nginx 的多线程机制和异步非阻塞机制。</p> \n <h4><a id=\"1_341\"></a>1、多进程机制</h4> \n <p>服务器每当收到一个客户端时，就有 服务器主进程 （ master process ）生成一个 子进程（ worker process ）出来和客户端建立连接进行交互，直到连接断开，该子进程就结束了。</p> \n <p>使用进程的好处是各个进程之间相互独立，不需要加锁，减少了使用锁对性能造成影响，同时降低编程的复杂度，降低开发成本。其次，采用独立的进程，可以让进程互相之间不会影响 ，如果一个进程发生异常退出时，其它进程正常工作， master 进程则很快启动新的 worker 进程，确保服务不会中断，从而将风险降到最低。</p> \n <p>缺点是操作系统生成一个子进程需要进行 内存复制等操作，在资源和时间上会产生一定的开销。当有大量请求时，会导致系统性能下降 。</p> \n <h4><a id=\"2_349\"></a>2、异步非阻塞机制</h4> \n <p>每个工作进程 使用 异步非阻塞方式 ，可以处理 多个客户端请求 。</p> \n <p>当某个 工作进程 接收到客户端的请求以后，调用 IO 进行处理，如果不能立即得到结果，就去 处理其他请求 （即为 非阻塞 ）；而 客户端 在此期间也 无需等待响应 ，可以去处理其他事情（即为 异步 ）。</p> \n <p>当 IO 返回时，就会通知此 工作进程 ；该进程得到通知，暂时 挂起 当前处理的事务去 响应客户端请求 。</p> \n <h2><a id=\"NginxMasterWorker_359\"></a>聊聊：请解释Nginx服务器上的Master和Worker进程分别是什么?</h2> \n <ul>\n  <li>主程序 Master process 启动后，通过一个 for 循环来 接收 和 处理外部信号 ；</li>\n  <li>主进程通过 fork() 函数产生 worker 子进程 ，每个子进程执行一个 for循环来实现Nginx服务器对事件的接收和处理 。</li>\n </ul> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/d34ed01f3db431d7f075675043a586a4.png\" alt=\"\"></p> \n <p>一般推荐 worker 进程数与CPU内核数一致，这样一来不存在大量的子进程生成和管理任务，避免了进程之间竞争CPU 资源和进程切换的开销。而且 Nginx 为了更好的利用 多核特性 ，提供了 CPU 亲缘性的绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来 Cache 的失效。</p> \n <p>对于每个请求，有且只有一个工作进程 对其处理。首先，每个 worker 进程都是从 master进程 fork 过来。在 master 进程里面，先建立好需要 listen 的 socket（listenfd） 之后，然后再 fork 出多个 worker 进程。</p> \n <p>所有 worker 进程的 listenfd 会在新连接到来时变得可读 ，为保证只有一个进程处理该连接，所有 worker 进程在注册 listenfd 读事件前抢占 accept_mutex ，抢到互斥锁的那个进程注册 listenfd 读事件 ，在读事件里调用 accept 接受该连接。</p> \n <p>当一个 worker 进程在 accept 这个连接之后，就开始读取请求、解析请求、处理请求，产生数据后，再返回给客户端 ，最后才断开连接。这样一个完整的请求就是这样的了。我们可以看到，一个请求，完全由 worker 进程来处理，而且只在一个 worker 进程中处理。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/993151b4b04b09b25f8472087adcb422.png\" alt=\"\"></p> \n <p>在 Nginx 服务器的运行过程中， 主进程和工作进程 需要进程交互。交互依赖于 Socket 实现的管道来实现。</p> \n <h2><a id=\"Nginx_384\"></a>聊聊：请列举Nginx服务器的最佳用途。</h2> \n <p>Nginx服务器的最佳用法是在网络上部署动态HTTP内容，使用SCGI、WSGI应用程序服务器、用于脚本的FastCGI处理程序。</p> \n <p>它还可以作为负载均衡器。</p> \n <h2><a id=\"Nginx_394\"></a>聊聊：Nginx负载均衡实现过程</h2> \n <p>首先在http模块中配置使用upstream模块定义后台的webserver的池子，并且给池子命名， 比如命名为proxy-web，</p> \n <p>在池子中我们可以添加多台后台webserver，其中状态检查、调度算法都是在池子中配置；</p> \n <p>然后在server模块中定义虚拟 location 地址，但是这个虚拟location 地址 不指定自己的web目录站点，</p> \n <p>它将使用location 匹配url然后转发到上面定义好的web池子中，</p> \n <p>后台的webserver的池子，最后根据调度策略再转发到后台web server上。</p> \n <h2><a id=\"Nginx_408\"></a>聊聊：Nginx负载均衡配置</h2> \n <pre><code class=\"prism language-bash\">Upstream proxy_nginx <span class=\"token punctuation\">{\n    <!-- --></span>\n	server <span class=\"token number\">192.168</span>.0.254 <span class=\"token assign-left variable\">weight</span><span class=\"token operator\">=</span>1max_fails<span class=\"token operator\">=</span><span class=\"token number\">2</span> <span class=\"token assign-left variable\">fail_timeout</span><span class=\"token operator\">=</span>10s <span class=\"token punctuation\">;</span> \n	server <span class=\"token number\">192.168</span>.0.253 <span class=\"token assign-left variable\">weight</span><span class=\"token operator\">=</span><span class=\"token number\">2</span> <span class=\"token assign-left variable\">max_fails</span><span class=\"token operator\">=</span>2fail_timeout<span class=\"token operator\">=</span>10s<span class=\"token punctuation\">;</span>\n	server192.168.0.252 backup<span class=\"token punctuation\">;</span> server192.168.0.251 down<span class=\"token punctuation\">;</span> \n<span class=\"token punctuation\">}</span>\n\nserver<span class=\"token punctuation\">{\n    <!-- --></span>\n	listen <span class=\"token number\">80</span><span class=\"token punctuation\">;</span>\n	server_name xiaoka.com<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\nlocation / <span class=\"token punctuation\">{\n    <!-- --></span>\n	proxy_pass http:// proxy_nginx<span class=\"token punctuation\">;</span>\n	proxy_set_header Host\n	proxy_set_header X-Real-IP\n	proxy_set_header X-Forwarded-For <span class=\"token variable\">$proxy_add_x_forwarded_for</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"nginx_432\"></a>聊聊：nginx的常用的负载均衡算法？</h2> \n <h4><a id=\"1roundrobin_434\"></a>1、round-robin</h4> \n <p>round-robin的意思是循环轮询。</p> \n <p>Nginx最简单的负载均衡配置如下</p> \n <pre><code class=\"prism language-bash\">http <span class=\"token punctuation\">{\n    <!-- --></span>\nupstream app1 <span class=\"token punctuation\">{\n    <!-- --></span>\n    server <span class=\"token number\">10.10</span>.10.1<span class=\"token punctuation\">;</span>\n    server <span class=\"token number\">10.10</span>.10.2<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\nserver <span class=\"token punctuation\">{\n    <!-- --></span>\n    listen <span class=\"token number\">80</span><span class=\"token punctuation\">;</span>\n    location / <span class=\"token punctuation\">{\n    <!-- --></span>\n        proxy_pass http://app1<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>upstream app1用来指定一个服务器组，该组的名字是app1，包含两台服务器。在指定服务器组里面包含的服务器时以形式“server ip/domain：port”的形式指定，其中80端口可以忽略。然后在接收到请求时通过“proxy_pass http://app1”把对应的请求转发到组app1上。Nginx默认的负载均衡算法就是循环轮询，如上配置我们采用的就是循环轮询，其会把接收到的请求循环的分发给其包含的（当前可用的）服务器。使用如上配置时，Nginx会把第1个请求给10.10.10.1，把第2个请求给10.10.10.2，第3个请求给10.10.10.1，以此类推。</p> \n <h4><a id=\"2leastconnected_456\"></a>2、least-connected</h4> \n <p>least-connected算法的中文翻译是最少连接，即每次都找连接数最少的服务器来转发请求。例如Nginx负载中有两台服务器，A和B，当Nginx接收到一个请求时，A正在处理的请求数是10，B正在处理的请求数是20，则Nginx会把当前请求交给A来处理。要启用最少连接负载算法只需要在定义服务器组时加上“least_conn”，如：</p> \n <pre><code class=\"prism language-bash\">upstream app1 <span class=\"token punctuation\">{\n    <!-- --></span>\n    least_conn<span class=\"token punctuation\">;</span>\n    server <span class=\"token number\">10.10</span>.10.1<span class=\"token punctuation\">;</span>\n    server <span class=\"token number\">10.10</span>.10.2<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h4><a id=\"3iphash_468\"></a>3、ip-hash</h4> \n <p>ip-hash算法会根据请求的客户端IP地址来决定当前请求应该交给谁。使用ip-hash算法时Nginx会确保来自同一客户端的请求都分发到同一服务器。要使用ip-hash算法时只需要在定义服务器组时加上“ip-hash ”指令，如：</p> \n <pre><code class=\"prism language-bash\">upstream app1 <span class=\"token punctuation\">{\n    <!-- --></span>\n    ip_hash<span class=\"token punctuation\">;</span>\n    server <span class=\"token number\">10.10</span>.10.1<span class=\"token punctuation\">;</span>\n    server <span class=\"token number\">10.10</span>.10.2<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h4><a id=\"4weighted_480\"></a>4、weighted</h4> \n <p>weighted算法也就是权重算法，会根据每个服务的权重来分发请求，权重大的请求相对会多分发一点，权重小的会少分发一点。这通常应用于多个服务器的性能不一致时。需要使用权重算法时只需要在定义服务器组时在服务器后面指定参数weight，如：</p> \n <pre><code class=\"prism language-bash\">upstream app1 <span class=\"token punctuation\">{\n    <!-- --></span>\n    server <span class=\"token number\">10.10</span>.10.1 <span class=\"token assign-left variable\">weight</span><span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">;</span>\n    server <span class=\"token number\">10.10</span>.10.2<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"Nginx__493\"></a>聊聊：Nginx 有哪些负载均衡策略</h2> \n <p>Nginx 默认提供的负载均衡策略：</p> \n <h4><a id=\"1round_robin_497\"></a>1、轮询（默认）round_robin</h4> \n <p>每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 down 掉，能自动剔除。</p> \n <h4><a id=\"2IP__ip_hash_501\"></a>2、IP 哈希 ip_hash</h4> \n <p>每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决 session 共享的问题。</p> \n <p>当然，实际场景下，一般不考虑使用 ip_hash 解决 session 共享。</p> \n <h4><a id=\"3_least_conn_507\"></a>3、最少连接 least_conn</h4> \n <p>下一个请求将被分派到活动连接数量最少的服务器</p> \n <h4><a id=\"4_weight_511\"></a>4、权重 weight</h4> \n <p>weight的值越大分配到的访问概率越高，主要用于后端每台服务器性能不均衡的情况下，达到合理的资源利用率。 还可以通过插件支持其他策略。</p> \n <h2><a id=\"ngx_http_upstream_module_515\"></a>聊聊：ngx_http_upstream_module的作用是什么?</h2> \n <p>ngx_http_upstream_module用于定义可通过fastcgi传递、proxy传递、uwsgi传递、memcached传递和scgi传递指令来引用的服务器组。</p> \n <h3><a id=\"Nginx_521\"></a>聊聊：Nginx配置高可用性怎么配置？</h3> \n <ul>\n  <li>当上游服务器(真实访问服务器)，一旦出现故障或者是没有及时相应的话，应该直接轮训到下一台服务器，保证服务器的高可用</li>\n  <li>Nginx配置代码：</li>\n </ul> \n <pre><code class=\"prism language-bash\">server <span class=\"token punctuation\">{\n    <!-- --></span>\n    listen       <span class=\"token number\">80</span><span class=\"token punctuation\">;</span>\n    server_name  www.lijie.com<span class=\"token punctuation\">;</span>\n    location / <span class=\"token punctuation\">{\n    <!-- --></span>\n        <span class=\"token comment\">### 指定上游服务器负载均衡服务器</span>\n        proxy_pass http://backServer<span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">###nginx与上游服务器(真实访问的服务器)超时时间 后端服务器连接的超时时间_发起握手等候响应超时时间</span>\n        proxy_connect_timeout 1s<span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">###nginx发送给上游服务器(真实访问的服务器)超时时间</span>\n        proxy_send_timeout 1s<span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">### nginx接受上游服务器(真实访问的服务器)超时时间</span>\n        proxy_read_timeout 1s<span class=\"token punctuation\">;</span>\n        index  index.html index.htm<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"Nginx_548\"></a>聊聊：Nginx为什么不使用多线程？</h2> \n <h4><a id=\"apache_550\"></a>apache:</h4> \n <p>创建多个进程或线程，而每个进程或线程都会为其分配cpu和内存（线程要比进程小的多，所以worker支持比perfork高的并发），并发过大会榨干服务器资源。</p> \n <h4><a id=\"Nginx_554\"></a>Nginx:</h4> \n <p>采用单线程来异步非阻塞处理请求（管理员可以配置Nginx主进程的工作进程的数量）(epoll)，不会为每个请求分配cpu和内存资源，节省了大量资源，同时也减少了大量的CPU的上下文切换。</p> \n <p>所以才使得Nginx支持更高的并发。</p> \n <h2><a id=\"Nginx_560\"></a>聊聊：Nginx为什么不使用多线程？</h2> \n <p>答：</p> \n <p>Nginx:</p> \n <p>采用单线程来异步非阻塞处理请求（管理员可以配置Nginx主进程的工作进程的数量），</p> \n <p>不会为每个请求分配cpu和内存资源，节省了大量资源，同时也减少了大量的CPU的上下文切换，所以才使得Nginx支持更高的并发。</p> \n <h2><a id=\"Nginx_570\"></a>聊聊：Nginx主要特性</h2> \n <ol>\n  <li>支持SSL 和TLSSNI.<br> Nginx它支持内核Poll模型，能经受高负载的考验,有报告表明能支持高达50,000个并发连接数。</li>\n  <li>Nginx具有很高的稳定性。<br> 例如当前 apache一旦上到200个以上进程，web响应速度就明显非常缓慢了。而Nginx采取了分阶段资源分配技术，使得它的CPU与内存占用率非常低。nginx官方表示保持10,000个没有活动的连接，它只占2.5M内存，所以类似DOS这样的攻击对nginx来说基本上是毫无用处的。</li>\n  <li>Nginx支持热部署。<br> 它的启动特别容易，并且几乎可以做到7*24不间断运行，即使运行数个月也不需要重新启动。对软件版本进行进行热升级。</li>\n  <li>Nginx采用master-slave模型,能够充分利用SMP的优势，且能够减少工作进程在磁盘IO的阻塞延迟。<br> 当采用select()/poll()调用时，还可以限制每个进程的连接数。</li>\n  <li>Nginx采用master-slave模型,能够充分利用SMP的优势，且能够减少工作进程在磁盘IO的阻塞延迟。<br> 当采用select()/poll()调用时，还可以限制每个进程的连接数。</li>\n  <li>Nginx采用了一些os提供的最新特性如对sendfile (Linux2.2+)， accept-filter<br> (FreeBSD4.1+)，TCP_DEFER_ACCEPT (Linux 2.4+)的支持,从而大大提高了性能。</li>\n  <li>免费开源，可以做高并发负载均衡。</li>\n </ol> \n <h2><a id=\"Nginx_592\"></a>聊聊：Nginx常用命令</h2> \n <h4><a id=\"1_594\"></a>1、启动</h4> \n <pre><code class=\"prism language-bash\">nginx\n</code></pre> \n <h4><a id=\"2_600\"></a>2、停止</h4> \n <pre><code class=\"prism language-bash\">nginx <span class=\"token parameter variable\">-s</span> stop \n或\nnginx <span class=\"token parameter variable\">-s</span> quit\n</code></pre> \n <h4><a id=\"3_608\"></a>3、重载配置</h4> \n <pre><code class=\"prism language-bash\">./sbin/nginx <span class=\"token parameter variable\">-s</span> reload<span class=\"token punctuation\">(</span>平滑重启 <span class=\"token punctuation\">)</span> \n或\n<span class=\"token function\">service</span> nginx reload\n</code></pre> \n <h4><a id=\"4_616\"></a>4、重载指定配置文件</h4> \n <pre><code class=\"prism language-shell\">.nginx <span class=\"token parameter variable\">-c</span> /usr/local/nginx/conf/nginx.conf\n</code></pre> \n <h4><a id=\"5_622\"></a>5、查看版本</h4> \n <pre><code class=\"prism language-shell\">nginx <span class=\"token parameter variable\">-v</span>\n</code></pre> \n <h4><a id=\"6_628\"></a>6、检查配置文件是否正确</h4> \n <pre><code class=\"prism language-shell\">nginx <span class=\"token parameter variable\">-t</span>\n</code></pre> \n <h4><a id=\"7_634\"></a>7、显示帮助命令</h4> \n <pre><code class=\"prism language-shell\">nginx <span class=\"token parameter variable\">-h</span>\n</code></pre> \n <h2><a id=\"Nginx_IO_642\"></a>聊聊：Nginx IO事件模型以及连接数上限</h2> \n <pre><code class=\"prism language-powershell\">events <span class=\"token punctuation\">{\n    <!-- --></span>\n    use epoll<span class=\"token punctuation\">;</span> <span class=\"token comment\">#epoll 是多路复⽤ IO(I/O Multiplexing)中的⼀种⽅式,但是仅⽤于 linux2.6 </span>\n    <span class=\"token comment\">#以上内核,可以⼤⼤提⾼ nginx 的性能</span>\n    worker_connections 1024<span class=\"token punctuation\">;</span><span class=\"token comment\">#单个后台 worker process 进程的最⼤并发链接数</span>\n    <span class=\"token comment\"># multi_accept on; </span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"_655\"></a>聊聊：动态资源、静态资源分离的原因</h2> \n <p>动态资源、静态资源分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，</p> \n <p>动静资源做好了拆分以后，我们就可以根据静态资源的特点将其做缓存操作，这就是网站静态化处理的核心思路</p> \n <p>动态资源、静态资源分离简单的概括是：动态文件与静态文件的分离</p> \n <p>二者分离的原因<br> 在我们的软件开发中，</p> \n <ul>\n  <li>有些请求是需要后台处理的（如：.jsp,.do等等），</li>\n  <li>有些请求是不需要经过后台处理的（如：css、html、jpg、js等等文件）</li>\n </ul> \n <p>这些不需要经过后台处理的文件称为静态文件，否则动态文件。</p> \n <p>因此我们后台处理忽略静态文件。这会有人又说那我后台忽略静态文件不就完了吗</p> \n <p>当然这是可以的，但是这样后台的请求次数就明显增多了。</p> \n <p>在我们对资源的响应速度有要求的时候，我们应该使用这种动静分离的策略去解决</p> \n <p>动、静分离将网站静态资源（HTML，JavaScript，CSS，img等文件）与后台应用分开部署，提高用户访问静态代码的速度，降低对后台应用访问</p> \n <p>这里我们将静态资源放到nginx中，动态资源转发到tomcat服务器中</p> \n <h2><a id=\"Nginx_685\"></a>聊聊：Nginx怎么做的动静分离？</h2> \n <p>只需要指定路径对应的目录。</p> \n <p>location/可以使用正则表达式匹配。并指定对应的硬盘中的目录。如下：</p> \n <pre><code class=\"prism language-bash\">location /image/ <span class=\"token punctuation\">{\n    <!-- --></span>\n    root /usr/local/static/<span class=\"token punctuation\">;</span>\n    autoindex on<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>创建目录</p> \n <pre><code class=\"prism language-bash\"><span class=\"token function\">mkdir</span> /usr/local/static/image\n</code></pre> \n <p>进入目录</p> \n <pre><code class=\"prism language-bash\"><span class=\"token builtin class-name\">cd</span> /usr/local/static/image\n</code></pre> \n <p>放一张照片上去</p> \n <pre><code class=\"prism language-bash\"><span class=\"token number\">1</span>.jpg\n</code></pre> \n <p>重启 nginx</p> \n <p>sudo nginx -s reload</p> \n <p>打开浏览器 输入 server_name/image/1.jpg 就可以访问该静态图片了</p> \n <h2><a id=\"_724\"></a>聊聊：什么是动静分离？</h2> \n <p>动静分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后，我们就可以根据静态资源的特点将其做缓存操作，这就是网站静态化处理的核心思路，实际上，何谓动？何谓静呢？拿我们 Java 来说 jsp、servlet 等就是动，因为他们离开我们的 web 服务器的支持就会无法正常工作。而 js、css 等文件就是静了。因为离开 web 服务器他一样能正常的工作。</p> \n <p>动静分离简单的概括是：动态文件与静态文件的分离。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/20e01a98a2284acc885cb6e43d55b9c7.png\" alt=\"Nginx动静分离\"></p> \n <h2><a id=\"Nginx_736\"></a>聊聊：Nginx动静态资源分离做过吗，为什么要这样做？</h2> \n <p>动态资源、静态资源分离，是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来。</p> \n <p>比如说 js、css、hrml从A服务器返回。图片从B服务器返回，其他请求从Tomcat服务器C返回。</p> \n <p>后台应用分开部署，提高用户访问静态代码的速度。而且现在还有CDN服务，不需要限制于服务器的带宽。</p> \n <h2><a id=\"Nginx_746\"></a>聊聊：Nginx如何做动静分离</h2> \n <p>Nginx 根据客户端请求的 url 来判断请求的是否是静态资源，如果请求的 url 包含 jpg、png，则由 Nginx 处理。如果请求的 url 是 .php 或者 .jsp 等等，这个时候这个请求是动态的，将转发给 tomcat 处理。</p> \n <p>总结来说，Nginx 是通过 url 来区分请求的类型，并转发给不同的服务端。</p> \n <h2><a id=\"Nginx_754\"></a>聊聊：Nginx动静分离的好处</h2> \n <ul>\n  <li>api 接口服务化：动静分离之后，后端应用更为服务化，只需要通过提供 api 接口即可，可以为多个功能模块甚至是多个平台的功能使用，可以有效的节省后端人力，更便于功能维护。</li>\n  <li>前后端开发并行：前后端只需要关心接口协议即可，各自的开发相互不干扰，并行开发，并行自测，可以有效的提高开发时间，也可以有些的减少联调时间</li>\n  <li>减轻后端服务器压力，提高静态资源访问速度：后端不用再将模板渲染为 html 返回给用户端，且静态服务器可以采用更为专业的技术提高静态资源的访问速度。</li>\n </ul> \n <h2><a id=\"Nginx__ApacheTomcat__764\"></a>聊聊：Nginx 和 Apache、Tomcat 之间的不同点</h2> \n <p><strong>Tomcat 和Nginx/Apache区别：</strong></p> \n <p>1、Nginx/Apache 是Web Server,而Apache Tomact是一个servlet container</p> \n <p>2、tomcat可以对jsp进行解析，nginx和apache只是web服务器，可以简单理解为只能提供html静态文件服务。</p> \n <p><strong>Nginx和Apache区别：</strong></p> \n <p>1）Nginx轻量级，同样起web 服务，比apache占用更少的内存及资源 。</p> \n <p>2）Nginx 抗并发，nginx 处理请求是异步非阻塞的，而apache 则是阻塞型的，在高并发下nginx 能保持低资源低消耗高性能 。</p> \n <p>3）Nginx提供负载均衡，可以做做反向代理，前端服务器</p> \n <p>4）Nginx多进程单线程，异步非阻塞；Apache多进程同步，阻塞。</p> \n <h2><a id=\"NginxApache__784\"></a>聊聊：Nginx和Apache 之间的不同点</h2> \n <table>\n  <thead>\n   <tr>\n    <th>nginx</th>\n    <th>apache</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>1.nginx 是一个基于web服务器</td>\n    <td>1.Apache 是一个基于流程的服务器</td>\n   </tr>\n   <tr>\n    <td>2.所有请求都由一个线程来处理</td>\n    <td>2.单线程处理单个请求</td>\n   </tr>\n   <tr>\n    <td>3.nginx避免子进程的概念</td>\n    <td>3.apache是基于子进程的</td>\n   </tr>\n   <tr>\n    <td>4.nginx类似于速度</td>\n    <td>4.apache类似于功率</td>\n   </tr>\n   <tr>\n    <td>5.nginx在内存消耗和连接方面比较好</td>\n    <td>5.apache在内存消耗和连接方面并没有提高</td>\n   </tr>\n   <tr>\n    <td>6.nginx在负载均衡方面表现较好</td>\n    <td>6.apache当流量达到进程的极限时，apache将拒绝新的连接</td>\n   </tr>\n   <tr>\n    <td>7.对于PHP来说，nginx更可取，因为他支持PHP</td>\n    <td>7.apache支持的php python Perl和其他语言，使用插件，当应用程序基于python和ruby时，它非常有用</td>\n   </tr>\n   <tr>\n    <td>8.nginx 不支持像ibmi 和 openvms 一样的os</td>\n    <td>8.apache支持更多的os</td>\n   </tr>\n   <tr>\n    <td>9.nginx 只具有核心功能</td>\n    <td>9.apache 提供了比Nginx更多的功能</td>\n   </tr>\n   <tr>\n    <td>10.nginx 性能和可伸缩性不依赖于硬件</td>\n    <td>10.apache 依赖于CPU和内存等硬件组件</td>\n   </tr>\n  </tbody>\n </table> \n <h2><a id=\"NginxApache_803\"></a>聊聊：Nginx与Apache对比</h2> \n <h3><a id=\"_805\"></a>优点</h3> \n <ol>\n  <li>轻量级，采用 C 语言 进行编写，同样的 web 服务，会占用更少的内存及资源。</li>\n  <li>抗并发，nginx 以 epoll and kqueue 作为开发模型，处理请求是异步非阻塞的，多个连接对应一个进程，负载能力比 apache 高很多，而 apache 则是同步多进程模型，只能一个连接对应一个进程，当压力过大时，它是会被阻塞型的。<br> 在高并发下 nginx 能保持低资源低消耗高性能 ，而 apache 在 PHP 处理慢或者前端压力很大的情况下，很容易出现进程数飙升，从而拒绝服务的现象。</li>\n  <li>设计高度模块化，编写模块相对简单。</li>\n  <li>配置简洁，正则配置让很多事情变得简单，而且改完配置能使用 -t 测试配置有没有问题，apache 配置复杂 ，重启的时候发现配置出错了，会很崩溃。</li>\n  <li>一般用于处理静态文件，静态处理性能比 apache 高三倍以上。</li>\n  <li>作为负载均衡服务器，支持 7 层负载均衡。</li>\n  <li>本身就是一个反向代理服务器，而且可以作为非常优秀的邮件代理服务器。</li>\n  <li>nginx 启动特别容易, 并且几乎可以做到 7*24 不间断运行，即使运行数个月也不需要重新启动，支持热部署，比如：实现不间断服务的情况下进行软件版本的升级与版本的回退。</li>\n  <li>社区活跃，各种高性能模块出品迅速。</li>\n </ol> \n <h3><a id=\"_818\"></a>缺点</h3> \n <ol>\n  <li>apache 的 rewrite 比 nginx 强大，在 rewrite 频繁的情况下，用 apache。</li>\n  <li>apache 发展到现在，模块超多，基本想到的都可以找到。</li>\n  <li>apache 更为成熟，少 bug ，nginx 的 bug 相对较多。</li>\n  <li>apache 超稳定，Nginx 一个进程死掉时，会影响到多个用户的使用，稳定性差。</li>\n  <li>apache 对 PHP 支持比较简单，nginx 需要配合其他后端用。</li>\n  <li>apache 在处理动态请求有优势，nginx 在这方面是鸡肋，一般动态请求要 apache 去做，nginx 适合静态和反向。</li>\n  <li>apache 仍然是目前的主流，拥有丰富的特性，成熟的技术和开发社区。</li>\n </ol> \n <h2><a id=\"NginxApache_830\"></a>聊聊：Nginx与Apache选择</h2> \n <h3><a id=\"Apache_832\"></a>Apache</h3> \n <p>●　apache 的 rewrite 比 <strong>nginx</strong> 强大，在 rewrite 频繁的情况下，用 apache</p> \n <p>●　apache 发展到现在，模块超多，基本想到的都可以找到</p> \n <p>●　apache 更为成熟，少 bug ，nginx 的 bug 相对较多</p> \n <p>●　apache 超稳定</p> \n <p>●　apache 对 <strong>PHP</strong> 支持比较简单，nginx 需要配合其他后端用</p> \n <p>●　apache 在处理动态请求有优势，nginx 在这方面是鸡肋，一般动态请求要 apache 去做，nginx 适合静态和反向。</p> \n <p>●　apache 仍然是目前的主流，拥有丰富的特性，成熟的技术和开发社区</p> \n <h3><a id=\"Nginx_850\"></a>Nginx</h3> \n <p>●　轻量级，采用 C 语言 进行编写，同样的 web 服务，会占用更少的内存及资源</p> \n <p>●　抗并发，nginx 以 epoll and kqueue 作为开发模型，处理请求是异步非阻塞的，负载能力比 apache 高很多，而 apache 则是阻塞型的。在高并发下 nginx 能保持低资源低消耗高性能 ，而 apache 在 PHP 处理慢或者前端压力很大的情况下，很容易出现进程数飙升，从而拒绝服务的现象。</p> \n <p>●　nginx 处理静态文件好，静态处理性能比 apache 高三倍以上</p> \n <p>●　nginx 的设计高度模块化，编写模块相对简单</p> \n <p>●　nginx 配置简洁，正则配置让很多事情变得简单，而且改完配置能使用 -t 测试配置有没有问题，apache 配置复杂 ，重启的时候发现配置出错了，会很崩溃</p> \n <p>●　nginx 作为负载均衡服务器，支持 7 层负载均衡</p> \n <p>●　nginx 本身就是一个反向代理服务器，而且可以作为非常优秀的邮件代理服务器</p> \n <p>●　启动特别容易, 并且几乎可以做到 7*24 不间断运行，即使运行数个月也不需要重新启动，还能够不间断服务的情况下进行软件版本的升级</p> \n <p>●　社区活跃，各种高性能模块出品迅速</p> \n <h2><a id=\"NginxHTTP_874\"></a>聊聊：Nginx如何处理HTTP请求。</h2> \n <p>Nginx使用反应器模式。</p> \n <p>主事件循环等待操作系统发出准备事件的信号，这样数据就可以从套接字读取，在该实例中读取到缓冲区并进行处理。</p> \n <p>单个线程可以提供数万个并发连接。</p> \n <h2><a id=\"Nginx_884\"></a>聊聊：Nginx是如何处理一个请求的呢？</h2> \n <p>首先，nginx在启动时，会解析配置文件，得到需要监听的端口与ip地址，</p> \n <p>然后在nginx的master进程里面，先初始化好这个监控的socket，再进行listen</p> \n <p>然后再fork出多个子进程出来, 子进程会竞争accept新的连接。</p> \n <p>此时，客户端就可以向nginx发起连接了。</p> \n <p>当客户端与nginx进行三次握手，与nginx建立好一个连接后，</p> \n <p>此时，某一个子进程会accept成功，然后创建nginx对连接的封装，即ngx_connection_t结构体，</p> \n <p>接着，根据事件调用相应的事件处理模块，如http模块与客户端进行数据的交换，</p> \n <p>最后，nginx或客户端来主动关掉连接，到此，一个连接就寿终正寝了</p> \n <h2><a id=\"NginxHTTP_11__906\"></a>聊聊：Nginx处理HTTP请求过程的 11 个阶段？</h2> \n <p>Nginx 处理 HTTP 请求的过程大概可以分为 11 个阶段，如下：</p> \n <ol>\n  <li>Read Request Headers：解析请求头。</li>\n  <li>Identify Configuration Block：识别由哪一个 location 进行处理，匹配 URL。</li>\n  <li>Apply Rate Limits：判断是否限速。例如可能这个请求并发的连接数太多超过了限制，或者 QPS 太高。</li>\n  <li>Perform Authentication：连接控制，验证请求。例如可能根据 Referrer 头部做一些防盗链的设置，或者验证用户的权限。</li>\n  <li>Generate Content：生成返回给用户的响应。为了生成这个响应，做反向代理的时候可能会和上游服务（Upstream Services）进行通信，然后这个过程中还可能会有些子请求或者重定向，那么还会走一下这个过程（Internal redirects and subrequests）。</li>\n  <li>Response Filters：过滤返回给用户的响应。比如压缩响应，或者对图片进行处理。</li>\n  <li>Log：记录日志。</li>\n </ol> \n <p>以上这七个步骤从整体上介绍了一下处理流程，下面还会再说一下实际的处理过程。</p> \n <h2><a id=\"NginxHTTP11_924\"></a>聊聊：Nginx处理HTTP请求的11个阶段</h2> \n <p>下面介绍一下详细的 11 个阶段，每个阶段都可能对应着一个甚至多个 HTTP 模块，通过这样一个模块对比，我们也能够很好的理解这些模块具体是怎么样发挥作用的。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/008e26c6502d4ab99da4290c9ea9d9ba.png\" alt=\"Nginx处理HTTP请求过程.png\"></p> \n <ol>\n  <li>POST_READ：在 read 完请求的头部之后，在没有对头部做任何处理之前，想要获取到一些原始的值，就应该在这个阶段进行处理。这里面会涉及到一个 realip 模块。</li>\n  <li>SERVER_REWRITE：和下面的 REWRITE 阶段一样，都只有一个模块叫 rewrite 模块，一般没有第三方模块会处理这个阶段。</li>\n  <li>FIND_CONFIG：做 location 的匹配，暂时没有模块会用到。</li>\n  <li>REWRITE：对 URL 做一些处理。</li>\n  <li>POST_WRITE：处于 REWRITE 之后，也是暂时没有模块会在这个阶段出现。</li>\n </ol> \n <p>接下来是确认用户访问权限的三个模块：</p> \n <ol>\n  <li>PREACCESS：是在 ACCESS 之前要做一些工作，例如并发连接和 QPS 需要进行限制，涉及到两个模块：limt_conn 和 limit_req</li>\n  <li>ACCESS：核心要解决的是用户能不能访问的问题，例如 auth_basic 是用户名和密码，access 是用户访问 IP，auth_request 根据第三方服务返回是否可以去访问。</li>\n  <li>POST_ACCESS：是在 ACCESS 之后会做一些事情，同样暂时没有模块会用到。</li>\n </ol> \n <p>最后的三个阶段处理响应和日志：</p> \n <ol>\n  <li>PRECONTENT：在处理 CONTENT 之前会做一些事情，例如会把子请求发送给第三方的服务去处理，try_files 模块也是在这个阶段中。</li>\n  <li>CONTENT：这个阶段涉及到的模块就非常多了，例如 index, autoindex, concat 等都是在这个阶段生效的。</li>\n  <li>LOG：记录日志 access_log 模块。</li>\n </ol> \n <p>以上的这些阶段都是严格按照顺序进行处理的，当然，每个阶段中各个 HTTP 模块的处理顺序也很重要，如果某个模块不把请求向下传递，后面的模块是接收不到请求的。</p> \n <p>而且每个阶段中的模块也不一定所有都要执行一遍，下面就接着讲一下各个阶段模块之间的请求顺序。</p> \n <h2><a id=\"NginxHTTP11_952\"></a>聊聊：Nginx处理HTTP请求的11个阶段的顺序处理</h2> \n <p>如下图所示，每一个模块处理之间是有序的，那么这个顺序怎么才能得到呢？其实非常简单，在源码 ngx_module.c 中，有一个数组 ngx_module_name，其中包含了在编译 Nginx 的时候的 with 指令所包含的所有模块，它们之间的顺序非常关键，在数组中顺序是相反的。</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">char</span> <span class=\"token operator\">*</span>ngx_module_names<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n    … …\n    <span class=\"token string\">\"ngx_http_static_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_autoindex_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_index_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_random_index_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_mirror_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_try_files_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_auth_request_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_auth_basic_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_access_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_limit_conn_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_limit_req_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_realip_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_referer_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_rewrite_module\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ngx_http_concat_module\"</span><span class=\"token punctuation\">,</span>\n    … …\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>灰色部分的模块是 Nginx 的框架部分去执行处理的，第三方模块没有机会在这里得到处理。</p> \n <p>在依次向下执行的过程中，也可能不按照这样的顺序。例如，在 access 阶段中，有一个指令叫 satisfy，它可以指示当有一个满足的时候就直接跳到下一个阶段进行处理，例如当 access 满足了，就直接跳到 try_files 模块进行处理，而不会再执行 auth_basic、auth_request 模块。</p> \n <p>在 content 阶段中，当 index 模块执行了，就不会再执行 auto_index 模块，而是直接跳到 log 模块。整个 11 个阶段所涉及到的模块和先后顺序如下图所示：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/f505b315ebc34be3bbc420c3a12fa9d2.png\" alt=\"Nginx处理HTTP请求过程.png\"></p> \n <h2><a id=\"Nginxnginxconf_990\"></a>聊聊：Nginx配置文件nginx.conf有哪些属性模块?</h2> \n <pre><code class=\"prism language-bash\">worker_processes  <span class=\"token number\">1</span>；                					<span class=\"token comment\"># worker进程的数量</span>\nevents <span class=\"token punctuation\">{\n    <!-- --></span>                              					<span class=\"token comment\"># 事件区块开始</span>\n    worker_connections  <span class=\"token number\">1024</span>；            				<span class=\"token comment\"># 每个worker进程支持的最大连接数</span>\n<span class=\"token punctuation\">}</span>                                    					<span class=\"token comment\"># 事件区块结束</span>\nhttp <span class=\"token punctuation\">{\n    <!-- --></span>                               					<span class=\"token comment\"># HTTP区块开始</span>\n    include       mime.types；            				<span class=\"token comment\"># Nginx支持的媒体类型库文件</span>\n    default_type  application/octet-stream；     		<span class=\"token comment\"># 默认的媒体类型</span>\n    sendfile        on；       							<span class=\"token comment\"># 开启高效传输模式</span>\n    keepalive_timeout  <span class=\"token number\">65</span>；       						<span class=\"token comment\"># 连接超时</span>\n    server <span class=\"token punctuation\">{\n    <!-- --></span>            								<span class=\"token comment\"># 第一个Server区块开始，表示一个独立的虚拟主机站点</span>\n        listen       <span class=\"token number\">80</span>；      							<span class=\"token comment\"># 提供服务的端口，默认80</span>\n        server_name  localhost；       					<span class=\"token comment\"># 提供服务的域名主机名</span>\n        location / <span class=\"token punctuation\">{\n    <!-- --></span>            						<span class=\"token comment\"># 第一个location区块开始</span>\n            root   html；       						<span class=\"token comment\"># 站点的根目录，相当于Nginx的安装目录</span>\n            index  index.html index.htm；      			<span class=\"token comment\"># 默认的首页文件，多个用空格分开</span>\n        <span class=\"token punctuation\">}</span>          										<span class=\"token comment\"># 第一个location区块结果</span>\n        error_page   <span class=\"token number\">500502503504</span>  /50x.html；     		<span class=\"token comment\"># 出现对应的http状态码时，使用50x.html回应客户</span>\n        location <span class=\"token operator\">=</span> /50x.html <span class=\"token punctuation\">{\n    <!-- --></span>          				<span class=\"token comment\"># location区块开始，访问50x.html</span>\n            root   html；      							<span class=\"token comment\"># 指定对应的站点目录为html</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>  \n    <span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span>\n</code></pre> \n <h2><a id=\"Nginx_1019\"></a>聊聊：在Nginx中，如何使用未定义的服务器名称来阻止处理请求?</h2> \n <p>只需将请求删除的服务器, 可以定义为：</p> \n <pre><code class=\"prism language-bash\">Server <span class=\"token punctuation\">{\n    <!-- --></span>\n    listen <span class=\"token number\">80</span><span class=\"token punctuation\">;</span>\n    server_name “ “ <span class=\"token punctuation\">;</span>\n    <span class=\"token builtin class-name\">return</span> <span class=\"token number\">444</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>这里，服务器名被保留为一个空字符串，它将在没有“主机”头字段的情况下匹配请求，而一个特殊的Nginx的非标准代码444被返回，从而终止连接。</p> \n <h2><a id=\"Nginx_1035\"></a>聊聊：Nginx的进程模型</h2> \n <ol>\n  <li>master-worker模式<br> 在master-worker模式下，有一个master进程和至少一个的worker进程。</li>\n  <li>单进程模式。<br> 单进程模式只有一个进程。</li>\n </ol> \n <h2><a id=\"NginxMasterWorker_1044\"></a>聊聊：Nginx服务器上的Master和Worker进程分别是什么?</h2> \n <p>Master进程：读取及评估配置和维持</p> \n <p>Worker进程：处理请求</p> \n <h2><a id=\"Nginx_1052\"></a>聊聊：Nginx惊群</h2> \n <p>惊群效应（thundering herd）是指多进程（多线程）在同时阻塞等待同一个事件的时候（休眠状态），</p> \n <p>如果等待的这个事件发生，那么他就会唤醒等待的所有进程（或者线程），但是最终却只能有一个进程（线程）获得这个时间的 “控制权”，对该事件进行处理，</p> \n <p>而其他进程（线程）获取 “控制权” 失败，只能重新进入休眠状态，这种现象和性能浪费就叫做惊群效应。</p> \n <h2><a id=\"_1062\"></a>聊聊：惊群效应消耗了什么</h2> \n <p>Linux 内核对用户进程（线程）频繁地做无效的调度、上下文切换等使系统性能大打折扣。上下文切换（context switch）过高会导致 CPU 像个搬运工，频繁地在寄存器和运行队列之间奔波，更多的时间花在了进程（线程）切换，而不是在真正工作的进程（线程）上面。</p> \n <p>直接的消耗包括 CPU 寄存器要保存和加载（例如程序计数器）、系统调度器的代码需要执行。间接的消耗在于多核 cache 之间的共享数据。为了确保只有一个进程（线程）得到资源，需要对资源操作进行加锁保护，加大了系统的开销。目前一些常见的服务器软件有的是通过锁机制解决的，比如 Nginx（它的锁机制是默认开启的，可以关闭）；还有些认为惊群对系统性能影响不大，没有去处理，比如 Lighttpd。</p> \n <h2><a id=\"Nginx__1070\"></a>聊聊：Nginx惊群效应? 以及解决方案</h2> \n <p>对于 Nginx 的惊群问题，我们首先需要理解的是，在 Nginx 启动过程中，master 进程会监听配置文件中指定的各个端口，然后 master 进程就会调用 fork() 方法创建各个子进程，根据进程的工作原理，子进程是会继承父进程的全部内存数据以及监听的端口的，也就是说 worker 进程在启动之后也是会监听各个端口的。</p> \n <p>关于惊群，指的就是当客户端有新建连接的请求到来时，就会触发各个 worker 进程的连接建立事件，但是只有一个 worker 进程能够正常处理该事件，而其他的 worker 进程会发现事件已经失效，从而重新循环进入等待状态。这种由于一个事件而 “惊” 起了所有 worker 进程的现象就是惊群问题。很明显，如果所有的 worker 进程都被触发了，那么这将消耗大量的资源。</p> \n <h3><a id=\"_1076\"></a>解决方案</h3> \n <p>在 Nginx 中，每个 worker 进程被创建的时候，都会调用 ngx_worker_process_init() 方法初始化当前 worker 进程，这个过程中有一个非常重要的步骤，即每个 worker 进程都会调用 epoll_create() 方法为自己创建一个独有的 epoll 句柄。</p> \n <p>对于每一个需要监听的端口，都有一个文件描述符与之对应，而 worker 进程只有将该文件描述符通过 epoll_ctl() 方法添加到当前进程的 epoll 句柄中，并且监听 accept 事件，此时才会被客户端的连接建立事件触发，从而处理该事件。从这里也可以看出，worker 进程如果没有将所需要监听的端口对应的文件描述符添加到该进程的 epoll 句柄中，那么其是无法被触发对应的事件的。</p> \n <p>基于这个原理，nginx 就使用了一个共享锁来控制当前进程是否有权限将需要监听的端口添加到当前进程的 epoll 句柄中，也就是说，只有获取锁的进程才会监听目标端口。通过这种方式，就保证了每次事件发生时，只有一个 worker 进程会被触发。如下图所示为 worker 进程工作循环的一个示意图：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/0bbbdaaa2ce74bb1a57f6f34acd8232c.png\" alt=\"Nginx惊群\"></p> \n <p>这里关于图中的流程，需要说明的一点是，每个 worker 进程在进入循环之后就会尝试获取共享锁，如果没有获取到，就会将所监听的端口的文件描述符从当前进程的 epoll 句柄中移除（即使并不存在也会移除），这么做的主要目的是防止丢失客户端连接事件，即使这可能造成少量的惊群问题，但是并不严重。</p> \n <p>试想一下，如果按照理论，在当前进程释放锁的时候就将监听的端口的文件描述符从 epoll 句柄中移除，那么在下一个 worker 进程获取锁之前，这段时间各个端口对应的文件描述符是没有任何 epoll 句柄进行监听的，此时就会造成事件的丢失。如果反过来，按照图中的在获取锁失败的时候才移除监听的文件描述符，由于获取锁失败，则说明当前一定有一个进程已经监听了这些文件描述符，因而此时移除是安全的。</p> \n <p>但是这样会造成的一个问题是，按照上图，当前进程在一个循环执行完毕的时候，会释放锁，然后处理其他的事件，注意这个过程中其是没有释放所监听的文件描述符的。此时，如果另一个进程获取到了锁，并且监听了文件描述符，那么这个时候就有两个进程监听了文件描述符，因而此时如果客户端发生连接建立事件，那么就会触发两个 worker 进程。这个问题是可以容忍的，主要原因有两点：</p> \n <ul>\n  <li>这个时候发生的惊群现象只触发了更少的 worker 进程，比起每次都惊起所有的 worker 进程要好很多；</li>\n  <li>会发生这种惊群问题的主要原因是，当前进程释放了锁，但是没有释放所监听的文件描述符，但是 worker 进程在释放锁之后主要是处理客户端连接的读写事件和检查标志位，这个过程是非常短的，在处理完之后，其就会尝试获取锁，这个时候就会释放所监听的文件描述符了，而相较而言，获取锁的 worker 进程在等待处理客户端的连接建立事件的事件就更长了，因而会发生惊群问题的概率还是比较小的。</li>\n </ul> \n <h3><a id=\"_1097\"></a>源码讲解</h3> \n <p>worker 进程初始事件的方法主要是在 ngx_process_events_and_timers() 方法中进行的，下面我们就来看看该方法是如何处理整个流程的，如下是该方法的源码：</p> \n <pre><code class=\"prism language-java\"><span class=\"token keyword\">void</span> <span class=\"token function\">ngx_process_events_and_timers</span><span class=\"token punctuation\">(</span>ngx_cycle_t <span class=\"token operator\">*</span>cycle<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n  ngx_uint_t flags<span class=\"token punctuation\">;</span>\n  ngx_msec_t timer<span class=\"token punctuation\">,</span> delta<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token function\">ngx_trylock_accept_mutex</span><span class=\"token punctuation\">(</span>cycle<span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token constant\">NGX_ERROR</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token keyword\">return</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token comment\">// 这里开始处理事件，对于kqueue模型，其指向的是ngx_kqueue_process_events()方法，</span>\n  <span class=\"token comment\">// 而对于epoll模型，其指向的是ngx_epoll_process_events()方法</span>\n  <span class=\"token comment\">// 这个方法的主要作用是，在对应的事件模型中获取事件列表，然后将事件添加到ngx_posted_accept_events</span>\n  <span class=\"token comment\">// 队列或者ngx_posted_events队列中</span>\n  <span class=\"token punctuation\">(</span><span class=\"token keyword\">void</span><span class=\"token punctuation\">)</span> <span class=\"token function\">ngx_process_events</span><span class=\"token punctuation\">(</span>cycle<span class=\"token punctuation\">,</span> timer<span class=\"token punctuation\">,</span> flags<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token comment\">// 这里开始处理accept事件，将其交由ngx_event_accept.c的ngx_event_accept()方法处理；</span>\n  <span class=\"token function\">ngx_event_process_posted</span><span class=\"token punctuation\">(</span>cycle<span class=\"token punctuation\">,</span> <span class=\"token operator\">&amp;</span>ngx_posted_accept_events<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token comment\">// 开始释放锁</span>\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>ngx_accept_mutex_held<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token function\">ngx_shmtx_unlock</span><span class=\"token punctuation\">(</span><span class=\"token operator\">&amp;</span>ngx_accept_mutex<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token comment\">// 如果不需要在事件队列中进行处理，则直接处理该事件</span>\n  <span class=\"token comment\">// 对于事件的处理，如果是accept事件，则将其交由ngx_event_accept.c的ngx_event_accept()方法处理；</span>\n  <span class=\"token comment\">// 如果是读事件，则将其交由ngx_http_request.c的ngx_http_wait_request_handler()方法处理；</span>\n  <span class=\"token comment\">// 对于处理完成的事件，最后会交由ngx_http_request.c的ngx_http_keepalive_handler()方法处理。</span>\n  <span class=\"token comment\">// 这里开始处理除accept事件外的其他事件</span>\n  <span class=\"token function\">ngx_event_process_posted</span><span class=\"token punctuation\">(</span>cycle<span class=\"token punctuation\">,</span> <span class=\"token operator\">&amp;</span>ngx_posted_events<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>	\n</code></pre> \n <p>上面的代码中，我们省略了大部分的检查工作，只留下了骨架代码。首先，worker 进程会调用 ngx_trylock_accept_mutex() 方法获取锁，这其中如果获取到了锁就会监听各个端口对应的文件描述符。然后会调用 ngx_process_events() 方法处理 epoll 句柄中监听到的事件。接着会释放共享锁，最后就是处理已建立连接的客户端的读写事件。下面我们来看一下 ngx_trylock_accept_mutex() 方法是如何获取共享锁的：</p> \n <pre><code class=\"prism language-java\">ngx_int_t <span class=\"token function\">ngx_trylock_accept_mutex</span><span class=\"token punctuation\">(</span>ngx_cycle_t <span class=\"token operator\">*</span>cycle<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n  <span class=\"token comment\">// 尝试使用CAS算法获取共享锁</span>\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token function\">ngx_shmtx_trylock</span><span class=\"token punctuation\">(</span><span class=\"token operator\">&amp;</span>ngx_accept_mutex<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token comment\">// ngx_accept_mutex_held为1表示当前进程已经获取到了锁</span>\n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>ngx_accept_mutex_held <span class=\"token operator\">&amp;&amp;</span> ngx_accept_events <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n      <span class=\"token keyword\">return</span> <span class=\"token constant\">NGX_OK</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token comment\">// 这里主要是将当前连接的文件描述符注册到对应事件的队列中，比如kqueue模型的change_list数组</span>\n    <span class=\"token comment\">// nginx在启用各个worker进程的时候，默认情况下，worker进程是会继承master进程所监听的socket句柄的，</span>\n    <span class=\"token comment\">// 这就导致一个问题，就是当某个端口有客户端事件时，就会把监听该端口的进程都给唤醒，</span>\n    <span class=\"token comment\">// 但是只有一个worker进程能够成功处理该事件，而其他的进程被唤醒之后发现事件已经过期，</span>\n    <span class=\"token comment\">// 因而会继续进入等待状态，这种现象称为\"惊群\"现象。</span>\n    <span class=\"token comment\">// nginx解决惊群现象的方式一方面是通过这里的共享锁的方式，即只有获取到锁的worker进程才能处理</span>\n    <span class=\"token comment\">// 客户端事件，但实际上，worker进程是通过在获取锁的过程中，为当前worker进程重新添加各个端口的监听事件，</span>\n    <span class=\"token comment\">// 而其他worker进程则不会监听。也就是说同一时间只有一个worker进程会监听各个端口，</span>\n    <span class=\"token comment\">// 这样就避免了\"惊群\"问题。</span>\n    <span class=\"token comment\">// 这里的ngx_enable_accept_events()方法就是为当前进程重新添加各个端口的监听事件的。</span>\n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token function\">ngx_enable_accept_events</span><span class=\"token punctuation\">(</span>cycle<span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token constant\">NGX_ERROR</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n      <span class=\"token function\">ngx_shmtx_unlock</span><span class=\"token punctuation\">(</span><span class=\"token operator\">&amp;</span>ngx_accept_mutex<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n      <span class=\"token keyword\">return</span> <span class=\"token constant\">NGX_ERROR</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token comment\">// 标志当前已经成功获取到了锁</span>\n    ngx_accept_events <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n    ngx_accept_mutex_held <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">return</span> <span class=\"token constant\">NGX_OK</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token comment\">// 前面获取锁失败了，因而这里需要重置ngx_accept_mutex_held的状态，并且将当前连接的事件给清除掉</span>\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>ngx_accept_mutex_held<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token comment\">// 如果当前进程的ngx_accept_mutex_held为1，则将其重置为0，并且将当前进程在各个端口上的监听</span>\n    <span class=\"token comment\">// 事件给删除掉</span>\n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token function\">ngx_disable_accept_events</span><span class=\"token punctuation\">(</span>cycle<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token constant\">NGX_ERROR</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n      <span class=\"token keyword\">return</span> <span class=\"token constant\">NGX_ERROR</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n    ngx_accept_mutex_held <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token keyword\">return</span> <span class=\"token constant\">NGX_OK</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>上面的代码中，本质上主要做了三件事：</p> \n <ol>\n  <li>通过 ngx_shmtx_trylock() 方法尝试使用CAS方法获取共享锁；</li>\n  <li>获取锁之后则调用 ngx_enable_accept_events() 方法监听目标端口对应的文件描述符；</li>\n  <li>如果没有获取到锁，则调用 ngx_disable_accept_events() 方法释放所监听的文件描述符；</li>\n </ol> \n <h3><a id=\"_1176\"></a>总结</h3> \n <p>惊群现象指所有的工作进程都在等待一个 socket，当 socket 客户端连接时，所有工作线程都被唤醒，但最终有且仅有一个工作线程去处理该连接，其他进程又要进入睡眠状态。</p> \n <p>Nginx 通过控制争抢处理 socket 的进程数量和抢占 ngx_accept_mutex 锁解决惊群现象。只有一个 ngx_accept_mutex 锁，谁拿到锁，谁处理该 socket 的请求。</p> \n <h2><a id=\"Nginx_IO_1184\"></a>聊聊：Nginx IO模型</h2> \n <p>Nginx 支持多种并发模型，并发模型的具体实现根据系统平台而有所不同。</p> \n <p>在支持多种并发模型的平台上，Nginx 自动选择最高效的模型。</p> \n <p>但我们也可以使用 use 指令在配置文件中显式地定义某个并发模型。</p> \n <h2><a id=\"Nginx_IO_1192\"></a>聊聊：Nginx IO模型</h2> \n <p>Nginx 支持多种并发模型，并发模型的具体实现根据系统平台而有所不同。在支持多种并发模型的平台上，Nginx 自动选择最高效的模型。但我们也可以使用 use 指令在配置文件中显式地定义某个并发模型。</p> \n <p>Nginx中支持的并发模型</p> \n <h3><a id=\"select_1198\"></a>select</h3> \n <p>IO 多路复用、标准并发模型。在编译 Nginx 时，如果所使用的系统平台没有更高效的并发模型，select 模块将被自动编译。configure 脚本的选项：–with-select_module 和 --without-select_module 可被用来强制性地开启或禁止 select 模块的编译。</p> \n <h3><a id=\"poll_1202\"></a>poll</h3> \n <p>IO 多路复用、标准并发模型。与 select 类似，在编译 Nginx 时，如果所使用的系统平台没有更高效的并发模型，poll 模块将被自动编译。configure 脚本的选项：–with-poll_module 和 --without-poll_module 可用于强制性地开启或禁止 poll 模块的编译。</p> \n <h3><a id=\"epoll_1206\"></a>epoll</h3> \n <p>IO 多路复用、高效并发模型，可在 Linux 2.6+ 及以上内核可以使用。</p> \n <h3><a id=\"kqueue_1210\"></a>kqueue</h3> \n <p>IO 多路复用、高效并发模型，可在 FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0, and Mac OS X 平台中使用。</p> \n <h3><a id=\"devpoll_1214\"></a>/dev/poll</h3> \n <p>高效并发模型，可在 Solaris 7 11/99+, HP/UX 11.22+ (eventport), IRIX 6.5.15+, and Tru64 UNIX 5.1A+ 平台使用。</p> \n <h3><a id=\"eventport_1218\"></a>eventport</h3> \n <p>高效并发模型，可用于 Solaris 10 平台，PS：由于一些已知的问题，建议使用/dev/poll替代。</p> \n <h2><a id=\"_epoll__Apache__select__Nginx__epoll_1222\"></a>聊聊：为什么 epoll 快，比较一下 Apache 常用的 select 和 Nginx 常用的 epoll：</h2> \n <h3><a id=\"select_1224\"></a>select</h3> \n <ol>\n  <li> <p>最大并发数限制，因为一个进程所打开的 FD （文件描述符）是有限制的，由 FD_SETSIZE 设置，默认值是 1024/2048，因此 Select 模型的最大并发数就被相应限制了。自己改改这个 FD_SETSIZE？ 想法虽好，可是先看看下面吧。</p> </li>\n  <li> <p>效率问题，select 每次调用都会线性扫描全部的 FD 集合，这样效率就会呈现线性下降，把 FD_SETSIZE 改大的后果就是，大家都慢慢来，什么？都超时了。</p> </li>\n  <li> <p>内核/用户空间，内存拷贝问题，如何让内核把 FD 消息通知给用户空间呢？在这个问题上 select 采取了内存拷贝方法，在 FD 非常多的时候，非常的耗费时间。</p> </li>\n </ol> \n <p>总结为：</p> \n <ol>\n  <li>连接数受限</li>\n  <li>查找配对速度慢</li>\n  <li>数据由内核拷贝到用户态消耗时间。</li>\n </ol> \n <h3><a id=\"epoll_1237\"></a>epoll</h3> \n <ol>\n  <li> <p>Epoll 没有最大并发连接的限制，上限是最大可以打开文件的数目，这个数字一般远大于 2048, 一般来说这个数目和系统内存关系很大 ，具体数目可以 cat /proc/sys/fs/file-max 查看。</p> </li>\n  <li> <p>效率提升，Epoll 最大的优点就在于它只管你 “活跃” 的连接 ，而跟连接总数无关，因此在实际的网络环境中，Epoll 的效率就会远远高于 select 和 poll。</p> </li>\n  <li> <p>内存共享，Epoll 在这点上使用了 “共享内存”，这个内存拷贝也省略了。</p> </li>\n </ol> \n <h2><a id=\"80Nginx_1249\"></a>聊聊：你如何通过不同于80的端口开启Nginx?</h2> \n <p>为了通过一个不同的端口开启Nginx，你必须进入/etc/Nginx/sites-enabled/，如果这是默认文件，那么你必须打开名为“default”的文件。</p> \n <p>编辑文件，并放置在你想要的端口 ：</p> \n <pre><code class=\"prism language-bash\">server <span class=\"token punctuation\">{\n    <!-- --></span>\n  listen <span class=\"token number\">81</span><span class=\"token punctuation\">;</span> \n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"location_1263\"></a>聊聊：location的作用是什么？</h2> \n <p>location指令的作用是根据用户请求的URI来执行不同的应用，也就是根据用户请求的网站URL进行匹配，匹配成功即进行相关的操作。</p> \n <h2><a id=\"location_1269\"></a>聊聊：location的语法能说出来吗？</h2> \n <p>location主要用于URI的匹配。</p> \n <pre><code>什么是 uri：\nURI：Uniform Resource Identifier，统一资源标识符；如下图的data.html;\nURN：Uniform Resource Name，统一资源名称，如下图的ste.org/img.png，比URI多个域名;\nURL：Uniform Resource Locator，统一资源定位符，如下面，URL包含了http协议、端口、域名、文件名。\n</code></pre> \n <p>URI的匹配， 示例如下:</p> \n <pre><code class=\"prism language-bash\"><span class=\"token comment\">#优先级1,精确匹配，根路径</span>\nlocation <span class=\"token operator\">=</span>/ <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token builtin class-name\">return</span> <span class=\"token number\">400</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\">#优先级2,以某个字符串开头,以av开头的，优先匹配这里，区分大小写</span>\nlocation ^~ /av <span class=\"token punctuation\">{\n    <!-- --></span>\n    root /data/av/<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\">#优先级3，区分大小写的正则匹配，匹配/media*****路径</span>\nlocation ~ /media <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token builtin class-name\">alias</span> /data/static/<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\">#优先级4 ，不区分大小写的正则匹配，所有的****.jpg|gif|png 都走这里</span>\nlocation ~* .*<span class=\"token punctuation\">\\</span>.<span class=\"token punctuation\">(</span>jpg<span class=\"token operator\">|</span>gif<span class=\"token operator\">|</span>png<span class=\"token operator\">|</span>js<span class=\"token operator\">|</span>css<span class=\"token punctuation\">)</span>$ <span class=\"token punctuation\">{\n    <!-- --></span>\n    root  /data/av/<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\">#优先7，通用匹配</span>\nlocation / <span class=\"token punctuation\">{\n    <!-- --></span>\n    <span class=\"token builtin class-name\">return</span> <span class=\"token number\">403</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"Nginx_1313\"></a>聊聊：Nginx如何定义错误提示页面</h2> \n <pre><code class=\"prism language-bash\"><span class=\"token comment\">#error_page 500 502 503 504 /50x.html;</span>\nlocation <span class=\"token operator\">=</span> /50x.html <span class=\"token punctuation\">{\n    <!-- --></span>\n    root /root<span class=\"token punctuation\">;</span> \n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"Nginx502503_1324\"></a>聊聊：是否有可能将Nginx的错误替换为502错误、503?</h2> \n <p>502 =错误网关</p> \n <p>503 =服务器超载</p> \n <p>有可能，但是您可以确保fastcgi_intercept_errors被设置为ON，并使用错误页面指令。</p> \n <pre><code class=\"prism language-bash\">Location / <span class=\"token punctuation\">{\n    <!-- --></span>\n    fastcgi_pass <span class=\"token number\">127.0</span>.01:9001<span class=\"token punctuation\">;</span>\n    fastcgi_intercept_errors on<span class=\"token punctuation\">;</span>\n    error_page <span class=\"token number\">502</span> <span class=\"token operator\">=</span><span class=\"token number\">503</span>/error_page.html<span class=\"token punctuation\">;</span>\n</code></pre> \n <h2><a id=\"nginx500502503504__1341\"></a>聊聊：nginx中500、502、503、504 有什么区别？</h2> \n <p><strong>500：</strong></p> \n <p>Internal Server Error 内部服务错误，比如脚本错误，编程语言语法错误。</p> \n <p><strong>502：</strong></p> \n <p>Bad Gateway错误，网关错误。比如服务器当前连接太多，响应太慢，页面素材太多、带宽慢。</p> \n <p><strong>503：</strong></p> \n <p>Service Temporarily Unavailable，服务不可用，web服务器不能处理HTTP请求，可能是临时超载或者是服务器进行停机维护。</p> \n <p><strong>504：</strong></p> \n <p>Gateway timeout 网关超时，程序执行时间过长导致响应超时，例如程序需要执行20秒，而nginx最大响应等待时间为10秒，这样就会出现超时。</p> \n <h2><a id=\"Nginx_1361\"></a>聊聊：Nginx如何精准匹配路径</h2> \n <pre><code class=\"prism language-bash\">location <span class=\"token operator\">=</span> /get <span class=\"token punctuation\">{\n    <!-- --></span> \n   <span class=\"token comment\">#规则 A </span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"Nginx_1371\"></a>聊聊：Nginx路径匹配优先级</h2> \n <p>多个location 配置的情况下匹配顺序为</p> \n <ol>\n  <li> <p>首先匹配 =</p> </li>\n  <li> <p>其次匹配 ^~</p> </li>\n  <li> <p>再其次是按文件中顺序的正则匹配</p> </li>\n  <li> <p>最后是交给 / 通用匹配。</p> </li>\n </ol> \n <p>当有匹配成功时候，停止匹配，按当前匹配规则处理请求。</p> \n <h2><a id=\"_1387\"></a>聊聊：如何将请求转发给后端应用服务器</h2> \n <pre><code class=\"prism language-bash\">location <span class=\"token operator\">=</span> / <span class=\"token punctuation\">{\n    <!-- --></span>\n	proxy_pass http://tomcat:8080/index\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"_1397\"></a>聊聊：如何根据文件类型设置过期时间</h2> \n <pre><code class=\"prism language-bash\">location ~* <span class=\"token punctuation\">\\</span>.<span class=\"token punctuation\">(</span>js<span class=\"token operator\">|</span>css<span class=\"token operator\">|</span>jpg<span class=\"token operator\">|</span>jpeg<span class=\"token operator\">|</span>gif<span class=\"token operator\">|</span>png<span class=\"token operator\">|</span>swf<span class=\"token punctuation\">)</span>$ <span class=\"token punctuation\">{\n    <!-- --></span>\n	<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>-f <span class=\"token variable\">$request_filename</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n    <!-- --></span>\n		expires 1h<span class=\"token punctuation\">;</span>\n		<span class=\"token builtin class-name\">break</span><span class=\"token punctuation\">;</span> \n	<span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"_1410\"></a>聊聊：如何禁止访问某个目录</h2> \n <pre><code class=\"prism language-bash\">location ^~/path/ <span class=\"token punctuation\">{\n    <!-- --></span>\n    deny all<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"NginxURL_1420\"></a>聊聊：在Nginx中，解释如何在URL中保留双斜线?</h2> \n <p>要在URL中保留双斜线，就必须使用merge_slashes_off;</p> \n <p>语法:merge_slashes [on/off]</p> \n <p>默认值: merge_slashes on</p> \n <p>环境: http，server</p> \n <h2><a id=\"Nginx_rewrite_1432\"></a>聊聊：Nginx rewrite全局变量</h2> \n <p>Nginx rewrite 常用的全局变量如下：</p> \n <table>\n  <thead>\n   <tr>\n    <th>变量</th>\n    <th>说明</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>$args</td>\n    <td>存放了请求 url 中的请求指令。比如 <code>http://www.myweb.name/server/source?arg1=value1&amp;arg2=value2</code> 中的arg1=value1&amp;arg2=value2</td>\n   </tr>\n   <tr>\n    <td>$content_length</td>\n    <td>存放请求头中的 Content-length 字段</td>\n   </tr>\n   <tr>\n    <td>$content_type</td>\n    <td>存放了请求头中的 Content-type 字段</td>\n   </tr>\n   <tr>\n    <td>$document_root</td>\n    <td>存放了针对当前请求的根路径</td>\n   </tr>\n   <tr>\n    <td>$document_uri</td>\n    <td>请求中的 uri，不包含请求指令 ，比如比如 <code>http://www.myweb.name/server/source?arg1=value1&amp;arg2=value2</code> 中的 /server/source</td>\n   </tr>\n   <tr>\n    <td>$host</td>\n    <td>存放了请求 url 中的主机字段，比如 <code>http://www.myweb.name/server/source?arg1=value1&amp;arg2=value2</code> 中的 <code>www.myweb.name</code>。如果请求中的主机部分字段不可用或者为空，则存放 nginx 配置中该 server 块中 server_name 指令的配置值</td>\n   </tr>\n   <tr>\n    <td>$http_user_agent</td>\n    <td>存放客户端的代理</td>\n   </tr>\n   <tr>\n    <td>$http_cookie</td>\n    <td>cookie</td>\n   </tr>\n   <tr>\n    <td>$limit_rate</td>\n    <td>nginx 配置中 limit_rate 指令的配置值</td>\n   </tr>\n   <tr>\n    <td>$remote_addr</td>\n    <td>客户端的地址</td>\n   </tr>\n   <tr>\n    <td>$remote_port</td>\n    <td>客户端与服务器端建立连接的端口号</td>\n   </tr>\n   <tr>\n    <td>$remote_user</td>\n    <td>变量中存放了客户端的用户名</td>\n   </tr>\n   <tr>\n    <td>$request_body_file</td>\n    <td>存放了发给后端服务器的本地文件资源的名称</td>\n   </tr>\n   <tr>\n    <td>$request_method</td>\n    <td>存放了客户端的请求方式，如 get,post 等</td>\n   </tr>\n   <tr>\n    <td>$request_filename</td>\n    <td>存放当前请求的资源文件的路径名</td>\n   </tr>\n   <tr>\n    <td>$requset_uri</td>\n    <td>当前请求的 uri,并且带有指令</td>\n   </tr>\n   <tr>\n    <td>$query_string</td>\n    <td><code>$args</code>含义相同</td>\n   </tr>\n   <tr>\n    <td>$scheme</td>\n    <td>客户端请求使用的协议，如 http, https, ftp 等</td>\n   </tr>\n   <tr>\n    <td>$server_protocol</td>\n    <td>客户端请求协议的版本，如 ”HTTP/1.0”, ”HTTP/1.1”</td>\n   </tr>\n   <tr>\n    <td>$server_addr</td>\n    <td>服务器的地址</td>\n   </tr>\n   <tr>\n    <td>$server_name</td>\n    <td>客户端请求到达的服务器的名称</td>\n   </tr>\n   <tr>\n    <td>$server_port</td>\n    <td>客户端请求到达的服务器的端口号</td>\n   </tr>\n   <tr>\n    <td>$uri</td>\n    <td>同 <code>$document_uri</code></td>\n   </tr>\n  </tbody>\n </table> \n <h2><a id=\"ngx_http_upstream_module_1464\"></a>请解释ngx_http_upstream_module的作用是什么?</h2> \n <p>ngx_http_upstream_module用于定义可通过fastcgi传递、proxy传递、uwsgi传递、memcached传递和scgi传递指令来引用的服务器组。</p> \n <h2><a id=\"stub_statussub_filter_1470\"></a>聊聊：stub_status和sub_filter指令的作用是什么?</h2> \n <p>Stub_status指令：该指令用于了解Nginx当前状态的当前状态，如当前的活动连接，接受和处理当前读/写/等待连接的总数</p> \n <p>Sub_filter指令：它用于搜索和替换响应中的内容，并快速修复陈旧的数据</p> \n <h2><a id=\"Nginx__1478\"></a>聊聊：Nginx 压缩了解吗，如何开启压缩？</h2> \n <p>开启nginx gzip压缩后，图片、css、js等静态资源的大小会减小，可节省带宽，提高传输效率，但是会消耗CPU资源。</p> \n <pre><code class=\"prism language-yaml\">gzip on;  \n<span class=\"token comment\">#开启gzip压缩功能</span>\ngzip_min_length 1k;\n<span class=\"token comment\">#设置允许压缩的页面最小字节数，页面字节数从header头的content-length中获取。默认值是0,不管页面多大都进行压缩。建议设置成大于1k。如果小于1k可能会越压越大。</span>\ngzip_buffers 4 16k;\n<span class=\"token comment\">#压缩缓冲区大小。表示申请4个单位为16k的内容作为压缩结果流缓存，默认值是申请与原始数据大小相同的内存空间来存储gzip压缩结果。</span>\ngzip_http_version 1.0;\n<span class=\"token comment\">#压缩版本（默认1.1，前端为squid2.5时使用1.0）用于设置识别http协议版本，默认是1.1,目前大部分浏览器已经支持gzip解压，使用默认即可。</span>\ngzip_comp_level 2;\n<span class=\"token comment\">#压缩比率。用来指定gzip压缩比，1压缩比量小，处理速度快；9压缩比量大，传输速度快，但处理最慢，也必将消耗cpu资源。</span>\ngzip_types text/plain application/x<span class=\"token punctuation\">-</span>javascript text/css application/xml;\n<span class=\"token comment\">#用来指定压缩的类型，“text/html”类型总是会被压缩。</span>\ngzip_vary on;\n<span class=\"token comment\">#vary header支持。该选项可以让前端的缓存服务器缓存经过gzip压缩的页面，例如用squid缓存经过nginx压缩的数据。</span>\n</code></pre> \n <p>要注意：需要和不需要压缩的对象</p> \n <p>（1）大于1k的纯文本文件html,js,css,xml,html.</p> \n <p>（2）图片，视频等不要压缩，因为不但不会减小，在压缩时消耗cpu和内存资源。</p> \n <h2><a id=\"Nginxgzip_1507\"></a>聊聊：Nginx开启gzip压缩</h2> \n <p>Nginx 开启 Gzip 压缩功能， 可以使网站的 css、js 、xml、html 文件在传输时进行压缩，提高访问速度, 进而优化 Nginx 性能。</p> \n <p>网站加载的速度取决于浏览器必须下载的所有文件的大小。减少要传输的文件的大小可以使网站不仅加载更快，而且对于那些宽带是按量计费的人来说也更友好。</p> \n <p>gzip 是一种流行的数据压缩程序。</p> \n <p>您可以使用 gzip 压缩 Nginx 实时文件。这些文件在检索时由支持它的浏览器解压缩，好处是 web 服务器和浏览器之间传输的数据量更小，速度更快。</p> \n <p>gzip 不一定适用于所有文件的压缩。例如，文本文件压缩得非常好，通常会缩小两倍以上。</p> \n <p>另一方面，诸如 JPEG或 PNG 文件之类的图像已经按其性质进行压缩，使用 gzip 压缩很难有好的压缩效果或者甚至没有效果。压缩文件会占用服务器资源，因此最好只压缩那些压缩效果好的文件。</p> \n <h2><a id=\"_1523\"></a>聊聊：开启压缩功能的好坏</h2> \n <ol>\n  <li> <p>好处:</p> <p>压缩是可以节省带宽，提高传输效率。</p> </li>\n  <li> <p>坏处:</p> <p>但是由于是在服务器上进行压缩，会消耗服务器起源</p> </li>\n </ol> \n <h2><a id=\"Nginxgzip_1537\"></a>聊聊：Nginx的gzip压缩的原理和优点</h2> \n <p>Nginx 开启 Gzip 压缩功能， 可以使网站的 css、js 、xml、html 文件在传输时进行压缩，提高访问速度, 进而优化 Nginx 性能。</p> \n <p>网站加载的速度取决于浏览器必须下载的所有文件的大小。减少要传输的文件的大小可以使网站不仅加载更快，而且对于那些宽带是按量计费的人来说也更友好。</p> \n <p>gzip 是一种流行的数据压缩程序。您可以使用 gzip 压缩 Nginx 实时文件。这些文件在检索时由支持它的浏览器解压缩，好处是 web 服务器和浏览器之间传输的数据量更小，速度更快。</p> \n <p>gzip 不一定适用于所有文件的压缩。例如，文本文件压缩得非常好，通常会缩小两倍以上。另一方面，诸如 JPEG或 PNG 文件之类的图像已经按其性质进行压缩，使用 gzip 压缩很难有好的压缩效果或者甚至没有效果。压缩文件会占用服务器资源，因此最好只压缩那些压缩效果好的文件。</p> \n <h3><a id=\"Nginx_gzip_1547\"></a>Nginx gzip配置作用</h3> \n <p>Nginx 开启 Gzip 压缩功能， 可以使网站的 css、js 、xml、html 文件在传输时进行压缩，提高访问速度, 进而优化 Nginx 性能! Web 网站上的图片，视频等其它多媒体文件以及大文件，因为压缩效果不好，所以对于图片没有必要支压缩，如果想要优化，可以图片的生命周期设置长一点，让客户端来缓存。</p> \n <p>开启 Gzip 功能后，Nginx 服务器会根据配置的策略对发送的内容, 如 css、js、xml、html 等静态资源进行压缩, 使得这些内容大小减少，在用户接收到返回内容之前对其进行处理，以压缩后的数据展现给客户。这样不仅可以节约大量的出口带宽，提高传输效率，还能提升用户快的感知体验, 一举两得; 尽管会消耗一定的 cpu 资源，但是为了给用户更好的体验还是值得的。</p> \n <p>经过 Gzip 压缩后页面大小可以变为原来的 30% 甚至更小，这样，用户浏览页面的时候速度会快得多。Gzip 的压缩页面需要浏览器和服务器双方都支持，实际上就是服务器端压缩，传到浏览器后浏览器解压并解析。浏览器那里不需要我们担心，因为目前的巨大多数浏览器 都支持解析 Gzip 过的页面。</p> \n <h3><a id=\"Nginx_gzip_1555\"></a>Nginx gzip配置参数</h3> \n <h4><a id=\"_1557\"></a>参数</h4> \n <table>\n  <thead>\n   <tr>\n    <th>参数</th>\n    <th>描述</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>gzip on</td>\n    <td>决定是否开启 gzip 模块，on 表示开启，off 表示关闭</td>\n   </tr>\n   <tr>\n    <td>gzip_min_length 1k</td>\n    <td>设置允许压缩的页面最小字节(从 header 头的 Content-Length 中获取) ，当返回内容大于此值时才会使用 gzip 进行压缩,以 K 为单位,当值为 0 时，所有页面都进行压缩。建议大于 1k</td>\n   </tr>\n   <tr>\n    <td>gzip_buffers 4 16k</td>\n    <td>设置 gzip 申请内存的大小，其作用是按块大小的倍数申请内存空间,param2:int(k) 后面单位是 k。这里设置以 16k 为单位,按照原始数据大小以 16k 为单位的 4 倍申请内存</td>\n   </tr>\n   <tr>\n    <td>gzip_http_version 1.1</td>\n    <td>识别 http 协议的版本,早起浏览器可能不支持 gzip 自解压,用户会看到乱码</td>\n   </tr>\n   <tr>\n    <td>gzip_comp_level 2</td>\n    <td>设置 gzip 压缩等级，等级越底压缩速度越快文件压缩比越小，反之速度越慢文件压缩比越大；等级1-9，最小的压缩最快 但是消耗 cpu</td>\n   </tr>\n   <tr>\n    <td>gzip_types text/plain</td>\n    <td>设置需要压缩的 MIME 类型,非设置值不进行压缩，即匹配压缩类型</td>\n   </tr>\n   <tr>\n    <td>gzip_vary on</td>\n    <td>启用应答头\"Vary: Accept-Encoding\"</td>\n   </tr>\n   <tr>\n    <td>gzip_proxied off</td>\n    <td>nginx 做为反向代理时启用</td>\n   </tr>\n   <tr>\n    <td>gzip_disable msie6</td>\n    <td>IE5.5 和 IE6 SP1 使用 msie6 参数来禁止 gzip 压缩 )指定哪些不需要 gzip 压缩的浏览器(将和User-Agents进行匹配),依赖于 PCRE 库</td>\n   </tr>\n  </tbody>\n </table> \n <h3><a id=\"Nginx_gzip_1571\"></a>Nginx gzip参数介绍</h3> \n <h4><a id=\"gzip_on_1573\"></a>gzip on</h4> \n <pre><code class=\"prism language-yaml\">打开或关闭gzip\n默认 off 关闭\n代码块 http<span class=\"token punctuation\">,</span> server<span class=\"token punctuation\">,</span> location<span class=\"token punctuation\">,</span> if in location\n</code></pre> \n <h4><a id=\"gzip_buffers_1581\"></a>gzip_buffers</h4> \n <p>设置用于处理请求压缩的缓冲区数量和大小。比如 32 4K 表示按照内存页（one memory page）大小以 4K 为单位（即一个系统中内存页为 4K），申请 32 倍的内存空间。建议此项不设置，使用默认值。</p> \n <pre><code class=\"prism language-yaml\"><span class=\"token key atrule\">Syntax</span><span class=\"token punctuation\">:</span> gzip_buffers number size;\n<span class=\"token key atrule\">Default</span><span class=\"token punctuation\">:</span>    \ngzip_buffers 32 4k<span class=\"token punctuation\">|</span>16 8k;\n<span class=\"token key atrule\">Context</span><span class=\"token punctuation\">:</span>    http<span class=\"token punctuation\">,</span> server<span class=\"token punctuation\">,</span> location\n</code></pre> \n <h4><a id=\"gzip_comp_level_1592\"></a>gzip_comp_level</h4> \n <p>设置 gzip 压缩级别，级别越底压缩速度越快文件压缩比越小，反之速度越慢文件压缩比越大</p> \n <pre><code class=\"prism language-yaml\"><span class=\"token key atrule\">Syntax</span><span class=\"token punctuation\">:</span> gzip_comp_level level;\n<span class=\"token key atrule\">Default</span><span class=\"token punctuation\">:</span>    \ngzip_comp_level 1;\n<span class=\"token key atrule\">Context</span><span class=\"token punctuation\">:</span>    http<span class=\"token punctuation\">,</span> server<span class=\"token punctuation\">,</span> location\n</code></pre> \n <p>不是压缩级别越高越好，其实 gzip_comp_level 1 的压缩能力已经够用了，后面级别越高，压缩的比例其实增长不大，反而很吃处理性能。</p> \n <p>另一方面，压缩一定要和静态资源缓存相结合，缓存压缩后的版本，否则每次都压缩高负载下服务器肯定吃不住。</p> \n <h4><a id=\"gzip_disable_1607\"></a>gzip_disable</h4> \n <p>通过表达式，表明哪些 UA 头不使用 gzip 压缩</p> \n <pre><code class=\"prism language-yaml\"><span class=\"token key atrule\">Syntax</span><span class=\"token punctuation\">:</span> gzip_disable regex <span class=\"token punctuation\">...</span>;\n<span class=\"token key atrule\">Default</span><span class=\"token punctuation\">:</span>    —\n<span class=\"token key atrule\">Context</span><span class=\"token punctuation\">:</span>    http<span class=\"token punctuation\">,</span> server<span class=\"token punctuation\">,</span> location\nThis directive appeared in version 0.6.23.\n</code></pre> \n <h4><a id=\"gzip_min_length_1618\"></a>gzip_min_length</h4> \n <p>当返回内容大于此值时才会使用gzip进行压缩,以 K 为单位,当值为 0 时，所有页面都进行压缩。</p> \n <pre><code class=\"prism language-yaml\"><span class=\"token key atrule\">Syntax</span><span class=\"token punctuation\">:</span> gzip_min_length length;\n<span class=\"token key atrule\">Default</span><span class=\"token punctuation\">:</span>    \ngzip_min_length 20;\n<span class=\"token key atrule\">Context</span><span class=\"token punctuation\">:</span>    http<span class=\"token punctuation\">,</span> server<span class=\"token punctuation\">,</span> location\n</code></pre> \n <h4><a id=\"gzip_http_version_1629\"></a>gzip_http_version</h4> \n <p>用于识别 http 协议的版本，早期的浏览器不支持 gzip 压缩，用户会看到乱码，所以为了支持前期版本加了此选项。默认在 http/1.0 的协议下不开启 gzip 压缩。</p> \n <pre><code class=\"prism language-yaml\"><span class=\"token key atrule\">Syntax</span><span class=\"token punctuation\">:</span> gzip_http_version 1.0 <span class=\"token punctuation\">|</span> 1.1;\n<span class=\"token key atrule\">Default</span><span class=\"token punctuation\">:</span>    \ngzip_http_version 1.1;\n<span class=\"token key atrule\">Context</span><span class=\"token punctuation\">:</span>    http<span class=\"token punctuation\">,</span> server<span class=\"token punctuation\">,</span> location\n</code></pre> \n <p>在应用服务器前，如果还有一层 Nginx 的集群作为负载均衡，在这一层上，若果没有开启 gzip。</p> \n <p>如果我们使用了proxy_pass 进行反向代理，那么 nginx 和后端的 upstream server 之间默认是用 HTTP/1.0 协议通信的。</p> \n <p>如果我们的 Cache Server 也是 nginx，而前端的 nginx 没有开启 gzip。同时，我们后端的 nginx 上没有设置gzip_http_version 为 1.0，那么 Cache 的 url 将不会进行 gzip 压缩。</p> \n <h4><a id=\"gzip_proxied_1646\"></a>gzip_proxied</h4> \n <p>Nginx 做为反向代理的时候启用：</p> \n <ol>\n  <li>off – 关闭所有的代理结果数据压缩</li>\n  <li>expired – 如果header中包含”Expires”头信息，启用压缩</li>\n  <li>no-cache – 如果header中包含”Cache-Control:no-cache”头信息，启用压缩</li>\n  <li>no-store – 如果header中包含”Cache-Control:no-store”头信息，启用压缩</li>\n  <li>private – 如果header中包含”Cache-Control:private”头信息，启用压缩</li>\n  <li>no_last_modified – 启用压缩，如果header中包含”Last_Modified”头信息，启用压缩</li>\n  <li>no_etag – 启用压缩，如果header中包含“ETag”头信息，启用压缩</li>\n  <li>auth – 启用压缩，如果header中包含“Authorization”头信息，启用压缩</li>\n  <li>any – 无条件压缩所有结果数据</li>\n </ol> \n <pre><code class=\"prism language-yaml\"><span class=\"token key atrule\">Syntax</span><span class=\"token punctuation\">:</span> gzip_proxied off <span class=\"token punctuation\">|</span> expired <span class=\"token punctuation\">|</span> no<span class=\"token punctuation\">-</span>cache <span class=\"token punctuation\">|</span> no<span class=\"token punctuation\">-</span>store <span class=\"token punctuation\">|</span> private <span class=\"token punctuation\">|</span> no_last_modified <span class=\"token punctuation\">|</span> no_etag <span class=\"token punctuation\">|</span> auth <span class=\"token punctuation\">|</span> any <span class=\"token punctuation\">...</span>;\n<span class=\"token key atrule\">Default</span><span class=\"token punctuation\">:</span>    \ngzip_proxied off;\n<span class=\"token key atrule\">Context</span><span class=\"token punctuation\">:</span>    http<span class=\"token punctuation\">,</span> server<span class=\"token punctuation\">,</span> location\n</code></pre> \n <h4><a id=\"gzip_types_1668\"></a>gzip_types</h4> \n <p>设置需要压缩的 MIME 类型,如果不在设置类型范围内的请求不进行压缩</p> \n <pre><code class=\"prism language-yaml\"><span class=\"token key atrule\">Syntax</span><span class=\"token punctuation\">:</span> gzip_types mime<span class=\"token punctuation\">-</span>type <span class=\"token punctuation\">...</span>;\n<span class=\"token key atrule\">Default</span><span class=\"token punctuation\">:</span>    \ngzip_types text/html;\n<span class=\"token key atrule\">Context</span><span class=\"token punctuation\">:</span>    http<span class=\"token punctuation\">,</span> server<span class=\"token punctuation\">,</span> location\n</code></pre> \n <h4><a id=\"gzip_vary_1679\"></a>gzip_vary</h4> \n <p>增加响应头”Vary: Accept-Encoding”，告诉接收方发送的数据经过了压缩处理，开启后的效果是在响应头部添加了Accept-Encoding:gzip，这对于本身不支持 gzip 压缩的客户端浏览器有用。</p> \n <pre><code class=\"prism language-yaml\"><span class=\"token key atrule\">Syntax</span><span class=\"token punctuation\">:</span> gzip_vary on <span class=\"token punctuation\">|</span> off;\n<span class=\"token key atrule\">Default</span><span class=\"token punctuation\">:</span>    \ngzip_vary off;\n<span class=\"token key atrule\">Context</span><span class=\"token punctuation\">:</span>    http<span class=\"token punctuation\">,</span> server<span class=\"token punctuation\">,</span> location\n</code></pre> \n <h3><a id=\"Nginx_gzip__1690\"></a>Nginx gzip 案例</h3> \n <p>我们首先，使用 vim 打开 nginx 的默认配置路径，具体命令如下：</p> \n <pre><code class=\"prism language-sh\"><span class=\"token function\">vim</span> /etc/nginx/conf.d/default.conf\n</code></pre> \n <p>我们执行如上命令，打开配置文件，此时配置文件如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/6b4a9894108f478daf942875fd2a14e2.png\" alt=\"\"></p> \n <p>现在，我们在 nginx 的根路径下新建一个 index.html，并写入内容，并使用浏览器访问，此时，浏览器输出如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/9dcc813e2cdb4fb6a94a3a6da9cc104e.png\" alt=\"\"></p> \n <p>现在，我们打开 nginx.conf 配置文件，如下图所示：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/a8d2dc6000dd4f26b7df84f45e18bc73.png\" alt=\"\"></p> \n <p>在 nginx 的 http 模块的配置里面，开启 gzip 配置，具体配置如下：</p> \n <pre><code class=\"prism language-yaml\">gzip  on;\ngzip_min_length  1k;\ngzip_buffers     4 16k;\ngzip_http_version 1.1;\ngzip_comp_level 9;\ngzip_types       text/plain application/x<span class=\"token punctuation\">-</span>javascript text/css application/xml text/javascript application/x<span class=\"token punctuation\">-</span>httpd<span class=\"token punctuation\">-</span>php application/javascript application/json;\ngzip_disable \"MSIE <span class=\"token punctuation\">[</span>1<span class=\"token punctuation\">-</span><span class=\"token number\">6</span><span class=\"token punctuation\">]</span>\\.\";\ngzip_vary on;\n</code></pre> \n <p>配置完成后，如下图所示：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/c7369cf7f6084293a7654db200eb1c35.png\" alt=\"\"></p> \n <p>现在，我们使用 reload 重新加载配置，具体命令如下：</p> \n <pre><code class=\"prism language-bash\">nginx <span class=\"token parameter variable\">-s</span> reload\n</code></pre> \n <p>执行完毕后，我们再次使用浏览器访问，此时输出如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/3ebe84bb07a646838b263123459f49d4.png\" alt=\"\"></p> \n <p>我们看到，此时输出了 gzip，并且浏览器的内容如下：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/157b8e5ce58d4348b82a38d94567488c.png\" alt=\"\"></p> \n <p>我们看到，浏览器的内容也正常输出了。</p> \n <h3><a id=\"Nginx_gzip_1743\"></a>Nginx gzip配置总结</h3> \n <p>Nginx 开启 Gzip 压缩功能， 可以使网站的 css、js 、xml、html 文件在传输时进行压缩，提高访问速度, 进而优化 Nginx 性能。</p> \n <h2><a id=\"Nginx_1749\"></a>聊聊：Nginx是否支持将请求压缩到上游?</h2> \n <p>您可以使用Nginx模块gunzip将请求压缩到上游。</p> \n <p>gunzip模块是一个过滤器，它可以对不支持“gzip”编码方法的客户机或服务器使用“内容编码:gzip”来解压缩响应。</p> \n <h2><a id=\"Nginx_1757\"></a>聊聊：如何在Nginx中获得当前的时间?</h2> \n <p>要获得Nginx的当前时间，必须使用SSI模块、$date_gmt和 $date_local的变量。<br> Proxy_set_header THE-TIME $date_gmt;</p> \n <h2><a id=\"Nginxs_1764\"></a>聊聊：用Nginx服务器解释-s的目的是什么?</h2> \n <p>用于运行Nginx -s参数的可执行文件。</p> \n <h2><a id=\"Nginx_1770\"></a>聊聊：如何在Nginx服务器上添加模块?</h2> \n <p>在编译过程中，必须选择Nginx模块，因为Nginx不支持模块的运行时间选择。</p> \n <p><strong>Nginx动态添加模块</strong></p> \n <p>很多时候，我们根据当时的项目情况和业务需求安装完 Nginx 后，后续随着业务的发展，往往会给安装好的 Nginx 添加其他的功能模块。在为 Nginx 添加功能模块时，要求 Nginx 不停机。</p> \n <p>这就涉及到如何为已安装的 Nginx 动态添加模块的问题。本文，就和小伙伴们一起探讨如何为已安装的 Nginx 动态添加模块的问题。</p> \n <h2><a id=\"Nginx_1780\"></a>聊聊：如何为Nginx动态添加模块</h2> \n <p>这里以安装第三方 ngx_http_google_filter_module 模块为例。</p> \n <p>Nginx 的模块是需要重新编译 Nginx，而不是像 Apache 一样配置文件引用 .so。</p> \n <h3><a id=\"_1786\"></a>下载扩展</h3> \n <p>下载第三方扩展模块 ngx_http_google_filter_module</p> \n <pre><code class=\"prism language-bash\"><span class=\"token comment\"># cd /data/software/</span>\n<span class=\"token comment\"># git clone https://github.com/cuber/ngx_http_google_filter_module</span>\n</code></pre> \n <h3><a id=\"_1795\"></a>查看安装模块</h3> \n <p>查看 Nginx 编译安装时安装了哪些模块，将命令行切换到 Nginx 执行程序所在的目录并输入 ./nginx -V，具体如下：</p> \n <pre><code class=\"prism language-bash\"><span class=\"token punctuation\">[</span>root@binghe sbin<span class=\"token punctuation\">]</span><span class=\"token comment\"># ./nginx -V</span>\nnginx version: nginx/1.19.1\nbuilt by gcc <span class=\"token number\">4.4</span>.7 <span class=\"token number\">20120313</span> <span class=\"token punctuation\">(</span>Red Hat <span class=\"token number\">4.4</span>.7-17<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">(</span>GCC<span class=\"token punctuation\">)</span> \nbuilt with OpenSSL <span class=\"token number\">1.0</span>.2 <span class=\"token number\">22</span> Jan <span class=\"token number\">2015</span>\nTLS SNI support enabled\nconfigure arguments: <span class=\"token parameter variable\">--prefix</span><span class=\"token operator\">=</span>/usr/local/nginx-1.19.1 --with-openssl<span class=\"token operator\">=</span>/usr/local/src/openssl-1.0.2 --with-pcre<span class=\"token operator\">=</span>/usr/local/src/pcre-8.37 --with-zlib<span class=\"token operator\">=</span>/usr/local/src/zlib-1.2.8 --with-http_ssl_module\n<span class=\"token punctuation\">[</span>root@binghe sbin<span class=\"token punctuation\">]</span><span class=\"token comment\"># </span>\n</code></pre> \n <p>可以看出编译安装 Nginx 使用的参数如下：</p> \n <pre><code class=\"prism language-bash\"><span class=\"token parameter variable\">--prefix</span><span class=\"token operator\">=</span>/usr/local/nginx-1.19.1 --with-openssl<span class=\"token operator\">=</span>/usr/local/src/openssl-1.0.2 --with-pcre<span class=\"token operator\">=</span>/usr/local/src/pcre-8.37 --with-zlib<span class=\"token operator\">=</span>/usr/local/src/zlib-1.2.8 --with-http_ssl_module\n</code></pre> \n <h3><a id=\"_1815\"></a>重新编译</h3> \n <p>加入需要安装的模块，重新编译，这里添加 --add-module=/data/software/ngx_http_google_filter_module，具体如下：</p> \n <pre><code class=\"prism language-bash\">./configure  <span class=\"token parameter variable\">--prefix</span><span class=\"token operator\">=</span>/usr/local/nginx-1.19.1 --with-openssl<span class=\"token operator\">=</span>/usr/local/src/openssl-1.0.2 --with-pcre<span class=\"token operator\">=</span>/usr/local/src/pcre-8.37 --with-zlib<span class=\"token operator\">=</span>/usr/local/src/zlib-1.2.8 --with-http_ssl_module -–add-module<span class=\"token operator\">=</span>/data/software/ngx_http_google_filter_module\n</code></pre> \n <p>如上，将之前安装Nginx的参数全部加上，最后添加 --add-module=/data/software/ngx_http_google_filter_module，之后，我们要进行编译操作，如下：</p> \n <pre><code class=\"prism language-bash\"><span class=\"token comment\"># make //千万不要make install，不然就真的覆盖</span>\n</code></pre> \n <p>这里，需要注意的是：不要执行 make install 命令。</p> \n <h3><a id=\"nginx_1831\"></a>替换nginx二进制文件</h3> \n <pre><code class=\"prism language-bash\"><span class=\"token comment\"># 备份原来的nginx执行程序</span>\n<span class=\"token comment\"># mv /usr/local/nginx-1.19.1/sbin/nginx /usr/local/nginx-1.19.1/sbin/nginx.bak</span>\n<span class=\"token comment\"># 将新编译的nginx执行程序复制到/usr/local/nginx-1.19.1/sbin/目录下</span>\n<span class=\"token comment\"># cp /opt/nginx/sbin/nginx /usr/local/nginx-1.19.1/sbin/</span>\n</code></pre> \n <h2><a id=\"_1842\"></a>聊聊：如何设置超时时间</h2> \n <pre><code class=\"prism language-bash\">http <span class=\"token punctuation\">{\n    <!-- --></span>\n	keepalive_timeout <span class=\"token number\">60</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">###设置客户端连接保持会话的超时时间，超过这个时间，服务器会关闭该连接。 </span>\n	\n	tcp_nodelay on<span class=\"token punctuation\">;</span> <span class=\"token comment\">####打开 tcp_nodelay，在包含了 keepalive 参数才有效</span>\n	\n	client_header_timeout <span class=\"token number\">15</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">####设置客户端请求头读取超时时间，如果超过这个时间，客户端还没有发送任何数据， Nginx 将返回“Request time out(408)”错误</span>\n	\n	client_body_timeout <span class=\"token number\">15</span><span class=\"token punctuation\">;</span><span class=\"token comment\">####设置客户端请求主体读取超时时间，如果超过这个时间，客户端还没有发送任何数据， Nginx 将返回“Request time out(408)”错误</span>\n	\n	send_timeout <span class=\"token number\">15</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">####指定响应客户端的超时时间。这个超过仅限于两个连接活动之间的时间，如果超过这个时间，客户端没有任何活动，Nginx 将会关闭连接。</span>\n\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"Nginx_1861\"></a>聊聊：Nginx如何限制浏览器和爬虫</h2> \n <h3><a id=\"Nginx_1863\"></a>Nginx限制爬虫</h3> \n <p>修改 nginx.conf，禁止网络爬虫的 ua，返回 403，具体配置如下：</p> \n <pre><code class=\"prism language-bash\">server<span class=\"token punctuation\">{\n    <!-- --></span>\n	listen <span class=\"token number\">80</span><span class=\"token punctuation\">;</span>\n	server_name <span class=\"token number\">127.0</span>.0.1<span class=\"token punctuation\">;</span> \n	<span class=\"token comment\"># 添加如下内容即可防止爬虫</span>\n	<span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$http_user_agent</span> ~* <span class=\"token string\">\"qihoobot|Baiduspider|Googlebot|Googlebot-Mobile|Googlebot-Image|Mediapartners-Google|Adsbot-Google|Feedfetcher-Google|Yahoo! Slurp|Yahoo! Slurp China|YoudaoBot|Sosospider|Sogou spider|Sogou web spider|MSNBot|ia_archiver|Tomato Bot\"</span><span class=\"token punctuation\">)</span> \n	<span class=\"token punctuation\">{\n    <!-- --></span>\n		<span class=\"token builtin class-name\">return</span> <span class=\"token number\">403</span><span class=\"token punctuation\">;</span>\n	<span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h3><a id=\"Nginx_1879\"></a>Nginx限制浏览器访问</h3> \n <p>限制浏览器访问：</p> \n <pre><code class=\"prism language-bash\"><span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token variable\">$http_user_agent</span> ~* <span class=\"token string\">\"Firefox|MSIE\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">{\n    <!-- --></span>\n     <span class=\"token builtin class-name\">return</span> <span class=\"token number\">403</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h3><a id=\"NginxIP_1892\"></a>Nginx限制IP访问</h3> \n <p>有时候我们需要针对屏蔽某些恶意的 IP 访问我们的网站，或者限制仅仅某些白名单 IP 才能访问我们的网站。</p> \n <p>这时候我们就可以在Nginx中通过简单的配置来达到目的。</p> \n <pre><code class=\"prism language-bash\"><span class=\"token comment\">#添加IP至allow（例如我们将10.208.96.192和10.208.96.193加入)</span>\nlocation <span class=\"token operator\">=</span> /index.html\n <span class=\"token punctuation\">{\n    <!-- --></span> \n  allow <span class=\"token number\">10.208</span>.96.192<span class=\"token punctuation\">;</span> \n   allow <span class=\"token number\">10.208</span>.96.193<span class=\"token punctuation\">;</span> \n   deny all<span class=\"token punctuation\">;</span> \n   root /work/weichuangli<span class=\"token punctuation\">;</span> \n  <span class=\"token punctuation\">}</span>\n</code></pre> \n <p>屏蔽单个ip访问</p> \n <pre><code class=\"prism language-css\"># 格式： deny ip<span class=\"token punctuation\">;</span>\ndeny 123.68.23.5<span class=\"token punctuation\">;</span>\n</code></pre> \n <p>允许单个ip访问</p> \n <pre><code class=\"prism language-css\"># 格式： allow ip<span class=\"token punctuation\">;</span>\nallow 123.68.25.6<span class=\"token punctuation\">;</span>\n</code></pre> \n <p>屏蔽所有ip访问</p> \n <pre><code class=\"prism language-undefined\">deny all;\n</code></pre> \n <p>允许所有ip访问</p> \n <pre><code class=\"prism language-undefined\">allow all;\n</code></pre> \n <p>屏蔽ip段访问</p> \n <pre><code class=\"prism language-bash\"><span class=\"token comment\"># deny ip/mask</span>\n<span class=\"token comment\"># 屏蔽172.12.62.0到172.45.62.255访问的命令 </span>\ndeny <span class=\"token number\">172.12</span>.62.0/24<span class=\"token punctuation\">;</span>\n</code></pre> \n <p>允许ip段访问</p> \n <pre><code class=\"prism language-bash\"><span class=\"token comment\"># allow ip/mask</span>\n<span class=\"token comment\"># 屏蔽172.102.0.0到172.102.255.255访问的命令 </span>\nallow <span class=\"token number\">172.102</span>.0.0/16<span class=\"token punctuation\">;</span>\n</code></pre> \n <h2><a id=\"502_1953\"></a>聊聊：502报错可能原因有哪些？</h2> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/b2f1e7f3edd54720703b2648512ee3e2.png\" alt=\"\"></p> \n <p>1）FastCGI进程是否已经启动</p> \n <p>2）FastCGI worker进程数是否不够</p> \n <p>3）FastCGI执行时间过长</p> \n <p>4）FastCGI Buffer不够</p> \n <p>nginx和apache一样，有前端缓冲限制，可以调整缓冲参数</p> \n <pre><code class=\"prism language-bash\">fastcgi_buffer_size 32k<span class=\"token punctuation\">;</span>   \nfastcgi_buffers <span class=\"token number\">8</span> 32k<span class=\"token punctuation\">;</span>\n</code></pre> \n <p>5）Proxy Buffer不够</p> \n <p>如果你用了Proxying，调整</p> \n <pre><code class=\"prism language-bash\">proxy_buffer_size 16k<span class=\"token punctuation\">;</span>  \nproxy_buffers <span class=\"token number\">4</span> 16k<span class=\"token punctuation\">;</span>\n</code></pre> \n <p>6）php脚本执行时间过长</p> \n <p>将php-fpm.conf的<code>&lt;value name=\"request_terminate_timeout\"&gt;0s&lt;/value&gt;</code>的0s改成一个时间</p> \n <h2><a id=\"Nginx__1987\"></a>聊聊：Nginx 如何解决跨域问题</h2> \n <p>跨域是前端开发中经常会遇到的问题，前端调用后台服务时，通常会遇到 No ‘Access-Control-Allow-Origin’ header is present on the requested resource 的错误，这是因为浏览器的同源策略拒绝了我们的请求。</p> \n <p>所谓同源是指，域名，协议，端口相同，浏览器执行一个脚本时同源的脚本才会被执行。</p> \n <p>如果非同源，那么在请求数据时，浏览器会在控制台中报一个异常，提示拒绝访问。</p> \n <p>这个问题我们通常会使用 CORS(跨源资源共享)或者 JSONP 去解决，这两种方法也是使用较多的方法。</p> \n <h2><a id=\"Nginx___1999\"></a>细聊：Nginx 如何 解决跨域问题</h2> \n <h3><a id=\"_2001\"></a>什么是跨域</h3> \n <p>跨域是前端开发中经常会遇到的问题，前端调用后台服务时，通常会遇到 No ‘Access-Control-Allow-Origin’ header is present on the requested resource 的错误，这是因为浏览器的同源策略拒绝了我们的请求。</p> \n <p>所谓同源是指，域名，协议，端口相同，浏览器执行一个脚本时同源的脚本才会被执行。如果非同源，那么在请求数据时，浏览器会在控制台中报一个异常，提示拒绝访问。这个问题我们通常会使用 CORS(跨源资源共享)或者 JSONP 去解决，这两种方法也是使用较多的方法。</p> \n <h3><a id=\"Nginx_2007\"></a>Nginx解决跨域方案一</h3> \n <h4><a id=\"_2009\"></a>解决跨域</h4> \n <p>这个使用 Nginx 的代理功能即可，在 a 服务器的 Nginx 添加如下示例配置：</p> \n <pre><code class=\"prism language-bash\">location ~ /xxx/ <span class=\"token punctuation\">{\n    <!-- --></span>\n	proxy_pass http://b.com<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>这样就把路径中带有 /xxx/ 的请求都转到了 b.com。如果不需要保存 cookie，保持 session 这样的功能，这样就可以了。</p> \n <p>然而，本项目就是要用到 cookie，所以就有了下边的内容。</p> \n <h4><a id=\"domain_2023\"></a>设置domain</h4> \n <p>因为 cookie 当中是有 domain 的，两个服务器的一般不同，比如 a 服务器返回的 Response Headers 中是</p> \n <pre><code>Set-Cookie:JSESSIONID=_3y4u02v4cbpBw10DoCrMSnjg7m34xuum1XRWBF1Uno; path=/; domain=a.com\n</code></pre> \n <p>而 b 服务器返回的是</p> \n <pre><code>Set-Cookie:JSESSIONID=_3y4u02v4cbpBw10DoCrMSnjg7m34xuum1XRWBF1Uno; path=/; domain=b.com\n</code></pre> \n <p>这时候如果 a 项目的页面调用了 b 的接口，浏览器发现接口返回的 domain 不是 a.com，就不会把 cookie 保存起来，session 也就失效了。Nginx 引入了 proxy_cookie_domain 来解决这个问题。示例：</p> \n <pre><code class=\"prism language-bash\">location ~ /xxx/ <span class=\"token punctuation\">{\n    <!-- --></span>\n	proxy_cookie_domain b.com a.com<span class=\"token punctuation\">;</span>\n	proxy_pass http://b.com<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>这样就可以在 Nginx 转接请求的时候自动把 domain 中的 b.com 转换成 a.com，这样 cookie 就可以设置成功了。</p> \n <p>但是，对于有些情况这样转换不灵光。比如，b 项目的 domain 是 .b.com，前边多了一个小点，那对应的改为 proxy_cookie_domain .b.com a.com; 可以不？通过实践，不行！！！</p> \n <p>通过查看 Nginx 文档，找到了解决办法。其实，除了上边那种配置方式外，Nginx 还支持正则配置：</p> \n <pre><code class=\"prism language-bash\">location ~ /xxx/ <span class=\"token punctuation\">{\n    <!-- --></span>\n	proxy_cookie_domain ~<span class=\"token punctuation\">\\</span>.?b.com a.com<span class=\"token punctuation\">;</span>\n	proxy_pass http://b.com<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>这样就可以把 domain 中的 .b.com 转换成 a.com 啦。</p> \n <h4><a id=\"path_2061\"></a>设置path</h4> \n <p>正常情况下完成以上两步就可以了，因为 cookie 中的 path 一般默认的是 path=/，也就是所有请求都可以访问本 cookie。但有些服务器会指定，只允许某个层级下的请求可以访问 cookie，比如：</p> \n <pre><code>Set-Cookie:JSESSIONID=_3y4u02v4cbpBw10DoCrMSnjg7m34xuum1XRWBF1Uno; path=/sub/; domain=b.com\n</code></pre> \n <p>这样就只允许相对根路径，以 /sub/ 开头的请求路径才能访问 cookie。这时候就又可能出现 cookie 无效的问题了，为了解决这个问题，可以使用 proxy_cookie_path。示例：</p> \n <pre><code class=\"prism language-bash\">location ~ /xxx/ <span class=\"token punctuation\">{\n    <!-- --></span>\n	proxy_cookie_domain ~<span class=\"token punctuation\">\\</span>.?b.com a.com<span class=\"token punctuation\">;</span>\n	proxy_cookie_path /sub/ /<span class=\"token punctuation\">;</span>\n	proxy_pass http://b.com<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>这样就把只允许 /sub/ 层级下的请求访问 cookie，改为允许所有请求访问 cookie 了。</p> \n <h3><a id=\"Nginx_2081\"></a>Nginx解决跨域方案二</h3> \n <p>或者，我们也可以直接简单粗暴的设置全局配置了，如下：</p> \n <pre><code class=\"prism language-bash\">http <span class=\"token punctuation\">{\n    <!-- --></span>\n    include       mime.types<span class=\"token punctuation\">;</span>\n    default_type  application/octet-stream<span class=\"token punctuation\">;</span>\n    sendfile        on<span class=\"token punctuation\">;</span>\n    <span class=\"token comment\">#连接超时时间，服务器会在这个时间过后关闭连接。</span>\n    keepalive_timeout  <span class=\"token number\">10</span><span class=\"token punctuation\">;</span>\n    <span class=\"token comment\"># gizp压缩</span>\n    <span class=\"token function\">gzip</span>  on<span class=\"token punctuation\">;</span>\n    <span class=\"token comment\"># 直接请求nginx也是会报跨域错误的这里设置允许跨域</span>\n    <span class=\"token comment\"># 如果代理地址已经允许跨域则不需要这些, 否则报错(虽然这样nginx跨域就没意义了)</span>\n    add_header Access-Control-Allow-Origin *<span class=\"token punctuation\">;</span>\n    add_header Access-Control-Allow-Headers X-Requested-With<span class=\"token punctuation\">;</span>\n    add_header Access-Control-Allow-Methods GET,POST,OPTIONS<span class=\"token punctuation\">;</span>\n    <span class=\"token comment\"># srever模块配置是http模块中的一个子模块，用来定义一个虚拟访问主机</span>\n    server <span class=\"token punctuation\">{\n    <!-- --></span>\n        listen       <span class=\"token number\">80</span><span class=\"token punctuation\">;</span>\n        server_name  localhost<span class=\"token punctuation\">;</span>\n        <span class=\"token comment\"># 根路径指到index.html</span>\n        location / <span class=\"token punctuation\">{\n    <!-- --></span>\n            root   html<span class=\"token punctuation\">;</span>\n            index  index.html index.htm<span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token comment\"># localhost/api 的请求会被转发到192.168.0.103:8080</span>\n        location /api <span class=\"token punctuation\">{\n    <!-- --></span>\n            rewrite ^/b/<span class=\"token punctuation\">(</span>.*<span class=\"token punctuation\">)</span>$ /<span class=\"token variable\">$1</span> <span class=\"token builtin class-name\">break</span><span class=\"token punctuation\">;</span> <span class=\"token comment\"># 去除本地接口/api前缀, 否则会出现404</span>\n            proxy_set_header Host <span class=\"token variable\">$host</span><span class=\"token punctuation\">;</span>\n            proxy_set_header X-Real-IP <span class=\"token variable\">$remote_addr</span><span class=\"token punctuation\">;</span>\n            proxy_set_header X-Forwarded-For <span class=\"token variable\">$proxy_add_x_forwarded_for</span><span class=\"token punctuation\">;</span>\n            proxy_pass http://192.168.0.103:8080<span class=\"token punctuation\">;</span> <span class=\"token comment\"># 转发地址</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token comment\"># 重定向错误页面到/50x.html</span>\n        error_page   <span class=\"token number\">500</span> <span class=\"token number\">502</span> <span class=\"token number\">503</span> <span class=\"token number\">504</span>  /50x.html<span class=\"token punctuation\">;</span>\n        location <span class=\"token operator\">=</span> /50x.html <span class=\"token punctuation\">{\n    <!-- --></span>\n            root   html<span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h2><a id=\"_2129\"></a>聊聊：漏桶流算法和令牌桶算法知道？</h2> \n <h3><a id=\"_2131\"></a>漏桶算法</h3> \n <p>漏桶算法是网络世界中流量整形或速率限制时经常使用的一种算法，它的主要目的是控制数据注入到网络的速率，平滑网络上的突发流量。漏桶算法提供了一种机制，通过它，突发流量可以被整形以便为网络提供一个稳定的流量。也就是我们刚才所讲的情况。漏桶算法提供的机制实际上就是刚才的案例：突发流量会进入到一个漏桶，漏桶会按照我们定义的速率依次处理请求，如果水流过大也就是突发流量过大就会直接溢出，则多余的请求会被拒绝。所以漏桶算法能控制数据的传输速率。</p> \n <h3><a id=\"_2135\"></a>令牌桶算法</h3> \n <p>令牌桶算法是网络流量整形和速率限制中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送。Google开源项目Guava中的RateLimiter使用的就是令牌桶控制算法。令牌桶算法的机制如下：存在一个大小固定的令牌桶，会以恒定的速率源源不断产生令牌。如果令牌消耗速率小于生产令牌的速度，令牌就会一直产生直至装满整个令牌桶。</p> \n <p>参考 ：</p> \n <p><a href=\"https://www.cnblogs.com/crazymakercircle/p/15187184.html\">限流：计数器、漏桶、令牌桶 三大算法的原理与实战（史上最全）</a></p> \n <h2><a id=\"Nginx_2145\"></a>聊聊：Nginx限流怎么做的？</h2> \n <p>Nginx限流就是限制用户请求速度，防止服务器受不了</p> \n <p>限流有3种</p> \n <ol>\n  <li>正常限制访问频率（正常流量）</li>\n  <li>突发限制访问频率（突发流量）</li>\n  <li>限制并发连接数</li>\n </ol> \n <p>Nginx的限流都是基于漏桶流算法，底下会说道什么是漏桶流</p> \n <h3><a id=\"_2157\"></a>正常限制访问频率（正常流量）</h3> \n <p>限制一个用户发送的请求，我Nginx多久接收一个请求。</p> \n <p>Nginx中使用ngx_http_limit_req_module模块来限制的访问频率，限制的原理实质是基于漏桶算法原理来实现的。在nginx.conf配置文件中可以使用limit_req_zone命令及limit_req命令限制单个IP的请求处理频率。</p> \n <pre><code class=\"prism language-bash\"><span class=\"token comment\">#定义限流维度，一个用户一分钟一个请求进来，多余的全部漏掉</span>\nlimit_req_zone <span class=\"token variable\">$binary_remote_addr</span> <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>one:10m <span class=\"token assign-left variable\">rate</span><span class=\"token operator\">=</span>1r/m<span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">#绑定限流维度</span>\nserver<span class=\"token punctuation\">{\n    <!-- --></span>\n		\n	location/seckill.html<span class=\"token punctuation\">{\n    <!-- --></span>\n		limit_req <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>zone<span class=\"token punctuation\">;</span>	\n		proxy_pass http://lj_seckill<span class=\"token punctuation\">;</span>\n	<span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <h3><a id=\"_2177\"></a>突发限制访问频率（突发流量）</h3> \n <p>限制一个用户发送的请求，我Nginx多久接收一个。</p> \n <p>上面的配置一定程度可以限制访问频率，但是也存在着一个问题：如果突发流量超出请求被拒绝处理，无法处理活动时候的突发流量，这时候应该如何进一步处理呢？Nginx提供burst参数结合nodelay参数可以解决流量突发的问题，可以设置能处理的超过设置的请求数外能额外处理的请求数。我们可以将之前的例子添加burst参数以及nodelay参数：</p> \n <pre><code class=\"prism language-bash\"><span class=\"token comment\">#定义限流维度，一个用户一分钟一个请求进来，多余的全部漏掉</span>\nlimit_req_zone <span class=\"token variable\">$binary_remote_addr</span> <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>one:10m <span class=\"token assign-left variable\">rate</span><span class=\"token operator\">=</span>1r/m<span class=\"token punctuation\">;</span>\n  \n<span class=\"token comment\">#绑定限流维度</span>\nserver<span class=\"token punctuation\">{\n    <!-- --></span>\n  		\n  	location/seckill.html<span class=\"token punctuation\">{\n    <!-- --></span>\n  		limit_req <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>zone <span class=\"token assign-left variable\">burst</span><span class=\"token operator\">=</span><span class=\"token number\">5</span> nodelay<span class=\"token punctuation\">;</span>\n  		proxy_pass http://lj_seckill<span class=\"token punctuation\">;</span>\n  	<span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n</code></pre> \n <p>为什么就多了一个 burst=5 nodelay; 呢，多了这个可以代表Nginx对于一个用户的请求会立即处理前五个，多余的就慢慢来落，没有其他用户的请求我就处理你的，有其他的请求的话我Nginx就漏掉不接受你的请求</p> \n <h3><a id=\"_2199\"></a>限制并发连接数</h3> \n <p>Nginx中的ngx_http_limit_conn_module模块提供了限制并发连接数的功能，可以使用limit_conn_zone指令以及limit_conn执行进行配置。接下来我们可以通过一个简单的例子来看下：</p> \n <pre><code class=\"prism language-bash\">http <span class=\"token punctuation\">{\n    <!-- --></span>\n    limit_conn_zone <span class=\"token variable\">$binary_remote_addr</span> <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>myip:10m<span class=\"token punctuation\">;</span>\n    limit_conn_zone <span class=\"token variable\">$server_name</span> <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>myServerName:10m<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n    \nserver <span class=\"token punctuation\">{\n    <!-- --></span>\n    location / <span class=\"token punctuation\">{\n    <!-- --></span>\n        limit_conn myip <span class=\"token number\">10</span><span class=\"token punctuation\">;</span>\n        limit_conn myServerName <span class=\"token number\">100</span><span class=\"token punctuation\">;</span>\n        rewrite / http://www.lijie.net permanent<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>上面配置了单个IP同时并发连接数最多只能10个连接，并且设置了整个虚拟服务器同时最大并发数最多只能100个链接。当然，只有当请求的header被服务器处理后，虚拟服务器的连接数才会计数。刚才有提到过Nginx是基于漏桶算法原理实现的，实际上限流一般都是基于漏桶算法和令牌桶算法实现的。接下来我们来看看两个算法的介绍：</p> \n <h2><a id=\"_2222\"></a>聊聊：限流了解吗，怎么限流的？</h2> \n <p>Nginx 提供两种限流方式，一是控制速率，二是控制并发连接数。</p> \n <h3><a id=\"1__2226\"></a>1、控制速率 限流</h3> \n <p>ngx_http_limit_req_module 模块提供了漏桶算法(leaky bucket)，可以限制单个IP的请求处理频率。</p> \n <p>Nginx限流使用的是leaky bucket算法，</p> \n <p><a href=\"https://www.cnblogs.com/crazymakercircle/p/15187184.html\">限流：计数器、漏桶、令牌桶 三大算法的原理与实战（史上最全）</a></p> \n <h4><a id=\"_2234\"></a>控制速率基本原理</h4> \n <p>我们从最简单的限流配置开始：</p> \n <pre><code class=\"prism language-bash\">limit_req_zone <span class=\"token variable\">$binary_remote_addr</span> <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>ip_limit:10m <span class=\"token assign-left variable\">rate</span><span class=\"token operator\">=</span>10r/s<span class=\"token punctuation\">;</span>\n\nserver <span class=\"token punctuation\">{\n    <!-- --></span>\n    location /login/ <span class=\"token punctuation\">{\n    <!-- --></span>\n        limit_req <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>ip_limit<span class=\"token punctuation\">;</span>\n        proxy_pass http://login_upstream<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <ul>\n  <li>$binary_remote_addr 针对客户端ip限流；</li>\n  <li>zone=ip_limit:10m 限流规则名称为ip_limit，允许使用10MB的内存空间来记录ip对应的限流状态；</li>\n  <li>rate=10r/s 限流速度为每秒10次请求</li>\n  <li>location /login/ 对登录进行限流</li>\n </ul> \n <p>限流速度为每秒10次请求，如果有10次请求同时到达一个空闲的nginx，他们都能得到执行吗？</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/46b0ec8af1d1904ffc7d510cad095395.png\" alt=\"空桶\"></p> \n <p>漏桶漏出请求是匀速的。</p> \n <p>10r/s是怎样匀速的呢？每100ms漏出一个请求。</p> \n <p>在这样的配置下，桶是空的，所有不能实时漏出的请求，都会被拒绝掉。</p> \n <p>所以如果10次请求同时到达，那么只有一个请求能够得到执行，其它的，都会被拒绝。</p> \n <p>这不太友好，大部分业务场景下我们希望这10个请求都能得到执行。</p> \n <h5><a id=\"Burst_2268\"></a>Burst</h5> \n <p>我们把配置改一下，解决上一节的问题</p> \n <pre><code class=\"prism language-bash\">limit_req_zone <span class=\"token variable\">$binary_remote_addr</span> <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>ip_limit:10m <span class=\"token assign-left variable\">rate</span><span class=\"token operator\">=</span>10r/s<span class=\"token punctuation\">;</span>\n\nserver <span class=\"token punctuation\">{\n    <!-- --></span>\n    location /login/ <span class=\"token punctuation\">{\n    <!-- --></span>\n        limit_req <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>ip_limit <span class=\"token assign-left variable\">burst</span><span class=\"token operator\">=</span><span class=\"token number\">12</span><span class=\"token punctuation\">;</span>\n        proxy_pass http://login_upstream<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <ul>\n  <li>burst=12 漏桶的大小设置为12</li>\n </ul> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/baad0cf2ce345dee99effbc11b182e7d.png\" alt=\"Burst\"></p> \n <p>逻辑上叫漏桶，实现起来是FIFO队列，把得不到执行的请求暂时缓存起来。</p> \n <p>这样漏出的速度仍然是100ms一个请求，但并发而来，暂时得不到执行的请求，可以先缓存起来。只有当队列满了的时候，才会拒绝接受新请求。</p> \n <p>这样漏桶在限流的同时，也起到了削峰填谷的作用。</p> \n <p>在这样的配置下，如果有10次请求同时到达，它们会依次执行，每100ms执行1个。</p> \n <p>虽然得到执行了，但因为排队执行，延迟大大增加，在很多场景下仍然是不能接受的。</p> \n <h5><a id=\"NoDelay_2297\"></a>NoDelay</h5> \n <p>继续修改配置，解决Delay太久导致延迟增加的问题</p> \n <pre><code class=\"prism language-bash\">limit_req_zone <span class=\"token variable\">$binary_remote_addr</span> <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>ip_limit:10m <span class=\"token assign-left variable\">rate</span><span class=\"token operator\">=</span>10r/s<span class=\"token punctuation\">;</span>\n\nserver <span class=\"token punctuation\">{\n    <!-- --></span>\n    location /login/ <span class=\"token punctuation\">{\n    <!-- --></span>\n        limit_req <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>ip_limit <span class=\"token assign-left variable\">burst</span><span class=\"token operator\">=</span><span class=\"token number\">12</span> nodelay<span class=\"token punctuation\">;</span>\n        proxy_pass http://login_upstream<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>nodelay 把开始执行请求的时间提前，以前是delay到从桶里漏出来才执行，现在不delay了，只要入桶就开始执行</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/6b554fae6e4de96fb76314cc80c2c9a8.png\" alt=\"NoDelay\"></p> \n <p>要么立刻执行，要么被拒绝，请求不会因为限流而增加延迟了。</p> \n <p>因为请求从桶里漏出来还是匀速的，桶的空间又是固定的，最终平均下来，还是每秒执行了5次请求，限流的目的还是达到了。</p> \n <p>但这样也有缺点，限流是限了，但是限得不那么匀速。以上面的配置举例，如果有12个请求同时到达，那么这12个请求都能够立刻执行，然后后面的请求只能匀速进桶，100ms执行1个。如果有一段时间没有请求，桶空了，那么又可能出现并发的12个请求一起执行。</p> \n <p>大部分情况下，这种限流不匀速，不算是大问题。不过nginx也提供了一个参数才控制并发执行也就是nodelay的请求的数量。</p> \n <pre><code class=\"prism language-bash\">limit_req_zone <span class=\"token variable\">$binary_remote_addr</span> <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>ip_limit:10m <span class=\"token assign-left variable\">rate</span><span class=\"token operator\">=</span>10r/s<span class=\"token punctuation\">;</span>\n\nserver <span class=\"token punctuation\">{\n    <!-- --></span>\n    location /login/ <span class=\"token punctuation\">{\n    <!-- --></span>\n        limit_req <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>ip_limit <span class=\"token assign-left variable\">burst</span><span class=\"token operator\">=</span><span class=\"token number\">12</span> <span class=\"token assign-left variable\">delay</span><span class=\"token operator\">=</span><span class=\"token number\">4</span><span class=\"token punctuation\">;</span>\n        proxy_pass http://login_upstream<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>delay=4 从桶内第5个请求开始delay</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/48e8e36bf9e0b69a03666a247f3bb36a.png\" alt=\"DelayNum\"></p> \n <p>这样通过控制delay参数的值，可以调整允许并发执行的请求的数量，使得请求变的均匀起来，在有些耗资源的服务上控制这个数量，还是有必要的。</p> \n <p>控制速率 基本原理讲完了，</p> \n <p>接下来，开始 控制速率 限流 的基础配置</p> \n <h4><a id=\"11____2349\"></a>1.1 控制速率 限流 的基础配置：</h4> \n <p>基于客户端192.168.1.1进行限流，</p> \n <p>定义了一个大小为10M，名称为myLimit的内存区，用于存储IP地址访问信息。<br> rate设置IP访问频率，rate=5r/s表示每秒只能处理每个IP地址的5个请求。</p> \n <pre><code class=\"prism language-bash\">http <span class=\"token punctuation\">{\n    <!-- --></span>\n	limit_req_zone <span class=\"token number\">192.168</span>.1.1 <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>myLimit:10m <span class=\"token assign-left variable\">rate</span><span class=\"token operator\">=</span>5r/s<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n\nserver <span class=\"token punctuation\">{\n    <!-- --></span>\n	location / <span class=\"token punctuation\">{\n    <!-- --></span>\n		limit_req <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>myLimit<span class=\"token punctuation\">;</span>\n		rewrite / http://www.hac.cn permanent<span class=\"token punctuation\">;</span>\n	<span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>参数解释：</p> \n <blockquote> \n  <p>limit_req_zone: 定义需要限流的对象。<br> zone: 定义共享内存区来存储访问信息。<br> rate: 用于设置最大访问速率。</p> \n </blockquote> \n <p>Nginx限流是按照毫秒级为单位的，也就是说1秒处理5个请求会变成每200ms只处理一个请求。如果200ms内已经处理完1个请求，但是还是有有新的请求到达，这时候Nginx就会拒绝处理该请求。</p> \n <h4><a id=\"12____2379\"></a>1.2 突发流量限制 访问频率</h4> \n <p>上面rate设置了 5r/s，</p> \n <p>如果有时候流量突然变大，超出的请求就被拒绝返回503了，突发的流量影响业务就不好了。</p> \n <p>这时候可以加上burst 参数，一般再结合 nodelay 一起使用。</p> \n <pre><code class=\"prism language-bash\">server <span class=\"token punctuation\">{\n    <!-- --></span>\n	location / <span class=\"token punctuation\">{\n    <!-- --></span>\n		limit_req <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>myLimit <span class=\"token assign-left variable\">burst</span><span class=\"token operator\">=</span><span class=\"token number\">20</span> nodelay<span class=\"token punctuation\">;</span>\n		rewrite / http://www.hac.cn permanent<span class=\"token punctuation\">;</span>\n	<span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p>burst=20 nodelay 表示这20个请求立马处理，不能延迟，相当于特事特办。不过，即使这20个突发请求立马处理结束，后续来了请求也不会立马处理。</p> \n <p>burst=20 相当于缓存队列中占了20个坑，即使请求被处理了，这20个位置也只能按 100ms一个来释放。</p> \n <h3><a id=\"2_2402\"></a><strong>2、控制并发连接数</strong></h3> \n <p>ngx_http_limit_conn_module 提供了限制连接数功能。</p> \n <p>主要是利用limit_conn_zone和limit_conn两个指令。</p> \n <p>利用连接数限制 某一个用户的ip连接的数量来控制流量。</p> \n <pre><code class=\"prism language-bash\">limit_conn_zone <span class=\"token variable\">$binary_remote_addr</span> <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>perip:10m<span class=\"token punctuation\">;</span>\nlimit_conn_zone <span class=\"token variable\">$server_name</span> <span class=\"token assign-left variable\">zone</span><span class=\"token operator\">=</span>perserver:10m<span class=\"token punctuation\">;</span> \n\nserver <span class=\"token punctuation\">{\n    <!-- --></span>  \n    listen       <span class=\"token number\">80</span><span class=\"token punctuation\">;</span>\n    server_name  localhost<span class=\"token punctuation\">;</span>\n    charset utf-8<span class=\"token punctuation\">;</span>\n    location / <span class=\"token punctuation\">{\n    <!-- --></span>\n        limit_conn perip <span class=\"token number\">10</span><span class=\"token punctuation\">;</span>      <span class=\"token comment\"># 单个客户端ip与服务器的连接数．</span>\n        limit_conn perserver <span class=\"token number\">100</span><span class=\"token punctuation\">;</span> ＃限制与服务器的总连接数\n        root   html<span class=\"token punctuation\">;</span>\n        index  index.html index.htm<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <blockquote> \n  <p>limit_conn perip 10 作用的key 是 $binary_remote_addr，表示限制单个IP同时最多能持有10个连接。<br> limit_conn perserver 100 作用的key是 $server_name，表示虚拟主机(server) 同时能处理并发连接的总数。</p> \n </blockquote> \n <h2><a id=\"nginxhttps_2434\"></a>聊聊：nginx如何配置https</h2> \n <pre><code class=\"prism language-bash\"><span class=\"token comment\">#server端基本配置 server {\n    <!-- --></span>\nlisten <span class=\"token number\">80</span><span class=\"token punctuation\">;</span>\nlisten <span class=\"token number\">443</span> ssl spdy<span class=\"token punctuation\">;</span>\nserver_name io.123.com<span class=\"token punctuation\">;</span>\ninclude   ssl/io.com<span class=\"token punctuation\">;</span>　　　　　　<span class=\"token comment\">#注意看下一个文件</span>\nlocation / <span class=\"token punctuation\">{\n    <!-- --></span>\nproxy_pass http:`<span class=\"token variable\"><span class=\"token variable\">`</span>//lb_io<span class=\"token punctuation\">;</span> <span class=\"token keyword\">if</span><span class=\"token variable\">`</span></span><span class=\"token variable\"><span class=\"token variable\">`</span><span class=\"token punctuation\">(</span>$scheme <span class=\"token operator\">=</span> http <span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{\n     <!-- --></span> <span class=\"token builtin class-name\">return</span><span class=\"token variable\">`</span></span><span class=\"token variable\"><span class=\"token variable\">`</span><span class=\"token number\">301</span> https:<span class=\"token variable\">`</span></span><span class=\"token variable\"><span class=\"token variable\">`</span>//$host$request_uri<span class=\"token punctuation\">;</span>　　　　<span class=\"token comment\">#此项配置为转换为https的基本配置</span> <span class=\"token punctuation\">}</span> proxy_set_header X-Real-IP $remote_addr<span class=\"token punctuation\">;</span> proxy_set_header Host $host<span class=\"token punctuation\">;</span> proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for<span class=\"token punctuation\">;</span> proxy_set_header X-Forwarded-Proto $scheme<span class=\"token punctuation\">;</span> proxy_http_version <span class=\"token number\">1.1</span><span class=\"token punctuation\">;</span> proxy_set_header Upgrade $http_upgrade<span class=\"token punctuation\">;</span> proxy_set_header Connection<span class=\"token variable\">`</span></span><span class=\"token variable\"><span class=\"token variable\">`</span>\"upgrade\"<span class=\"token variable\">`</span></span><span class=\"token variable\"><span class=\"token variable\">`</span><span class=\"token punctuation\">;</span> <span class=\"token punctuation\">}</span> access_log /data/logs/nginx/access/niuaero.log main<span class=\"token punctuation\">;</span> <span class=\"token punctuation\">}</span> ssl_certificate ssl/ca/io.com.pem<span class=\"token punctuation\">;</span>　　　　<span class=\"token comment\">#这个为购买的https证书，供应商会生成</span> ssl_certificate_key ssl/ca/io.com.key<span class=\"token punctuation\">;</span> ssl_session_timeout 5m<span class=\"token punctuation\">;</span> ssl_protocols TLSv1 TLSv1.1 TLSv1.2<span class=\"token punctuation\">;</span> <span class=\"token comment\">#启用TLS1.1、TLS1.2要求OpenSSL1.0.1及以上版本，若您的OpenSSL版本低于要求，请使用 ssl_protocols TLSv1;</span> ssl_ciphers HIGH:<span class=\"token operator\">!</span>RC4:<span class=\"token operator\">!</span>MD5:<span class=\"token operator\">!</span>aNULL:<span class=\"token operator\">!</span>eNULL:<span class=\"token operator\">!</span>NULL:<span class=\"token operator\">!</span>DH:<span class=\"token operator\">!</span>EDH:<span class=\"token operator\">!</span>EXP:+MEDIUM<span class=\"token punctuation\">;</span> ssl_prefer_server_ciphers <span class=\"token variable\">`</span></span><span class=\"token variable\"><span class=\"token variable\">`</span>on<span class=\"token variable\">`</span></span>`<span class=\"token punctuation\">;</span>\n\n</code></pre> \n <h2><a id=\"Nginx_2469\"></a>聊聊：Nginx常用优化配置</h2> \n <ol>\n  <li>调整worker_processes指定Nginx需要创建的worker进程数量，刚才有提到worker进程数一般设置为和CPU核心数一致。</li>\n  <li>调整worker_connections设置Nginx最多可以同时服务的客户端数。结合worker_processes配置可以获得每秒可以服务的最大客户端数。</li>\n  <li>启动gzip压缩，可以对文件大小进行压缩，减少了客户端http的传输带宽，可以大幅度提高页面的加载速度。</li>\n  <li>启用缓存，如果请求静态资源，启用缓存是可以大幅度提升性能的。</li>\n </ol> \n <h2><a id=\"Nginx_2478\"></a>聊聊：Nginx常见的优化配置有哪些？</h2> \n <p><strong>1、调整worker_processes</strong></p> \n <p>指Nginx要生成的worker数量,最佳实践是每个CPU运行1个工作进程。</p> \n <p>了解系统中的CPU核心数，输入</p> \n <pre><code class=\"prism language-bash\">$ <span class=\"token function\">grep</span> processor / proc / cpuinfo <span class=\"token operator\">|</span> <span class=\"token function\">wc</span> <span class=\"token parameter variable\">-l</span>\n</code></pre> \n <p><strong>2、最大化worker_connections</strong></p> \n <p>Nginx Web服务器可以同时提供服务的客户端数。与worker_processes结合使用时，获得每秒可以服务的最大客户端数</p> \n <pre><code>最大客户端数/秒=工作进程*工作者连接数\n</code></pre> \n <p>为了最大化Nginx的全部潜力，应将工作者连接设置为核心一次可以运行的允许的最大进程数1024。</p> \n <p><strong>3、启用Gzip压缩</strong></p> \n <p>压缩文件大小，减少了客户端http的传输带宽，因此提高了页面加载速度</p> \n <p>建议的gzip配置示例如下:( 在http部分内）</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/0ca5a7b7bdd1200ecdf0b32bbc54f9ea.png\" alt=\"\"></p> \n <p><strong>4、为静态文件启用缓存</strong></p> \n <p>为静态文件启用缓存，以减少带宽并提高性能，可以添加下面的命令，限定计算机缓存网页的静态文件：</p> \n <pre><code class=\"prism language-bash\">location ~* .<span class=\"token punctuation\">(</span>jpg<span class=\"token operator\">|</span>jpeg<span class=\"token operator\">|</span>png<span class=\"token operator\">|</span>gif<span class=\"token operator\">|</span>ico<span class=\"token operator\">|</span>css<span class=\"token operator\">|</span>js<span class=\"token punctuation\">)</span>$ <span class=\"token punctuation\">{\n    <!-- --></span>  \n    expires 365d<span class=\"token punctuation\">;</span>  \n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p><strong>5、Timeouts</strong></p> \n <p>keepalive连接减少了打开和关闭连接所需的CPU和网络开销，获得最佳性能需要调整的变量可参考：</p> \n <p><img src=\"https://img-blog.csdnimg.cn/img_convert/26084d9712acffd259ace46c39f3b4a9.png\" alt=\"\"></p> \n <p><strong>6、禁用access_logs</strong></p> \n <p>访问日志记录，它记录每个nginx请求，因此消耗了大量CPU资源，从而降低了nginx性能。</p> \n <p>完全禁用访问日志记录</p> \n <pre><code class=\"prism language-bash\">access_log off<span class=\"token punctuation\">;</span>\n</code></pre> \n <p>如果必须具有访问日志记录，则启用访问日志缓冲</p> \n <p>配置如下：</p> \n <pre><code class=\"prism language-bash\">access_log /var/log/nginx/access.log main <span class=\"token assign-left variable\">buffer</span><span class=\"token operator\">=</span>32k <span class=\"token assign-left variable\">flush</span><span class=\"token operator\">=</span>1m<span class=\"token punctuation\">;</span>\n</code></pre> \n <p>当系统处于负载状态时，启用日志缓冲区以降低 nginx worker 进程阻塞。</p> \n <p>大量的磁盘读写和 cpu 资源使用对于服务器资源也是一种巨大消耗。</p> \n <p>将日志数据缓冲到内存中可能是很小的一个优化手段， buffer 参数意义是缓冲区的大小，功能是当缓冲区已经写满时，日志会被写入文件中；</p> \n <p>flush 参数意义是缓冲区内日志在缓冲区内存中保存的最长时间，功能即当缓存中的日志超过最大缓存时间，也会被写入到文件中， 不足的地方即写入到日志文件的日志有些许延迟，即时调试中应当关闭日志缓冲。 。</p> \n <p><strong>7、指令定义错误日志目录及记录错误日志的等级</strong></p> \n <p>为了精确定位 nginx 的错误日志，使用自带的 error_log 指令定义错误日志目录及记录错误日志的等级，配置如下：</p> \n <p>Bash</p> \n <pre><code class=\"prism language-bash\">error_log /var/log/nginx/error.log warn<span class=\"token punctuation\">;</span>\n</code></pre> \n <p>error_log 指令配置时需要一个必选的日志目录和一个可选的错误等级选项。</p> \n <p>除 if 指令外， error_log 指令能在所有的上下文中使用。错误日志等级包括：</p> \n <p>debug、info、notice、warn、error、crit、alert 和 emerg。给出的日志</p> \n <p>等级顺序就是记录最小到最严谨的日志等级顺序。需要注意的是 debug 日志</p> \n <p>需要在编译 nginx 服务器时，带上 --with-debug 标识才能使用。</p> \n <p>当服务器配置出错时，首先需要查看错误日志以定位问题。错误日志</p> \n <p>也是定位应用服务器(如 FastCGI 服务)的利器。</p> \n <p>通过错误日志，我们可以调试 worker 进程连接错误、内存分配、客户端 IP 和 应用服务器等问题。</p> \n <p>错误日志格式不支持自定义日志格式 ；但他同样记录当前时间、日志等级和具体信息等数据。</p> \n <p>注意：错误日志的默认设置适用于全局。</p> \n <p>要覆盖它，请将 error_log 指令放在 main （顶级）配置上下文中。 error_log 在开源 NGINX 1.5.2 版中添加了在同一配置级别指定多个指令的功能。</p> \n <h2><a id=\"Nginx_2592\"></a>细致聊聊：如何进行Nginx的调优</h2> \n <p><strong>1、worker_processes的进程数，数量要与CPU数量一致，通过lscpu查看</strong></p> \n <pre><code class=\"prism language-sql\">worker_processes <span class=\"token number\">1</span><span class=\"token punctuation\">;</span> \n</code></pre> \n <p>2.1 worker process打开文件数的优化</p> \n <pre><code class=\"prism language-sql\">worker_rlimit_nofile <span class=\"token number\">65535</span><span class=\"token punctuation\">;</span>\n</code></pre> \n <p>2.2 优化了nginx的worker进程最多打开数量的参数之后，还需要优化系统内核参数（允许打开最多文件的参数）</p> \n <pre><code class=\"prism language-bash\">临时配置：\n<span class=\"token builtin class-name\">ulimit</span> <span class=\"token parameter variable\">-Hn</span> <span class=\"token number\">100000</span>\n<span class=\"token builtin class-name\">ulimit</span> <span class=\"token parameter variable\">-Sn</span> <span class=\"token number\">100000</span>     \n永久配置：\n<span class=\"token function\">vim</span> /etc/security/limits.conf\n* soft nofile <span class=\"token number\">100000</span>\n* hard nofile <span class=\"token number\">100000</span>\n</code></pre> \n <p><strong>3、单个进程最大连接数的优化</strong></p> \n <pre><code class=\"prism language-bash\">events <span class=\"token punctuation\">{\n    <!-- --></span>\n    worker_connections <span class=\"token number\">2048</span><span class=\"token punctuation\">;</span>\n    multi_accept on<span class=\"token punctuation\">;</span>\n    use epoll<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span>\n</code></pre> \n <p><strong>4、隐藏版本信息的优化</strong></p> \n <pre><code class=\"prism language-bash\">server_tokens off<span class=\"token punctuation\">;</span>\n</code></pre> \n <p><strong>5、高效文件传输模式的</strong></p> \n <pre><code class=\"prism language-bash\">sendfile on<span class=\"token punctuation\">;</span>\ntcp_nopush on<span class=\"token punctuation\">;</span>\ntcp_nodelay on<span class=\"token punctuation\">;</span>\n</code></pre> \n <p><strong>6、访问日志关闭的优化</strong></p> \n <pre><code class=\"prism language-bash\">access_log off<span class=\"token punctuation\">;</span>\n</code></pre> \n <p><strong>7、超时时间的优化</strong></p> \n <pre><code class=\"prism language-bash\">keepalive_timeout <span class=\"token number\">10</span><span class=\"token punctuation\">;</span> //设置客户端保持活动状态的超时时间\nclient_header_timeout <span class=\"token number\">10</span><span class=\"token punctuation\">;</span> //客户端请求头读取超时时间\nclient_body_timeout <span class=\"token number\">10</span><span class=\"token punctuation\">;</span> //客户端请求体读取超时时间\nreset_timedout_connection on<span class=\"token punctuation\">;</span> //在客户端停止响应之后,允许服务器关闭连接,释放socket关联的内存\nsend_timeout <span class=\"token number\">10</span><span class=\"token punctuation\">;</span> //指定客户端的超时时间，如果在10s内客户端没有任何响应，nginx会自动断开连接\n</code></pre> \n <p><strong>8、gzip的优化</strong></p> \n <pre><code class=\"prism language-bash\"><span class=\"token function\">gzip</span> on<span class=\"token punctuation\">;</span>//开启压缩\ngzip_min_length <span class=\"token number\">1000</span><span class=\"token punctuation\">;</span>//小文件不压缩\ngzip_comp_level <span class=\"token number\">6</span><span class=\"token punctuation\">;</span>//压缩比例\ngzip_types text/plain text/css application/json application/x-javascript text/xml\napplication/xml application/xml+rss text/javascript<span class=\"token punctuation\">;</span>//对指定文件类型进行压缩\n</code></pre> \n <p><strong>9、缓存静态页面的优化 （文件句柄是打开文件的唯一标示）</strong></p> \n <pre><code class=\"prism language-bash\">open_file_cache <span class=\"token assign-left variable\">max</span><span class=\"token operator\">=</span><span class=\"token number\">100000</span> <span class=\"token assign-left variable\">inactive</span><span class=\"token operator\">=</span>20s<span class=\"token punctuation\">;</span> //设置服务器最大缓存10万个文件句柄，关闭20s内无请求的句柄\nopen_file_cache_valid 30s<span class=\"token punctuation\">;</span>//文件句柄的有效期为30s\nopen_file_cache_min_uses <span class=\"token number\">2</span><span class=\"token punctuation\">;</span>//最少打开2次才会被缓存\nopen_file_cache_errors on<span class=\"token punctuation\">;</span>\n</code></pre> \n <h2><a id=\"_2679\"></a>参考文献</h2> \n <p><a href=\"https://www.cnblogs.com/crazymakercircle/p/15187184.html\">限流：计数器、漏桶、令牌桶 三大算法的原理与实战（史上最全）</a></p> \n <h2><a id=\"_2686\"></a>推荐阅读：</h2> \n <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128670335\">Docker面试题（史上最全 + 持续更新）</a>》<br> 《 <a href=\"https://blog.csdn.net/crazymakercircle/article/details/128533821\">场景题：假设10W人突访，你的系统如何做到不 雪崩？</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124790425\">尼恩Java面试宝典</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057567\">Springcloud gateway 底层原理、核心实战 (史上最全)</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124120506\">Flux、Mono、Reactor 实战（史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125059491\">sentinel （史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057545\">Nacos (史上最全)</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/123420859\">分库分表 Sharding-JDBC 底层原理、核心实战（史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/114527369\">TCP协议详解 (史上最全)</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126992542\">clickhouse 超底层原理 + 高可用实操 （史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120702536\">nacos高可用（图解+秒懂+史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264803\">队列之王： Disruptor 原理、架构、源码 一文穿透</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264508\">环形队列、 条带环形队列 Striped-RingBuffer （史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125135726\">一文搞定：SpringBoot、SLF4j、Log4j、Logback、Netty之间混乱关系（史上最全）</a><br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128265067\">单例模式（史上最全）</a><br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125017316\">红黑树（ 图解 + 秒懂 + 史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/109459593\">分布式事务 （秒懂）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128123114\">缓存之王：Caffeine 源码、架构、原理（史上最全，10W字 超级长文）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/113751575\">缓存之王：Caffeine 的使用（史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126579528\">Java Agent 探针、字节码增强 ByteBuddy（史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120747767\">Docker原理（图解+秒懂+史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/116425814\">Redis分布式锁（图解 - 秒懂 - 史上最全）</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85956246\">Zookeeper 分布式锁 - 图解 - 秒懂</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85922561\">Zookeeper Curator 事件监听 - 10分钟看懂</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83957259\">Netty 粘包 拆包 | 史上最全解读</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83758107\">Netty 100万级高并发服务器配置</a>》<br> 《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/102557988\">Springcloud 高并发 配置 （一文全懂）</a>》</p> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 4702);
INSERT INTO `crawlerblog` VALUES (123124036, 'K8S面试题（史上最全 + 持续更新）', '40岁资深老架构师尼恩', '<div id=\"content_views\" class=\"markdown_views prism-atom-one-dark\"> \n <svg xmlns=\"http://www.w3.org/2000/svg\" style=\"display: none;\"> \n  <path stroke-linecap=\"round\" d=\"M5,0 0,2.5 5,5z\" id=\"raphael-marker-block\" style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"></path> \n </svg> \n <h2><a id=\"38K8S_0\"></a>尼恩面试宝典专题38：K8S面试题（史上最全、持续更新）</h2> \n <h4><a id=\"V26_1\"></a>本文版本说明：V26</h4> \n <h2><a id=\"_3\"></a>《尼恩面试宝典》升级规划为：</h2> \n <p>后续基本上，<strong>每一个月，都会发布一次</strong>，最新版本，可以联系构师尼恩获取， 发送 “领取电子书” 获取。</p> \n <h2><a id=\"k8s_9\"></a>什么是k8s？说出你的理解</h2> \n <p>K8s是kubernetes的简称，其本质是一个开源的容器编排系统，主要用于管理容器化的应用，</p> \n <p>其目标是让部署容器化的应用简单并且高效（powerful）,Kubernetes提供了应用部署，规划，更新，维护的一种机制。</p> \n <p>说简单点：k8s就是一个编排容器的系统，一个可以管理容器应用全生命周期的工具，从创建应用，应用的部署，应用提供服务，扩容缩容应用，应用更新，都非常的方便，而且还可以做到故障自愈，</p> \n <p>所以，k8s是一个非常强大的容器编排系统。</p> \n <h2><a id=\"k8s_21\"></a>k8s的组件有哪些，作用分别是什么？</h2> \n <p>k8s主要由master节点和node节点构成。</p> \n <p>master节点负责管理集群，node节点是容器应用真正运行的地方。</p> \n <p>master节点包含的组件有：kube-api-server、kube-controller-manager、kube-scheduler、etcd。</p> \n <p>node节点包含的组件有：kubelet、kube-proxy、container-runtime。</p> \n <p><strong>kube-api-server：</strong></p> \n <p>以下简称api-server，api-server是k8s最重要的核心组件之一，它是k8s集群管理的统一访问入口，提供了RESTful API接口, 实现了认证、授权和准入控制等安全功能；api-server还是其他组件之间的数据交互和通信的枢纽，其他组件彼此之间并不会直接通信，其他组件对资源对象的增、删、改、查和监听操作都是交由api-server处理后，api-server再提交给etcd数据库做持久化存储，只有api-server才能直接操作etcd数据库，其他组件都不能直接操作etcd数据库，其他组件都是通过api-server间接的读取，写入数据到etcd。</p> \n <p><strong>kube-controller-manager：</strong></p> \n <p>以下简称controller-manager，controller-manager是k8s中各种控制器的的管理者，是k8s集群内部的管理控制中心，也是k8s自动化功能的核心；controller-manager内部包含replication controller、node controller、deployment controller、endpoint controller等各种资源对象的控制器，每种控制器都负责一种特定资源的控制流程，而controller-manager正是这些controller的核心管理者。</p> \n <p><strong>kube-scheduler：</strong></p> \n <p>以下简称scheduler，scheduler负责集群资源调度，其作用是将待调度的pod通过一系列复杂的调度算法计算出最合适的node节点，然后将pod绑定到目标节点上。shceduler会根据pod的信息，全部节点信息列表，过滤掉不符合要求的节点，过滤出一批候选节点，然后给候选节点打分，选分最高的就是最佳节点，scheduler就会把目标pod安置到该节点。</p> \n <p><strong>Etcd：</strong></p> \n <p>etcd是一个分布式的键值对存储数据库，主要是用于保存k8s集群状态数据，比如，pod，service等资源对象的信息；etcd可以是单个也可以有多个，多个就是etcd数据库集群，etcd通常部署奇数个实例，在大规模集群中，etcd有5个或7个节点就足够了；另外说明一点，etcd本质上可以不与master节点部署在一起，只要master节点能通过网络连接etcd数据库即可。</p> \n <p><strong>kubelet：</strong></p> \n <p>每个node节点上都有一个kubelet服务进程，kubelet作为连接master和各node之间的桥梁，负责维护pod和容器的生命周期，当监听到master下发到本节点的任务时，比如创建、更新、终止pod等任务，kubelet 即通过控制docker来创建、更新、销毁容器；<br> 每个kubelet进程都会在api-server上注册本节点自身的信息，用于定期向master汇报本节点资源的使用情况。</p> \n <p><strong>kube-proxy：</strong></p> \n <p>kube-proxy运行在node节点上，在Node节点上实现Pod网络代理，维护网络规则和四层负载均衡工作，kube-proxy会监听api-server中从而获取service和endpoint的变化情况，创建并维护路由规则以提供服务IP和负载均衡功能。简单理解此进程是Service的透明代理兼负载均衡器，其核心功能是将到某个Service的访问请求转发到后端的多个Pod实例上。</p> \n <p>container-runtime：容器运行时环境，即运行容器所需要的一系列程序，目前k8s支持的容器运行时有很多，如docker、rkt或其他，比较受欢迎的是docker，但是新版的k8s已经宣布弃用docker。</p> \n <h2><a id=\"Kubernetes_60\"></a>简述Kubernetes相关基础概念?</h2> \n <p>答：</p> \n <p><strong>master：</strong></p> \n <p>k8s集群的管理节点，负责管理集群，提供集群的资源数据访问入口。拥有Etcd存储服务（可选），运行Api Server进程，Controller Manager服务进程及Scheduler服务进程；</p> \n <p><strong>node（worker）：</strong></p> \n <p>Node（worker）是Kubernetes集群架构中运行Pod的服务节点，是Kubernetes集群操作的单元，用来承载被分配Pod的运行，是Pod运行的宿主机。运行docker eninge服务，守护进程kunelet及负载均衡器kube-proxy；</p> \n <p><strong>pod：</strong></p> \n <p>运行于Node节点上，若干相关容器的组合。Pod内包含的容器运行在同一宿主机上，使用相同的网络命名空间、IP地址和端口，能够通过localhost进行通信。Pod是Kurbernetes进行创建、调度和管理的最小单位，它提供了比容器更高层次的抽象，使得部署和管理更加灵活。一个Pod可以包含一个容器或者多个相关容器；</p> \n <p><strong>label：</strong></p> \n <p>Kubernetes中的Label实质是一系列的Key/Value键值对，其中key与value可自定义。Label可以附加到各种资源对象上，如Node、Pod、Service、RC等。一个资源对象可以定义任意数量的Label，同一个Label也可以被添加到任意数量的资源对象上去。Kubernetes通过Label Selector（标签选择器）查询和筛选资源对象；</p> \n <p><strong>Replication Controller：</strong></p> \n <p>Replication Controller用来管理Pod的副本，保证集群中存在指定数量的Pod副本。</p> \n <p>集群中副本的数量大于指定数量，则会停止指定数量之外的多余容器数量。反之，则会启动少于指定数量个数的容器，保证数量不变。</p> \n <p>Replication Controller是实现弹性伸缩、动态扩容和滚动升级的核心；</p> \n <p><strong>Deployment：</strong></p> \n <p>Deployment在内部使用了RS来实现目的，Deployment相当于RC的一次升级，其最大的特色为可以随时获知当前Pod的部署进度；</p> \n <p><strong>HPA（Horizontal Pod Autoscaler）：</strong></p> \n <p>Pod的横向自动扩容，也是Kubernetes的一种资源，通过追踪分析RC控制的所有Pod目标的负载变化情况，来确定是否需要针对性的调整Pod副本数量；</p> \n <p><strong>Service：</strong></p> \n <p>Service定义了Pod的逻辑集合和访问该集合的策略，是真实服务的抽象。</p> \n <p>Service提供了一个统一的服务访问入口以及服务代理和发现机制，关联多个相同Label的Pod，用户不需要了解后台Pod是如何运行；</p> \n <p><strong>Volume：</strong></p> \n <p>Volume是Pod中能够被多个容器访问的共享目录，Kubernetes中的Volume是定义在Pod上，可以被一个或多个Pod中的容器挂载到某个目录下；</p> \n <p><strong>Namespace：</strong></p> \n <p>Namespace用于实现多租户的资源隔离，可将集群内部的资源对象分配到不同的Namespace中，形成逻辑上的不同项目、小组或用户组，便于不同的Namespace在共享使用整个集群的资源的同时还能被分别管理；</p> \n <h2><a id=\"KubernetesDocker_110\"></a>简述Kubernetes和Docker的关系?</h2> \n <p>答：</p> \n <p>Docker开源的容器引擎，一种更加轻量级的虚拟化技术；</p> \n <p>K8s，容器管理工具，用来管理容器pod的集合，它可以实现容器集群的自动化部署、自动扩缩容、维护等功能；</p> \n <h2><a id=\"Kubernetes_124\"></a>简述Kubernetes如何实现集群管理?</h2> \n <p>答：在集群管理方面，Kubernetes将集群中的机器划分为一个Master节点和一群工作节点Node。</p> \n <p>其中，在Master节点运行着集群管理相关的一组进程kube-apiserver、kube-controller-manager和kube-scheduler，这些进程实现了整个集群的资源管理、Pod调度、弹性伸缩、安全控制、系统监控和纠错等管理能力，并且都是全自动完成的；</p> \n <h2><a id=\"Kubernetes_134\"></a>简述Kubernetes的优势、适应场景及其特点?</h2> \n <p>答：</p> \n <p>优势：容器编排、轻量级、开源、弹性伸缩、负载均衡；</p> \n <p>场景：快速部署应用、快速扩展应用、无缝对接新的应用功能、节省资源，优化硬件资源的使用；</p> \n <p>特点：</p> \n <p>可移植: 支持公有云、私有云、混合云、多重云（multi-cloud）、</p> \n <p>可扩展: 模块化,、插件化、可挂载、可组合、</p> \n <p>自动化: 自动部署、自动重启、自动复制、自动伸缩/扩展；</p> \n <h2><a id=\"Kubernetes_154\"></a>简述Kubernetes的缺点或当前的不足之处?</h2> \n <p>​ 答：</p> \n <p>安装过程和配置相对困难复杂、管理服务相对繁琐、运行和编译需要很多时间、它比其他替代品更昂贵、对于简单的应用程序来说，可能不需要涉及Kubernetes即可满足；</p> \n <h2><a id=\"KubernetesMinikubeKubectlKubelet_160\"></a>简述Kubernetes中什么是Minikube、Kubectl、Kubelet?</h2> \n <p>答：</p> \n <p>Minikube 是一种可以在本地轻松运行一个单节点 Kubernetes 群集的工具；</p> \n <p>Kubectl 是一个命令行工具，可以使用该工具控制Kubernetes集群管理器，如检查群集资源，创建、删除和更新组件，查看应用程序；</p> \n <p>Kubelet 是一个代理服务，它在每个节点上运行，并使从服务器与主服务器通信；</p> \n <h2><a id=\"kubelet_172\"></a>kubelet的功能、作用是什么？（重点，经常会问）</h2> \n <p>答：kubelet部署在每个node节点上的，它主要有4个功能：<br> 1、节点管理。</p> \n <p>kubelet启动时会向api-server进行注册，然后会定时的向api-server汇报本节点信息状态，资源使用状态等，这样master就能够知道node节点的资源剩余，节点是否失联等等相关的信息了。master知道了整个集群所有节点的资源情况，这对于 pod 的调度和正常运行至关重要。<br> 2、pod管理。</p> \n <p>kubelet负责维护node节点上pod的生命周期，当kubelet监听到master的下发到自己节点的任务时，比如要创建、更新、删除一个pod，kubelet 就会通过CRI（容器运行时接口）插件来调用不同的容器运行时来创建、更新、删除容器；常见的容器运行时有docker、containerd、rkt等等这些容器运行时，我们最熟悉的就是docker了，但在新版本的k8s已经弃用docker了，k8s1.24版本中已经使用containerd作为容器运行时了。</p> \n <p>3、容器健康检查。</p> \n <p>pod中可以定义启动探针、存活探针、就绪探针等3种，我们最常用的就是存活探针、就绪探针，kubelet 会定期调用容器中的探针来检测容器是否存活，是否就绪，如果是存活探针，则会根据探测结果对检查失败的容器进行相应的重启策略；</p> \n <p>4、Metrics Server资源监控。</p> \n <p>在node节点上部署Metrics Server用于监控node节点、pod的CPU、内存、文件系统、网络使用等资源使用情况，而kubelet则通过Metrics Server获取所在节点及容器的上的数据。</p> \n <h2><a id=\"kubeapiserverpodkubeapiserver_190\"></a>kube-api-server的端口是多少？各个pod是如何访问kube-api-server的？</h2> \n <p>kube-api-server的端口是8080和6443，前者是http的端口，后者是https的端口，以我本机使用kubeadm安装的k8s为例：</p> \n <p>在命名空间的kube-system命名空间里，有一个名称为kube-api-master的pod，</p> \n <p>这个pod就是运行着kube-api-server进程，它绑定了master主机的ip地址和6443端口，但是在default命名空间下，存在一个叫kubernetes的服务，该服务对外暴露端口为443，目标端口6443，</p> \n <p>这个服务的ip地址是clusterip地址池里面的第一个地址，同时这个服务的yaml定义里面并没有指定标签选择器，</p> \n <p>也就是说这个kubernetes服务所对应的endpoint是手动创建的，该endpoint也是名称叫做kubernetes，该endpoint的yaml定义里面代理到master节点的6443端口，也就是kube-api-server的IP和端口。</p> \n <p>这样一来，其他pod访问kube-api-server的整个流程就是：pod创建后嵌入了环境变量，pod获取到了kubernetes这个服务的ip和443端口，请求到kubernetes这个服务其实就是转发到了master节点上的6443端口的kube-api-server这个pod里面。</p> \n <h2><a id=\"k8s_206\"></a>k8s中命名空间的作用是什么？</h2> \n <p>amespace是kubernetes系统中的一种非常重要的资源，namespace的主要作用是用来实现多套环境的资源隔离，或者说是多租户的资源隔离。</p> \n <p>k8s通过将集群内部的资源分配到不同的namespace中，可以形成逻辑上的隔离，以方便不同的资源进行隔离使用和管理。</p> \n <p>不同的命名空间可以存在同名的资源，命名空间为资源提供了一个作用域。</p> \n <p>可以通过k8s的授权机制，将不同的namespace交给不同的租户进行管理，这样就实现了多租户的资源隔离，还可以结合k8s的资源配额机制，限定不同的租户能占用的资源，例如CPU使用量、内存使用量等等来实现租户可用资源的管理。</p> \n <h2><a id=\"k8sRESTKubernetes_Proxy_APIProxy_218\"></a>k8s提供了大量的REST接口，其中有一个是Kubernetes Proxy API接口，简述一下这个Proxy接口的作用，已经怎么使用。</h2> \n <p>kubernetes proxy api接口，从名称中可以得知，proxy是代理的意思，其作用就是代理rest请求；</p> \n <p>Kubernets API server 将接收到的rest请求转发到某个node上的kubelet守护进程的rest接口，由该kubelet进程负责响应。</p> \n <p>我们可以使用这种Proxy接口来直接访问某个pod，这对于逐一排查pod异常问题很有帮助。<br> 下面是一些简单的例子：</p> \n <pre><code class=\"prism language-bash\">http://<span class=\"token operator\">&lt;</span>kube-api-server<span class=\"token operator\">&gt;</span>:<span class=\"token operator\">&lt;</span>api-sever-port<span class=\"token operator\">&gt;</span>/api/v1/nodes/node名称/proxy/pods  	<span class=\"token comment\">#查看指定node的所有pod信息</span>\nhttp://<span class=\"token operator\">&lt;</span>kube-api-server<span class=\"token operator\">&gt;</span>:<span class=\"token operator\">&lt;</span>api-sever-port<span class=\"token operator\">&gt;</span>/api/v1/nodes/node名称/proxy/stats  	<span class=\"token comment\">#查看指定node的物理资源统计信息</span>\nhttp://<span class=\"token operator\">&lt;</span>kube-api-server<span class=\"token operator\">&gt;</span>:<span class=\"token operator\">&lt;</span>api-sever-port<span class=\"token operator\">&gt;</span>/api/v1/nodes/node名称/proxy/spec  	<span class=\"token comment\">#查看指定node的概要信息</span>\n\nhttp://<span class=\"token operator\">&lt;</span>kube-api-server<span class=\"token operator\">&gt;</span>:<span class=\"token operator\">&lt;</span>api-sever-port<span class=\"token operator\">&gt;</span>/api/v1/namespace/命名名称/pods/pod名称/pod服务的url/  	<span class=\"token comment\">#访问指定pod的程序页面</span>\nhttp://<span class=\"token operator\">&lt;</span>kube-api-server<span class=\"token operator\">&gt;</span>:<span class=\"token operator\">&lt;</span>api-sever-port<span class=\"token operator\">&gt;</span>/api/v1/namespace/命名名称/servers/svc名称/url/  	<span class=\"token comment\">#访问指定server的url程序页面</span>\n\n</code></pre> \n <h2><a id=\"pod_239\"></a>pod是什么？</h2> \n <p>在kubernetes的世界中，k8s并不直接处理容器，而是使用多个容器共存的理念，这组容器就叫做pod。</p> \n <p>pod是k8s中可以创建和管理的最小单元，是资源对象模型中由用户创建或部署的最小资源对象模型，其他的资源对象都是用来支撑pod对象功能的，比如，pod控制器就是用来管理pod对象的，service或者imgress资源对象是用来暴露pod引用对象的，persistentvolume资源是用来为pod提供存储等等，</p> \n <p>简而言之，k8s不会直接处理容器，而是pod，pod才是k8s中可以创建和管理的最小单元，也是基本单元。</p> \n <h2><a id=\"pod_247\"></a>pod的原理是什么？</h2> \n <p>在微服务的概念里，一般的，一个容器会被设计为运行一个进程，除非进程本身产生子进程，</p> \n <p>这样，由于不能将多个进程聚集在同一个单独的容器中，所以需要一种更高级的结构将容器绑定在一起，并将它们作为一个单元进行管理，这就是k8s中pod的背后原理。</p> \n <h2><a id=\"pod_253\"></a>pod有什么特点？</h2> \n <p>1、每个pod就像一个独立的逻辑机器，k8s会为每个pod分配一个集群内部唯一的IP地址，所以每个pod都拥有自己的IP地址、主机名、进程等；<br> 2、一个pod可以包含1个或多个容器，1个容器一般被设计成只运行1个进程，1个pod只可能运行在单个节点上，即不可能1个pod跨节点运行，pod的生命周期是短暂，也就是说pod可能随时被消亡（如节点异常，pod异常等情况）；<br> 2、每一个pod都有一个特殊的被称为\"根容器\"的pause容器，也称info容器，pause容器对应的镜像属于k8s平台的一部分，除了pause容器，每个pod还包含一个或多个跑业务相关组件的应用容器；<br> 3、一个pod中的容器共享network命名空间；<br> 4、一个pod里的多个容器共享pod IP，这就意味着1个pod里面的多个容器的进程所占用的端口不能相同，否则在这个pod里面就会产生端口冲突；既然每个pod都有自己的IP和端口空间，那么对不同的两个pod来说就不可能存在端口冲突；<br> 5、应该将应用程序组织到多个pod中，而每个pod只包含紧密相关的组件或进程；<br> 6、pod是k8s中扩容、缩容的基本单位，也就是说k8s中扩容缩容是针对pod而言而非容器。</p> \n <h2><a id=\"pod_265\"></a>pod的重启策略有哪些？</h2> \n <p>pod重启容器策略是指针对pod内所有容器的重启策略，不是重启pod，其可以通过restartPolicy字段配置pod重启容器的策略，如下：</p> \n <ul>\n  <li> <p>Always: 当容器终止退出后，总是重启容器，默认策略就是Always。</p> </li>\n  <li> <p>OnFailure: 当容器异常退出，退出状态码非0时，才重启容器。</p> </li>\n  <li> <p>Never: 当容器终止退出，不管退出状态码是什么，从不重启容器。</p> </li>\n </ul> \n <h2><a id=\"pod_274\"></a>pod的镜像拉取策略有哪几种？</h2> \n <p>pod镜像拉取策略可以通过imagePullPolicy字段配置镜像拉取策略，</p> \n <p>主要有3中镜像拉取策略，如下：</p> \n <ul>\n  <li>IfNotPresent: 默认值，镜像在node节点宿主机上不存在时才拉取。</li>\n  <li>Always: 总是重新拉取，即每次创建pod都会重新从镜像仓库拉取一次镜像。</li>\n  <li>Never: 永远不会主动拉取镜像，仅使用本地镜像，需要你手动拉取镜像到node节点，如果node节点不存在镜像则pod启动失败。</li>\n </ul> \n <h2><a id=\"kubenetespod3_288\"></a>kubenetes针对pod资源对象的健康监测机制?（必须记住3重探测方式，重点，经常问）</h2> \n <p>提供了三类probe（探针）来执行对pod的健康监测：</p> \n <ul>\n  <li>livenessProbe探针 （存活探针）:</li>\n </ul> \n <p>可以根据用户自定义规则来判定pod是否健康，用于判断容器是否处于Running状态，</p> \n <p>如果不是，kubelet就会杀掉该容器，并根据重启策略做相应的处理。如果容器不包含该探针，那么kubelet就会默认返回值都是success;</p> \n <ul>\n  <li>ReadinessProbe探针:</li>\n </ul> \n <p>同样是可以根据用户自定义规则来判断pod是否健康，容器服务是否可用（Ready），如果探测失败，控制器会将此pod从对应service的endpoint列表中移除，从此不再将任何请求调度到此Pod上，直到下次探测成功;</p> \n <ul>\n  <li>startupProbe探针:</li>\n </ul> \n <p>启动检查机制，应用一些启动缓慢的业务，避免业务长时间启动而被上面两类探针kill掉，</p> \n <p>这个问题也可以换另一种方式解决，就是定义上面两类探针机制时，初始化时间定义的长一些即可;</p> \n <p>备注：每种探测方法能支持以下几个相同的检查参数，用于设置控制检查时间：</p> \n <ul>\n  <li> <p>initialDelaySeconds：初始第一次探测间隔，用于应用启动的时间，防止应用还没启动而健康检查失败；</p> </li>\n  <li> <p>periodSeconds：检查间隔，多久执行probe检查，默认为10s；</p> </li>\n  <li> <p>timeoutSeconds：检查超时时长，探测应用timeout后为失败；</p> </li>\n  <li> <p>successThreshold：成功探测阈值，表示探测多少次为健康正常，默认探测1次。</p> </li>\n </ul> \n <h2><a id=\"ReadinessProbelivenessProbe_322\"></a>就绪探针（ReadinessProbe探针）与存活探针（livenessProbe探针）区别是什么？</h2> \n <p>两者作用不一样，</p> \n <p>存活探针是将检查失败的容器杀死，创建新的启动容器来保持pod正常工作；</p> \n <p>就绪探针是，当就绪探针检查失败，并不重启容器，而是将pod移出endpoint，就绪探针确保了service中的pod都是可用的，确保客户端只与正常的pod交互并且客户端永远不会知道系统存在问题。</p> \n <h2><a id=\"_334\"></a>存活探针的属性参数有哪几个？</h2> \n <p>存活探针的附加属性参数有以下几个：</p> \n <ul>\n  <li> <p>initialDelaySeconds：表示在容器启动后延时多久秒才开始探测；</p> </li>\n  <li> <p>periodSeconds：表示执行探测的频率，即间隔多少秒探测一次，默认间隔周期是10秒，最小1秒；</p> </li>\n  <li> <p>timeoutSeconds：表示探测超时时间，默认1秒，最小1秒，表示容器必须在超时时间范围内做出响应，否则视为本次探测失败；</p> </li>\n  <li> <p>successThreshold：表示最少连续探测成功多少次才被认定为成功，默认是1，对于liveness必须是1，最小值是1；</p> </li>\n  <li> <p>failureThreshold：表示连续探测失败多少次才被认定为失败，默认是3，连续3次失败，k8s 将根据pod重启策略对容器做出决定；</p> </li>\n </ul> \n <p>注意：定义存活探针时，一定要设置initialDelaySeconds属性，该属性为初始延时，如果不设置，默认容器启动时探针就开始探测了，这样可能会存在<br> 应用程序还未启动就绪，就会导致探针检测失败，k8s就会根据pod重启策略杀掉容器然后再重新创建容器的莫名其妙的问题。<br> 在生产环境中，一定要定义一个存活探针。</p> \n <h2><a id=\"pod_354\"></a>pod的就绪探针有哪几种？</h2> \n <p>我们知道，当一个pod启动后，就会立即加入service的endpoint ip列表中，并开始接收到客户端的链接请求，</p> \n <p>假若此时pod中的容器的业务进程还没有初始化完毕，那么这些客户端链接请求就会失败，为了解决这个问题，kubernetes提供了就绪探针来解决这个问题的。</p> \n <p>在pod中的容器定义一个就绪探针，就绪探针周期性检查容器，</p> \n <p>如果就绪探针检查失败了，说明该pod还未准备就绪，不能接受客户端链接，则该pod将从endpoint列表中移除，</p> \n <p>pod被剔除了, service就不会把请求分发给该pod，</p> \n <p>然后就绪探针继续检查，如果随后容器就绪，则再重新把pod加回endpoint列表。</p> \n <p>kubernetes提供了3种探测容器的存活探针，如下：</p> \n <ul>\n  <li> <p>httpGet：通过容器的IP、端口、路径发送http 请求，返回200-400范围内的状态码表示成功。</p> </li>\n  <li> <p>exec：在容器内执行shell命令，根据命令退出状态码是否为0进行判断，0表示健康，非0表示不健康。</p> </li>\n  <li> <p>TCPSocket：与容器的IP、端口建立TCP Socket链接，能建立则说明探测成功，不能建立则说明探测失败</p> </li>\n </ul> \n <h2><a id=\"pod_378\"></a>pod的就绪探针的属性参数有哪些</h2> \n <p>就绪探针的附加属性参数有以下几个：</p> \n <ul>\n  <li> <p>initialDelaySeconds：延时秒数，即容器启动多少秒后才开始探测，不写默认容器启动就探测；</p> </li>\n  <li> <p>periodSeconds ：执行探测的频率（秒），默认为10秒，最低值为1；</p> </li>\n  <li> <p>timeoutSeconds ：超时时间，表示探测时在超时时间内必须得到响应，负责视为本次探测失败，默认为1秒，最小值为1；</p> </li>\n  <li> <p>failureThreshold ：连续探测失败的次数，视为本次探测失败，默认为3次，最小值为1次；</p> </li>\n  <li> <p>successThreshold ：连续探测成功的次数，视为本次探测成功，默认为1次，最小值为1次；</p> </li>\n </ul> \n <h2><a id=\"pod_398\"></a>pod的重启策略是什么？</h2> \n <p>答：通过命令“<a href=\"https://so.csdn.net/so/search?q=kubectl&amp;spm=1001.2101.3001.7020\">kubectl</a> explain pod.spec”查看pod的重启策略;</p> \n <ul>\n  <li> <p>Always：但凡pod对象终止就重启，此为默认策略;</p> </li>\n  <li> <p>OnFailure：仅在pod对象出现错误时才重启;</p> </li>\n </ul> \n <h2><a id=\"_pod_410\"></a>简单讲一下 pod创建过程</h2> \n <p>情况一、使用kubectl run命令创建的pod：</p> \n <pre><code>注意：\nkubectl run 在旧版本中创建的是deployment，\n但在新的版本中创建的是pod则其创建过程不涉及deployment\n</code></pre> \n <p>如果是单独的创建一个pod，则其创建过程是这样的：<br> 1、首先，用户通过kubectl或其他api客户端工具提交需要创建的pod信息给apiserver；<br> 2、apiserver验证客户端的用户权限信息，验证通过开始处理创建请求生成pod对象信息，并将信息存入etcd，然后返回确认信息给客户端；<br> 3、apiserver开始反馈etcd中pod对象的变化，其他组件使用watch机制跟踪apiserver上的变动；<br> 4、scheduler发现有新的pod对象要创建，开始调用内部算法机制为pod分配最佳的主机，并将结果信息更新至apiserver；<br> 5、node节点上的kubelet通过watch机制跟踪apiserver发现有pod调度到本节点，尝试调用docker启动容器，并将结果反馈apiserver；<br> 6、apiserver将收到的pod状态信息存入etcd中。<br> 至此，整个pod创建完毕。</p> \n <p>情况二、使用deployment来创建pod：</p> \n <p>1、首先，用户使用kubectl create命令或者kubectl apply命令提交了要创建一个deployment资源请求；<br> 2、api-server收到创建资源的请求后，会对客户端操作进行身份认证，在客户端的~/.kube文件夹下，已经设置好了相关的用户认证信息，这样api-server会知道我是哪个用户，并对此用户进行鉴权，当api-server确定客户端的请求合法后，就会接受本次操作，并把相关的信息保存到etcd中，然后返回确认信息给客户端。<br> 3、apiserver开始反馈etcd中过程创建的对象的变化，其他组件使用watch机制跟踪apiserver上的变动。<br> 4、controller-manager组件会监听api-server的信息，controller-manager是有多个类型的，比如Deployment Controller, 它的作用就是负责监听Deployment，此时Deployment Controller发现有新的deployment要创建，那么它就会去创建一个ReplicaSet，一个ReplicaSet的产生，又被另一个叫做ReplicaSet Controller监听到了，紧接着它就会去分析ReplicaSet的语义，它了解到是要依照ReplicaSet的template去创建Pod, 它一看这个Pod并不存在，那么就新建此Pod，当Pod刚被创建时，它的nodeName属性值为空，代表着此Pod未被调度。<br> 5、调度器Scheduler组件开始介入工作，Scheduler也是通过watch机制跟踪apiserver上的变动，发现有未调度的Pod，则根据内部算法、节点资源情况，pod定义的亲和性反亲和性等等，调度器会综合的选出一批候选节点，在候选节点中选择一个最优的节点，然后将pod绑定该该节点，将信息反馈给api-server。<br> 6、kubelet组件布署于Node之上，它也是通过watch机制跟踪apiserver上的变动，监听到有一个Pod应该要被调度到自身所在Node上来，kubelet首先判断本地是否在此Pod，如果不存在，则会进入创建Pod流程，创建Pod有分为几种情况，第一种是容器不需要挂载外部存储，则相当于直接docker run把容器启动，但不会直接挂载docker网络，而是通过CNI调用网络插件配置容器网络，如果需要挂载外部存储，则还要调用CSI来挂载存储。kubelet创建完pod，将信息反馈给api-server，api-servier将pod信息写入etcd。<br> 7、Pod建立成功后，ReplicaSet Controller会对其持续进行关注，如果Pod因意外或被我们手动退出，ReplicaSet Controller会知道，并创建新的Pod，以保持replicas数量期望值。</p> \n <h2><a id=\"k8s_pod_443\"></a>k8s 创建一个pod的详细流程，涉及的组件怎么通信的？</h2> \n <p>答：</p> \n <p>1）客户端提交创建请求，可以通过 api-server 提供的 restful 接口，或者是通过 kubectl 命令行工具，支持的数据类型包括 JSON 和 YAML；</p> \n <p>2）api-server 处理用户请求，将 pod 信息存储至 etcd 中；</p> \n <p>3）kube-scheduler 通过 api-server 提供的接口监控到未绑定的 pod，尝试为 pod 分配 node 节点，主要分为两个阶段，预选阶段和优选阶段，其中预选阶段是遍历所有的 node 节点，根据策略筛选出候选节点，而优选阶段是在第一步的基础上，为每一个候选节点进行打分，分数最高者胜出；</p> \n <p>4）选择分数最高的节点，进行 pod binding 操作，并将结果存储至 etcd 中；</p> \n <p>5）随后目标节点的 kubelet 进程通过 api-server 提供的接口监测到 kube-scheduler 产生的 pod 绑定事件，然后从 etcd 获取 pod 清单，下载镜像并启动容器；</p> \n <h2><a id=\"pod_461\"></a>简单描述一下pod的终止过程</h2> \n <p>1、用户向apiserver发送删除pod对象的命令；<br> 2、apiserver中的pod对象信息会随着时间的推移而更新，在宽限期内（默认30s），pod被视为dead；<br> 3、将pod标记为terminating状态；<br> 4、kubectl在监控到pod对象为terminating状态了就会启动pod关闭过程；<br> 5、endpoint控制器监控到pod对象的关闭行为时将其从所有匹配到此endpoint的server资源endpoint列表中删除；<br> 6、如果当前pod对象定义了preStop钩子处理器，则在其被标记为terminating后会意同步的方式启动执行；<br> 7、pod对象中的容器进程收到停止信息；<br> 8、宽限期结束后，若pod中还存在运行的进程，那么pod对象会收到立即终止的信息；<br> 9、kubelet请求apiserver将此pod资源的宽限期设置为0从而完成删除操作，此时pod对用户已不可见。</p> \n <h2><a id=\"pod_473\"></a>pod的生命周期有哪几种？</h2> \n <p>pod生命周期有的5种状态（也称5种相位），如下：</p> \n <ul>\n  <li> <p>Pending（挂起）：API server已经创建pod，但是该pod还有一个或多个容器的镜像没有创建，包括正在下载镜像的过程；</p> </li>\n  <li> <p>Running（运行中）：Pod内所有的容器已经创建，且至少有一个容器处于运行状态、正在启动括正在重启状态；</p> </li>\n  <li> <p>Succeed（成功）：Pod内所有容器均已退出，且不会再重启；</p> </li>\n  <li> <p>Failed（失败）：Pod内所有容器均已退出，且至少有一个容器为退出失败状态</p> </li>\n  <li> <p>Unknown（未知）：某于某种原因apiserver无法获取该pod的状态，可能由于网络通行问题导致；</p> </li>\n </ul> \n <h2><a id=\"podpending_487\"></a>pod一致处于pending状态一般有哪些情况，怎么排查？（重点，持续更新）</h2> \n <p>（这个问题被问到的概率非常大）<br> 一个pod一开始创建的时候，它本身就是会处于pending状态，这时可能是正在拉取镜像，正在创建容器的过程。</p> \n <p>如果等了一会发现pod一直处于pending状态，</p> \n <p>那么我们可以使用kubectl describe命令查看一下pod的Events详细信息。一般可能会有这么几种情况导致pod一直处于pending状态：<br> 1、调度器调度失败。</p> \n <p>Scheduer调度器无法为pod分配一个合适的node节点。</p> \n <p>而这又会有很多种情况，比如，node节点处在cpu、内存压力，导致无节点可调度；pod定义了资源请求，没有node节点满足资源请求；node节点上有污点而pod没有定义容忍；pod中定义了亲和性或反亲和性而没有节点满足这些亲和性或反亲和性；以上是调度器调度失败的几种情况。<br> 2、pvc、pv无法动态创建。</p> \n <p>如果因为pvc或pv无法动态创建，那么pod也会一直处于pending状态，比如要使用StatefulSet 创建redis集群，因为粗心大意，定义的storageClassName名称写错了，那么会造成无法创建pvc，这种情况pod也会一直处于pending状态，或者，即使pvc是正常创建了，但是由于某些异常原因导致动态供应存储无法正常创建pv，那么这种情况pod也会一直处于pending状态。</p> \n <h2><a id=\"DaemonSet_506\"></a>DaemonSet资源对象的特性？</h2> \n <p>答：</p> \n <p>DaemonSet这种资源对象会在每个k8s集群中的节点上运行，并且每个节点只能运行一个pod，这是它和deployment资源对象的最大也是唯一的区别。</p> \n <p>所以，在其yaml文件中，不支持定义replicas，</p> \n <p>除此之外，与Deployment、RS等资源对象的写法相同,</p> \n <p>DaemonSet一般使用的场景有</p> \n <ul>\n  <li>在去做每个节点的日志收集工作；</li>\n  <li>监控每个节点的的运行状态;</li>\n </ul> \n <h2><a id=\"Pod_521\"></a>删除一个Pod会发生什么事情？</h2> \n <p>答：</p> \n <p>Kube-apiserver会接受到用户的删除指令，默认有30秒时间等待优雅退出，超过30秒会被标记为死亡状态，</p> \n <p>此时Pod的状态Terminating，kubelet看到pod标记为Terminating就开始了关闭Pod的工作;</p> \n <p>关闭流程如下：</p> \n <p>1）pod从service的endpoint列表中被移除；</p> \n <p>2)如果该pod定义了一个停止前的钩子，其会在pod内部被调用，停止钩子一般定义了如何优雅的结束进程；</p> \n <p>3)进程被发送TERM信号（kill -14）;</p> \n <p>4)当超过优雅退出的时间后，Pod中的所有进程都会被发送SIGKILL信号（kill -9）;</p> \n <h2><a id=\"pod_543\"></a>pod的共享资源？</h2> \n <p>​ 答：</p> \n <p>1）PID 命名空间：Pod 中的不同应用程序可以看到其他应用程序的进程 ID；</p> \n <p>2）网络命名空间：Pod 中的多个容器能够访问同一个IP和端口范围；</p> \n <p>3）IPC 命名空间：Pod 中的多个容器能够使用 SystemV IPC 或 POSIX 消息队列进行通信；</p> \n <p>4）UTS 命名空间：Pod 中的多个容器共享一个主机名；</p> \n <p>5）Volumes（共享存储卷）：Pod 中的各个容器可以访问在 Pod 级别定义的 Volumes；</p> \n <h2><a id=\"pod_561\"></a>pod的初始化容器是干什么的？</h2> \n <p>init container，初始化容器用于在启动应用容器之前完成应用容器所需要的前置条件，</p> \n <p>初始化容器本质上和应用容器是一样的，但是初始化容器是仅允许一次就结束的任务，初始化容器具有两大特征：</p> \n <p>1、初始化容器必须运行完成直至结束，若某初始化容器运行失败，那么kubernetes需要重启它直到成功完成；<br> 2、初始化容器必须按照定义的顺序执行，当且仅当前一个初始化容器成功之后，后面的一个初始化容器才能运行；</p> \n <h2><a id=\"pod_570\"></a>pod的资源请求、限制如何定义？</h2> \n <p>pod的资源请求、资源限制可以直接在pod中定义</p> \n <p>主要包括两块内容，</p> \n <ul>\n  <li>limits，限制pod能使用的最大cpu和内存，</li>\n  <li>requests，pod启动时申请的cpu和内存。</li>\n </ul> \n <pre><code class=\"prism language-bash\"> resources:					<span class=\"token comment\">#资源配额</span>\n      limits:					<span class=\"token comment\">#限制最大资源，上限</span>\n        cpu: <span class=\"token number\">2</span>					<span class=\"token comment\">#CPU限制，单位是code数</span>\n        memory: 2G				<span class=\"token comment\">#内存最大限制</span>\n      requests:					<span class=\"token comment\">#请求资源（最小，下限）</span>\n        cpu: <span class=\"token number\">1</span>					<span class=\"token comment\">#CPU请求，单位是code数</span>\n        memory: 500G			<span class=\"token comment\">#内存最小请求</span>\n\n</code></pre> \n <h2><a id=\"podcommandargsdockerentrypointc_592\"></a>pod的定义中有个command和args参数，这两个参数不会和docker镜像的entrypointc冲突吗？</h2> \n <p>不会。</p> \n <p>在pod中定义的command参数用于指定容器的启动命令列表，如果不指定，则默认使用Dockerfile打包时的启动命令，args参数用于容器的启动命令需要的参数列表；</p> \n <p>特别说明：</p> \n <p>kubernetes中的command、args其实是实现覆盖dockerfile中的ENTRYPOINT的功能的。</p> \n <pre><code class=\"prism language-bash\"><span class=\"token number\">1</span>、如果command和args均没有写，那么使用Dockerfile的配置；\n<span class=\"token number\">2</span>、如果command写了但args没写，那么Dockerfile默认的配置会被忽略，执行指定的command；\n<span class=\"token number\">3</span>、如果command没写但args写了，那么Dockerfile中的ENTRYPOINT的会被执行，使用当前args的参数；\n<span class=\"token number\">4</span>、如果command和args都写了，那么Dockerfile会被忽略，执行输入的command和args。\n\n\n</code></pre> \n <h2><a id=\"pause_615\"></a>pause容器作用是什么？</h2> \n <p>每个pod里运行着一个特殊的被称之为pause的容器，也称根容器，而其他容器则称为业务容器；</p> \n <p>创建pause容器主要是为了为业务容器提供 Linux命名空间，共享基础：包括 pid、icp、net 等，以及启动 init 进程，并收割僵尸进程；</p> \n <p>这些业务容器共享pause容器的网络命名空间和volume挂载卷，</p> \n <p>当pod被创建时，pod首先会创建pause容器，从而把其他业务容器加入pause容器，从而让所有业务容器都在同一个命名空间中，这样可以就可以实现网络共享。</p> \n <p>pod还可以共享存储，在pod级别引入数据卷volume，业务容器都可以挂载这个数据卷从而实现持久化存储。</p> \n <h2><a id=\"_629\"></a>标签及标签选择器是什么，如何使用？</h2> \n <p>标签是键值对类型，标签可以附加到任何资源对象上，主要用于管理对象，查询和筛选。</p> \n <p>标签常被用于标签选择器的匹配度检查，从而完成资源筛选；一个资源可以定义一个或多个标签在其上面。</p> \n <p>标签选择器，标签要与标签选择器结合在一起，标签选择器允许我们选择标记有特定标签的资源对象子集，如pod，并对这些特定标签的pod进行查询，删除等操作。</p> \n <p>标签和标签选择器最重要的使用之一在于，在deployment中，在pod模板中定义pod的标签，然后在deployment定义标签选择器，这样就通过标签选择器来选择哪些pod是受其控制的，service也是通过标签选择器来关联哪些pod最后其服务后端pod。</p> \n <h2><a id=\"servicepod_641\"></a>service是如何与pod关联的？</h2> \n <p>答案是通过标签选择器，每一个由deployment创建的pod都带有标签，这样，service就可以定义标签选择器来关联哪些pod是作为其后端了，就是这样，service就与pod管联在一起了。</p> \n <h2><a id=\"servicepod_647\"></a>service的域名解析格式、pod的域名解析格式</h2> \n <p>service的DNS域名表示格式为<code>&lt;servicename&gt;.&lt;namespace&gt;.svc.&lt;clusterdomain&gt;</code>，</p> \n <p>servicename是service的名称，namespace是service所处的命名空间，clusterdomain是k8s集群设置的域名后缀，一般默认为 cluster.local</p> \n <p>pod的DNS域名格式为：<code>&lt;pod-ip&gt;.&lt;namespace&gt;.pod.&lt;clusterdomain&gt;</code> ，</p> \n <p>其中，pod-ip需要使用-将ip直接的点替换掉，namespace为pod所在的命名空间，clusterdomain是k8s集群设置的域名后缀，一般默认为 cluster.local ，</p> \n <p>演示如下：<code>10-244-1-223.default.pod.cluster.local</code></p> \n <p>对于deployment、daemonsets等创建的pod，还还可以通过<code>&lt;pod-ip&gt;.&lt;deployment-name&gt;.&lt;namespace&gt;.svc.&lt;clusterdomain&gt;</code> 这样的域名访问。</p> \n <h2><a id=\"service_663\"></a>service的类型有哪几种</h2> \n <p>service的类型一般有4中，分别是：</p> \n <ul>\n  <li> <p>ClusterIP：表示service仅供集群内部使用，默认值就是ClusterIP类型</p> </li>\n  <li> <p>NodePort：表示service可以对外访问应用，会在每个节点上暴露一个端口，这样外部浏览器访问地址为：任意节点的IP：NodePort就能连上service了</p> </li>\n  <li> <p>LoadBalancer：表示service对外访问应用，这种类型的service是公有云环境下的service，此模式需要外部云厂商的支持，需要有一个公网IP地址</p> </li>\n  <li> <p>ExternalName：这种类型的service会把集群外部的服务引入集群内部，这样集群内直接访问service就可以间接的使用集群外部服务了</p> </li>\n </ul> \n <p>一般情况下，service都是ClusterIP类型的，通过ingress接入的外部流量。</p> \n <h2><a id=\"PodService_679\"></a>Pod到Service的通信？</h2> \n <p>​</p> \n <p>1）k8s在创建服务时为服务分配一个虚拟IP，客户端通过该IP访问服务，服务则负责将请求转发到后端Pod上；</p> \n <p>2）Service是通过kube-proxy服务进程实现，该进程在每个Node上均运行可以看作一个透明代理兼负载均衡器；</p> \n <p>3）对每个TCP类型Service，kube-proxy都会在本地Node上建立一个SocketServer来负责接受请求，然后均匀发送到后端Pod默认采用Round Robin负载均衡算法；</p> \n <p>4）Service的Cluster IP与NodePort等概念是kube-proxy通过Iptables的NAT转换实现，kube-proxy进程动态创建与Service相关的Iptables规则；</p> \n <p>5）kube-proxy通过查询和监听API Server中Service与Endpoints的变化来实现其主要功能，包括为新创建的Service打开一个本地代理对象，接收请求针对针对发生变化的Service列表，kube-proxy会逐个处理；</p> \n <h2><a id=\"podservicepodservice_697\"></a>一个应用pod是如何发现service的，或者说，pod里面的容器用于是如何连接service的？</h2> \n <p>答：有两种方式，一种是通过环境变量，另一种是通过service的dns域名方式。</p> \n <p>1、环境变量：</p> \n <p>当pod被创建之后，k8s系统会自动为容器注入集群内有效的service名称和端口号等信息为环境变量的形式，</p> \n <p>这样容器应用直接通过取环境变量值就能访问service了，</p> \n <p>如<code>curl http://${WEBAPP_SERVICE_HOST}:{WEBAPP_SERVICE_PORT}</code></p> \n <p>2、DNS方式：</p> \n <p>使用dns域名解析的前提是k8s集群内有DNS域名解析服务器，</p> \n <p>默认k8s中会有一个CoreDNS作为k8s集群的默认DNS服务器提供域名解析服务器；</p> \n <p>service的DNS域名表示格式为<code>&lt;servicename&gt;.&lt;namespace&gt;.svc.&lt;clusterdomain&gt;</code>，</p> \n <p>servicename是service的名称，namespace是service所处的命名空间，clusterdomain是k8s集群设置的域名后缀，一般默认为 cluster.local ，</p> \n <p>这样容器应用直接通过service域名就能访问service了，</p> \n <p>如<code>wget http://svc-deployment-nginx.default.svc.cluster.local:80</code>，</p> \n <p>另外，service的port端口如果定义了名称，那么port也可以通过DNS进行解析，</p> \n <p>格式为：<code>_&lt;portname&gt;._&lt;protocol&gt;.&lt;servicename&gt;.&lt;namespace&gt;.svc.&lt;clusterdomain&gt;</code></p> \n <h2><a id=\"servicek8s_729\"></a>如何创建一个service代理外部的服务，或者换句话来说，在k8s集群内的应用如何访问外部的服务，如数据库服务，缓存服务等?</h2> \n <p>答：可以通过创建一个没有标签选择器的service来代理集群外部的服务。</p> \n <p>1、创建service时不指定selector标签选择器，但需要指定service的port端口、端口的name、端口协议等，这样创建出来的service因为没有指定标签选择器就不会自动创建endpoint；</p> \n <p>2、手动创建一个与service同名的endpoint，endpoint中定义外部服务的IP和端口，endpoint的名称一定要与service的名称一样，端口协议也要一样，端口的name也要与service的端口的name一样，不然endpoint不能与service进行关联。</p> \n <p>完成以上两步，k8s会自动将service和同名的endpoint进行关联，</p> \n <p>这样，k8s集群内的应用服务直接访问这个service就可以相当于访问外部的服务了。</p> \n <h2><a id=\"serviceendpointkubeproxys_743\"></a>service、endpoint、kube-proxys三种的关系是什么？</h2> \n <p><strong>service</strong>：</p> \n <p>在kubernetes中，service是一种为一组功能相同的pod提供单一不变的接入点的资源。</p> \n <p>当service被建立时，service的IP和端口不会改变，这样外部的客户端（也可以是集群内部的客户端）通过service的IP和端口来建立链接，这些链接会被路由到提供该服务的任意一个pod上。</p> \n <p>通过这样的方式，客户端不需要知道每个单独提供服务的pod地址，这样pod就可以在集群中随时被创建或销毁。</p> \n <p><strong>endpoint</strong>：</p> \n <p>service维护一个叫endpoint的资源列表，endpoint资源对象保存着service关联的pod的ip和端口。</p> \n <p>从表面上看，当pod消失，service会在endpoint列表中剔除pod，当有新的pod加入，service就会将pod ip加入endpoint列表；</p> \n <p>但是正在底层的逻辑是，endpoint的这种自动剔除、添加、更新pod的地址其实底层是由<code>endpoint controller</code>控制的，<code>endpoint controller</code>负责监听service和对应的pod副本的变化，如果监听到service被删除，则删除和该service同名的endpoint对象，如果监听到新的service被创建或者修改，则根据该service信息获取得相关pod列表，然后创建或更新service对应的endpoint对象，如果监听到pod事件，则更新它所对应的service的endpoint对象。</p> \n <p><strong>kube-proxy</strong>：</p> \n <p>kube-proxy运行在node节点上，在Node节点上实现Pod网络代理，维护网络规则和四层负载均衡工作，</p> \n <p><code>kube-proxy</code>会监听<code>api-server</code>中从而获取service和endpoint的变化情况，创建并维护路由规则以提供服务IP和负载均衡功能。</p> \n <p>简单理解此进程是Service的透明代理兼负载均衡器，其核心功能是将到某个Service的访问请求转发到后端的多个Pod实例上。</p> \n <h2><a id=\"serviceserviceservice_769\"></a>无头service和普通的service有什么区别，无头service使用场景是什么？</h2> \n <p>答：</p> \n <p><strong>无头service</strong>没有cluster ip，在定义service时将 <code>service.spec.clusterIP：None</code>，就表示创建的是无头service。</p> \n <p><strong>普通的service</strong>是用于为一组后端pod提供请求连接的负载均衡，让客户端能通过固定的service ip地址来访问pod，这类的pod是没有状态的，同时service还具有负载均衡和服务发现的功能。普通service跟我们平时使用的nginx反向代理很相识。</p> \n <p>试想这样一种情况，有6个redis pod ,它们相互之间要通信并要组成一个redis集群，</p> \n <p>不需要所谓的service负载均衡，这时无头service就是派上用场了，</p> \n <p>无头service由于没有cluster ip，kube-proxy就不会处理它也就不会对它生成规则负载均衡，无头service直接绑定的是pod 的ip。无头service仍会有标签选择器，有标签选择器就会有endpoint资源。</p> \n <p><strong>无头service使用场景：</strong></p> \n <p>无头service一般用于有状态的应用场景，如Kaka集群、Redis集群等，这类pod之间需要相互通信相互组成集群，不在需要所谓的service负载均衡。</p> \n <h2><a id=\"deployment_789\"></a>deployment怎么扩容或缩容？</h2> \n <p>答：直接修改pod副本数即可，可以通过下面的方式来修改pod副本数：</p> \n <p>1、直接修改yaml文件的replicas字段数值，然后<code>kubectl apply -f xxx.yaml</code>来实现更新；</p> \n <p>2、使用<code>kubectl edit deployment xxx</code> 修改replicas来实现在线更新；</p> \n <p>3、使用<code>kubectl scale --replicas=5 deployment/deployment-nginx</code>命令来扩容缩容。</p> \n <h2><a id=\"deployment_799\"></a>deployment的更新升级策略有哪些？</h2> \n <p>答：deployment的升级策略主要有两种。</p> \n <p>1、Recreate 重建更新：这种更新策略会杀掉所有正在运行的pod，然后再重新创建的pod；</p> \n <p>2、rollingUpdate 滚动更新：这种更新策略，deployment会以滚动更新的方式来逐个更新pod，同时通过设置滚动更新的两个参数<code>maxUnavailable、maxSurge</code>来控制更新的过程。</p> \n <h2><a id=\"deployment_807\"></a>deployment的滚动更新策略有两个特别主要的参数，解释一下它们是什么意思？</h2> \n <p>答：deployment的滚动更新策略，rollingUpdate 策略，主要有两个参数，maxUnavailable、maxSurge。</p> \n <ul>\n  <li> <p>maxUnavailable：最大不可用数，maxUnavailable用于指定deployment在更新的过程中不可用状态的pod的最大数量，maxUnavailable的值可以是一个整数值，也可以是pod期望副本的百分比，如25%，计算时向下取整。</p> </li>\n  <li> <p>maxSurge：最大激增数，maxSurge指定deployment在更新的过程中pod的总数量最大能超过pod副本数多少个，maxUnavailable的值可以是一个整数值，也可以是pod期望副本的百分比，如25%，计算时向上取整。</p> </li>\n </ul> \n <h2><a id=\"deployment_815\"></a>deployment更新的命令有哪些？</h2> \n <p>答：可以通过三种方式来实现更新deployment。</p> \n <p>1、直接修改yaml文件的镜像版本，然后<code>kubectl apply -f xxx.yaml</code>来实现更新；</p> \n <p>2、使用<code>kubectl edit deployment xxx</code> 实现在线更新；</p> \n <p>3、使用<code>kubectl set image deployment/nginx busybox=busybox nginx=nginx:1.9.1</code> 命令来更新。</p> \n <h2><a id=\"deployment_827\"></a>简述一下deployment的更新过程?</h2> \n <p>deployment是通过控制replicaset来实现，由replicaset真正创建pod副本，每更新一次deployment，都会创建新的replicaset，下面来举例deployment的更新过程：</p> \n <p>假设要升级一个nginx-deployment的版本镜像为nginx:1.9，deployment的定义滚动更新参数如下：</p> \n <pre><code class=\"prism language-bash\">replicas: <span class=\"token number\">3</span>\ndeployment.spec.strategy.type: RollingUpdate\nmaxUnavailable：25%\nmaxSurge：25%\n\n</code></pre> \n <p>通过计算我们得出，3*25%=0.75，maxUnavailable是向下取整，则maxUnavailable=0，maxSurge是向上取整，则maxSurge=1，所以我们得出在整个deployment升级镜像过程中，不管旧的pod和新的pod是如何创建消亡的，pod总数最大不能超过3+maxSurge=4个，最大pod不可用数3-maxUnavailable=3个。</p> \n <p>现在具体讲一下deployment的更新升级过程：</p> \n <p>使用<code>kubectl set image deployment/nginx nginx=nginx:1.9 --record</code> 命令来更新；</p> \n <p>1、deployment创建一个新的replaceset，先新增1个新版本pod，此时pod总数为4个，不能再新增了，再新增就超过pod总数4个了；旧=3，新=1，总=4；</p> \n <p>2、减少一个旧版本的pod，此时pod总数为3个，这时不能再减少了，再减少就不满足最大pod不可用数3个了；旧=2，新=1，总=3；</p> \n <p>3、再新增一个新版本的pod，此时pod总数为4个，不能再新增了；旧=2，新=2，总=4；</p> \n <p>4、减少一个旧版本的pod，此时pod总数为3个，这时不能再减少了；旧=1，新=2，总=3；</p> \n <p>5、再新增一个新版本的pod，此时pod总数为4个，不能再新增了；旧=1，新=3，总=4；</p> \n <p>6、减少一个旧版本的pod，此时pod总数为3个，更新完成，pod都是新版本了；旧=0，新=3，总=3；</p> \n <h2><a id=\"deployment_859\"></a>deployment的回滚使用什么命令</h2> \n <p>在升级deployment时kubectl set image 命令加上 --record 参数可以记录具体的升级历史信息，</p> \n <p>使用<code>kubectl rollout history deployment/deployment-nginx</code> 命令来查看指定的deployment升级历史记录，</p> \n <p>如果需要回滚到某个指定的版本，可以使用<code>kubectl rollout undo deployment/deployment-nginx --to-revision=2</code> 命令来实现。</p> \n <h2><a id=\"_869\"></a>讲一下都有哪些存储卷，作用分别是什么?</h2> \n <table>\n  <thead>\n   <tr>\n    <th>卷</th>\n    <th>作用</th>\n    <th>常用场景</th>\n   </tr>\n  </thead>\n  <tbody>\n   <tr>\n    <td>emptyDir</td>\n    <td>用于存储临时数据的简单空目录</td>\n    <td>一个pod中的多个容器需要共享彼此的数据 ，emptyDir的数据随着容器的消亡也会销毁</td>\n   </tr>\n   <tr>\n    <td>hostPath</td>\n    <td>用于将目录从工作节点的文件系统挂载到pod中</td>\n    <td>不常用，缺点是，pod的调度不是固定的，也就是当pod消失后deployment重新创建一个pod，而这pod如果不是被调度到之前pod的节点，那么该pod就不能访问之前的数据</td>\n   </tr>\n   <tr>\n    <td>configMap</td>\n    <td>用于将非敏感的数据保存到键值对中，使用时可以使用作为环境变量、命令行参数arg，存储卷被pods挂载使用</td>\n    <td>将应用程序的不敏感配置文件创建为configmap卷，在pod中挂载configmap卷，可是实现热更新</td>\n   </tr>\n   <tr>\n    <td>secret</td>\n    <td>主要用于存储和管理一些敏感数据，然后通过在 Pod 的容器里挂载 Volume 的方式或者环境变量的方式访问到这些 Secret 里保存的信息了，pod会自动解密Secret 的信息</td>\n    <td>将应用程序的账号密码等敏感信息通过secret卷的形式挂载到pod中使用</td>\n   </tr>\n   <tr>\n    <td>downwardApi</td>\n    <td>主要用于暴露pod元数据，如pod的名字</td>\n    <td>pod中的应用程序需要指定pod的name等元数据，就可以通过downwardApi 卷的形式挂载给pod使用</td>\n   </tr>\n   <tr>\n    <td>projected</td>\n    <td>这是一种特殊的卷，用于将上面这些卷一次性的挂载给pod使用</td>\n    <td>将上面这些卷一次性的挂载给pod使用</td>\n   </tr>\n   <tr>\n    <td>pvc</td>\n    <td>pvc是存储卷声明</td>\n    <td>通常会创建pvc表示对存储的申请，然后在pod中使用pvc</td>\n   </tr>\n   <tr>\n    <td>网络存储卷</td>\n    <td>pod挂载网络存储卷，这样就能将数据持久化到后端的存储里</td>\n    <td>常见的网络存储卷有nfs存储、glusterfs 卷、ceph rbd存储卷</td>\n   </tr>\n  </tbody>\n </table> \n <h2><a id=\"pv_884\"></a>pv的访问模式有哪几种</h2> \n <p>pv的访问模式有3种，如下：</p> \n <ul>\n  <li> <p>ReadWriteOnce，简写：RWO 表示，只仅允许单个节点以读写方式挂载；</p> </li>\n  <li> <p>ReadOnlyMany，简写：ROX 表示，可以被许多节点以只读方式挂载；</p> </li>\n  <li> <p>ReadWriteMany，简写：RWX 表示，可以被多个节点以读写方式挂载；</p> </li>\n </ul> \n <h2><a id=\"pv_894\"></a>pv的回收策略有哪几种</h2> \n <p>主要有3中回收策略：retain 保留、delete 删除、 Recycle回收。</p> \n <ul>\n  <li> <p>Retain：保留，该策略允许手动回收资源，当删除PVC时，PV仍然存在，PV被视为已释放，管理员可以手动回收卷。</p> </li>\n  <li> <p>Delete：删除，如果Volume插件支持，删除PVC时会同时删除PV，动态卷默认为Delete，目前支持Delete的存储后端包括AWS EBS，GCE PD，Azure Disk，OpenStack Cinder等。</p> </li>\n  <li> <p>Recycle：回收，如果Volume插件支持，Recycle策略会对卷执行rm -rf清理该PV，并使其可用于下一个新的PVC，但是本策略将来会被弃用，目前只有NFS和HostPath支持该策略。（这种策略已经被废弃，不用记）</p> </li>\n </ul> \n <h2><a id=\"pv_905\"></a>在pv的生命周期中，一般有几种状态</h2> \n <p>pv一共有4中状态，分别是：</p> \n <p>创建pv后，pv的的状态有以下4种：Available（可用）、Bound（已绑定）、Released（已释放）、Failed（失败）</p> \n <pre><code class=\"prism language-bash\">Available，表示pv已经创建正常，处于可用状态；\nBound，表示pv已经被某个pvc绑定，注意，一个pv一旦被某个pvc绑定，那么该pvc就独占该pv，其他pvc不能再与该pv绑定；\nReleased，表示pvc被删除了，pv状态就会变成已释放；\nFailed，表示pv的自动回收失败；\n\n</code></pre> \n <h2><a id=\"pv_921\"></a>pv存储空间不足怎么扩容?</h2> \n <p>一般的，我们会使用动态分配存储资源，</p> \n <p>在创建storageclass时指定参数 allowVolumeExpansion：true，表示允许用户通过修改pvc申请的存储空间自动完成pv的扩容，</p> \n <p>当增大pvc的存储空间时，不会重新创建一个pv，而是扩容其绑定的后端pv。</p> \n <p>这样就能完成扩容了。但是allowVolumeExpansion这个特性只支持扩容空间不支持减少空间。</p> \n <h2><a id=\"_933\"></a>存储类的资源回收策略:</h2> \n <p>主要有2中回收策略，delete 删除，默认就是delete策略、retain 保留。<br> Retain：保留，该策略允许手动回收资源，当删除PVC时，PV仍然存在，PV被视为已释放，管理员可以手动回收卷。<br> Delete：删除，如果Volume插件支持，删除PVC时会同时删除PV，动态卷默认为Delete，目前支持Delete的存储后端包括AWS EBS，GCE PD，Azure Disk，OpenStack Cinder等。</p> \n <p>注意：使用存储类动态创建的pv默认继承存储类的回收策略，当然当pv创建后你也可以手动修改pv的回收策略。</p> \n <h2><a id=\"node_943\"></a>怎么使一个node脱离集群调度，比如要停机维护单又不能影响业务应用</h2> \n <p>使用kubectl drain 命令</p> \n <h2><a id=\"k8s_951\"></a>k8s生产中遇到什么特别映像深刻的问题吗，问题排查解决思路是怎么样的？（重点）</h2> \n <p>（此问题被问到的概率高达90%，所以可以自己准备几个自己在生产环境中遇到的问题进行讲解）</p> \n <p>答：前端的lb负载均衡服务器上的keepalived出现过脑裂现象。</p> \n <p>1、当时问题现象是这样的，vip同时出现在主服务器和备服务器上，但业务上又没受到影响；<br> 2、这时首先去查看备服务器上的keepalived日志，发现有日志信息显示凌晨的时候备服务器出现了vrrp协议超时，所以才导致了备服务器接管了vip；查看主服务器上的keepalived日志，没有发现明显的报错信息，继续查看主服务器和备服务器上的keepalived进程状态，都是running状态的；查看主服务器上检测脚本所检测的进程，其进程也是正常的，也就是说主服务器根本没有成功执行检测脚本（成功执行检查脚本是会kill掉keepalived进程，脚本里面其实就是配置了检查nginx进程是否存活，如果检查到nginx不存活则kill掉keepalived，这样来实现备服务器接管vip）；<br> 3、排查服务器上的防火墙、selinux，防火墙状态和selinux状态都是关闭着的；<br> 4、使用tcpdump工具在备服务器上进行抓取数据包分析，分析发现，现在确实是备接管的vip，也确实是备服务器也在对外发送vrrp心跳包，所以现在外部流量应该都是流入备服务器上的vip；<br> 5、怀疑：主服务器上设置的vrrp心跳包时间间隔太长，以及检测脚本设置的检测时间设置不合理导致该问题；<br> 6、修改vrrp协议的心跳包时间间隔，由原来的2秒改成1秒就发送一次心跳包；检测脚本的检测时间也修改短一点，同时还修改检测脚本的检测失败的次数，比如连续检测2次失败才认定为检测失败；<br> 7、重启主备上的keepalived，现在keepalived是正常的，主服务器上有vip，备服务器上没有vip；<br> 8、持续观察：第二天又发现keepalived出现过脑裂现象，vip又同时出现在主服务器和备服务器上，又是凌晨的时候备服务器显示vrrp心跳包超时，所以才导致备服务器接管了vip；<br> 9、同样的时间，都是凌晨，vrrp协议超时；很奇怪，很有理由怀疑是网络问题，询问第三方厂家上层路由器是否禁止了vrrp协议，第三方厂家回复，没有禁止vrrp协议；<br> 10、百度、看官方文档求解；<br> 11、百度、看官网文档得知，keepalived有2种传播模式，一种是组播模式，一种是单播模式，keepalived默认在组播模式下工作，主服务器会往主播地址224.0.0.18发送心跳包，当局域网内有多个keepalived实例的时候，如果都用主播模式，会存在冲突干扰的情况，所以官方建议使用单播模式通信，单播模式就是点对点通行，即主向备服务器一对一的发送心跳包；</p> \n <p>12、将keepalived模式改为单播模式，继续观察，无再发生脑裂现象。问题得以解决。</p> \n <h2><a id=\"k8s_971\"></a>k8s生产中遇到什么特别映像深刻的问题吗，问题排查解决思路是怎么样的？（重点）</h2> \n <p>参考答案二：测试环境二进制搭建etcd集群，etcd集群出现2个leader的现象。<br> 1、问题现象就是：刚搭建的k8s集群，是测试环境的，搭建完成之后发现，使用kubectl get nodes 显示没有资源，kubectl get namespace 一会能正常显示全部的命名空间，一会又显示不了命名空间，这种奇怪情况。<br> 2、当时经验不是很足，第一点想到的是不是因为网络插件calico没装导致的，但是想想，即使没有安装网络插件，最多是node节点状态是notready，也不可能是没有资源发现呀；<br> 3、然后想到etcd数据库，k8s的资源都是存储在etcd数据库中的；<br> 4、查看etcd进程服务的启动状态，发现etcd服务状态是处于running状态，但是日志有大量的报错信息，日志大概报错信息就是集群节点的id不匹配，存在冲突等等报错信息；<br> 5、使用etcdctl命令查看etcd集群的健康状态，发现集群是health状态，但是居然显示有2个leader，这很奇怪（当初安装etcd的时候其实也只是简单看到了集群是健康状态，然后没注意到有2个leader，也没太关注etcd服务进程的日志报错信息，以为etcd集群状态是health状态就可以了）<br> 6、现在etcd出现了2个leader，肯定是存在问题的；<br> 7、全部检测一遍etcd的各个节点的配置文件，确认配置文件里面各个参数配置都没有问题，重启etcd集群，报错信息仍未解决，仍然存在2个leader；<br> 8、尝试把其中一个leader节点踢出集群，然后再重新添加它进入集群，仍然是报错，仍然显示有2个leader；<br> 9、尝试重新生成etcd的证书，重新颁发etcd的证书，问题仍然存在，仍然显示有2个leader；日志仍是报错集群节点的id不匹配，存在冲突；<br> 10、计算etcd命令的MD5值，确保各个节点的etcd命令是相同的，确保在scp传输的时候没有损耗等等，问题仍未解决；<br> 11、无解，请求同事，架构师介入帮忙排查问题，仍未解决；<br> 12、删除全部etcd相关的文件，重新部署etcd集群，etcd集群正常了，现在只有一个leader，使用命令kubectl get nodes 查看节点，也能正常显示了；<br> 13、最终问题的原因也没有定位出来，只能怀疑是环境问题了，由于是刚部署的k8s测试环境，etcd里面没有数据，所以可以删除重新创建etcd集群，如果是线上环境的etcd集群出现这种问题，就不能随便删除etcd集群了，必须要先进行数据备份才能进行其他方法的处理。</p> \n <h2><a id=\"etcd_990\"></a>etcd集群节点可以设置为偶数个吗，为什么要设置为基数个呢？</h2> \n <p>不能，也不建议这么设置。</p> \n <p>底层的原理，涉及到集群的脑裂 ，</p> \n <p>具体的答案，请参考 《尼恩java面试宝典 专题14》</p> \n <p><img src=\"https://img-blog.csdnimg.cn/e16f1bf77303495485b4df7e4584bdaa.png\" alt=\"在这里插入图片描述\"></p> \n <p><img src=\"https://img-blog.csdnimg.cn/f89139533bfa42a4a57447b276a19509.png\" alt=\"在这里插入图片描述\"></p> \n <h2><a id=\"etcd_1006\"></a>etcd集群节点之间是怎么同步数据的？</h2> \n <p>总体而言，是 通过Raft协议进行节点之间数据同步， 保证节点之间的数据一致性</p> \n <p>在正式开始介绍 Raft 协议之间，我们有必要简单介绍一下其相关概念。</p> \n <p>在现实的场景中，节点之间的一致性也就很难保证，这样就需要 Paxos、Raft 等一致性协议。</p> \n <p>一致性协议可以保证在集群中大部分节点可用的情况下，集群依然可以工作并给出一个正确的结果，从而保证依赖于该集群的其他服务不受影响。</p> \n <p>这里的“大部分节点可用”指的是集群中超过半数以上的节点可用，例如，集群中共有 5个节点，此时其中有 2 个节点出现故障宕机，剩余的可用节点数为 3，此时，集群中大多数节点处于可用的状态，从外部来看集群依然是可用的。</p> \n <p>常见的一致性算法有Paxos、Raft等，</p> \n <p>Paxos协议是Leslie Lamport于1990年提出的一种基于消息传递的、具有高度容错特性的一致性算法，Paxos 算法解决的主要问题是分布式系统内如何就某个值达成一致。在相当长的一段时间内，Paxos 算法几乎成为一致性算法的代名词，</p> \n <p>但是 Paxos 有两个明显的缺点：第一个也是最明显的缺点就是 Paxos 算法难以理解，Paxos 算法的论文本身就比较晦涩难懂，要完全理解 Paxos 协议需要付出较大的努力，很多经验丰富的开发者在看完 Paxos 论文之后，无法将其有效地应用到具体工程实践中，这明显增加了工程化的门槛，也正因如此，才出现了几次用更简单的术语来解释 Paxos 的尝试。</p> \n <p>Paxos算法的第二个缺点就是它没有提供构建现实系统的良好基础，也有很多工程化 Paxos 算法的尝试，但是它们对 Paxos 算法本身做了比较大的改动，彼此之间的实现差距都比较大，实现的功能和目的都有所不同，同时与Paxos算法的描述有很多出入。例如，著名Chubby，它实现了一个类Paxos的算法，但其中很多细节并未被明确。本章并不打算详细介绍 Paxos 协议的相关内容，如果读者对Paxos感兴趣，则可以参考Lamport发表的三篇论文：《The Part-Time Parliament》、《Paxos made simple》、《Fast Paxos》。</p> \n <p>Raft算法是一种用于管理复制日志的一致性算法，其功能与Paxos算法相同类似，但其算法结构和Paxos算法不同，在设计Raft算法时设计者就将易于理解作为其目标之一，这使得Raft算法更易于构建实际的系统，大幅度减少了工程化的工作量，也方便开发者此基础上进行扩展。</p> \n <p>Raft协议中，核心就是用于：</p> \n <ul>\n  <li>Leader选举</li>\n  <li>日志复制。</li>\n </ul> \n <h3><a id=\"Leader_1035\"></a>Leader选举</h3> \n <p>Raft 协议的工作模式是一个 Leader 节点和多个 Follower 节点的模式，也就是常说的Leader-Follower 模式。</p> \n <p>在 Raft 协议中，每个节点都维护了一个状态机，该状态机有三种状态，分别是Leader状态、Follower状态和Candidate状态，在任意时刻，集群中的任意一个节点都处于这三个状态之一。</p> \n <p>各个状态和转换条件如图所示。<br> <img src=\"https://img-blog.csdnimg.cn/85663942ddfb437a8eeee92f79a531f4.png\" alt=\"在这里插入图片描述\"></p> \n <p>在多数情况下，集群中有一个Leader节点，其他节点都处于Follower状态，下面简单介绍一下每个状态的节点负责的主要工作。</p> \n <ul>\n  <li> <p>Leader节点负责处理所有客户端的请求，当接收到客户端的写入请求时，Leader节点会在本地追加一条相应的日志，然后将其封装成消息发送到集群中其他的Follower节点。当Follower节点收到该消息时会对其进行响应。如果集群中多数（超过半数）节点都已收到该请求对应的日志记录时，则 Leader 节点认为该条日志记录已提交（committed），可以向客户端返回响应。Leader 还会处理客户端的只读请求，其中涉及一个简单的优化，后面介绍具体实现时，再进行详细介绍。Leader节点的另一项工作是定期向集群中的 Follower 节点发送心跳消息，这主要是为了防止集群中的其他Follower节点的选举计时器超时而触发新一轮选举。</p> </li>\n  <li> <p>Follower节点不会发送任何请求，它们只是简单地响应来自Leader或者Candidate 的请求；Follower节点也不处理Client的请求，而是将请求重定向给集群的Leader节点进行处理。</p> </li>\n  <li> <p>Candidate节点是由Follower节点转换而来的，当Follower节点长时间没有收到Leader节点发送的心跳消息时，则该节点的选举计时器就会过期，同时会将自身状态转换成Candidate，发起新一轮选举。选举的具体过程在下面详细描述。</p> </li>\n </ul> \n <p>了解了Raft协议中节点的三种状态及各个状态下节点的主要行为之后，我们通过一个示例介绍Raft协议中Leader选举的大致流程。为了方便描述，我们假设当前集群中有三个节点（A、B、C），如图所示。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/cd86035aff7640949ebe64082b63aa3c.png\" alt=\"在这里插入图片描述\"></p> \n <p>在Raft协议中有两个时间控制Leader选举发生，其中一个是选举超时时间（election timeout），每个Follower节点在接收不到Leader节点的心跳消息之后，并不会立即发起新一轮选举，而是需要等待一段时间之后才切换成Candidate状态发起新一轮选举。这段等待时长就是这里所说的election timeout（后面介绍etcd的具体实现时会提到，Follower节点等待的时长并不完全等于该配置）。之所以这样设计，主要是 Leader 节点发送的心跳消息可能因为瞬间的网络延迟或程序瞬间的卡顿而迟到（或是丢失），因此就触发新一轮选举是没有必要的。election timeout一般设置为150ms～300ms之间的随机数。另一个超时时间是心跳超时时间（heartbeat timeout），也就是Leader节点向集群中其他Follower节点发送心跳消息的时间间隔。</p> \n <p>当集群初始化时，所有节点都处于 Follower 的状态，此时的集群中没有 Leader 节点。当Follower 节点一段时间（选举计时器超时）内收不到 Leader 节点的心跳消息，则认为 Leader节点出现故障导致其任期（Term）过期，Follower节点会转换成Candidate状态，发起新一轮的选举。所谓 “任期（Term）”，实际上就是一个全局的、连续递增的整数，在 Raft 协议中每进行一次选举，任期（Term）加一，在每个节点中都会记录当前的任期值（currentTerm）。每一个任期都是从一次选举开始的，在选举时，会出现一个或者多个 Candidate 节点尝试成为 Leader节点，如果其中一个Candidate节点赢得选举，则该节点就会切换为Leader状态并成为该任期的Leader节点，直到该任期结束。</p> \n <p>回到前面的示例中，此时节点 A 由于长时间未收到 Leader 的心跳消息，就会切换成为Candidate状态并发起选举（节点A的选举计时器（election timer）已被重置）。</p> \n <p>在选举过程中，节点A首先会将自己的选票投给自己，并会向集群中其他节点发送选举请求（Request Vote）以获取其选票，如图2-3（1）所示；此时的节点B和节点C还都是处于Term=0的任期之中，且都是Follower状态，均未投出Term=1任期中的选票，所以节点B和节点C在接收到节点A的选举请求后会将选票投给节点A，另外，节点B、C在收到节点A的选举请求的同时会将选举定时器重置，这是为了防止一个任期中同时出现多个Candidate节点，导致选举失败，如图2-3 （2）所示。</p> \n <p>注意，节点B和节点C也会递增自身记录的Term值。<br> <img src=\"https://img-blog.csdnimg.cn/dc406fa0f9a2460fb765e48ff1c372e0.png\" alt=\"在这里插入图片描述\"></p> \n <p>在节点 A 收到节点 B、C 的投票之后，其收到了集群中超过半数的选票，所以在 Term=1这个任期中，该集群的Leader节点就是节点A，其他节点将切换成Follower状态，如图2-4所示。</p> \n <p>另外需要读者了解的是，集群中的节点除了记录当期任期号（currentTerm），还会记录在该任期中当前节点的投票结果（VoteFor）。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/4ea4fde0b7f44bf38f1b159ae26aa0ef.png\" alt=\"在这里插入图片描述\"></p> \n <p>继续前面的示例，成为Term=1任期的Leader节点之后，节点A会定期向集群中的其他节点发送心跳消息，如图2-5（1）所示，</p> \n <p>这样就可以防止节点B和节点C中的选举计时器（election timer）超时而触发新一轮的选举；当节点B和节点C（Follower）收到节点A的心跳消息之后会重置选举计时器，如图2-5（2）所示，由此可见，心跳超时时间（heartbeat timeout）需要远远小于选举超时时间（election timeout）</p> \n <p><img src=\"https://img-blog.csdnimg.cn/d221517b5e794b6fac6f705a75225d27.png\" alt=\"在这里插入图片描述\"></p> \n <p>到这里读者可能会问，如果有两个或两个以上节点的选举计时器同时过期，则这些节点会同时由 Follower 状态切换成 Candidate 状态，然后同时触发新一轮选举，在该轮选举中，每个Candidate节点获取的选票都不到半数，无法选举出Leader节点，那么Raft协议会如何处理呢？这种情况确实存在，假设集群中有4个节点，其中节点A和节点B的选举计时器同时到期，切换到Candidate状态并向集群中其他节点发出选举请求，如图2-6（1）所示。</p> \n <p>这里假设节点A发出的选举请求先抵达节点C，节点B发出的选举请求先抵达节点D，如图2-6（2）所示，节点A和节点B除了得到自身的选票之外，还分别得到了节点C和节点D投出的选票，得票数都是2，都没有超过半数。在这种情况下，Term=4这个任期会以选举失败结束，随着时间的流逝，当任意节点的选举计时器到期之后，会再次发起新一轮的选举。前面提到过election timeout是在一个时间区间内取的随机数，所以在配置合理的时候，像上述情况多次出现的概率并不大。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/e21e573adf37422096f4b7a7f26c66fe.png\" alt=\"在这里插入图片描述\"></p> \n <p>继续上面的示例，这里假设节点A的选举计时器再次到期（此次节点B、C、D 的选举计时器并未到期），它会切换成Candidate状态并发起新一轮选举（Term=5），如图2-7（1）所示，其中节点B虽然处于Candidate状态，但是接收到Term值比自身记录的Term值大的请求时，节点会切换成Follower状态并更新自身记录的Term值，所以该示例中的节点B也会将选票投给节点A，如图2-7（2）所示。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/5bfb92202e9d45a8b9d97a4830903d0b.png\" alt=\"在这里插入图片描述\"></p> \n <p>在获取集群中半数以上的选票并成为新任期（Term=5）的 Leader 之后，节点 A 会定期向集群中其他节点发送心跳消息；当集群中其他节点收到Leader节点的心跳消息的时候，会重置选举定时器，如图2-8所示。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/050a9d1dc9cf4a5ea410bfec89d505ef.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeXpubO-8gQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>介绍完集群启动时的Leader选举流程之后，下面分析Leader节点宕机之后重新选举的场景。继续上述4节点集群的示例，在系统运行一段时间后，集群当前的Leader节点（A）因为故障而宕机，此时将不再有心跳消息发送到集群的其他Follower节点（节点B、C、D），一段时间后，会有一个Follower节点的选举计时器最先超时，这里假设节点D的选举计时器最先超时，然后它将切换为Candidate状态并发起新一轮选举，如图2-9（1）所示。<br> <img src=\"https://img-blog.csdnimg.cn/39965656ea004da48e9a12a4536e9175.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeXpubO-8gQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>当节点B和节点C收到节点D的选举请求后，会将其选票投给节点D，由于节点A已经宕机，没有参加此次选举，也就无法进行投票，但是在此轮选举中，节点D依然获得了半数以上的选票，故成为新任期（Term=6）的Leader节点，并开始向其他Follower节点发送心跳消息，如图2-10所示。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/5fbb4bc3734148e5a8c27124040c2b00.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeXpubO-8gQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>当节点A恢复之后，会收到节点D发来的心跳消息，该消息中携带的任期号（Term=6）大于节点A当前记录的任期号（Term=5），所以节点A会切换成Follower状态。在Raft协议中，当某个节点接收到的消息所携带的任期号大于当前节点本身记录的任期号，那么该节点会更新自身记录的任期号，同时会切换为Follower状态并重置选举计时器，这是Raft算法中所有节点最后请读者考虑一个场景：如果集群中选出的Leader节点频繁崩溃或是其他原因导致选举频繁发生，这会使整个集群中没有一个稳定的Leader节点，这样客户端无法与集群中的Leader节点正常交互，也就会导致整个集群无法正常工作。</p> \n <p>Leader选举是Raft算法中对时间要求较为严格的一个点，一般要求整个集群中的时间满足如下不等式：<br> 广播时间 ＜＜ 选举超时时间 ＜＜ 平均故障间隔时间</p> \n <p>在上述不等式中，广播时间指的是从一个节点发送心跳消息到集群中的其他节点并接收响应的平均时间；平均故障间隔时间就是对于一个节点而言，两次故障之间的平均时间。为了保证整个Raft集群可用，广播时间必须比选举超时时间小一个数量级，这样Leader节点才能够发送稳定的心跳消息来重置其他 Follower 节点的选举计时器，从而防止它们切换成 Candidate 状态，触发新一轮选举。在前面的描述中也提到过，选举超时时间是一个随机数，通过这种随机的方式，会使得多个Candidate节点瓜分选票的情况明显减少，也就减少了选举耗时。</p> \n <p>另外，选举超时时间应该比平均故障间隔时间小几个数量级，这样Leader节点才能稳定存在，整个集群才能稳定运行。当Leader节点崩溃之后，整个集群会有大约相当于选举超时的时间不可用，这种情况占比整个集群稳定运行的时间还是非常小的。</p> \n <p>广播时间和平均故障间隔时间是由网络和服务器本身决定的，但是选举超时时间是可以由我们自己调节的。</p> \n <p>一般情况下，广播时间可以做到0.5ms～50ms，选举超时时间设置为200ms～1s之间，而大多数服务器的平均故障间隔时间都在几个月甚至更长，很容易满足上述不等式的时间需求。</p> \n <h3><a id=\"_1145\"></a>日志复制</h3> \n <p>通过上一节介绍的Leader选举过程，集群中最终会选举出一个Leader节点，而集群中剩余的其他节点将会成为Follower节点。</p> \n <p>Leader节点除了向Follower节点发送心跳消息，<strong>还会处理客户端的请求</strong>，并将客户端的更新操作以消息（Append Entries消息）的形式发送到集群中所有的Follower节点。</p> \n <p>当Follower节点记录收到的这些消息之后，会向Leader节点返回相应的响应消息。当Leader节点在收到半数以上的Follower节点的响应消息之后，会对客户端的请求进行应答。</p> \n <p>最后，Leader会提交客户端的更新操作，该过程会发送Append Entries消息到Follower节点，通知Follower节点该操作已经提交，同时Leader节点和Follower节点也就可以将该操作应用到自己的状态机中。</p> \n <p>上面这段描述仅仅是Raft协议中日志复制部分的大致流程，下面我们依然通过一个示例描述该过程，为了方便描述，我们依然假设当前集群中有三个节点（A、B、C），其中A是Leader节点，B、C是Follower 节点，此时有一个客户端发送了一个更新操作到集群，如图 2-11（1）所示。前面提到过，集群中只有Leader节点才能处理客户端的更新操作，这里假设客户端直接将请求发给了节点A。当收到客户端的请求时，节点A会将该更新操作记录到本地的Log中，如图2-11（2）所示。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/45356dc22a224dd1b40e915b8de5c296.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeXpubO-8gQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>之后，节点A会向其他节点发送Append Entries消息，其中记录了Leader节点最近接收到的请求日志，如图2-12（1）所示。集群中其他Follower节点收到该Append Entries消息之后，会将该操作记录到本地的Log中，并返回相应的响应消息，如图2-12（2）所示。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/bca50412245c4e6abdfd64b55d52044a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeXpubO-8gQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>当Leader节点收到半数以上的响应消息之后，会认为集群中有半数以上的节点已经记录了该更新操作，Leader 节点会将该更新操作对应的日志记录设置为已提交（committed），并应用到自身的状态机中。同时 Leader 节点还会对客户端的请求做出响应，如图 2-13（1）所示。同时，Leader节点也会向集群中的其他Follower节点发送消息，通知它们该更新操作已经被提交，Follower节点收到该消息之后，才会将该更新操作应用到自己的状态机中，如图2-13（2）所示。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/584db40228b3480fadb714be447c8c9f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeXpubO-8gQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>在上述示例的描述中我们可以看到，集群中各个节点都会维护一个本地Log用于记录更新操作，除此之外，每个节点还会维护commitIndex和lastApplied两个值，它们是本地Log的索引值，其中commitIndex表示的是当前节点已知的、最大的、已提交的日志索引值，lastApplied表示的是当前节点最后一条被应用到状态机中的日志索引值。当节点中的 commitIndex 值大于lastApplied值时，会将lastApplied 加1，并将lastApplied对应的日志应用到其状态机中。</p> \n <p>在Leader节点中不仅需要知道自己的上述信息，还需要了解集群中其他Follower节点的这些信息，例如，Leader节点需要了解每个Follower节点的日志复制到哪个位置，从而决定下次发送 Append Entries 消息中包含哪些日志记录。为此，Leader 节点会维护 nextIndex[]和matchIndex[]两个数组，这两个数组中记录的都是日志索引值，其中nextIndex[]数组记录了需要发送给每个 Follower 节点的下一条日志的索引值，matchIndex[]表示记录了已经复制给每个Follower节点的最大的日志索引值。</p> \n <p>这里简单看一下 Leader 节点与某一个 Follower 节点复制日志时，对应 nextIndex 和matchIndex值的变化：Follower节点中最后一条日志的索引值大于等于该Follower节点对应的nextIndex 值，那么通过 Append Entries 消息发送从 nextIndex 开始的所有日志。之后，Leader节点会检测该 Follower 节点返回的相应响应，如果成功则更新相应该 Follower 节点对应的nextIndex值和matchIndex值；如果因为日志不一致而失败，则减少nextIndex值重试。</p> \n <p>下面我们依然通过一个示例来说明nextIndex[]和matchIndex[]在日志复制过程中的作用，假设集群现在有三个节点，其中节点A是Leader节点（Term=1），而Follower节点C因为宕机导致有一段时间未与Leader节点同步日志。此时，节点C的Log中并不包含全部的已提交日志，而只是节点A的Log的子集，节点C故障排除后重新启动，当前集群的状态如图2-14所示（这里只关心Log、nextIndex[]、matchIndex[]，其他的细节省略，另外需要注意的是，图中的Term=1表示的是日志发送时的任期号，而非当前的任期号）。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/a74a2bb5e0b34dd4a297d97a5584aa12.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeXpubO-8gQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>A作为Leader节点，记录了nextIndex[]和matchIndex[]，所以知道应该向节点C发送哪些日志，在本例中，Leader节点在下次发送Append Entries消息时会携带Index=2的消息（这里为了描述简单，每条消息只携带单条日志，Raft协议采用批量发送的方式，这样效率更高），如图2-15（1）所示。当节点C收到Append Entries消息后，会将日志记录到本地Log中，然后向Leader 节点返回追加日志成功的响应，当 Leader 节点收到响应之后，会递增节点 C 对应的nextIndex和matchIndex，这样Leader节点就知道下次发送日志的位置了，该过程如图2-15（2）所示。</p> \n <p>在上例中，当Leader节点并未发生过切换，所以Leader节点始终准确地知道节点C对应nextIndex值和matchIndex值。</p> \n <p>如果在上述示例中，在节点C故障恢复后，节点A宕机后重启，并且导致节点B成为新任期（Term=2）的 Leader 节点，则此时节点 B 并不知道旧 Leader 节点中记录的 nextIndex[]和matchIndex[]信息，所以新Leader节点会重置nextIndex[]和matchIndex[]，其中会将nextIndex[]全部重置为其自身Log的最后一条已提交日志的Index值，而matchIndex[]全部重置为0，如图2-16所示。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/67ef8d17747c49f08c2c890800d6cb1e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeXpubO-8gQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p><img src=\"https://img-blog.csdnimg.cn/27d53d3f03a34f7f9b6bf435ded2da51.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeXpubO-8gQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>随后，新任期中的Leader节点会向其他节点发送Append Entries消息，如图2-17（1）所示，节点A已经拥有了当前Leader的全部日志记录，所以会返回追加成功的响应并等待后续的日志，而节点C并没有Index=2和Index=3两条日志，所以返回追加日志失败的响应，在收到该响应后，Leader节点会将nextIndex前移，如图2-17（2）所示。</p> \n <p><img src=\"https://img-blog.csdnimg.cn/77ed46f5a5d94a648e70b2c8401ff739.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeXpubO-8gQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>然后新 Leader 节点会再次尝试发送 Append Entries 消息，循环往复，不断减小 nextIndex值，直至节点C返回追加成功的响应，之后就进入了正常追加消息记录的流程，不再赘述。</p> \n <p>了解了 Log 日志及节点中基本的数据结构之后，请读者回顾前面描述的选举过程，</p> \n <p>其中Follower节点的投票过程并不像前面描述的那样简单（先收到哪个Candidate节点的选举请求，就将选票投给哪个Candidate节点），Follower节点还需要比较该Candidate节点的日志记录与自身的日志记录，拒绝那些日志没有自己新的Candidate节点发来的投票请求，确保将选票投给包含了全部已提交（committed）日志记录的 Candidate 节点。</p> \n <p>这也就保证了已提交的日志记录不会丢失：Candidate节点为了成为Leader节点，必然会在选举过程中向集群中半数以上的节点发送选举请求，因为已提交的日志记录必须存在集群中半数以上的节点中，这也就意味着每一条已提交的日志记录肯定在这些接收到节点中的至少存在一份。也就是说，记录全部已提交日志的节点和接收到Candidate节点的选举请求的节点必然存在交集，如图2-18所示。<br> <img src=\"https://img-blog.csdnimg.cn/972aece1557b4251aafbf9f3a39ea44d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeXpubO-8gQ==,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p> \n <p>如果Candidate节点上的日志记录与集群中大多数节点上的日志记录一样新，那么其日志一定包含所有已经提交的日志记录，也就可以获得这些节点的投票并成为Leader。</p> \n <p>在比较两个节点的日志新旧时，Raft 协议通过比较两节点日志中的最后一条日志记录的索引值和任期号，以决定谁的日志比较新：首先会比较最后一条日志记录的任期号，如果最后的日志记录的任期号不同，那么任期号大的日志记录比较新；如果最后一条日志记录的任期号相同，那么日志索引较大的 比较新。</p> \n <p>这里只是大概介绍一下 Raft 协议的流程和节点使用的各种数据结构，读者需要了解的是Raft 协议的工作原理，如果对上述数据结构描述感到困惑，在后面介绍etcd-raft 模块时，还会再次涉及这些数据结构，到时候读者可以结合代码及这里的描述进一步进行分析。</p> \n <h2><a id=\"kubeproxy_1236\"></a>请详述kube-proxy原理?</h2> \n <p>​ 答：集群中每个Node上都会运行一个kube-proxy服务进程，他是Service的透明代理兼均衡负载器，其核心功能是将某个Service的访问转发到后端的多个Pod上。</p> \n <p>kube-proxy通过监听集群状态变更，并对本机iptables做修改，从而实现网络路由。</p> \n <p>而其中的负载均衡，也是通过iptables的特性实现的。</p> \n <p>从V1.8版本开始，用IPVS（IP Virtual Server）模式，用于路由规则的配置，主要优势是：</p> \n <p>1）为大型集群提供了更好的扩展性和性能。采用哈希表的数据结构，更高效；</p> \n <p>2）支持更复杂的负载均衡算法；</p> \n <p>3）支持服务器健康检查和连接重试；</p> \n <p>4）可以动态修改ipset的集合；</p> \n <h2><a id=\"flannel__ovs__1256\"></a>flannel 和 ovs 网络的区别？</h2> \n <p>​ 答：</p> \n <p>1）配置是否自动化：OpenvSwitch（ovs）作为开源的交换机软件，相对比较成熟和稳定，支持各种网络隧道和协议，经历了大型项目 OpenStack 的考验，而 flannel 除了支持建立覆盖网络来实现 Pod 到 Pod 之间的无缝通信之外，还跟 docker、k8s 的架构体系紧密结合，flannel 能感知 k8s 中的 service 对象，然后动态维护自己的路由表，并通过 etcd 来协助 docker 对整个 k8s 集群的 docker0 网段进行规范，而 ovs ，这些操作则需要手动完成，假如集群中有 N 个节点，则需要建立 N(N-1)/2 个 Vxlan 或者 gre 连接，这取决于集群的规模，如果集群的规模很大，则必须通过自动化脚本来初始化，避免出错。</p> \n <p>2）是否支持隔离：flannel 虽然很方便实现 Pod 到 Pod 之间的通信，但不能实现多租户隔离，也不能很好地限制 Pod 的网络流量，而 ovs 网络有两种模式：单租户模式和多租户模式，单租户模式直接使用 openvswitch + vxlan 将 k8s 的 pod 网络组成一个大二层，所有的 pod 可以互相通信访问，多租户模式以 Namespace 为维度分配虚拟网络，从而形成一个网络独立用户，一个 Namespace 中的 pod 无法访问其他 Namespace 中的 pod 和 svc 对象；</p> \n <h2><a id=\"k8sPod_1266\"></a>k8s集群外流量怎么访问Pod？</h2> \n <p>答：</p> \n <p>可以通过Service的NodePort方式访问，会在所有节点监听同一个端口，比如：30000，访问节点的流量会被重定向到对应的Service上面；</p> \n <h2><a id=\"K8S__QoS_1274\"></a>K8S 资源限制 QoS？</h2> \n <p>​ 答：Quality of Service（Qos）</p> \n <p>主要有三种类别：</p> \n <p>1）BestEffort：什么都不设置（CPU or Memory），佛系申请资源；</p> \n <p>2）Burstable：Pod 中的容器至少一个设置了CPU 或者 Memory 的请求；</p> \n <p>3）Guaranteed：Pod 中的所有容器必须设置 CPU 和 Memory，并且 request 和 limit 值相等；</p> \n <h2><a id=\"k8s_1288\"></a>k8s数据持久化的方式有哪些？</h2> \n <p>​ 答：</p> \n <p>1)EmptyDir（空目录）：没有指定要挂载宿主机上的某个目录，直接由Pod内保部映射到宿主机上。类似于docker中的manager volume；场景有：a.只需要临时将数据保存在磁盘上，比如在合并/排序算法中；b.作为两个容器的共享存储，使得第一个内容管理的容器可以将生成的数据存入其中，同时由同一个webserver容器对外提供这些页面;emptyDir的特性：同个pod里面的不同容器，共享同一个持久化目录，当pod节点删除时，volume的数据也会被删除。如果仅仅是容器被销毁，pod还在，则不会影响volume中的数据。总结来说：emptyDir的数据持久化的生命周期和使用的pod一致。一般是作为临时存储使用。</p> \n <p>2）Hostpath：将宿主机上已存在的目录或文件挂载到容器内部。类似于docker中的bind mount挂载方式；</p> \n <p>3）PersistentVolume（简称PV）：基于NFS服务的PV，也可以基于GFS的PV。它的作用是统一数据持久化目录，方便管理，PVC是向PV申请应用所需的容量大小，K8s集群中可能会有多个PV，PVC和PV若要关联，其定义的访问模式必须一致。定义的storageClassName也必须一致，若群集中存在相同的（名字、访问模式都一致）两个PV，那么PVC会选择向它所需容量接近的PV去申请，或者随机申请；</p> \n <h2><a id=\"K8S_1300\"></a>K8S的基本组成部分？</h2> \n <p>答：</p> \n <p>Master节点主要有五个组件，分别是kubectl、api-server、controller-manager、kube-scheduler 和 etcd；</p> \n <p>node节点主要有三个组件，分别是 kubelet、kube-proxy 和 容器运行时 docker 或者 rkt；</p> \n <p>kubectl：客户端命令行工具，作为整个系统的操作入口。<br> apiserver：以REST API服务形式提供接口，作为整个系统的控制入口。<br> controller-manager：执行整个系统的后台任务，包括节点状态状况、Pod个数、Pods和Service的关联等。<br> kube-scheduler：负责节点资源管理，接收来自kube-apiserver创建Pods任务，并分配到某个节点。<br> etcd：负责节点间的服务发现和配置共享。<br> kube-proxy：运行在每个计算节点上，负责Pod网络代理。定时从etcd获取到service信息来做相应的策略。<br> kubelet：运行在每个计算节点上，作为agent，接收分配该节点的Pods任务及管理容器，周期性获取容器状态，反馈给kube-apiserver。<br> DNS：一个可选的DNS服务，用于为每个Service对象创建DNS记录，这样所有的Pod就可以通过DNS访问服务了。</p> \n <h2><a id=\"K8s_1321\"></a>K8s中镜像的下载策略是什么？</h2> \n <p>​ 答：可通过命令“kubectl explain pod.spec.containers”来查看imagePullPolicy这行的解释，</p> \n <p>K8s的镜像下载策略有三种：</p> \n <p>Always：镜像标签为latest时，总是从指定的仓库中获取镜像；</p> \n <p>Never：禁止从仓库中下载镜像，也就是说只能使用本地镜像；</p> \n <p>IfNotPresent：仅当本地没有对应镜像时，才从目标仓库中下载；</p> \n <h2><a id=\"_1333\"></a>标签与标签选择器的作用是什么？</h2> \n <p>​ 答：标签：是当相同类型的资源对象越来越多的时候，为了更好的管理，可以按照标签将其分为一个组，为的是提升资源对象的管理效率；标签选择器：就是标签的查询过滤条件。</p> \n <h2><a id=\"K8s_1337\"></a>K8s的负载均衡器？</h2> \n <p>​ 答：负载均衡器是暴露服务的最常见和标准方式之一。</p> \n <p>根据工作环境使用两种类型的负载均衡器，即内部负载均衡器或外部负载均衡器。内部负载均衡器自动平衡负载并使用所需配置分配容器，而外部负载均衡器将流量从外部负载引导至后端容器；</p> \n <h2><a id=\"kubelet__Node__1343\"></a>kubelet 监控 Node 节点资源使用是通过什么组件来实现的？</h2> \n <p>​ 答：用Metrics Server提供核心指标，包括Node、Pod的CPU和内存的使用。而Metrics Server需要采集node上的cAdvisor提供的数据资源，</p> \n <p>当 kubelet 服务启动时，它会自动启动 cAdvisor 服务，然后 cAdvisor 会实时采集所在节点的性能指标及在节点上运行的容器的性能指标。</p> \n <p>kubelet 的启动参数 --cadvisor-port 可自定义 cAdvisor 对外提供服务的端口号，默认是 4194；</p> \n <h2><a id=\"Pod_1353\"></a>Pod的状态？</h2> \n <p>​ 答：</p> \n <p>1）Pending：已经创建了Pod，但是其内部还有容器没有创建；</p> \n <p>2）Running：Pod内部的所有容器都已经创建，只有由一个容器还处于运行状态或者重启状态；</p> \n <p>3）Succeeed：Pod内所有容器均已经成功执行并且退出，不会再重启；</p> \n <p>4）Failed：Pod内所有容器都退出，但至少有一个为退出失败状态；</p> \n <p>5）Unknown：由于某种原因不能获取该Pod的状态，可能是网络问题；</p> \n <h2><a id=\"deploymentrs_1369\"></a>deployment/rs的区别？</h2> \n <p>​ 答：deployment是rs的超集，提供更多的部署功能，如：回滚、暂停和重启、 版本记录、事件和状态查看、滚动升级和替换升级。</p> \n <p>如果能使用deployment，则不应再使用rc和rs；</p> \n <h2><a id=\"rcrs_1379\"></a>rc/rs实现原理？</h2> \n <p>答：</p> \n <p>Replication Controller 可以保证Pod始终处于规定的副本数，</p> \n <p>而当前推荐的做法是使用Deployment+ReplicaSet，</p> \n <p>ReplicaSet 号称下一代的 Replication Controller，当前唯一区别是RS支持set-based selector，</p> \n <p>RC是通过ReplicationManager监控RC和RC内Pod的状态，从而增删Pod，以实现维持特定副本数的功能，RS也是大致相同；</p> \n <h2><a id=\"kubernetes_1393\"></a>kubernetes服务发现？</h2> \n <p>答：</p> \n <p>1）环境变量： 当你创建一个Pod的时候，kubelet会在该Pod中注入集群内所有Service的相关环境变量。<strong>需要注意:</strong> 要想一个Pod中注入某个Service的环境变量，则必须Service要先比该Pod创建；</p> \n <p>2）DNS：可以通过cluster add-on方式轻松的创建KubeDNS来对集群内的Service进行服务发现；</p> \n <h2><a id=\"k8sservcie_1401\"></a>k8s发布(暴露)服务，servcie的类型有那些？</h2> \n <p>答：</p> \n <p>kubernetes原生的，一个Service的ServiceType决定了其发布服务的方式。</p> \n <p>1） ClusterIP：这是k8s默认的ServiceType。通过集群内的ClusterIP在内部发布服务。</p> \n <p>2）NodePort：这种方式是常用的，用来对集群外暴露Service，你可以通过访问集群内的每个NodeIP:NodePort的方式，访问到对应Service后端的Endpoint。</p> \n <p>3）LoadBalancer: 这也是用来对集群外暴露服务的，不同的是这需要Cloud Provider的支持，比如AWS等。</p> \n <p>4）ExternalName：这个也是在集群内发布服务用的，需要借助KubeDNS(version &gt;= 1.7)的支持，就是用KubeDNS将该service和ExternalName做一个Map，KubeDNS返回一个CNAME记录；</p> \n <h2><a id=\"ETCD_1417\"></a>简述ETCD及其特点?</h2> \n <p>答：etcd是一个分布式的、高可用的、一致的key-value存储数据库，基于Go语言实现，主要用于共享配置和服务发现。特点：</p> \n <p>1）完全复制：集群中的每个节点都可以使用完整的存档；</p> \n <p>2）高可用性：Etcd可用于避免硬件的单点故障或网络问题；</p> \n <p>3）一致性：每次读取都会返回跨多主机的最新写入；</p> \n <p>4）简单：包括一个定义良好、面向用户的API（gRPC）；</p> \n <p>5）安全：实现了带有可选的客户端证书身份验证的自动化TLS；</p> \n <p>6）快速：每秒10000次写入的基准速度；</p> \n <p>7）可靠：使用Raft算法实现了强一致、高可用的服务存储目录；</p> \n <h2><a id=\"ETCD_1437\"></a>简述ETCD适应的场景?</h2> \n <p>​ 答：</p> \n <p>1）服务发现：服务发现要解决的也是分布式系统中最常见的问题之一，即在同一个分布式集群中的进程或服务，要如何才能找到对方并建立连接。本质上来说，服务发现就是想要了解集群中是否有进程在监听udp或tcp端口，并且通过名字就可以查找和连接。</p> \n <p>2）消息发布与订阅：在分布式系统中，最实用对的一种组件间的通信方式：消息发布与订阅。构建一个配置共享中心，数据提供者在这个配置中心发布消息，而消息使用者订阅他们关心的主题，一旦主题有消息发布，就会实时通知订阅者。达成集中式管理与动态更新。应用中用到的一些配置信息放到etcd上进行集中管理。</p> \n <p>3）负载均衡：分布式系统中，为了保证服务的高可用以及数据的一致性，通常都会把数据和服务部署多份，以此达到对等服务，即使其中的某一个服务失效了，也不影响使用。etcd本身分布式架构存储的信息访问支持负载均衡。</p> \n <p>4）分布式通知与协调：通过注册与异步通知机制，实现分布式环境下不同系统之间的通知与协调，从而对数据变更做到实时处理。</p> \n <p>5）分布式锁：因为etcd使用Raft算法保持了数据的强一致性，某次操作存储到集群中的值必然是全局一致的，所以很容易实现分布式锁。锁服务有两种使用方式，一是保持独占，二是控制时序。</p> \n <p>6）分布式队列：分布式队列的常规用法与场景五中所描述的分布式锁的控制时序用法类似，即创建一个先进先出的队列，保证顺序。</p> \n <p>7）集群监控与Leader精选：通过etcd来进行监控实现起来非常简单并且实时性强；</p> \n <h2><a id=\"Kubernetes_RC_1459\"></a>简述Kubernetes RC的机制?</h2> \n <p>​ 答：Replication Controller用来管理Pod的副本，保证集群中存在指定数量的Pod副本。当定义了RC并提交至Kubernetes集群中之后，Master节点上的Controller Manager组件获悉，并同时巡检系统中当前存活的目标Pod，并确保目标Pod实例的数量刚好等于此RC的期望值，若存在过多的Pod副本在运行，系统会停止一些Pod，反之则自动创建一些Pod；</p> \n <h2><a id=\"kubeproxy_1465\"></a>简述kube-proxy作用?</h2> \n <p>答：kube-proxy 运行在所有节点上，它监听 apiserver 中 service 和 endpoint 的变化情况，创建路由规则以提供服务 IP 和负载均衡功能。</p> \n <p>简单理解此进程是Service的透明代理兼负载均衡器，其核心功能是将到某个Service的访问请求转发到后端的多个Pod实例上；</p> \n <h2><a id=\"kubeproxy_iptables_1475\"></a>简述kube-proxy iptables原理?</h2> \n <p>​ 答：Kubernetes从1.2版本开始，将iptables作为kube-proxy的默认模式。iptables模式下的kube-proxy不再起到Proxy的作用，其核心功能：通过API Server的Watch接口实时跟踪Service与Endpoint的变更信息，并更新对应的iptables规则，Client的请求流量则通过iptables的NAT机制“直接路由”到目标Pod；</p> \n <h2><a id=\"kubeproxy_ipvs_1479\"></a>简述kube-proxy ipvs原理?</h2> \n <p>答：IPVS在Kubernetes1.11中升级为GA稳定版。</p> \n <p>IPVS则专门用于高性能负载均衡，并使用更高效的数据结构（Hash表），允许几乎无限的规模扩张，因此被kube-proxy采纳为最新模式；</p> \n <p>在IPVS模式下，使用iptables的扩展ipset，而不是直接调用iptables来生成规则链。</p> \n <p>iptables规则链是一个线性的数据结构，ipset则引入了带索引的数据结构，因此当规则很多时，也可以很高效地查找和匹配；</p> \n <p>可以将ipset简单理解为一个IP（段）的集合，这个集合的内容可以是IP地址、IP网段、端口等，iptables可以直接添加规则对这个“可变的集合”进行操作，这样做的好处在于可以大大减少iptables规则的数量，从而减少性能损耗；</p> \n <h2><a id=\"kubeproxy_ipvsiptables_1491\"></a>简述kube-proxy ipvs和iptables的异同?</h2> \n <p>答：iptables与IPVS都是基于Netfilter实现的，但因为定位不同，二者有着本质的差别：</p> \n <p>iptables是为防火墙而设计的；IPVS则专门用于高性能负载均衡，并使用更高效的数据结构（Hash表），允许几乎无限的规模扩张。</p> \n <p>与iptables相比，IPVS拥有以下明显优势：为大型集群提供了更好的可扩展性和性能；支持比iptables更复杂的复制均衡算法（最小负载、最少连接、加权等）；支持服务器健康检查和连接重试等功能；可以动态修改ipset的集合，即使iptables的规则正在使用这个集合；</p> \n <h2><a id=\"KubernetesPod_1501\"></a>简述Kubernetes中什么是静态Pod?</h2> \n <p>答：静态pod是由kubelet进行管理的仅存在于特定Node的Pod上，他们不能通过API Server进行管理，无法与ReplicationController、Deployment或者DaemonSet进行关联，并且kubelet无法对他们进行健康检查。</p> \n <p>静态Pod总是由kubelet进行创建，并且总是在kubelet所在的Node上运行；</p> \n <h2><a id=\"Kubernetes_Pod_1511\"></a>简述Kubernetes Pod的常见调度方式?</h2> \n <p>答：</p> \n <p>1）Deployment或RC：该调度策略主要功能就是自动部署一个容器应用的多份副本，以及持续监控副本的数量，在集群内始终维持用户指定的副本数量；</p> \n <p>2）NodeSelector：定向调度，当需要手动指定将Pod调度到特定Node上，可以通过Node的标签（Label）和Pod的nodeSelector属性相匹配；</p> \n <p>3）NodeAffinity亲和性调度：亲和性调度机制极大的扩展了Pod的调度能力，目前有两种节点亲和力表达：硬规则，必须满足指定的规则，调度器才可以调度Pod至Node上（类似nodeSelector，语法不同）；软规则，优先调度至满足的Node的节点，但不强求，多个优先级规则还可以设置权重值；</p> \n <p>4）Taints和Tolerations（污点和容忍）：Taint：使Node拒绝特定Pod运行；Toleration：为Pod的属性，表示Pod能容忍（运行）标注了Taint的Node；</p> \n <h2><a id=\"Kubernetesinit_container_1527\"></a>简述Kubernetes初始化容器（init container）?</h2> \n <p>答：init container的运行方式与应用容器不同，它们必须先于应用容器执行完成，当设置了多个init container时，将按顺序逐个运行，并且只有前一个init container运行成功后才能运行后一个init container。</p> \n <p>当所有init container都成功运行后，Kubernetes才会初始化Pod的各种信息，并开始创建和运行应用容器；</p> \n <h2><a id=\"Kubernetes_deployment_1537\"></a>简述Kubernetes deployment升级过程?</h2> \n <p>答：</p> \n <p>初始创建Deployment时，系统创建了一个ReplicaSet，并按用户的需求创建了对应数量的Pod副本；</p> \n <p>当更新Deployment时，系统创建了一个新的ReplicaSet，并将其副本数量扩展到1，然后将旧ReplicaSet缩减为2；</p> \n <p>之后，系统继续按照相同的更新策略对新旧两个ReplicaSet进行逐个调整；</p> \n <p>最后，新的ReplicaSet运行了对应个新版本Pod副本，旧的ReplicaSet副本数量则缩减为0；</p> \n <h2><a id=\"Kubernetes_deployment_1553\"></a>简述Kubernetes deployment升级策略?</h2> \n <p>答：</p> \n <p>在Deployment的定义中，可以通过spec.strategy指定Pod更新的策略，</p> \n <p>目前支持两种策略：Recreate（重建）和RollingUpdate（滚动更新），</p> \n <p>默认值为RollingUpdate；</p> \n <p>Recreate：设置spec.strategy.type=Recreate，表示Deployment在更新Pod时，会先杀掉所有正在运行的Pod，然后创建新的Pod；</p> \n <p>RollingUpdate：设置spec.strategy.type=RollingUpdate，表示Deployment会以滚动更新的方式来逐个更新Pod。同时，可以通过设置spec.strategy.rollingUpdate下的两个参数（maxUnavailable和maxSurge）来控制滚动更新的过程；</p> \n <h2><a id=\"Kubernetes_DaemonSet_1569\"></a>简述Kubernetes DaemonSet类型的资源特性?</h2> \n <p>答：</p> \n <p>DaemonSet资源对象会在每个Kubernetes集群中的节点上运行，并且每个节点只能运行一个pod，这是它和deployment资源对象的最大也是唯一的区别。</p> \n <p>因此，在定义yaml文件中，不支持定义replicas。</p> \n <p>它的一般使用场景如下：在去做每个节点的日志收集工作。监控每个节点的的运行状态。</p> \n <h2><a id=\"Kubernetes_1581\"></a>简述Kubernetes自动扩容机制?</h2> \n <p>答：</p> \n <p>Kubernetes使用Horizontal Pod Autoscaler（HPA）的控制器实现基于CPU使用率进行自动Pod扩缩容的功能。</p> \n <p>HPA控制器周期性地监测目标Pod的资源性能指标，并与HPA资源对象中的扩缩容条件进行对比，在满足条件时对Pod副本数量进行调整；</p> \n <h2><a id=\"Kubernetes_Service_1593\"></a>简述Kubernetes Service分发后端的策略?</h2> \n <p>答：</p> \n <p>1）RoundRobin：默认为轮询模式，即轮询将请求转发到后端的各个Pod上；</p> \n <p>2）SessionAffinity：基于客户端IP地址进行会话保持的模式，即第1次将某个客户端发起的请求转发到后端的某个Pod上，之后从相同的客户端发起的请求都将被转发到后端相同的Pod上；</p> \n <h2><a id=\"Kubernetes_Headless_Service_1605\"></a>简述Kubernetes Headless Service?</h2> \n <p>答：在某些应用场景中，若需要人为指定负载均衡器，不使用Service提供的默认负载均衡的功能，或者应用程序希望知道属于同组服务的其他实例。</p> \n <p>Kubernetes提供了Headless Service来实现这种功能，即不为Service设置ClusterIP（入口IP地址），仅通过Label Selector将后端的Pod列表返回给调用的客户端；</p> \n <h2><a id=\"Kubernetes_1615\"></a>简述Kubernetes外部如何访问集群内的服务?</h2> \n <p>答：</p> \n <p>映射Pod到物理机：将Pod端口号映射到宿主机，即在Pod中采用hostPort方式，以使客户端应用能够通过物理机访问容器应用；</p> \n <p>映射Service到物理机：将Service端口号映射到宿主机，即在Service中采用nodePort方式，以使客户端应用能够通过物理机访问容器应用；</p> \n <p>映射Service到LoadBalancer：通过设置LoadBalancer映射到云服务商提供的LoadBalancer地址。这种用法仅用于在公有云服务提供商的云平台上设置Service的场景；</p> \n <h2><a id=\"Kubernetes_ingress_1629\"></a>简述Kubernetes ingress?</h2> \n <p>​ 答：</p> \n <p>K8s的Ingress资源对象，用于将不同URL的访问请求转发到后端不同的Service，以实现HTTP层的业务路由机制。</p> \n <p>K8s使用了Ingress策略和Ingress Controller，两者结合并实现了一个完整的Ingress负载均衡器。</p> \n <p>使用Ingress进行负载分发时，Ingress Controller基于Ingress规则将客户端请求直接转发到Service对应的后端Endpoint（Pod）上，从而跳过kube-proxy的转发功能，kube-proxy不再起作用，</p> \n <p>全过程为：ingress controller + ingress 规则 ----&gt; services；</p> \n <h2><a id=\"Kubernetes_1643\"></a>简述Kubernetes镜像的下载策略?</h2> \n <p>​ 答：</p> \n <p>1）Always：镜像标签为latest时，总是从指定的仓库中获取镜像；</p> \n <p>2）Never：禁止从仓库中下载镜像，也就是说只能使用本地镜像；</p> \n <p>3）IfNotPresent：仅当本地没有对应镜像时，才从目标仓库中下载；默认的镜像下载策略是：当镜像标签是latest时，默认策略是Always；当镜像标签是自定义时（也就是标签不是latest），那么默认策略是IfNotPresent；</p> \n <h2><a id=\"Kubernetes_1655\"></a>简述Kubernetes的负载均衡器?</h2> \n <p>​ 答：</p> \n <p>根据工作环境使用两种类型的负载均衡器，即内部负载均衡器或外部负载均衡器。</p> \n <p>内部负载均衡器自动平衡负载并使用所需配置分配容器，而外部负载均衡器将流量从外部负载引导至后端容器；</p> \n <h2><a id=\"KubernetesAPI_Server_1665\"></a>简述Kubernetes各模块如何与API Server通信?</h2> \n <p>答：K8s API Server作为集群的核心，负责集群各功能模块之间的通信。</p> \n <p>集群内的各个功能模块通过API Server将信息存入etcd，当需要获取和操作这些数据时，则通过API Server提供的REST接口（用GET、LIST或WATCH方法）来实现，从而实现各模块之间的信息交互。</p> \n <p>1）kubelet进程与API Server的交互：每个Node上的kubelet每隔一个时间周期，就会调用一次API Server的REST接口报告自身状态，API Server在接收到这些信息后，会将节点状态信息更新到etcd中；</p> \n <p>2）kube-controller-manager进程与API Server的交互：kube-controller-manager中的Node Controller模块通过API Server提供的Watch接口实时监控Node的信息，并做相应处理</p> \n <p>；3）kube-scheduler进程与API Server的交互：Scheduler通过API Server的Watch接口监听到新建Pod副本的信息后，会检索所有符合该Pod要求的Node列表，开始执行Pod调度逻辑，在调度成功后将Pod绑定到目标节点上；</p> \n <h2><a id=\"Kubernetes_Scheduler_1681\"></a>简述Kubernetes Scheduler作用及实现原理?</h2> \n <p>​ 答：</p> \n <p>Scheduler是负责Pod调度的重要功能模块，负责接收Controller Manager创建的新Pod，为其调度至目标Node，调度完成后，目标Node上的kubelet服务进程接管后继工作，负责Pod接下来生命周期；</p> \n <p>Scheduler的作用是将待调度的Pod，按照特定的调度算法和调度策略绑定（Binding）到集群中某个合适的Node上，并将绑定信息写入etcd中；</p> \n <p>Scheduler通过调度算法调度为待调度Pod列表中的每个Pod从Node列表中选择一个最适合的Node来实现Pod的调度。随后，目标节点上的kubelet通过API Server监听到Kubernetes Scheduler产生的Pod绑定事件，然后获取对应的Pod清单，下载Image镜像并启动容器；</p> \n <h2><a id=\"Kubernetes_SchedulerPodworker_1693\"></a>简述Kubernetes Scheduler使用哪两种算法将Pod绑定到worker节点?</h2> \n <p>​ 答：</p> \n <p>1）预选（Predicates）：输入是所有节点，输出是满足预选条件的节点。kube-scheduler根据预选策略过滤掉不满足策略的Nodes。如果某节点的资源不足或者不满足预选策略的条件则无法通过预选；</p> \n <p>2）优选（Priorities）：输入是预选阶段筛选出的节点，优选会根据优先策略为通过预选的Nodes进行打分排名，选择得分最高的Node。例如，资源越富裕、负载越小的Node可能具有越高的排名；</p> \n <h2><a id=\"Kubernetes_kubelet_1703\"></a>简述Kubernetes kubelet的作用?</h2> \n <p>​ 答：</p> \n <p>在Kubernetes集群中，在每个Node（又称Worker）上都会启动一个kubelet服务进程。</p> \n <p>该进程用于处理Master下发到本节点的任务，管理Pod及Pod中的容器。</p> \n <p>每个kubelet进程都会在API Server上注册节点自身的信息，定期向Master汇报节点资源的使用情况，并通过cAdvisor监控容器和节点资源；</p> \n <h2><a id=\"Kubernetes_kubeletWorker_1715\"></a>简述Kubernetes kubelet监控Worker节点资源是使用什么组件来实现的?</h2> \n <p>​ 答:</p> \n <p>kubelet使用cAdvisor对worker节点资源进行监控。</p> \n <p>在 Kubernetes 系统中，cAdvisor 已被默认集成到 kubelet 组件内，当 kubelet 服务启动时，它会自动启动 cAdvisor 服务，然后 cAdvisor 会实时采集所在节点的性能指标及在节点上运行的容器的性能指标；</p> \n <h2><a id=\"Kubernetes_1725\"></a>简述Kubernetes如何保证集群的安全性?</h2> \n <p>​ 答：</p> \n <p>1）基础设施方面：保证容器与其所在宿主机的隔离；</p> \n <p>2）用户权限：划分普通用户和管理员的角色；</p> \n <p>3）API Server的认证授权：Kubernetes集群中所有资源的访问和变更都是通过Kubernetes API Server来实现的，因此需要建议采用更安全的HTTPS或Token来识别和认证客户端身份（Authentication），以及随后访问权限的授权（Authorization）环节；</p> \n <p>4）API Server的授权管理：通过授权策略来决定一个API调用是否合法。对合法用户进行授权并且随后在用户访问时进行鉴权，建议采用更安全的RBAC方式来提升集群安全授权；</p> \n <p>5）AdmissionControl（准入机制）：对kubernetes api的请求过程中，顺序为：先经过认证 &amp; 授权，然后执行准入操作，最后对目标对象进行操作；</p> \n <h2><a id=\"Kubernetes_1741\"></a>简述Kubernetes准入机制?</h2> \n <p>答：</p> \n <p>在对集群进行请求时，每个准入控制代码都按照一定顺序执行。</p> \n <p>如果有一个准入控制拒绝了此次请求，那么整个请求的结果将会立即返回，并提示用户相应的error信息，准入控制（AdmissionControl）准入控制本质上为一段准入代码，在对kubernetes api的请求过程中，顺序为：先经过认证 &amp; 授权，然后执行准入操作，最后对目标对象进行操作。</p> \n <p>常用组件（控制代码）如下：</p> \n <p>AlwaysAdmit：允许所有请求；</p> \n <p>AlwaysDeny：禁止所有请求，多用于测试环境；</p> \n <p>ServiceAccount：它将serviceAccounts实现了自动化，它会辅助serviceAccount做一些事情，比如如果pod没有serviceAccount属性，它会自动添加一个default，并确保pod的serviceAccount始终存在；</p> \n <p>LimitRanger：观察所有的请求，确保没有违反已经定义好的约束条件，这些条件定义在namespace中LimitRange对象中；</p> \n <p>NamespaceExists：观察所有的请求，如果请求尝试创建一个不存在的namespace，则这个请求被拒绝；</p> \n <h2><a id=\"Kubernetes_RBAC_1763\"></a>简述Kubernetes RBAC及其特点（优势）?</h2> \n <p>​ 答：</p> \n <p>RBAC是基于角色的访问控制，是一种基于个人用户的角色来管理对计算机或网络资源的访问的方法，</p> \n <p>优势：</p> \n <p>1）对集群中的资源和非资源权限均有完整的覆盖；</p> \n <p>2）整个RBAC完全由几个API对象完成， 同其他API对象一样， 可以用kubectl或API进行操作；</p> \n <p>3）可以在运行时进行调整，无须重新启动API Server；</p> \n <h2><a id=\"Kubernetes_Secret_1779\"></a>简述Kubernetes Secret作用?</h2> \n <p>​ 答：</p> \n <p>Secret对象，主要作用是保管私密数据，比如密码、OAuth Tokens、SSH Keys等信息。</p> \n <p>将这些私密信息放在Secret对象中比直接放在Pod或Docker Image中更安全，也更便于使用和分发；</p> \n <h2><a id=\"Kubernetes_Secret_1789\"></a>简述Kubernetes Secret有哪些使用方式?</h2> \n <p>​ 答：</p> \n <p>1）在创建Pod时，通过为Pod指定Service Account来自动使用该Secret；</p> \n <p>2）通过挂载该Secret到Pod来使用它；</p> \n <p>3）在Docker镜像下载时使用，通过指定Pod的spc.ImagePullSecrets来引用它；</p> \n <h2><a id=\"Kubernetes_PodSecurityPolicy_1801\"></a>简述Kubernetes PodSecurityPolicy机制?</h2> \n <p>​ 答：</p> \n <p>Kubernetes PodSecurityPolicy是为了更精细地控制Pod对资源的使用方式以及提升安全策略。</p> \n <p>在开启PodSecurityPolicy准入控制器后，Kubernetes默认不允许创建任何Pod，需要创建PodSecurityPolicy策略和相应的RBAC授权策略（Authorizing Policies），Pod才能创建成功；</p> \n <h2><a id=\"Kubernetes_PodSecurityPolicy_1811\"></a>简述Kubernetes PodSecurityPolicy机制能实现哪些安全策略?</h2> \n <p>1）特权模式：privileged是否允许Pod以特权模式运行；</p> \n <p>2）宿主机资源：控制Pod对宿主机资源的控制，如hostPID：是否允许Pod共享宿主机的进程空间；</p> \n <p>3）用户和组：设置运行容器的用户ID（范围）或组（范围）；</p> \n <p>4）提升权限：AllowPrivilegeEscalation：设置容器内的子进程是否可以提升权限，通常在设置非root用户（MustRunAsNonRoot）时进行设置；</p> \n <p>5）SELinux：进行SELinux的相关配置；</p> \n <h2><a id=\"Kubernetes_1827\"></a>简述Kubernetes网络模型?</h2> \n <p>答：Kubernetes网络模型中每个Pod都拥有一个独立的IP地址，不管它们是否运行在同一个Node（宿主机）中，都要求它们可以直接通过对方的IP进行访问；</p> \n <p>同时为每个Pod都设置一个IP地址的模型使得同一个Pod内的不同容器会共享同一个网络命名空间，也就是同一个Linux网络协议栈。</p> \n <p>这就意味着同一个Pod内的容器可以通过localhost来连接对方的端口；在Kubernetes的集群里，IP是以Pod为单位进行分配的。一个Pod内部的所有容器共享一个网络堆栈；</p> \n <h2><a id=\"Kubernetes_CNI_1839\"></a>简述Kubernetes CNI模型?</h2> \n <p>答：</p> \n <p>Kubernetes CNI模型是对容器网络进行操作和配置的规范，通过插件的形式对CNI接口进行实现。</p> \n <p>CNI仅关注在创建容器时分配网络资源，和在销毁容器时删除网络资源。</p> \n <p>容器（Container）：是拥有独立Linux网络命名空间的环境，例如使用Docker或rkt创建的容器。容器需要拥有自己的Linux网络命名空间，这是加入网络的必要条件；</p> \n <p>网络（Network）：表示可以互连的一组实体，这些实体拥有各自独立、唯一的IP地址，可以是容器、物理机或者其他网络设备（比如路由器）等；</p> \n <h2><a id=\"Kubernetes_1855\"></a>简述Kubernetes网络策略?</h2> \n <p>​ 答：</p> \n <p>为实现细粒度的容器间网络访问隔离策略，K8s引入Network Policy主要功能是对Pod间的网络通信进行限制和准入控制，设置允许访问或禁止访问的客户端Pod列表。</p> \n <p>Network Policy定义网络策略，配合策略控制器（Policy Controller）进行策略的实现；</p> \n <h2><a id=\"Kubernetes_1865\"></a>简述Kubernetes网络策略原理?</h2> \n <p>​ 答：</p> \n <p>Network Policy的工作原理主要为：policy controller需要实现一个API Listener，监听用户设置的Network Policy定义，并将网络访问规则通过各Node的Agent进行实际设置（Agent则需要通过CNI网络插件实现）；</p> \n <h2><a id=\"Kubernetesflannel_1873\"></a>简述Kubernetes中flannel的作用?</h2> \n <p>​ 答：</p> \n <p>1）它能协助Kubernetes，给每一个Node上的Docker容器都分配互相不冲突的IP地址；</p> \n <p>2）它能在这些IP地址之间建立一个覆盖网络（Overlay Network），通过这个覆盖网络，将数据包原封不动地传递到目标容器内；</p> \n <h2><a id=\"Kubernetes_Calico_1883\"></a>简述Kubernetes Calico网络组件实现原理?</h2> \n <p>​ 答：</p> \n <p>Calico是一个基于BGP的纯三层的网络方案，与OpenStack、Kubernetes、AWS、GCE等云平台都能够良好地集成，Calico在每个计算节点都利用Linux Kernel实现了一个高效的vRouter来负责数据转发。每个vRouter都通过BGP协议把在本节点上运行的容器的路由信息向整个Calico网络广播，并自动设置到达其他节点的路由转发规则；Calico保证所有容器之间的数据流量都是通过IP路由的方式完成互联互通的。</p> \n <p>Calico节点组网时可以直接利用数据中心的网络结构（L2或者L3），不需要额外的NAT、隧道或者Overlay Network，没有额外的封包解包，能够节约CPU运算，提高网络效率；</p> \n <h2><a id=\"Kubernetes_1893\"></a>简述Kubernetes共享存储的作用?</h2> \n <p>​ 答：</p> \n <p>Kubernetes对于有状态的容器应用或者对数据需要持久化的应用，因此需要更加可靠的存储来保存应用产生的重要数据，以便容器应用在重建之后仍然可以使用之前的数据。因此需要使用共享存储；</p> \n <h2><a id=\"Kubernetes_PVPVC_1901\"></a>简述Kubernetes PV和PVC?</h2> \n <p>答：</p> \n <p>PV是对底层网络共享存储的抽象，将共享存储定义为一种“资源”；</p> \n <p>PVC则是用户对存储资源的一个“申请”；</p> \n <h2><a id=\"Kubernetes_PV_1911\"></a>简述Kubernetes PV生命周期内的阶段?</h2> \n <p>答：</p> \n <p>1）Available：可用状态，还未与某个PVC绑定；</p> \n <p>2）Bound：已与某个PVC绑定；</p> \n <p>3）Released：绑定的PVC已经删除，资源已释放，但没有被集群回收；</p> \n <p>4）Failed：自动资源回收失败；</p> \n <h2><a id=\"Kubernetes_CSI_1923\"></a>简述Kubernetes CSI模型?</h2> \n <p>答：</p> \n <p>CSI是Kubernetes推出与容器对接的存储接口标准，存储提供方只需要基于标准接口进行存储插件的实现，就能使用Kubernetes的原生存储机制为容器提供存储服务，CSI使得存储提供方的代码能和Kubernetes代码彻底解耦，部署也与Kubernetes核心组件分离；</p> \n <p>CSI包括CSI Controller：的主要功能是提供存储服务视角对存储资源和存储卷进行管理和操作；Node的主要功能是对主机（Node）上的Volume进行管理和操作；</p> \n <h2><a id=\"Kubernetes_Worker_1931\"></a>简述Kubernetes Worker节点加入集群的过程?</h2> \n <p>​ 答：在该Node上安装Docker、kubelet和kube-proxy服务； 然后配置kubelet和kubeproxy的启动参数，将Master URL指定为当前Kubernetes集群Master的地址，最后启动这些服务； 通过kubelet默认的自动注册机制，新的Worker将会自动加入现有的Kubernetes集群中； Kubernetes Master在接受了新Worker的注册之后，会自动将其纳入当前集群的调度范围；</p> \n <h2><a id=\"Kubernetes_Pod_1935\"></a>简述Kubernetes Pod如何实现对节点的资源控制?</h2> \n <p>​ 答：</p> \n <p>Kubernetes集群里的节点提供的资源主要是计算资源，计算资源是可计量的能被申请、分配和使用的基础资源。当前Kubernetes集群中的计算资源主要包括CPU、GPU及Memory。</p> \n <p>CPU与Memory是被Pod使用的，因此在配置Pod时可以通过参数CPU Request及Memory Request为其中的每个容器指定所需使用的CPU与Memory量，Kubernetes会根据Request的值去查找有足够资源的Node来调度此Pod；</p> \n <h2><a id=\"Kubernetes_RequestsLimitsPod_1945\"></a>简述Kubernetes Requests和Limits如何影响Pod的调度?</h2> \n <p>​ 答：</p> \n <p>当一个Pod创建成功时，Kubernetes调度器（Scheduler）会为该Pod选择一个节点来执行。对于每种计算资源（CPU和Memory）而言，每个节点都有一个能用于运行Pod的最大容量值。调度器在调度时，首先要确保调度后该节点上所有Pod的CPU和内存的Requests总和，不超过该节点能提供给Pod使用的CPU和Memory的最大容量值；</p> \n <h2><a id=\"Kubernetes_Metric_Service_1953\"></a>简述Kubernetes Metric Service?</h2> \n <p>答：在Kubernetes从1.10版本后采用Metrics Server作为默认的性能数据采集和监控，主要用于提供核心指标（Core Metrics），包括Node、Pod的CPU和内存使用指标。</p> \n <p>对其他自定义指标（Custom Metrics）的监控则由Prometheus等组件来完成；</p> \n <h2><a id=\"KubernetesEFK_1963\"></a>简述Kubernetes中，如何使用EFK实现日志的统一管理？</h2> \n <p>答：</p> \n <p>在Kubernetes集群环境中，通常一个完整的应用或服务涉及组件过多，建议对日志系统进行集中化管理，EFK是 Elasticsearch、Fluentd 和 Kibana 的组合，</p> \n <p>Elasticsearch：是一个搜索引擎，负责存储日志并提供查询接口；</p> \n <p>Fluentd：负责从 Kubernetes 搜集日志，每个node节点上面的fluentd监控并收集该节点上面的系统日志，并将处理过后的日志信息发送给Elasticsearch；</p> \n <p>Kibana：提供了一个 Web GUI，用户可以浏览和搜索存储在 Elasticsearch 中的日志；</p> \n <h2><a id=\"Kubernetes_1979\"></a>简述Kubernetes如何进行优雅的节点关机维护?</h2> \n <p>​ 答：由于Kubernetes节点运行大量Pod，因此在进行关机维护之前，建议先使用kubectl drain将该节点的Pod进行驱逐，然后进行关机维护；</p> \n <h2><a id=\"Kubernetes_1985\"></a>简述Kubernetes集群联邦?</h2> \n <p>​ 答：Kubernetes集群联邦可以将多个Kubernetes集群作为一个集群进行管理。因此，可以在一个数据中心/云中创建多个Kubernetes集群，并使用集群联邦在一个地方控制/管理所有集群；</p> \n <h2><a id=\"Helm_1991\"></a>简述Helm及其优势?</h2> \n <p>​ 答：Helm 是 Kubernetes 的软件包管理工具，Helm能够将一组K8S资源打包统一管理, 是查找、共享和使用为Kubernetes构建的软件的最佳方式。 Helm中通常每个包称为一个Chart，一个Chart是一个目录，优势：1）统一管理、配置和更新这些分散的 k8s 的应用资源文件；2）分发和复用一套应用模板；3）将应用的一系列资源当做一个软件包管理；4）对于应用发布者而言，可以通过 Helm 打包应用、管理应用依赖关系、管理应用版本并发布应用到软件仓库；5）对于使用者而言，使用 Helm 后不用需要编写复杂的应用部署文件，可以以简单的方式在 Kubernetes 上查找、安装、升级、回滚、卸载应用程序；</p> \n <h2><a id=\"_1997\"></a>标签与标签选择器的作用是什么?</h2> \n <p>​ 答：</p> \n <p>1）标签可以附加在kubernetes任何资源对象之上的键值型数据，常用于标签选择器的匹配度检查，从而完成资源筛选；</p> \n <p>2）标签选择器用于表达标签的查询条件或选择标准，Kubernetes API目前支持两个选择器：基于等值关系（equality-based）的标签选项器以及基于集合关系（set-based）的标签选择器；</p> \n <h2><a id=\"Google_2007\"></a>什么是Google容器引擎?</h2> \n <p>​ 答：Google Container Engine（GKE）是Docker容器和集群的开源管理平台。这个基于 Kubernetes的引擎仅支持在Google的公共云服务中运行的群集；</p> \n <h2><a id=\"image_2017\"></a>image的状态有那些？</h2> \n <p>​ 答：</p> \n <p>1）Running：Pod所需的容器已经被成功调度到某个节点，且已经成功运行；</p> \n <p>2）Pending：APIserver创建了pod资源对象，并且已经存入etcd中，但它尚未被调度完成或者仍然处于仓库中下载镜像的过程；</p> \n <p>3）Unknown：APIserver无法正常获取到pod对象的状态，通常是其无法与所在工作节点的kubelet通信所致；</p> \n <h2><a id=\"Service_2029\"></a>Service这种资源对象的作用是什么?</h2> \n <p>​ 答：</p> \n <p>service就是将多个POD划分到同一个逻辑组中，并统一向外提供服务，POD是通过Label Selector加入到指定的service中。</p> \n <p>Service相当于是一个负载均衡器，用户请求会先到达service，再由service转发到它内部的某个POD上，通过 services.spec.type 字段来指定：</p> \n <p>1）ClusterIP：用于集群内部访问。该类型会为service分配一个IP，集群内部请求先到达service，再由service转发到其内部的某个POD上；</p> \n <p>2）NodePort：用于集群外部访问。该类型会将Service的Port映射到集群的每个Node节点上，然后在集群之外，就能通过Node节点上的映射端口访问到这个Service；</p> \n <p>3）LoadBalancer：用于集群外部访问。该类型是在所有Node节点前又挂了一个负载均衡器，作为集群外部访问的统一入口，外部流量会先到达LoadBalancer，再由它转发到集群的node节点上，通过nodePort再转发给对应的service，最后由service转发到后端Pod中；</p> \n <p>4）ExternalName：创建一个DNS别名（即CNAME）并指向到某个Service Name上，也就是为某个Service Name添加一条CNAME记录，当有请求访问这个CNAME时会自动解析到这个Service Name上；</p> \n <h2><a id=\"_2047\"></a>常用的标签分类有哪些?</h2> \n <p>​ 答：release（版本）：stable（稳定版）、canary（金丝雀版本）、beta（测试版本）、environment（环境变量）：dev（开发）、qa（测试）、production（生产）、application（应用）：ui、as（application software应用软件）、pc、sc、tier（架构层级）：frontend（前端）、backend（后端）、cache（缓存）、partition（分区）：customerA（客户A）、customerB（客户B）、track（品控级别）：daily（每天）、weekly（每周）；</p> \n <h2><a id=\"Job_2053\"></a>说说你对Job这种资源对象的了解?</h2> \n <p>​ 答：</p> \n <p>Job控制一组Pod容器，可以通过Job这种资源对象定义并启动一个批处理任务的Job，其中Job所控制的Pod副本是短暂运行的，可以将其视为一组Docker容器，每个Docker容器都仅仅运行一次，当Job控制的所有Pod的副本都运行结束时，对应的Job也就结来。</p> \n <p>Job生成的副本是不能自动重启的，对应的Pod副本的RestartPolicy都被设置为Never。</p> \n <p>Job所控制的Pod副本的工作模式能够多实例并行计算。</p> \n <h2><a id=\"k8s_2065\"></a>k8s是怎么进行服务注册的?</h2> \n <p>​ 答：</p> \n <p>1）Service创建的时候会向 API Server 用 POST 方式提交一个新的 Service 定义，这个请求需要经过认证、鉴权以及其它的准入策略检查过程之后才会放行；</p> \n <p>2）CoreDns 会为Service创建一个dns记录，Service 得到一个 ClusterIP（虚拟 IP 地址），并保存到集群数据仓库；</p> \n <p>3）在集群范围内传播 Service 配置；</p> \n <h2><a id=\"KubernetesDocker_Swarm_2077\"></a>Kubernetes与Docker Swarm的区别如何?</h2> \n <p>​ 答：</p> \n <p>1）安装和部署：k8s安装很复杂;但是一旦安装完毕，集群就非常强大，Docker Swarm安装非常简单;但是集群不是很强大;2)图形用户界面：k8s有，Docker Swarm无；</p> \n <p>3）可伸缩性：k8s支持，Docker Swarm比k8s快5倍；</p> \n <p>4）自动伸缩：k8s有，Docker Swarm无；</p> \n <p>5）负载均衡：k8s在不同的Pods中的不同容器之间平衡负载流量，需要手动干预，Docker Swarm可以自动平衡集群中容器之间的流量；</p> \n <p>6）滚动更新回滚：k8s支持，Docker Swarm可以部署滚动更新，但不能自动回滚；</p> \n <p>7）数据量：k8s可以共享存储卷。只能与其他集装箱在同一Pod，Docker Swarm可以与任何其他容器共享存储卷；</p> \n <p>8）日志记录和监控：k8s内置的日志和监控工具，Docker Swarm要用第三方工具进行日志记录和监控；</p> \n <h2><a id=\"Container_Orchestration_2097\"></a>什么是Container Orchestration?</h2> \n <p>答：</p> \n <p>1）资源编排 - 负责资源的分配，如限制 namespace 的可用资源，scheduler 针对资源的不同调度策略；</p> \n <p>2）工作负载编排 - 负责在资源之间共享工作负载，如 Kubernetes 通过不同的 controller 将 Pod 调度到合适的 node 上，并且负责管理它们的生命周期；</p> \n <p>3）服务编排 - 负责服务发现和高可用等，如 Kubernetes 中可用通过 Service 来对内暴露服务，通过 Ingress 来对外暴露服务；容器编排常用的控制器有：Deployment 经常被作为无状态实例控制器使用; StatefulSet 是一个有状态实例控制器; DaemonSet 可以指定在选定的 Node 上跑，每个 Node 上会跑一个副本，它有一个特点是它的 Pod 的调度不经过调度器，在 Pod 创建的时候就直接绑定 NodeName；最后一个是定时任务，它是一个上级控制器，和 Deployment 有些类似，当一个定时任务触发的时候，它会去创建一个 Job ，具体的任务实际上是由 Job 来负责执行的；</p> \n <h2><a id=\"Heapster_2111\"></a>什么是Heapster?</h2> \n <p>​ 答：</p> \n <p>Heapster 是 K8s 原生的集群监控方案。</p> \n <p>Heapster 以 Pod 的形式运行，它会自动发现集群节点、从节点上的 Kubelet 获取监控数据。Kubelet 则是从节点上的 cAdvisor 收集数据；</p> \n <h2><a id=\"k8s_Architecture_2121\"></a>k8s Architecture的不同组件有哪些?</h2> \n <p>​ 答：</p> \n <p>主要有两个组件 – 主节点和工作节点。</p> \n <p>主节点具有kube-controller-manager，kube-apiserver，kube-scheduler等组件。</p> \n <p>而工作节点具有kubelet和kube-proxy等组件；</p> \n <h2><a id=\"Kubernetes_2133\"></a>能否介绍一下Kubernetes中主节点的工作情况?</h2> \n <p>​ 答：</p> \n <p>主节点是集群控制节点，负责集群管理和控制，包含：</p> \n <p>1）apiserver: rest接口，资源增删改查入口；</p> \n <p>2）controller-manager:所有资源对象的控制中心；</p> \n <p>3）scheduler:负责资源调度，例如pod调度；</p> \n <p>4）etcd: 保存资源对象数据；</p> \n <h2><a id=\"kubeapiserverkubescheduler_2149\"></a>kube-apiserver和kube-scheduler的作用是什么？</h2> \n <p>​ 答：</p> \n <p>kube-apiserver: rest接口，增删改查接口，集群内模块通信；</p> \n <p>kube-scheduler: 将待调度的pod按照调度算法绑定到合适的pod，并将绑定信息写入etcd；</p> \n <h2><a id=\"Kubernetes_2157\"></a>你能简要介绍一下Kubernetes控制管理器吗？</h2> \n <p>Kubernetes控制管理器是集群内部的控制中心，负责node,pod,namespace等管理，</p> \n <p>控制管理器负责管理各种控制器，每个控制器通过api server监控资源对象状态，将现有状态修正到期望状态；</p> \n <h2><a id=\"Kubernetes_2167\"></a>Kubernetes有哪些不同类型的服务？</h2> \n <ul>\n  <li>ClusterIP、</li>\n  <li>NodePort、</li>\n  <li>LoadBalancer、</li>\n  <li>ExternalName；</li>\n </ul> \n <h2><a id=\"Kubernetes_2178\"></a>你对Kubernetes的负载均衡器有什么了解？</h2> \n <p>答：</p> \n <p>1）内部负载均衡器: 自动平衡负载并使用所需配置分配容器；</p> \n <p>2）外部负载均衡器: 将流量从外部负载引导至后端容器；</p> \n <h2><a id=\"Kubernetes_2188\"></a>使用Kubernetes时可以采取哪些最佳安全措施?</h2> \n <p>​</p> \n <p>1）确保容器本身安全；</p> \n <p>2）锁定容器的Linux内核；</p> \n <p>3）使用基于角色的访问控制（RBAC）；</p> \n <p>4）保守秘密的辛勤工作；5）保持网络安全；</p> \n <p>​</p> \n <h2><a id=\"_2206\"></a>参考文献：</h2> \n <p>https://blog.csdn.net/qq_21222149/article/details/89201744</p> \n <p>https://blog.csdn.net/warrior_0319/article/details/80073720<br> http://www.sel.zju.edu.cn/?p=840<br> http://alexander.holbreich.org/docker-components-explained/<br> https://www.cnblogs.com/sparkdev/p/9129334.htmls</p> \n <h2><a id=\"_2217\"></a>推荐阅读：</h2> \n <ul>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128670335\">Docker面试题（史上最全 + 持续更新）</a>》</p> </li>\n  <li> <p>《 <a href=\"https://blog.csdn.net/crazymakercircle/article/details/128533821\">场景题：假设10W人突访，你的系统如何做到不 雪崩？</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124790425\">尼恩Java面试宝典</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057567\">Springcloud gateway 底层原理、核心实战 (史上最全)</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/124120506\">Flux、Mono、Reactor 实战（史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125059491\">sentinel （史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125057545\">Nacos (史上最全)</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/123420859\">分库分表 Sharding-JDBC 底层原理、核心实战（史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/114527369\">TCP协议详解 (史上最全)</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126992542\">clickhouse 超底层原理 + 高可用实操 （史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120702536\">nacos高可用（图解+秒懂+史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264803\">队列之王： Disruptor 原理、架构、源码 一文穿透</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128264508\">环形队列、 条带环形队列 Striped-RingBuffer （史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125135726\">一文搞定：SpringBoot、SLF4j、Log4j、Logback、Netty之间混乱关系（史上最全）</a></p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128265067\">单例模式（史上最全）</a></p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/125017316\">红黑树（ 图解 + 秒懂 + 史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/109459593\">分布式事务 （秒懂）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/128123114\">缓存之王：Caffeine 源码、架构、原理（史上最全，10W字 超级长文）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/113751575\">缓存之王：Caffeine 的使用（史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/126579528\">Java Agent 探针、字节码增强 ByteBuddy（史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/120747767\">Docker原理（图解+秒懂+史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/116425814\">Redis分布式锁（图解 - 秒懂 - 史上最全）</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85956246\">Zookeeper 分布式锁 - 图解 - 秒懂</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/85922561\">Zookeeper Curator 事件监听 - 10分钟看懂</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83957259\">Netty 粘包 拆包 | 史上最全解读</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/83758107\">Netty 100万级高并发服务器配置</a>》</p> </li>\n  <li> <p>《<a href=\"https://blog.csdn.net/crazymakercircle/article/details/102557988\">Springcloud 高并发 配置 （一文全懂）</a>》</p> </li>\n </ul> \n</div>', 'https://profile.csdnimg.cn/6/D/B/3_crazymakercircle', 3307);

-- ----------------------------
-- Table structure for saves
-- ----------------------------
DROP TABLE IF EXISTS `saves`;
CREATE TABLE `saves`  (
  `blogid` int(0) NOT NULL,
  `uid` int(0) NOT NULL,
  `createtime` timestamp(0) NULL DEFAULT CURRENT_TIMESTAMP(0) ON UPDATE CURRENT_TIMESTAMP(0),
  `id` int(0) NOT NULL AUTO_INCREMENT,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 73 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of saves
-- ----------------------------
INSERT INTO `saves` VALUES (4, 1, '2023-01-12 17:22:29', 64);
INSERT INTO `saves` VALUES (5, 1, '2023-01-13 15:22:48', 65);
INSERT INTO `saves` VALUES (123123124, 1, '2023-01-14 18:39:06', 66);
INSERT INTO `saves` VALUES (123123125, 1, '2023-01-14 18:39:12', 67);
INSERT INTO `saves` VALUES (123123126, 1, '2023-01-14 18:39:32', 69);
INSERT INTO `saves` VALUES (123, 16, '2023-01-14 20:28:29', 70);
INSERT INTO `saves` VALUES (123123136, 17, '2023-01-22 23:38:59', 73);

-- ----------------------------
-- Table structure for thumbs
-- ----------------------------
DROP TABLE IF EXISTS `thumbs`;
CREATE TABLE `thumbs`  (
  `blogid` int(0) NOT NULL,
  `uid` int(0) NOT NULL,
  `createtime` timestamp(0) NULL DEFAULT CURRENT_TIMESTAMP(0) ON UPDATE CURRENT_TIMESTAMP(0),
  `id` int(0) NOT NULL AUTO_INCREMENT,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 74 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of thumbs
-- ----------------------------
INSERT INTO `thumbs` VALUES (4, 1, '2023-01-12 17:22:18', 63);
INSERT INTO `thumbs` VALUES (5, 1, '2023-01-14 21:13:32', 70);
INSERT INTO `thumbs` VALUES (123123136, 17, '2023-01-22 23:39:01', 74);

-- ----------------------------
-- Table structure for type
-- ----------------------------
DROP TABLE IF EXISTS `type`;
CREATE TABLE `type`  (
  `typeid` bigint(0) NOT NULL AUTO_INCREMENT,
  `typename` varchar(50) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT '',
  PRIMARY KEY (`typeid`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 88 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of type
-- ----------------------------
INSERT INTO `type` VALUES (1, '潮流');
INSERT INTO `type` VALUES (2, '科技');
INSERT INTO `type` VALUES (22, '运动');
INSERT INTO `type` VALUES (23, '美食');
INSERT INTO `type` VALUES (41, '喜剧');

-- ----------------------------
-- Table structure for user
-- ----------------------------
DROP TABLE IF EXISTS `user`;
CREATE TABLE `user`  (
  `uid` bigint(0) NOT NULL AUTO_INCREMENT,
  `username` varchar(30) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `password` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  `avatar` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `is_flag` bigint(0) NOT NULL DEFAULT 0,
  `blogger` bigint(0) NULL DEFAULT 0,
  PRIMARY KEY (`uid`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 18 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of user
-- ----------------------------
INSERT INTO `user` VALUES (1, 'aaa', '123456', 'https://unsplash.it/100/100?image=1036', 2, 1);
INSERT INTO `user` VALUES (2, 'admin', '123456', 'https://unsplash.it/800/450?image=1032', -1, -1);
INSERT INTO `user` VALUES (16, 'bbb', '123456', 'https://unsplash.it/800/450?image=1005', 2, 1);
INSERT INTO `user` VALUES (17, 'ccc', '123456', 'https://unsplash.it/800/450?image=100', 1, 0);
INSERT INTO `user` VALUES (18, 'ddd', '123456', 'https://unsplash.it/800/450?image=1039 ', 0, 0);

-- ----------------------------
-- View structure for blog_views
-- ----------------------------
DROP VIEW IF EXISTS `blog_views`;
CREATE ALGORITHM = UNDEFINED SQL SECURITY DEFINER VIEW `blog_views` AS select `v`.`blog_id` AS `blog_id`,`b`.`title` AS `title`,`v`.`create_time` AS `create_time`,`v`.`ip` AS `ip` from (`views` `v` join `blog` `b`) where (`b`.`blog_id` = `v`.`blog_id`);

-- ----------------------------
-- View structure for comments_statistics
-- ----------------------------
DROP VIEW IF EXISTS `comments_statistics`;
CREATE ALGORITHM = UNDEFINED SQL SECURITY DEFINER VIEW `comments_statistics` AS select `cp`.`blog_id` AS `blog_id`,`b`.`title` AS `title`,`b`.`uid` AS `uid`,ifnull((select count(0) from `comment` `c` where ((date_format(`c`.`create_time`,'%y-%m-%d') = (curdate() - interval 6 day)) and (`c`.`blog_id` = `cp`.`blog_id`))),0) AS `seven_day`,ifnull((select count(0) from `comment` `c` where ((date_format(`c`.`create_time`,'%y-%m-%d') = (curdate() - interval 5 day)) and (`c`.`blog_id` = `cp`.`blog_id`))),0) AS `six_day`,ifnull((select count(0) from `comment` `c` where ((date_format(`c`.`create_time`,'%y-%m-%d') = (curdate() - interval 4 day)) and (`c`.`blog_id` = `cp`.`blog_id`))),0) AS `five_day`,ifnull((select count(0) from `comment` `c` where ((date_format(`c`.`create_time`,'%y-%m-%d') = (curdate() - interval 3 day)) and (`c`.`blog_id` = `cp`.`blog_id`))),0) AS `four_day`,ifnull((select count(0) from `comment` `c` where ((date_format(`c`.`create_time`,'%y-%m-%d') = (curdate() - interval 2 day)) and (`c`.`blog_id` = `cp`.`blog_id`))),0) AS `three_day`,ifnull((select count(0) from `comment` `c` where ((date_format(`c`.`create_time`,'%y-%m-%d') = (curdate() - interval 1 day)) and (`c`.`blog_id` = `cp`.`blog_id`))),0) AS `two_day`,ifnull((select count(0) from `comment` `c` where ((date_format(`c`.`create_time`,'%y-%m-%d') > (curdate() - interval 1 day)) and (`c`.`blog_id` = `cp`.`blog_id`))),0) AS `one_day` from (`comment` `cp` join `blog` `b`) where (`b`.`blog_id` = `cp`.`blog_id`) group by `cp`.`blog_id`;

SET FOREIGN_KEY_CHECKS = 1;
